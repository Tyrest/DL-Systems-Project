{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10-714 Homework 4\n",
    "\n",
    "In this homework, you will leverage all of the components built in the last three homeworks to solve some modern problems with high performing network structures. We will start by adding a few new ops leveraging our new CPU/CUDA backends. Then, you will implement convolution, and a convolutional neural network to train a classifier on the CIFAR-10 image classification dataset. Then, you will implement recurrent and long-short term memory (LSTM) neural networks, and do word-level prediction language modeling on the Penn Treebank dataset. \n",
    "\n",
    "As always, we will start by copying this notebook and getting the starting code.\n",
    "Reminder: __you must save a copy in drive__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/dlsys10714/mugrade.git (\u001b[2mHEAD\u001b[0m)       \u001b[0m\n",
      "\u001b[2K\u001b[1A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/dlsys10714/mugrade.git (\u001b[2mHEAD\u001b[0m)[0m\u001b[1A\n",
      "\u001b[2K\u001b[1A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/dlsys10714/mugrade.git (\u001b[2mHEAD\u001b[0m)[0m\u001b[1A\n",
      "\u001b[2K\u001b[1A    \u001b[32m\u001b[1mUpdated\u001b[0m\u001b[39m https://github.com/dlsys10714/mugrade.git (\u001b[2mac73f725eb2ce0e2c6a38fa540035\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 671ms\u001b[0m\u001b[0m                                          \u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 0.04ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# # Code to set up the assignment\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd /content/drive/MyDrive/\n",
    "# !mkdir -p 10714\n",
    "# %cd /content/drive/MyDrive/10714\n",
    "# !git clone https://github.com/dlsys10714/hw4.git\n",
    "# %cd /content/drive/MyDrive/10714/hw4\n",
    "\n",
    "!uv pip install --upgrade --no-deps git+https://github.com/dlsys10714/mugrade.git\n",
    "!uv pip install pybind11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQUIRED FOR MUGRADE\n",
    "MY_API_KEY = \"\"\n",
    "HW4_NAME = \"hw4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mCMake Error: The current CMakeCache.txt directory /home/tyler/Documents/CMU/DL-Systems-Project/build/CMakeCache.txt is different than the directory /home/tyler/Documents/CMU/Deep-Learning-Systems/hw4_extra/build where CMakeCache.txt was created. This may result in binaries being created in the wrong place. If you are not sure, reedit the CMakeCache.txt\u001b[0m\n",
      "\u001b[0mCMake Error: The source \"/home/tyler/Documents/CMU/DL-Systems-Project/CMakeLists.txt\" does not match the source \"/home/tyler/Documents/CMU/Deep-Learning-Systems/hw4_extra/CMakeLists.txt\" used to generate cache.  Re-run cmake with a different source directory.\u001b[0m\n",
      "make: *** [Makefile:8: lib] Error 1\n"
     ]
    }
   ],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONPATH=./python\n",
      "env: NEEDLE_BACKEND=nd\n"
     ]
    }
   ],
   "source": [
    "%set_env PYTHONPATH ./python\n",
    "%set_env NEEDLE_BACKEND nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the datasets you will be using for this assignment\n",
    "\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "!mkdir -p './data/ptb'\n",
    "# Download Penn Treebank dataset\n",
    "ptb_data = \"https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.\"\n",
    "for f in ['train.txt', 'test.txt', 'valid.txt']:\n",
    "    if not os.path.exists(os.path.join('./data/ptb', f)):\n",
    "        urllib.request.urlretrieve(ptb_data + f, os.path.join('./data/ptb', f))\n",
    "\n",
    "# Download CIFAR-10 dataset\n",
    "if not os.path.isdir(\"./data/cifar-10-batches-py\"):\n",
    "    urllib.request.urlretrieve(\"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\", \"./data/cifar-10-python.tar.gz\")\n",
    "    !tar -xvzf './data/cifar-10-python.tar.gz' -C './data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To finish setting up the assignment, go ahead and fill in all the code in `python/needle/autograd.py` using your solution code from the previous homework. Also copy the solutions in `src/ndarray_backend_cpu.cc` and `src/ndarray_backend_cuda.cu` from homework 3.\n",
    "\n",
    "**Note**: Be careful not to accidentally delete or modify any new imports and function declarations when copying over code from previous assignments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: ND Backend [10 pts]\n",
    "\n",
    "Recall that in homework 2, the `array_api` was imported as `numpy`. In this part, the goal is to write the necessary operations with `array_api` imported from the needle backend `NDArray` in `python/needle/backend_ndarray/ndarray.py`. Make sure to copy the solutions for `reshape`, `permute`, `broadcast_to` and `__getitem__` from homework 3.\n",
    "\n",
    "Fill in the following classes in `python/needle/ops/ops_logarithmic.py` and `python/needle/ops/ops_mathematic.py`:\n",
    "\n",
    "- `PowerScalar`\n",
    "- `EWiseDiv`\n",
    "- `DivScalar`\n",
    "- `Transpose`\n",
    "- `Reshape`\n",
    "- `BroadcastTo`\n",
    "- `Summation`\n",
    "- `MatMul`\n",
    "- `Negate`\n",
    "- `Log`\n",
    "- `Exp`\n",
    "- `ReLU`\n",
    "- `LogSumExp`\n",
    "- `Tanh` (new)\n",
    "- `Stack` (new)\n",
    "- `Split` (new)\n",
    "\n",
    "Note that for most of these, you already wrote the solutions in the previous homework and you should not change most part of your previous solution, if issues arise, please check if the `array_api` function used is supported in the needle backend. \n",
    "\n",
    "The `Tanh`, `Stack`, and `Split` operators are newly added. `Stack` concatenates same-sized tensors along a new axis, and `Split` undoes this operation. The gradients of the two operations can be written in terms of each other. We do not directly test `Split`, and only test the backward pass of `Stack` (for which we assume you used `Split`).\n",
    "\n",
    "**Note:** You may want to make your Summation op support sums over multiple axes; you will likely need it for the backward pass of the BroadcastTo op if yours supports broadcasting over multiple axes at a time. However, this is more about ease of use than necessity, and we leave this decision up to you (there are no corresponding tests).\n",
    "\n",
    "**Note:** Depending on your implementations, you may want to ensure that you call `.compact()` before reshaping arrays. (If this is necessary, you will run into corresponding error messages later in the assignment.)\n",
    "\n",
    "**Note**: Be careful not to accidentally delete or modify any new imports and function declarations when copying over code from previous assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]9;4;3;\u001b\\\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.11, pytest-9.0.1, pluggy-1.6.0 -- /home/tyler/Documents/CMU/DL-Systems-Project/.venv/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/tyler/Documents/CMU/DL-Systems-Project\n",
      "plugins: anyio-4.11.0\n",
      "collected 1803 items / 1685 deselected / 118 selected                          \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_nd_backend.py::test_ewise_fn[cpu-shape0-divide] \u001b]9;4;1;0\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m    [  0%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_ewise_fn[cpu-shape0-subtract] \u001b]9;4;1;0\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m  [  1%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_ewise_fn[cpu-shape1-divide] \u001b]9;4;1;1\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m    [  2%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_ewise_fn[cpu-shape1-subtract] \u001b]9;4;1;2\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m  [  3%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_ewise_fn[cuda-shape0-divide] \u001b]9;4;1;3\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m   [  4%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_ewise_fn[cuda-shape0-subtract] \u001b]9;4;1;4\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_ewise_fn[cuda-shape1-divide] \u001b]9;4;1;5\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m   [  5%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_ewise_fn[cuda-shape1-subtract] \u001b]9;4;1;5\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_scalar_fn[cpu-shape0-divide] \u001b]9;4;1;6\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m   [  7%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_scalar_fn[cpu-shape0-subtract] \u001b]9;4;1;7\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_scalar_fn[cpu-shape1-divide] \u001b]9;4;1;8\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m   [  9%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_scalar_fn[cpu-shape1-subtract] \u001b]9;4;1;9\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_scalar_fn[cuda-shape0-divide] \u001b]9;4;1;10\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m  [ 11%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_scalar_fn[cuda-shape0-subtract] \u001b]9;4;1;11\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_scalar_fn[cuda-shape1-divide] \u001b]9;4;1;11\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m  [ 12%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_scalar_fn[cuda-shape1-subtract] \u001b]9;4;1;12\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cpu-16-16-16] \u001b]9;4;1;13\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m           [ 14%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cpu-8-8-8] \u001b]9;4;1;14\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m              [ 15%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cpu-1-2-3] \u001b]9;4;1;15\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m              [ 16%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cpu-3-4-5] \u001b]9;4;1;16\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m              [ 16%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cpu-5-4-3] \u001b]9;4;1;16\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m              [ 17%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cpu-16-16-32] \u001b]9;4;1;17\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m           [ 18%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cpu-64-64-64] \u001b]9;4;1;18\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m           [ 19%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cpu-72-72-72] \u001b]9;4;1;19\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m           [ 20%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cpu-72-73-74] \u001b]9;4;1;20\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m           [ 21%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cpu-74-73-72] \u001b]9;4;1;21\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m           [ 22%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cpu-128-128-128] \u001b]9;4;1;22\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m        [ 22%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cuda-16-16-16] \u001b]9;4;1;22\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m          [ 23%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cuda-8-8-8] \u001b]9;4;1;23\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m             [ 24%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cuda-1-2-3] \u001b]9;4;1;24\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m             [ 25%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cuda-3-4-5] \u001b]9;4;1;25\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m             [ 26%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cuda-5-4-3] \u001b]9;4;1;26\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m             [ 27%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cuda-16-16-32] \u001b]9;4;1;27\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m          [ 27%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cuda-64-64-64] \u001b]9;4;1;27\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m          [ 28%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cuda-72-72-72] \u001b]9;4;1;28\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m          [ 29%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cuda-72-73-74] \u001b]9;4;1;29\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m          [ 30%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cuda-74-73-72] \u001b]9;4;1;30\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m          [ 31%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_matmul[cuda-128-128-128] \u001b]9;4;1;31\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m       [ 32%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_power[cpu-shape0] \u001b]9;4;1;32\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m              [ 33%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_power[cpu-shape1] \u001b]9;4;1;33\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m              [ 33%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_power[cuda-shape0] \u001b]9;4;1;33\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m             [ 34%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_power[cuda-shape1] \u001b]9;4;1;34\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m             [ 35%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_log[cpu-shape0] \u001b]9;4;1;35\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m                [ 36%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_log[cpu-shape1] \u001b]9;4;1;36\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m                [ 37%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_log[cuda-shape0] \u001b]9;4;1;37\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m               [ 38%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_log[cuda-shape1] \u001b]9;4;1;38\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m               [ 38%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_exp[cpu-shape0] \u001b]9;4;1;38\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m                [ 39%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_exp[cpu-shape1] \u001b]9;4;1;39\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m                [ 40%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_exp[cuda-shape0] \u001b]9;4;1;40\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m               [ 41%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_exp[cuda-shape1] \u001b]9;4;1;41\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m               [ 42%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_relu[cpu-shape0] \u001b]9;4;1;42\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m               [ 43%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_relu[cpu-shape1] \u001b]9;4;1;43\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m               [ 44%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_relu[cuda-shape0] \u001b]9;4;1;44\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m              [ 44%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_relu[cuda-shape1] \u001b]9;4;1;44\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m              [ 45%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_tanh[cpu-shape0] \u001b]9;4;1;45\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m               [ 46%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_tanh[cpu-shape1] \u001b]9;4;1;46\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m               [ 47%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_tanh[cuda-shape0] \u001b]9;4;1;47\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m              [ 48%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_tanh[cuda-shape1] \u001b]9;4;1;48\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m              [ 49%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_tanh_backward[cpu-shape0] \u001b]9;4;1;49\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m      [ 50%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_tanh_backward[cpu-shape1] \u001b]9;4;1;50\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m      [ 50%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_tanh_backward[cuda-shape0] \u001b]9;4;1;50\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m     [ 51%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_tanh_backward[cuda-shape1] \u001b]9;4;1;51\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m     [ 52%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_stack[cpu-shape0-0-1] \u001b]9;4;1;52\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m          [ 53%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_stack[cpu-shape1-0-2] \u001b]9;4;1;53\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m          [ 54%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_stack[cpu-shape2-2-5] \u001b]9;4;1;54\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m          [ 55%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_stack[cuda-shape0-0-1] \u001b]9;4;1;55\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m         [ 55%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_stack[cuda-shape1-0-2] \u001b]9;4;1;55\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m         [ 56%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_stack[cuda-shape2-2-5] \u001b]9;4;1;56\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m         [ 57%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_stack_backward[cpu-shape0-0-1] \u001b]9;4;1;57\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_stack_backward[cpu-shape1-0-2] \u001b]9;4;1;58\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_stack_backward[cpu-shape2-2-5] \u001b]9;4;1;59\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_stack_backward[cuda-shape0-0-1] \u001b]9;4;1;60\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_stack_backward[cuda-shape1-0-2] \u001b]9;4;1;61\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_stack_backward[cuda-shape2-2-5] \u001b]9;4;1;61\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_summation[cpu-shape0-None] \u001b]9;4;1;62\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m     [ 63%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_summation[cpu-shape1-0] \u001b]9;4;1;63\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m        [ 64%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_summation[cpu-shape2-1] \u001b]9;4;1;64\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m        [ 65%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_summation[cpu-shape3-2] \u001b]9;4;1;65\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m        [ 66%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_summation[cuda-shape0-None] \u001b]9;4;1;66\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m    [ 66%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_summation[cuda-shape1-0] \u001b]9;4;1;66\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m       [ 67%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_summation[cuda-shape2-1] \u001b]9;4;1;67\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m       [ 68%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_summation[cuda-shape3-2] \u001b]9;4;1;68\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m       [ 69%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_summation_backward[cpu-shape0-None] \u001b]9;4;1;69\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_summation_backward[cpu-shape1-0] \u001b]9;4;1;70\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_summation_backward[cpu-shape2-1] \u001b]9;4;1;71\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_summation_backward[cpu-shape3-2] \u001b]9;4;1;72\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_summation_backward[cuda-shape0-None] \u001b]9;4;1;72\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_summation_backward[cuda-shape1-0] \u001b]9;4;1;73\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_summation_backward[cuda-shape2-1] \u001b]9;4;1;74\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_summation_backward[cuda-shape3-2] \u001b]9;4;1;75\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_broadcast_to[cpu-shape0-shape_to0] \u001b]9;4;1;76\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_broadcast_to[cpu-shape1-shape_to1] \u001b]9;4;1;77\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_broadcast_to[cuda-shape0-shape_to0] \u001b]9;4;1;77\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_broadcast_to[cuda-shape1-shape_to1] \u001b]9;4;1;78\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_reshape[cpu-shape0-shape_to0] \u001b]9;4;1;79\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m  [ 80%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_reshape[cpu-shape1-shape_to1] \u001b]9;4;1;80\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m  [ 81%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_reshape[cuda-shape0-shape_to0] \u001b]9;4;1;81\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_reshape[cuda-shape1-shape_to1] \u001b]9;4;1;82\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_transpose[cpu-axes0-shape0] \u001b]9;4;1;83\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m    [ 83%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_transpose[cpu-axes0-shape1] \u001b]9;4;1;83\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m    [ 84%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_transpose[cpu-axes1-shape0] \u001b]9;4;1;84\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m    [ 85%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_transpose[cpu-axes1-shape1] \u001b]9;4;1;85\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m    [ 86%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_transpose[cpu-None-shape0] \u001b]9;4;1;86\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m     [ 87%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_transpose[cpu-None-shape1] \u001b]9;4;1;87\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m     [ 88%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_transpose[cuda-axes0-shape0] \u001b]9;4;1;88\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m   [ 88%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_transpose[cuda-axes0-shape1] \u001b]9;4;1;88\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m   [ 89%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_transpose[cuda-axes1-shape0] \u001b]9;4;1;89\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m   [ 90%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_transpose[cuda-axes1-shape1] \u001b]9;4;1;90\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m   [ 91%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_transpose[cuda-None-shape0] \u001b]9;4;1;91\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m    [ 92%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_transpose[cuda-None-shape1] \u001b]9;4;1;92\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m    [ 93%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_logsumexp[cpu-shape0-None] \u001b]9;4;1;93\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m     [ 94%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_logsumexp[cpu-shape1-0] \u001b]9;4;1;94\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m        [ 94%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_logsumexp[cpu-shape2-1] \u001b]9;4;1;94\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m        [ 95%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_logsumexp[cpu-shape3-2] \u001b]9;4;1;95\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m        [ 96%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_logsumexp[cuda-shape0-None] \u001b]9;4;1;96\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m    [ 97%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_logsumexp[cuda-shape1-0] \u001b]9;4;1;97\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m       [ 98%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_logsumexp[cuda-shape2-1] \u001b]9;4;1;98\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m       [ 99%]\u001b[0m\n",
      "tests/hw4/test_nd_backend.py::test_logsumexp[cuda-shape3-2] \u001b]9;4;1;99\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m       [100%]\u001b[0m\u001b]9;4;0;\u001b\\\n",
      "\n",
      "\u001b[32m===================== \u001b[32m\u001b[1m118 passed\u001b[0m, \u001b[33m1685 deselected\u001b[0m\u001b[32m in 1.13s\u001b[0m\u001b[32m =====================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"nd_backend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b]9;4;3;\u001b\\\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.11, pytest-9.0.1, pluggy-1.6.0\n",
      "rootdir: /home/tyler/Documents/CMU/DL-Systems-Project\n",
      "plugins: anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mUsing needle backend\n",
      "collected 10 items / 9 deselected / 1 selected                                 \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_nd_backend.py \u001b]9;4;2;0\u001b\\\u001b[31mF\u001b[0m\u001b]9;4;0;\u001b\\\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m____________________________ submit_new_nd_backend _____________________________\u001b[0m\n",
      "\n",
      "pyfuncitem = <Function submit_new_nd_backend>\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.hookimpl(hookwrapper=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mpytest_pyfunc_call\u001b[39;49;00m(pyfuncitem):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m## prior to test, initialize submission\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mglobal\u001b[39;49;00m _values, _submission_id, _errors\u001b[90m\u001b[39;49;00m\n",
      "        _values = []\u001b[90m\u001b[39;49;00m\n",
      "        _errors = \u001b[94m0\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        func_name = pyfuncitem.name[\u001b[94m7\u001b[39;49;00m:]\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mMUGRADE_OP\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] == \u001b[33m\"\u001b[39;49;00m\u001b[33msubmit\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      ">           _submission_id = start_submission(func_name)\u001b[90m\u001b[39;49;00m\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31m.venv/lib/python3.12/site-packages/mugrade/mugrade.py\u001b[0m:105: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "func_name = 'new_nd_backend'\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mstart_submission\u001b[39;49;00m(func_name):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\" Begin a submisssion to the mugrade server \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        response = requests.post(_server_url + \u001b[33m\"\u001b[39;49;00m\u001b[33msubmit\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                                 params = {\u001b[33m\"\u001b[39;49;00m\u001b[33muser_key\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mMUGRADE_KEY\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
      "                                           \u001b[33m\"\u001b[39;49;00m\u001b[33massignment\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mMUGRADE_HW\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
      "                                           \u001b[33m\"\u001b[39;49;00m\u001b[33mproblem\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: func_name},\u001b[90m\u001b[39;49;00m\n",
      "                                 verify=\u001b[94mFalse\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m response.status_code != \u001b[94m200\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      ">           \u001b[94mraise\u001b[39;49;00m \u001b[96mException\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mError : \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mresponse.text\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           Exception: Error : {\"detail\":\"Invalid API key\"}\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m.venv/lib/python3.12/site-packages/mugrade/mugrade.py\u001b[0m:56: Exception\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1msubmit_new_nd_backend\u001b[0m - Exception: Error : {\"detail\":\"Invalid API key\"}\n",
      "\u001b[31m======================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m9 deselected\u001b[0m\u001b[31m in 0.89s\u001b[0m\u001b[31m ========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"$MY_API_KEY\" \"$HW4_NAME\" -k \"new_nd_backend\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: CIFAR-10 dataset [10 points]\n",
    "\n",
    "Next, you will write support for the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) image classification dataset, which consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class. There are 50k training images and 10k test images. \n",
    "\n",
    "Start by implementing the `__init__` function in the `CIFAR10Dataset` class in `python/needle/data/datasets/cifar10_dataset.py`. You can read in the link above how to properly read the CIFAR-10 dataset files you downloaded at the beginning of the homework. Also fill in `__getitem__` and `__len__`. Note that the return shape of the data from `__getitem__` should be in order (3, 32, 32).\n",
    "\n",
    "Copy `python/needle/data/data_transforms.py` and `python/needle/data/data_basic.py` from previous homeworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]9;4;3;\u001b\\\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.11, pytest-9.0.1, pluggy-1.6.0 -- /home/tyler/Documents/CMU/DL-Systems-Project/.venv/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/tyler/Documents/CMU/DL-Systems-Project\n",
      "plugins: anyio-4.11.0\n",
      "collected 1803 items / 1793 deselected / 10 selected                           \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_cifar_ptb_data.py::test_cifar10_dataset[True] \u001b]9;4;1;0\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m      [ 10%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_cifar10_dataset[False] \u001b]9;4;1;10\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m     [ 20%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cpu-True-1] \u001b]9;4;1;20\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cpu-True-15] \u001b]9;4;1;30\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cpu-False-1] \u001b]9;4;1;40\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cpu-False-15] \u001b]9;4;1;50\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cuda-True-1] \u001b]9;4;1;60\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cuda-True-15] \u001b]9;4;1;70\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cuda-False-1] \u001b]9;4;1;80\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cuda-False-15] \u001b]9;4;1;90\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\u001b]9;4;0;\u001b\\\n",
      "\n",
      "\u001b[32m===================== \u001b[32m\u001b[1m10 passed\u001b[0m, \u001b[33m1793 deselected\u001b[0m\u001b[32m in 3.19s\u001b[0m\u001b[32m ======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"test_cifar10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b]9;4;3;\u001b\\\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.11, pytest-9.0.1, pluggy-1.6.0\n",
      "rootdir: /home/tyler/Documents/CMU/DL-Systems-Project\n",
      "plugins: anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mUsing needle backend\n",
      "collected 10 items / 9 deselected / 1 selected                                 \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_cifar_ptb_data.py \u001b]9;4;2;0\u001b\\\u001b[31mF\u001b[0m\u001b]9;4;0;\u001b\\\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m________________________________ submit_cifar10 ________________________________\u001b[0m\n",
      "\n",
      "pyfuncitem = <Function submit_cifar10>\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.hookimpl(hookwrapper=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mpytest_pyfunc_call\u001b[39;49;00m(pyfuncitem):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m## prior to test, initialize submission\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mglobal\u001b[39;49;00m _values, _submission_id, _errors\u001b[90m\u001b[39;49;00m\n",
      "        _values = []\u001b[90m\u001b[39;49;00m\n",
      "        _errors = \u001b[94m0\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        func_name = pyfuncitem.name[\u001b[94m7\u001b[39;49;00m:]\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mMUGRADE_OP\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] == \u001b[33m\"\u001b[39;49;00m\u001b[33msubmit\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      ">           _submission_id = start_submission(func_name)\u001b[90m\u001b[39;49;00m\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31m.venv/lib/python3.12/site-packages/mugrade/mugrade.py\u001b[0m:105: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "func_name = 'cifar10'\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mstart_submission\u001b[39;49;00m(func_name):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\" Begin a submisssion to the mugrade server \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        response = requests.post(_server_url + \u001b[33m\"\u001b[39;49;00m\u001b[33msubmit\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                                 params = {\u001b[33m\"\u001b[39;49;00m\u001b[33muser_key\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mMUGRADE_KEY\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
      "                                           \u001b[33m\"\u001b[39;49;00m\u001b[33massignment\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mMUGRADE_HW\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
      "                                           \u001b[33m\"\u001b[39;49;00m\u001b[33mproblem\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: func_name},\u001b[90m\u001b[39;49;00m\n",
      "                                 verify=\u001b[94mFalse\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m response.status_code != \u001b[94m200\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      ">           \u001b[94mraise\u001b[39;49;00m \u001b[96mException\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mError : \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mresponse.text\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           Exception: Error : {\"detail\":\"Invalid API key\"}\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m.venv/lib/python3.12/site-packages/mugrade/mugrade.py\u001b[0m:56: Exception\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_cifar_ptb_data.py::\u001b[1msubmit_cifar10\u001b[0m - Exception: Error : {\"detail\":\"Invalid API key\"}\n",
      "\u001b[31m======================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m9 deselected\u001b[0m\u001b[31m in 0.84s\u001b[0m\u001b[31m ========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"$MY_API_KEY\" \"$HW4_NAME\" -k \"cifar10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 3: Convolutional neural network [40 points]\n",
    "\n",
    "Here's an outline of what you will do in this task.\n",
    "\n",
    "In `python/needle/backend_ndarray/ndarray.py`, implement:\n",
    "- `flip`\n",
    "- `pad`\n",
    "\n",
    "In `python/needle/ops/ops_mathematic.py`, implement (forward and backward):\n",
    "- `Flip`\n",
    "- `Dilate`\n",
    "- `UnDilate`\n",
    "- `Conv`\n",
    "\n",
    "In `python/needle/nn/nn_conv.py`, implement:\n",
    "- `Conv`\n",
    "\n",
    "In `apps/models.py`, fill in the `ResNet9` class.  \n",
    "\n",
    "In `apps/simple_ml.py`, fill in:\n",
    "- `epoch_general_cifar10`,\n",
    "- `train_cifar10`\n",
    "- `evaluate_cifar10`\n",
    "\n",
    "We have provided a `BatchNorm2d` implementation in `python/needle/nn/nn_basic.py` for you as a wrapper around your previous `BatchNorm1d` implementation. \n",
    "\n",
    "**Note**: Remember to copy the solution of `nn_basic.py` from previous homework, make sure to not overwrite the `BatchNorm2d` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding ndarrays\n",
    "\n",
    "Convolution as typically implemented in deep learning libraries cuts down the size of inputs;\n",
    "e.g., a (1, 32, 32, 3) image convolved with a 3x3 filter would give a (1, 30, 30, c) output.\n",
    "A way around this is to pad the input ndarray before performing convolution, e.g., pad with zeros to get a (1, 34, 34, 3) ndarray so that the result is (1, 32, 32, 3). \n",
    "\n",
    "Padding is also required for the backward pass of convolution.\n",
    "\n",
    "You should implement `pad` in `ndarray.py` to closely reflect the behavior of `np.pad`.\n",
    "That is, `pad` should take a tuple of 2-tuples with length equal to the number of dimensions of the array,\n",
    "where each element in the 2-tuple corresponds to \"left padding\" and \"right padding\", respectively.\n",
    "\n",
    "For example, if `A` is a (10, 32, 32, 8) ndarray (think NHWC), then `A.pad( (0, 0), (2, 2), (2, 2), (0, 0) )` would be a (10, 36, 36, 8) ndarray where the \"spatial\" dimension has been padded by two zeros on all sides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]9;4;3;\u001b\\\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.11, pytest-9.0.1, pluggy-1.6.0 -- /home/tyler/Documents/CMU/DL-Systems-Project/.venv/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/tyler/Documents/CMU/DL-Systems-Project\n",
      "plugins: anyio-4.11.0\n",
      "collected 1803 items / 1801 deselected / 2 selected                            \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_conv.py::test_pad_forward[params0-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;0\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_pad_forward[params1-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;50\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\u001b]9;4;0;\u001b\\\n",
      "\n",
      "\u001b[32m====================== \u001b[32m\u001b[1m2 passed\u001b[0m, \u001b[33m1801 deselected\u001b[0m\u001b[32m in 0.85s\u001b[0m\u001b[32m ======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"pad_forward\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flipping ndarrays & FlipOp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ctypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some utility code for a demonstration below which you can probably ignore. It might be instructive to check out the `offset` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads off the underlying data array in order (i.e., offset 0, offset 1, ..., offset n)\n",
    "# i.e., ignoring strides\n",
    "def raw_data(X):\n",
    "    X = np.array(X) # copy, thus compact X\n",
    "    return np.frombuffer(ctypes.string_at(X.ctypes.data, X.nbytes), dtype=X.dtype, count=X.size)\n",
    "\n",
    "# Xold and Xnew should reference the same underlying data\n",
    "def offset(Xold, Xnew):\n",
    "    assert Xold.itemsize == Xnew.itemsize\n",
    "    # compare addresses to the beginning of the arrays\n",
    "    return (Xnew.ctypes.data - Xold.ctypes.data)//Xnew.itemsize\n",
    "\n",
    "def strides(X):\n",
    "    return ', '.join([str(x//X.itemsize) for x in X.strides])\n",
    "\n",
    "def format_array(X, shape):\n",
    "    assert len(shape) == 3, \"I only made this formatting work for ndims = 3\"\n",
    "    def chunks(l, n):\n",
    "        n = max(1, n)\n",
    "        return (l[i:i+n] for i in range(0, len(l), n))\n",
    "    a = [str(x) if x >= 10 else ' ' + str(x) for x in X]\n",
    "    a = ['(' + ' '.join(y) + ')' for y in [x for x in chunks(a, shape[-1])]]\n",
    "    a = ['|' + ' '.join(y) + '|' for y in [x for x in chunks(a, shape[-2])]]\n",
    "    return '  '.join(a)\n",
    "\n",
    "def inspect_array(X, *, is_a_copy_of):\n",
    "    # compacts X, then reads it off in order\n",
    "    print('Data: %s' % format_array(raw_data(X), X.shape))\n",
    "    # compares address of X to copy_of, thus finding X's offset\n",
    "    print('Offset: %s' % offset(is_a_copy_of, X))\n",
    "    print('Strides: %s' % strides(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "In order to implement the backwards pass of 2D convolution, we will (probably) need a function which _flips_\n",
    "axes of ndarrays. We say \"probably\" because you could probably cleverly implement your convolution forward\n",
    "function to avoid this. However, we think it is easiest to think about this if you have the ability to \"flip\" the kernel along its vertical and horizontal dimensions.\n",
    "\n",
    "We will try to build up your intuition for the \"flip\" operation below in order to help you figure out how to implement it in `ndarray.py`. To do that, we explore numpy's `np.flip` function below. One thing to note is that\n",
    "`flip` is typically implemented by using negative strides and changing the _offset_ of the underlying array.\n",
    "\n",
    "For example, flipping an array on _all_ of its axes is equivalent to reversing the array. In this case, you can imagine that we would want all the strides to be negative, and the offset to be the length of the array (to start at the end of the array and \"stride\" backwards).\n",
    "\n",
    "Since we did not explicitly support negative strides in our implementation for the last homework, we will merely call `NDArray.make` with them to make our \"flipped\" array and then immediately call `.compact()`. Other than changing unsigned ints to signed ints in a few places, we suspect your existing `compact` function should not have to change at all to accomodate negative strides. In the .cc and .cu files we distributed, we have already changed the function signatures to reflect this.\n",
    "\n",
    "Alternatively, you could simply implement `flip` in the CPU backend by copying memory, which you _may_ find more intuitive. We suggest following our mini tutorial below to keep your implementation Python-focused, since we believe it is involves approximately the same amount of effort to implement it slightly more naively in C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this array as reference for the other examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: |( 1  2  3  4) ( 5  6  7  8)|  |( 9 10 11 12) (13 14 15 16)|  |(17 18 19 20) (21 22 23 24)|\n",
      "Offset: 0\n",
      "Strides: 8, 4, 1\n"
     ]
    }
   ],
   "source": [
    "A = np.arange(1, 25).reshape(3, 2, 4)\n",
    "inspect_array(A, is_a_copy_of=A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have put brackets around each axis of the array. Notice that for this array, the offset is 0 and the strides are all positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what happens when you flip the array along the last axis below. \n",
    "Note that the `inspect_array` function compacts the array after flipping it so you can see the\n",
    "\"logical\" order of the data, and the offset is calculated by comparing the address of the **non**-compacted\n",
    "flipped array with that of `is_copy_of`, i.e., the array `A` we looked at above.\n",
    "\n",
    "That is, we are looking at how numpy calculates the strides and offset for flipped arrays in order\n",
    "to copy this behavior in our own implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: |( 4  3  2  1) ( 8  7  6  5)|  |(12 11 10  9) (16 15 14 13)|  |(20 19 18 17) (24 23 22 21)|\n",
      "Offset: 3\n",
      "Strides: 8, 4, -1\n"
     ]
    }
   ],
   "source": [
    "inspect_array(np.flip(A, (2,)), is_a_copy_of=A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So flipping the last axis reverses the order of the elements within each 4-dimensional \"cell\", as you can see above. The stride corresponding to the axis we flipped has been negated. And the offset is 3 -- this makes sense, e.g., because we want the new \"first\" element of the array to be 4, which was at index 3 in `A`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: |( 5  6  7  8) ( 1  2  3  4)|  |(13 14 15 16) ( 9 10 11 12)|  |(21 22 23 24) (17 18 19 20)|\n",
      "Offset: 4\n",
      "Strides: 8, -4, 1\n"
     ]
    }
   ],
   "source": [
    "inspect_array(np.flip(A, (1,)), is_a_copy_of=A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again for the middle axis: we negate the middle stride, and the offset is 4, which seems reasonable since we now want the first element to be 5, which was at index 4 in the original array `A`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: |(17 18 19 20) (21 22 23 24)|  |( 9 10 11 12) (13 14 15 16)|  |( 1  2  3  4) ( 5  6  7  8)|\n",
      "Offset: 16\n",
      "Strides: -8, 4, 1\n"
     ]
    }
   ],
   "source": [
    "inspect_array(np.flip(A, (0,)), is_a_copy_of=A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to infer the more general algorithm for computing the offset given the axis to flip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe what happens when we flip _all_ axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: |(24 23 22 21) (20 19 18 17)|  |(16 15 14 13) (12 11 10  9)|  |( 8  7  6  5) ( 4  3  2  1)|\n",
      "Offset: 23\n",
      "Strides: -8, -4, -1\n"
     ]
    }
   ],
   "source": [
    "inspect_array(np.flip(A, (0, 1, 2)), is_a_copy_of=A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier, the offset is then sufficient to point to the last element of the array, and this is just the \"reverse order\" version of `A`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we flip just axes 1 and 0..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: |(21 22 23 24) (17 18 19 20)|  |(13 14 15 16) ( 9 10 11 12)|  |( 5  6  7  8) ( 1  2  3  4)|\n",
      "Offset: 20\n",
      "Strides: -8, -4, 1\n"
     ]
    }
   ],
   "source": [
    "inspect_array(np.flip(A, (0, 1)), is_a_copy_of=A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The offset is 20. Looking back on our previous offset computations, do you notice something?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "\n",
    "With this exploration of numpy's ndarray flipping functionality, which uses negative strides and a custom offset,\n",
    "try to implement `flip` in `ndarray.py`. You also must implement \"flip\" forward and backward functions in `ops_mathematic.py`; note that these should be extremely short.\n",
    "\n",
    "**Important:** You should call NDArray.make with the new strides and offset, and then immediately `.compact()` this array. The resulting array is then copied and has positive strides. We want this (less-than-optimal) behavior because we did not account for negative strides in our previous implementation. _Aside:_ If you want, consider where/if negative strides break your implementation. `__getitem__` definitely doesn't work due to how we processed slices; is there anything else? (_Note_: this isn't graded.)\n",
    "\n",
    "Also, if you want to add a `flip` operator implementation on the CPU/CUDA backends instead, that's also okay.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]9;4;3;\u001b\\\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.11, pytest-9.0.1, pluggy-1.6.0 -- /home/tyler/Documents/CMU/DL-Systems-Project/.venv/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/tyler/Documents/CMU/DL-Systems-Project\n",
      "plugins: anyio-4.11.0\n",
      "collected 1803 items / 1763 deselected / 40 selected                           \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_conv.py::test_flip_forward[params0-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;0\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params0-needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;2\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params1-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;5\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params1-needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;7\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params2-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;10\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params2-needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;12\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params3-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;15\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params3-needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;17\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params4-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;20\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params4-needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;22\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params5-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;25\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params5-needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;27\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params6-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;30\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params6-needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;32\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params7-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;35\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params7-needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;37\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params8-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;40\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params8-needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;42\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params9-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;45\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_forward[params9-needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;47\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params0-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;50\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params0-needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;52\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params1-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;55\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params1-needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;57\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params2-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;60\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params2-needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;62\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params3-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;65\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params3-needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;67\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params4-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;70\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params4-needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;72\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params5-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;75\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params5-needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;77\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params6-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;80\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params6-needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;82\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params7-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;85\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params7-needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;87\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params8-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;90\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params8-needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;92\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params9-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;95\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_flip_backward[params9-needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;97\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\u001b]9;4;0;\u001b\\\n",
      "\n",
      "\u001b[32m===================== \u001b[32m\u001b[1m40 passed\u001b[0m, \u001b[33m1763 deselected\u001b[0m\u001b[32m in 1.27s\u001b[0m\u001b[32m ======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"flip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dilation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dilation operator puts zeros between elements of an ndarray. We will need it for computing the backward pass of convolution when the stride of the convolution is greater than 1. As an example, dilation should do the following to a 2x2 matrix when dilated by 1 on both axes:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 4\n",
    "\\end{bmatrix}\n",
    "\\Longrightarrow\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 2 & 0 \\\\\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "3 & 0 & 4 & 0 \\\\\n",
    "0 & 0 & 0 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "To get some intuition for why we need dilation for the backward pass of strided convolution, consider a  `stride=2`, `padding=\"same\"`, `input_channels=output_channels=8` convolution applied to an input of size (10, 32, 32, 8). The resulting output will be of size (10, 16, 16, 8) due to the stride, and thus `out_grad` will have shape (10, 16, 16, 8). Yet, the gradient of the input needs to, of course, have shape (10, 32, 32, 8) -- so we must need to increase the size of `out_grad` in some way. Consider also that you could implement strided convolution as `Conv(x)[:, ::2, ::2, :]`, i.e., only keeping every other pixel in the spatial dimension.\n",
    "\n",
    "\n",
    "Implement `Dilate` and `UnDilate` in `ops_mathematic.py`. Each operator takes two additional parameters (in attrs): the `dilation` amount and the `axes` to dilate. You must also implement the corresponding op `UnDilate`, whose forward pass will be used to implement the gradient of `Dilate`. (This is so we do not have to implement `GetItem` and `SetItem` ops, which can be highly inefficient to backprop through without additional optimizations.)\n",
    "\n",
    "**Note**: The dilation amount is additive, not multiplicative. In the example above, a dilation of `1` implies adding one row/column of zeros between each element along each dilated axis (and one removed row/column for each undilated axis). A dilation of `0` means no change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]9;4;3;\u001b\\\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.11, pytest-9.0.1, pluggy-1.6.0 -- /home/tyler/Documents/CMU/DL-Systems-Project/.venv/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/tyler/Documents/CMU/DL-Systems-Project\n",
      "plugins: anyio-4.11.0\n",
      "collected 1803 items / 1777 deselected / 26 selected                           \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_conv.py::test_dilate_forward[needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;0\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_forward[needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;3\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params0-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;7\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params0-needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;11\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params1-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;15\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params1-needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;19\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params2-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;23\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params2-needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;26\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params3-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;30\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params3-needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;34\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params4-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;38\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params4-needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;42\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params5-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;46\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params5-needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;50\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params6-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;53\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params6-needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;57\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params7-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;61\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params7-needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;65\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params8-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;69\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params8-needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;73\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params9-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;76\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params9-needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;80\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params10-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;84\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params10-needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;88\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params11-needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;92\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_dilate_backward[params11-needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;96\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\u001b]9;4;0;\u001b\\\n",
      "\n",
      "\u001b[32m===================== \u001b[32m\u001b[1m26 passed\u001b[0m, \u001b[33m1777 deselected\u001b[0m\u001b[32m in 1.21s\u001b[0m\u001b[32m ======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"dilate\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit new ops (flip/dilation) to mugrade [10 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b]9;4;3;\u001b\\\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.11, pytest-9.0.1, pluggy-1.6.0\n",
      "rootdir: /home/tyler/Documents/CMU/DL-Systems-Project\n",
      "plugins: anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mUsing needle backend\n",
      "collected 10 items / 9 deselected / 1 selected                                 \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_conv.py \u001b]9;4;2;0\u001b\\\u001b[31mF\u001b[0m\u001b]9;4;0;\u001b\\\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m________________________________ submit_new_ops ________________________________\u001b[0m\n",
      "\n",
      "pyfuncitem = <Function submit_new_ops>\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.hookimpl(hookwrapper=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mpytest_pyfunc_call\u001b[39;49;00m(pyfuncitem):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m## prior to test, initialize submission\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mglobal\u001b[39;49;00m _values, _submission_id, _errors\u001b[90m\u001b[39;49;00m\n",
      "        _values = []\u001b[90m\u001b[39;49;00m\n",
      "        _errors = \u001b[94m0\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        func_name = pyfuncitem.name[\u001b[94m7\u001b[39;49;00m:]\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mMUGRADE_OP\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] == \u001b[33m\"\u001b[39;49;00m\u001b[33msubmit\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      ">           _submission_id = start_submission(func_name)\u001b[90m\u001b[39;49;00m\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31m.venv/lib/python3.12/site-packages/mugrade/mugrade.py\u001b[0m:105: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "func_name = 'new_ops'\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mstart_submission\u001b[39;49;00m(func_name):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\" Begin a submisssion to the mugrade server \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        response = requests.post(_server_url + \u001b[33m\"\u001b[39;49;00m\u001b[33msubmit\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                                 params = {\u001b[33m\"\u001b[39;49;00m\u001b[33muser_key\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mMUGRADE_KEY\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
      "                                           \u001b[33m\"\u001b[39;49;00m\u001b[33massignment\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mMUGRADE_HW\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
      "                                           \u001b[33m\"\u001b[39;49;00m\u001b[33mproblem\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: func_name},\u001b[90m\u001b[39;49;00m\n",
      "                                 verify=\u001b[94mFalse\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m response.status_code != \u001b[94m200\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      ">           \u001b[94mraise\u001b[39;49;00m \u001b[96mException\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mError : \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mresponse.text\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           Exception: Error : {\"detail\":\"Invalid API key\"}\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m.venv/lib/python3.12/site-packages/mugrade/mugrade.py\u001b[0m:56: Exception\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1msubmit_new_ops\u001b[0m - Exception: Error : {\"detail\":\"Invalid API key\"}\n",
      "\u001b[31m======================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m9 deselected\u001b[0m\u001b[31m in 0.89s\u001b[0m\u001b[31m ========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"$MY_API_KEY\" \"$HW4_NAME\" -k \"new_ops\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution forward\n",
    "\n",
    "Implement the forward pass of 2D multi-channel convolution in `ops_mathematic.py`. You should probably refer to [this notebook](https://github.com/dlsyscourse/public_notebooks/blob/main/convolution_implementation.ipynb) from lecture, which implements 2D multi-channel convolution using im2col in numpy.\n",
    "\n",
    "**Note:** Your convolution op should accept tensors in the NHWC format, as in the example above, and weights in the format (kernel_size, kernel_size, input_channels, output_channels).\n",
    "\n",
    "However, you will need to add two additional features. Your convolution function should accept arguments for `padding` (default 0) and `stride` (default 1). For `padding`, you should simply apply your padding function to the spatial dimensions (i.e., axes 1 and 2). \n",
    "\n",
    "Implementing strided convolution should consist of a relatively small set of changes to your plain convolution implementation.\n",
    "\n",
    "We recommend working your way up through the full feature set: Implement convolution without stride first, ensuring you pass some of the tests below, and then add in support for stride."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]9;4;3;\u001b\\\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.11, pytest-9.0.1, pluggy-1.6.0 -- /home/tyler/Documents/CMU/DL-Systems-Project/.venv/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/tyler/Documents/CMU/DL-Systems-Project\n",
      "plugins: anyio-4.11.0\n",
      "collected 1803 items / 1769 deselected / 34 selected                           \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape0-W_shape0-1-0] \u001b]9;4;1;0\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape1-W_shape1-1-1] \u001b]9;4;1;2\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape2-W_shape2-1-2] \u001b]9;4;1;5\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape3-W_shape3-1-0] \u001b]9;4;1;8\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape4-W_shape4-1-0] \u001b]9;4;1;11\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape5-W_shape5-2-0] \u001b]9;4;1;14\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape6-W_shape6-2-1] \u001b]9;4;1;17\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape7-W_shape7-2-2] \u001b]9;4;1;20\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape8-W_shape8-2-0] \u001b]9;4;1;23\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape9-W_shape9-2-0] \u001b]9;4;1;26\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape10-W_shape10-1-0] \u001b]9;4;1;29\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape11-W_shape11-1-0] \u001b]9;4;1;32\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape12-W_shape12-1-0] \u001b]9;4;1;35\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape13-W_shape13-1-0] \u001b]9;4;1;38\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape14-W_shape14-1-0] \u001b]9;4;1;41\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape15-W_shape15-1-0] \u001b]9;4;1;44\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape16-W_shape16-1-0] \u001b]9;4;1;47\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape0-W_shape0-1-0] \u001b]9;4;1;50\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape1-W_shape1-1-1] \u001b]9;4;1;52\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape2-W_shape2-1-2] \u001b]9;4;1;55\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape3-W_shape3-1-0] \u001b]9;4;1;58\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape4-W_shape4-1-0] \u001b]9;4;1;61\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape5-W_shape5-2-0] \u001b]9;4;1;64\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape6-W_shape6-2-1] \u001b]9;4;1;67\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape7-W_shape7-2-2] \u001b]9;4;1;70\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape8-W_shape8-2-0] \u001b]9;4;1;73\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape9-W_shape9-2-0] \u001b]9;4;1;76\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape10-W_shape10-1-0] \u001b]9;4;1;79\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape11-W_shape11-1-0] \u001b]9;4;1;82\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape12-W_shape12-1-0] \u001b]9;4;1;85\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape13-W_shape13-1-0] \u001b]9;4;1;88\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape14-W_shape14-1-0] \u001b]9;4;1;91\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape15-W_shape15-1-0] \u001b]9;4;1;94\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape16-W_shape16-1-0] \u001b]9;4;1;97\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\u001b]9;4;0;\u001b\\\n",
      "\n",
      "\u001b[32m===================== \u001b[32m\u001b[1m34 passed\u001b[0m, \u001b[33m1769 deselected\u001b[0m\u001b[32m in 1.07s\u001b[0m\u001b[32m ======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"op_conv and forward\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the gradients of 2D multi-channel convolution can be technically quite challenging (especially \"rigorously\"). We will try to provide some useful hints here. Basically, we encourage you to make use of the surprising fact that _whatever makes the dimensions work out is typically right_.\n",
    "\n",
    "Ultimately, the backward pass of convolution can be done in terms of the convolution operator itself, with some clever manipulations using `flip`, `dilate`, and multiple applications of `transpose` to both the arguments and the results.\n",
    "\n",
    "In the last section, we essentially implemented convolution as a matrix product: ignoring the various restride and reshape operations, we basically have something like `X @ W`, where `X` is the input and `W` is the weight. We also have `out_grad`, which is the same shape as `X @ W`. Now, you have already implemented the backward pass of matrix multiplication in a previous assignment, and we can use this knowledge to get some insight into the backward pass of convolution. In particular, referencing your matmul backward implementation, you may notice (heuristically speaking here):\n",
    "\n",
    "`X.grad = out_grad @ W.transpose` \\\n",
    "`W.grad = X.transpose @ out_grad`\n",
    "\n",
    "Surprisingly enough, things work out if we just assume that these are also convolutions (and now assuming that `out_grad`, `W`, and `X` are tensors amenable to 2D multi-channel convolution instead of matrices):\n",
    "\n",
    "`X.grad = conv(out_grad, W)` \\\n",
    "`W.grad = conv(X, out_grad)`\n",
    "\n",
    "In which the \"\" indicates that you need to apply some additional operators to these terms in order to get the dimensions to work out, such as permuting/transposing axes, dilating, changing the `padding=` argument to the convolution function, or permuting/transposing axes of the resulting convolution.\n",
    "\n",
    "As we saw on the [last few slides here](https://dlsyscourse.org/slides/conv_nets.pdf) in class, the transpose of a convolution can be found by simply flipping the kernel. Since we're working in 2D instead of 1D, this means flipping the kernel both vertically and horizontally (thus why we implemented `flip`).\n",
    "\n",
    "Summarizing some hints for both `X.grad` and `W.grad`:\n",
    "\n",
    "`X.grad`\n",
    "- The convolution of `out_grad` and `W`, with some operations applied to those\n",
    "- `W` should be flipped over both the kernel dimensions\n",
    "- If the convolution is strided, increase the size of `out_grad` with a corresponding dilation\n",
    "- Do an example to analyze dimensions: note the shape you want for `X.grad`, and think about how you must permute/transpose the arguments and add padding to the convolution to achieve this shape \n",
    "    - This padding depends on both the kernel size and the `padding` argument to the convolution\n",
    "\n",
    "`W.grad`\n",
    "- The convolution of `X` and `out_grad`, with some operations applied to those\n",
    "- The gradients of `W` must be accumulated over the batches; how can you make the conv operator itself do this accumulation?\n",
    "    - Consider turning batches into channels via transpose/permute\n",
    "- Analyze dimensions: how can you modify `X` and `out_grad` so that the shape of their convolution matches the shape of `W`? You may need to transpose/permute the result.\n",
    "    - Remember to account for the `padding` argument passed to convolution\n",
    "\n",
    "General tips\n",
    "- Deal with strided convolutions last (you should be able to just drop in `dilate` when you've passed most of the tests)\n",
    "- Start with the case where `padding=0`, then consider changing `padding` arguments\n",
    "- You can \"permute\" axes with multiple calls to `transpose`\n",
    "\n",
    "It might also be useful to skip ahead to nn.Conv, pass the forward tests, and then use both the tests below and the nn.Conv backward tests to debug your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]9;4;3;\u001b\\\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.11, pytest-9.0.1, pluggy-1.6.0 -- /home/tyler/Documents/CMU/DL-Systems-Project/.venv/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/tyler/Documents/CMU/DL-Systems-Project\n",
      "plugins: anyio-4.11.0\n",
      "collected 1803 items / 1769 deselected / 34 selected                           \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape0-W_shape0-1-0] \u001b]9;4;2;0\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [  2%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape1-W_shape1-1-1] \u001b]9;4;2;2\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [  5%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape2-W_shape2-1-2] \u001b]9;4;2;5\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [  8%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape3-W_shape3-1-0] \u001b]9;4;2;8\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [ 11%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape4-W_shape4-1-0] \u001b]9;4;2;11\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [ 14%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape5-W_shape5-2-0] \u001b]9;4;2;14\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [ 17%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape6-W_shape6-2-1] \u001b]9;4;2;17\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [ 20%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape7-W_shape7-2-2] \u001b]9;4;2;20\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [ 23%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape8-W_shape8-2-0] \u001b]9;4;2;23\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [ 26%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape9-W_shape9-2-0] \u001b]9;4;2;26\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [ 29%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape10-W_shape10-1-0] \u001b]9;4;2;29\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [ 32%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape11-W_shape11-1-0] \u001b]9;4;2;32\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [ 35%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape12-W_shape12-1-0] \u001b]9;4;2;35\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [ 38%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape13-W_shape13-1-0] \u001b]9;4;2;38\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [ 41%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape14-W_shape14-1-0] \u001b]9;4;2;41\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [ 44%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape15-W_shape15-1-0] \u001b]9;4;2;44\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [ 47%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape16-W_shape16-1-0] \u001b]9;4;2;47\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [ 50%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape0-W_shape0-1-0] \u001b]9;4;2;50\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [ 52%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape1-W_shape1-1-1] \u001b]9;4;2;52\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [ 55%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape2-W_shape2-1-2] \u001b]9;4;2;55\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [ 58%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape3-W_shape3-1-0] \u001b]9;4;2;58\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [ 61%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape4-W_shape4-1-0] \u001b]9;4;2;61\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [ 64%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape5-W_shape5-2-0] \u001b]9;4;2;64\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [ 67%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape6-W_shape6-2-1] \u001b]9;4;2;67\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [ 70%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape7-W_shape7-2-2] \u001b]9;4;2;70\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [ 73%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape8-W_shape8-2-0] \u001b]9;4;2;73\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [ 76%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape9-W_shape9-2-0] \u001b]9;4;2;76\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [ 79%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape10-W_shape10-1-0] \u001b]9;4;2;79\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [ 82%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape11-W_shape11-1-0] \u001b]9;4;2;82\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [ 85%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape12-W_shape12-1-0] \u001b]9;4;2;85\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [ 88%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape13-W_shape13-1-0] \u001b]9;4;2;88\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [ 91%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape14-W_shape14-1-0] \u001b]9;4;2;91\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [ 94%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape15-W_shape15-1-0] \u001b]9;4;2;94\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [ 97%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape16-W_shape16-1-0] \u001b]9;4;2;97\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m [100%]\u001b[0m\u001b]9;4;0;\u001b\\\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape0-W_shape0-1-0] _\u001b[0m\n",
      "\n",
      "Z_shape = (3, 14, 14, 8), W_shape = (3, 3, 8, 16), stride = 1, padding = 0\n",
      "backward = True, device = cpu()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
      "      2.1704152   -0.38803983]\n",
      "   [  2.245844...2.618842     0.71487164]\n",
      "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
      "      0.03223436   2.0512383 ]]]])\n",
      "W_shape    = (3, 3, 8, 16)\n",
      "Wtch       = tensor([[[[  4.2827,   8.1336,  -4.6223,  ...,   2.0798,   2.1704,  -0.3880],\n",
      "          [  2.2458,  -0.6565,  -3.7547,...   0.7149],\n",
      "          [ -4.0937,   3.7292, -10.5518,  ...,   0.3174,   0.0322,   2.0512]]]],\n",
      "       requires_grad=True)\n",
      "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
      "     4.75044203e+00 -7.56786048e...3e+00]\n",
      "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
      "    -8.48226726e-01 -2.29984760e+00]]]])\n",
      "Z_shape    = (3, 14, 14, 8)\n",
      "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
      "            4.7504e+00, -7.5679e-01],\n",
      "          [...[ 1.0991e+01,  2.2317e+00,  4.6206e+00,  ..., -6.2309e-01,\n",
      "           -8.4823e-01, -2.2998e+00]]]], requires_grad=True)\n",
      "_W         = array([[[[  4.282669  ,   8.133604  ,  -4.6223483 , ...,   2.0798197 ,\n",
      "            2.1704152 ,  -0.38803983],\n",
      "        ... , -10.551835  , ...,   0.31741843,\n",
      "            0.03223436,   2.0512383 ]]]],\n",
      "      shape=(3, 3, 8, 16), dtype=float32)\n",
      "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
      "          -4.88638926e+00,  4.75044203e+00, -7.56786...9e+00, ...,\n",
      "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
      "      shape=(3, 14, 14, 8), dtype=float32)\n",
      "backward   = True\n",
      "device     = cpu()\n",
      "err1       = np.float32(0.00073335366)\n",
      "err2       = np.float32(0.0013963837)\n",
      "out        = tensor([[[[-2.1851e+01, -1.8266e+02, -2.9496e+02,  ...,  9.3036e+01,\n",
      "           -1.0480e+02,  1.1030e+02],\n",
      "          [...,  5.7277e+02, -9.0837e+01,  ..., -1.8747e+02,\n",
      "           -1.1281e+02,  2.0660e+02]]]], grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(-6614.2402, grad_fn=<SumBackward0>)\n",
      "padding    = 0\n",
      "stride     = 1\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c5662838c0>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c67590cb60>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c67590cb60>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c67590cb60>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c67590cb60>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[-117.863464 -117.863464 -117.863464 ... -117.863464 -117.863464\n",
      "    -117.863464]\n",
      "   [ -18.305077  -18.305077  -18.305077 ...  -18.305077  -18.305077\n",
      "     -18.305077]\n",
      "   [ -83.70589   -83.70589   -83.70589  ...  -83.70589   -83.70589\n",
      "     -83.70589 ]\n",
      "   ...\n",
      "   [ -94.59245   -94.59245   -94.59245  ...  -94.59245   -94.59245\n",
      "     -94.59245 ]\n",
      "   [ 113.50016   113.50016   113.50016  ...  113.50016   113.50016\n",
      "     113.50016 ]\n",
      "   [-163.46542  -163.46542  -163.46542  ... -163.46542  -163.46542\n",
      "    -163.46542 ]]\n",
      "\n",
      "  [[ -72.387054  -72.387054  -72.387054 ...  -72.387054  -72.387054\n",
      "     -72.387054]\n",
      "   [ -12.95504   -12.95504   -12.95504  ...  -12.95504   -12.95504\n",
      "     -12.95504 ]\n",
      "   [ -60.1023    -60.1023    -60.1023   ...  -60.1023    -60.1023\n",
      "     -60.1023  ]\n",
      "   ...\n",
      "   [-134.91211  -134.91211  -134.91211  ... -134.91211  -134.91211\n",
      "    -134.91211 ]\n",
      "   [  58.04833    58.04833    58.04833  ...   58.04833    58.04833\n",
      "      58.04833 ]\n",
      "   [-149.94443  -149.94443  -149.94443  ... -149.94443  -149.94443\n",
      "    -149.94443 ]]\n",
      "\n",
      "  [[ -31.305983  -31.305983  -31.305983 ...  -31.305983  -31.305983\n",
      "     -31.305983]\n",
      "   [  41.738014   41.738014   41.738014 ...   41.738014   41.738014\n",
      "      41.738014]\n",
      "   [ -41.51856   -41.51856   -41.51856  ...  -41.51856   -41.51856\n",
      "     -41.51856 ]\n",
      "   ...\n",
      "   [ -55.21545   -55.21545   -55.21545  ...  -55.21545   -55.21545\n",
      "     -55.21545 ]\n",
      "   [  26.683502   26.683502   26.683502 ...   26.683502   26.683502\n",
      "      26.683502]\n",
      "   [-130.78413  -130.78413  -130.78413  ... -130.78413  -130.78413\n",
      "    -130.78413 ]]]\n",
      "\n",
      "\n",
      " [[[-120.4241   -120.4241   -120.4241   ... -120.4241   -120.4241\n",
      "    -120.4241  ]\n",
      "   [  28.03527    28.03527    28.03527  ...   28.03527    28.03527\n",
      "      28.03527 ]\n",
      "   [ -61.260155  -61.260155  -61.260155 ...  -61.260155  -61.260155\n",
      "     -61.260155]\n",
      "   ...\n",
      "   [-184.45692  -184.45692  -184.45692  ... -184.45692  -184.45692\n",
      "    -184.45692 ]\n",
      "   [  88.74799    88.74799    88.74799  ...   88.74799    88.74799\n",
      "      88.74799 ]\n",
      "   [ -93.74545   -93.74545   -93.74545  ...  -93.74545   -93.74545\n",
      "     -93.74545 ]]\n",
      "\n",
      "  [[ -64.364494  -64.364494  -64.364494 ...  -64.364494  -64.364494\n",
      "     -64.364494]\n",
      "   [  -7.776188   -7.776188   -7.776188 ...   -7.776188   -7.776188\n",
      "      -7.776188]\n",
      "   [ -34.25772   -34.25772   -34.25772  ...  -34.25772   -34.25772\n",
      "     -34.25772 ]\n",
      "   ...\n",
      "   [-213.2781   -213.2781   -213.2781   ... -213.2781   -213.2781\n",
      "    -213.2781  ]\n",
      "   [  39.10958    39.10958    39.10958  ...   39.10958    39.10958\n",
      "      39.10958 ]\n",
      "   [ -93.828     -93.828     -93.828    ...  -93.828     -93.828\n",
      "     -93.828   ]]\n",
      "\n",
      "  [[ -20.186165  -20.186165  -20.186165 ...  -20.186165  -20.186165\n",
      "     -20.186165]\n",
      "   [  41.759117   41.759117   41.759117 ...   41.759117   41.759117\n",
      "      41.759117]\n",
      "   [ -30.735855  -30.735855  -30.735855 ...  -30.735855  -30.735855\n",
      "     -30.735855]\n",
      "   ...\n",
      "   [-137.9915   -137.9915   -137.9915   ... -137.9915   -137.9915\n",
      "    -137.9915  ]\n",
      "   [ -15.200287  -15.200287  -15.200287 ...  -15.200287  -15.200287\n",
      "     -15.200287]\n",
      "   [ -82.541794  -82.541794  -82.541794 ...  -82.541794  -82.541794\n",
      "     -82.541794]]]\n",
      "\n",
      "\n",
      " [[[-100.66364  -100.66364  -100.66364  ... -100.66364  -100.66364\n",
      "    -100.66364 ]\n",
      "   [  20.235909   20.235909   20.235909 ...   20.235909   20.235909\n",
      "      20.235909]\n",
      "   [ -66.781624  -66.781624  -66.781624 ...  -66.781624  -66.781624\n",
      "     -66.781624]\n",
      "   ...\n",
      "   [-212.27026  -212.27026  -212.27026  ... -212.27026  -212.27026\n",
      "    -212.27026 ]\n",
      "   [  55.76574    55.76574    55.76574  ...   55.76574    55.76574\n",
      "      55.76574 ]\n",
      "   [ -91.51832   -91.51832   -91.51832  ...  -91.51832   -91.51832\n",
      "     -91.51832 ]]\n",
      "\n",
      "  [[ -73.383575  -73.383575  -73.383575 ...  -73.383575  -73.383575\n",
      "     -73.383575]\n",
      "   [  12.9244     12.9244     12.9244   ...   12.9244     12.9244\n",
      "      12.9244  ]\n",
      "   [ -18.37703   -18.37703   -18.37703  ...  -18.37703   -18.37703\n",
      "     -18.37703 ]\n",
      "   ...\n",
      "   [-257.76913  -257.76913  -257.76913  ... -257.76913  -257.76913\n",
      "    -257.76913 ]\n",
      "   [  16.773888   16.773888   16.773888 ...   16.773888   16.773888\n",
      "      16.773888]\n",
      "   [ -82.270966  -82.270966  -82.270966 ...  -82.270966  -82.270966\n",
      "     -82.270966]]\n",
      "\n",
      "  [[ -11.111122  -11.111122  -11.111122 ...  -11.111122  -11.111122\n",
      "     -11.111122]\n",
      "   [  44.496124   44.496124   44.496124 ...   44.496124   44.496124\n",
      "      44.496124]\n",
      "   [ -27.203125  -27.203125  -27.203125 ...  -27.203125  -27.203125\n",
      "     -27.203125]\n",
      "   ...\n",
      "   [-158.30197  -158.30197  -158.30197  ... -158.30197  -158.30197\n",
      "    -158.30197 ]\n",
      "   [ -20.719353  -20.719353  -20.719353 ...  -20.719353  -20.719353\n",
      "     -20.719353]\n",
      "   [ -93.38875   -93.38875   -93.38875  ...  -93.38875   -93.38875\n",
      "     -93.38875 ]]]], W.grad.numpy(): [[[[-117.86352  -117.86352  -117.86352  ... -117.86352  -117.86352\n",
      "    -117.86352 ]\n",
      "   [ -18.30505   -18.30505   -18.30505  ...  -18.30505   -18.30505\n",
      "     -18.30505 ]\n",
      "   [ -83.7058    -83.7058    -83.7058   ...  -83.7058    -83.7058\n",
      "     -83.7058  ]\n",
      "   ...\n",
      "   [ -94.59242   -94.59242   -94.59242  ...  -94.59242   -94.59242\n",
      "     -94.59242 ]\n",
      "   [ 113.50013   113.50013   113.50013  ...  113.50013   113.50013\n",
      "     113.50013 ]\n",
      "   [-163.46544  -163.46544  -163.46544  ... -163.46544  -163.46544\n",
      "    -163.46544 ]]\n",
      "\n",
      "  [[ -72.38704   -72.38704   -72.38704  ...  -72.38704   -72.38704\n",
      "     -72.38704 ]\n",
      "   [ -12.955032  -12.955032  -12.955032 ...  -12.955032  -12.955032\n",
      "     -12.955032]\n",
      "   [ -60.102333  -60.102333  -60.102333 ...  -60.102333  -60.102333\n",
      "     -60.102333]\n",
      "   ...\n",
      "   [-134.91219  -134.91219  -134.91219  ... -134.91219  -134.91219\n",
      "    -134.91219 ]\n",
      "   [  58.048294   58.048294   58.048294 ...   58.048294   58.048294\n",
      "      58.048294]\n",
      "   [-149.9445   -149.9445   -149.9445   ... -149.9445   -149.9445\n",
      "    -149.9445  ]]\n",
      "\n",
      "  [[ -31.30602   -31.30602   -31.30602  ...  -31.30602   -31.30602\n",
      "     -31.30602 ]\n",
      "   [  41.738      41.738      41.738    ...   41.738      41.738\n",
      "      41.738   ]\n",
      "   [ -41.518616  -41.518616  -41.518616 ...  -41.518616  -41.518616\n",
      "     -41.518616]\n",
      "   ...\n",
      "   [ -55.215454  -55.215454  -55.215454 ...  -55.215454  -55.215454\n",
      "     -55.215454]\n",
      "   [  26.683535   26.683535   26.683535 ...   26.683535   26.683535\n",
      "      26.683535]\n",
      "   [-130.7842   -130.7842   -130.7842   ... -130.7842   -130.7842\n",
      "    -130.7842  ]]]\n",
      "\n",
      "\n",
      " [[[-120.42416  -120.42416  -120.42416  ... -120.42416  -120.42416\n",
      "    -120.42416 ]\n",
      "   [  28.035273   28.035273   28.035273 ...   28.035273   28.035273\n",
      "      28.035273]\n",
      "   [ -61.260204  -61.260204  -61.260204 ...  -61.260204  -61.260204\n",
      "     -61.260204]\n",
      "   ...\n",
      "   [-184.457    -184.457    -184.457    ... -184.457    -184.457\n",
      "    -184.457   ]\n",
      "   [  88.747925   88.747925   88.747925 ...   88.747925   88.747925\n",
      "      88.747925]\n",
      "   [ -93.745514  -93.745514  -93.745514 ...  -93.745514  -93.745514\n",
      "     -93.745514]]\n",
      "\n",
      "  [[ -64.364494  -64.364494  -64.364494 ...  -64.364494  -64.364494\n",
      "     -64.364494]\n",
      "   [  -7.776159   -7.776159   -7.776159 ...   -7.776159   -7.776159\n",
      "      -7.776159]\n",
      "   [ -34.25773   -34.25773   -34.25773  ...  -34.25773   -34.25773\n",
      "     -34.25773 ]\n",
      "   ...\n",
      "   [-213.27806  -213.27806  -213.27806  ... -213.27806  -213.27806\n",
      "    -213.27806 ]\n",
      "   [  39.109554   39.109554   39.109554 ...   39.109554   39.109554\n",
      "      39.109554]\n",
      "   [ -93.82804   -93.82804   -93.82804  ...  -93.82804   -93.82804\n",
      "     -93.82804 ]]\n",
      "\n",
      "  [[ -20.186209  -20.186209  -20.186209 ...  -20.186209  -20.186209\n",
      "     -20.186209]\n",
      "   [  41.759132   41.759132   41.759132 ...   41.759132   41.759132\n",
      "      41.759132]\n",
      "   [ -30.73585   -30.73585   -30.73585  ...  -30.73585   -30.73585\n",
      "     -30.73585 ]\n",
      "   ...\n",
      "   [-137.99155  -137.99155  -137.99155  ... -137.99155  -137.99155\n",
      "    -137.99155 ]\n",
      "   [ -15.200264  -15.200264  -15.200264 ...  -15.200264  -15.200264\n",
      "     -15.200264]\n",
      "   [ -82.54181   -82.54181   -82.54181  ...  -82.54181   -82.54181\n",
      "     -82.54181 ]]]\n",
      "\n",
      "\n",
      " [[[-100.663704 -100.663704 -100.663704 ... -100.663704 -100.663704\n",
      "    -100.663704]\n",
      "   [  20.235903   20.235903   20.235903 ...   20.235903   20.235903\n",
      "      20.235903]\n",
      "   [ -66.78166   -66.78166   -66.78166  ...  -66.78166   -66.78166\n",
      "     -66.78166 ]\n",
      "   ...\n",
      "   [-212.27031  -212.27031  -212.27031  ... -212.27031  -212.27031\n",
      "    -212.27031 ]\n",
      "   [  55.765717   55.765717   55.765717 ...   55.765717   55.765717\n",
      "      55.765717]\n",
      "   [ -91.51837   -91.51837   -91.51837  ...  -91.51837   -91.51837\n",
      "     -91.51837 ]]\n",
      "\n",
      "  [[ -73.383575  -73.383575  -73.383575 ...  -73.383575  -73.383575\n",
      "     -73.383575]\n",
      "   [  12.92442    12.92442    12.92442  ...   12.92442    12.92442\n",
      "      12.92442 ]\n",
      "   [ -18.377075  -18.377075  -18.377075 ...  -18.377075  -18.377075\n",
      "     -18.377075]\n",
      "   ...\n",
      "   [-257.76904  -257.76904  -257.76904  ... -257.76904  -257.76904\n",
      "    -257.76904 ]\n",
      "   [  16.773893   16.773893   16.773893 ...   16.773893   16.773893\n",
      "      16.773893]\n",
      "   [ -82.27101   -82.27101   -82.27101  ...  -82.27101   -82.27101\n",
      "     -82.27101 ]]\n",
      "\n",
      "  [[ -11.111122  -11.111122  -11.111122 ...  -11.111122  -11.111122\n",
      "     -11.111122]\n",
      "   [  44.49609    44.49609    44.49609  ...   44.49609    44.49609\n",
      "      44.49609 ]\n",
      "   [ -27.20313   -27.20313   -27.20313  ...  -27.20313   -27.20313\n",
      "     -27.20313 ]\n",
      "   ...\n",
      "   [-158.3019   -158.3019   -158.3019   ... -158.3019   -158.3019\n",
      "    -158.3019  ]\n",
      "   [ -20.719355  -20.719355  -20.719355 ...  -20.719355  -20.719355\n",
      "     -20.719355]\n",
      "   [ -93.38881   -93.38881   -93.38881  ...  -93.38881   -93.38881\n",
      "     -93.38881 ]]]]\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape1-W_shape1-1-1] _\u001b[0m\n",
      "\n",
      "Z_shape = (3, 14, 14, 8), W_shape = (3, 3, 8, 16), stride = 1, padding = 1\n",
      "backward = True, device = cpu()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
      "      2.1704152   -0.38803983]\n",
      "   [  2.245844...2.618842     0.71487164]\n",
      "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
      "      0.03223436   2.0512383 ]]]])\n",
      "W_shape    = (3, 3, 8, 16)\n",
      "Wtch       = tensor([[[[  4.2827,   8.1336,  -4.6223,  ...,   2.0798,   2.1704,  -0.3880],\n",
      "          [  2.2458,  -0.6565,  -3.7547,...   0.7149],\n",
      "          [ -4.0937,   3.7292, -10.5518,  ...,   0.3174,   0.0322,   2.0512]]]],\n",
      "       requires_grad=True)\n",
      "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
      "     4.75044203e+00 -7.56786048e...3e+00]\n",
      "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
      "    -8.48226726e-01 -2.29984760e+00]]]])\n",
      "Z_shape    = (3, 14, 14, 8)\n",
      "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
      "            4.7504e+00, -7.5679e-01],\n",
      "          [...[ 1.0991e+01,  2.2317e+00,  4.6206e+00,  ..., -6.2309e-01,\n",
      "           -8.4823e-01, -2.2998e+00]]]], requires_grad=True)\n",
      "_W         = array([[[[  4.282669  ,   8.133604  ,  -4.6223483 , ...,   2.0798197 ,\n",
      "            2.1704152 ,  -0.38803983],\n",
      "        ... , -10.551835  , ...,   0.31741843,\n",
      "            0.03223436,   2.0512383 ]]]],\n",
      "      shape=(3, 3, 8, 16), dtype=float32)\n",
      "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
      "          -4.88638926e+00,  4.75044203e+00, -7.56786...9e+00, ...,\n",
      "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
      "      shape=(3, 14, 14, 8), dtype=float32)\n",
      "backward   = True\n",
      "device     = cpu()\n",
      "err1       = np.float32(0.0)\n",
      "err2       = np.float32(0.0018022073)\n",
      "out        = tensor([[[[ 107.2545, -109.1249,   -9.3744,  ...,  118.7832,  127.2525,\n",
      "           -146.6358],\n",
      "          [-296.2552,  ...[-107.9026,   -8.9582,  137.1271,  ..., -355.2759,  128.8402,\n",
      "             28.4111]]]], grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(-12155.8203, grad_fn=<SumBackward0>)\n",
      "padding    = 1\n",
      "stride     = 1\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c566184f80>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c56558a7b0>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c56558a7b0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c56558a7b0>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c56558a7b0>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[ -79.25961    -79.25961    -79.25961   ...  -79.25961\n",
      "     -79.25961    -79.25961  ]\n",
      "   [  46.918587    46.918587    46.918587  ...   46.918587\n",
      "      46.918587    46.918587 ]\n",
      "   [-105.12892   -105.12892   -105.12892   ... -105.12892\n",
      "    -105.12892   -105.12892  ]\n",
      "   ...\n",
      "   [-159.3573    -159.3573    -159.3573    ... -159.3573\n",
      "    -159.3573    -159.3573   ]\n",
      "   [   9.509541     9.509541     9.509541  ...    9.509541\n",
      "       9.509541     9.509541 ]\n",
      "   [-151.12027   -151.12027   -151.12027   ... -151.12027\n",
      "    -151.12027   -151.12027  ]]\n",
      "\n",
      "  [[ -82.72235    -82.72235    -82.72235   ...  -82.72235\n",
      "     -82.72235    -82.72235  ]\n",
      "   [  74.58126     74.58126     74.58126   ...   74.58126\n",
      "      74.58126     74.58126  ]\n",
      "   [-103.02985   -103.02985   -103.02985   ... -103.02985\n",
      "    -103.02985   -103.02985  ]\n",
      "   ...\n",
      "   [-137.12236   -137.12236   -137.12236   ... -137.12236\n",
      "    -137.12236   -137.12236  ]\n",
      "   [ -16.714417   -16.714417   -16.714417  ...  -16.714417\n",
      "     -16.714417   -16.714417 ]\n",
      "   [-171.92789   -171.92789   -171.92789   ... -171.92789\n",
      "    -171.92789   -171.92789  ]]\n",
      "\n",
      "  [[ -56.836605   -56.836605   -56.836605  ...  -56.836605\n",
      "     -56.836605   -56.836605 ]\n",
      "   [  46.877205    46.877205    46.877205  ...   46.877205\n",
      "      46.877205    46.877205 ]\n",
      "   [ -74.973366   -74.973366   -74.973366  ...  -74.973366\n",
      "     -74.973366   -74.973366 ]\n",
      "   ...\n",
      "   [-136.1901    -136.1901    -136.1901    ... -136.1901\n",
      "    -136.1901    -136.1901   ]\n",
      "   [ -14.834892   -14.834892   -14.834892  ...  -14.834892\n",
      "     -14.834892   -14.834892 ]\n",
      "   [-161.43825   -161.43825   -161.43825   ... -161.43825\n",
      "    -161.43825   -161.43825  ]]]\n",
      "\n",
      "\n",
      " [[[ -75.40626    -75.40626    -75.40626   ...  -75.40626\n",
      "     -75.40626    -75.40626  ]\n",
      "   [  36.887493    36.887493    36.887493  ...   36.887493\n",
      "      36.887493    36.887493 ]\n",
      "   [-112.95888   -112.95888   -112.95888   ... -112.95888\n",
      "    -112.95888   -112.95888  ]\n",
      "   ...\n",
      "   [-177.26762   -177.26762   -177.26762   ... -177.26762\n",
      "    -177.26762   -177.26762  ]\n",
      "   [  -3.9332294   -3.9332294   -3.9332294 ...   -3.9332294\n",
      "      -3.9332294   -3.9332294]\n",
      "   [-120.56535   -120.56535   -120.56535   ... -120.56535\n",
      "    -120.56535   -120.56535  ]]\n",
      "\n",
      "  [[ -59.869705   -59.869705   -59.869705  ...  -59.869705\n",
      "     -59.869705   -59.869705 ]\n",
      "   [  60.670822    60.670822    60.670822  ...   60.670822\n",
      "      60.670822    60.670822 ]\n",
      "   [-114.85127   -114.85127   -114.85127   ... -114.85127\n",
      "    -114.85127   -114.85127  ]\n",
      "   ...\n",
      "   [-158.23895   -158.23895   -158.23895   ... -158.23895\n",
      "    -158.23895   -158.23895  ]\n",
      "   [ -33.13743    -33.13743    -33.13743   ...  -33.13743\n",
      "     -33.13743    -33.13743  ]\n",
      "   [-149.52196   -149.52196   -149.52196   ... -149.52196\n",
      "    -149.52196   -149.52196  ]]\n",
      "\n",
      "  [[ -35.41703    -35.41703    -35.41703   ...  -35.41703\n",
      "     -35.41703    -35.41703  ]\n",
      "   [  39.196243    39.196243    39.196243  ...   39.196243\n",
      "      39.196243    39.196243 ]\n",
      "   [ -76.205154   -76.205154   -76.205154  ...  -76.205154\n",
      "     -76.205154   -76.205154 ]\n",
      "   ...\n",
      "   [-157.48651   -157.48651   -157.48651   ... -157.48651\n",
      "    -157.48651   -157.48651  ]\n",
      "   [ -31.508728   -31.508728   -31.508728  ...  -31.508728\n",
      "     -31.508728   -31.508728 ]\n",
      "   [-136.02847   -136.02847   -136.02847   ... -136.02847\n",
      "    -136.02847   -136.02847  ]]]\n",
      "\n",
      "\n",
      " [[[ -97.8186     -97.8186     -97.8186    ...  -97.8186\n",
      "     -97.8186     -97.8186   ]\n",
      "   [  16.265648    16.265648    16.265648  ...   16.265648\n",
      "      16.265648    16.265648 ]\n",
      "   [ -76.15587    -76.15587    -76.15587   ...  -76.15587\n",
      "     -76.15587    -76.15587  ]\n",
      "   ...\n",
      "   [-222.50916   -222.50916   -222.50916   ... -222.50916\n",
      "    -222.50916   -222.50916  ]\n",
      "   [   6.9185753    6.9185753    6.9185753 ...    6.9185753\n",
      "       6.9185753    6.9185753]\n",
      "   [ -68.112045   -68.112045   -68.112045  ...  -68.112045\n",
      "     -68.112045   -68.112045 ]]\n",
      "\n",
      "  [[ -73.99478    -73.99478    -73.99478   ...  -73.99478\n",
      "     -73.99478    -73.99478  ]\n",
      "   [  34.570396    34.570396    34.570396  ...   34.570396\n",
      "      34.570396    34.570396 ]\n",
      "   [ -80.39506    -80.39506    -80.39506   ...  -80.39506\n",
      "     -80.39506    -80.39506  ]\n",
      "   ...\n",
      "   [-215.1049    -215.1049    -215.1049    ... -215.1049\n",
      "    -215.1049    -215.1049   ]\n",
      "   [ -46.699192   -46.699192   -46.699192  ...  -46.699192\n",
      "     -46.699192   -46.699192 ]\n",
      "   [-106.62414   -106.62414   -106.62414   ... -106.62414\n",
      "    -106.62414   -106.62414  ]]\n",
      "\n",
      "  [[ -38.120407   -38.120407   -38.120407  ...  -38.120407\n",
      "     -38.120407   -38.120407 ]\n",
      "   [   6.7269135    6.7269135    6.7269135 ...    6.7269135\n",
      "       6.7269135    6.7269135]\n",
      "   [ -35.737206   -35.737206   -35.737206  ...  -35.737206\n",
      "     -35.737206   -35.737206 ]\n",
      "   ...\n",
      "   [-223.96396   -223.96396   -223.96396   ... -223.96396\n",
      "    -223.96396   -223.96396  ]\n",
      "   [ -28.201767   -28.201767   -28.201767  ...  -28.201767\n",
      "     -28.201767   -28.201767 ]\n",
      "   [ -98.7813     -98.7813     -98.7813    ...  -98.7813\n",
      "     -98.7813     -98.7813   ]]]], W.grad.numpy(): [[[[ -79.25961    -79.25961    -79.25961   ...  -79.25961\n",
      "     -79.25961    -79.25961  ]\n",
      "   [  46.918587    46.918587    46.918587  ...   46.918587\n",
      "      46.918587    46.918587 ]\n",
      "   [-105.12889   -105.12889   -105.12889   ... -105.12889\n",
      "    -105.12889   -105.12889  ]\n",
      "   ...\n",
      "   [-159.35725   -159.35725   -159.35725   ... -159.35725\n",
      "    -159.35725   -159.35725  ]\n",
      "   [   9.509503     9.509503     9.509503  ...    9.509503\n",
      "       9.509503     9.509503 ]\n",
      "   [-151.12033   -151.12033   -151.12033   ... -151.12033\n",
      "    -151.12033   -151.12033  ]]\n",
      "\n",
      "  [[ -82.72238    -82.72238    -82.72238   ...  -82.72238\n",
      "     -82.72238    -82.72238  ]\n",
      "   [  74.58125     74.58125     74.58125   ...   74.58125\n",
      "      74.58125     74.58125  ]\n",
      "   [-103.02983   -103.02983   -103.02983   ... -103.02983\n",
      "    -103.02983   -103.02983  ]\n",
      "   ...\n",
      "   [-137.1224    -137.1224    -137.1224    ... -137.1224\n",
      "    -137.1224    -137.1224   ]\n",
      "   [ -16.714432   -16.714432   -16.714432  ...  -16.714432\n",
      "     -16.714432   -16.714432 ]\n",
      "   [-171.92796   -171.92796   -171.92796   ... -171.92796\n",
      "    -171.92796   -171.92796  ]]\n",
      "\n",
      "  [[ -56.836594   -56.836594   -56.836594  ...  -56.836594\n",
      "     -56.836594   -56.836594 ]\n",
      "   [  46.877205    46.877205    46.877205  ...   46.877205\n",
      "      46.877205    46.877205 ]\n",
      "   [ -74.973404   -74.973404   -74.973404  ...  -74.973404\n",
      "     -74.973404   -74.973404 ]\n",
      "   ...\n",
      "   [-136.1901    -136.1901    -136.1901    ... -136.1901\n",
      "    -136.1901    -136.1901   ]\n",
      "   [ -14.834877   -14.834877   -14.834877  ...  -14.834877\n",
      "     -14.834877   -14.834877 ]\n",
      "   [-161.43837   -161.43837   -161.43837   ... -161.43837\n",
      "    -161.43837   -161.43837  ]]]\n",
      "\n",
      "\n",
      " [[[ -75.406235   -75.406235   -75.406235  ...  -75.406235\n",
      "     -75.406235   -75.406235 ]\n",
      "   [  36.88748     36.88748     36.88748   ...   36.88748\n",
      "      36.88748     36.88748  ]\n",
      "   [-112.95888   -112.95888   -112.95888   ... -112.95888\n",
      "    -112.95888   -112.95888  ]\n",
      "   ...\n",
      "   [-177.26758   -177.26758   -177.26758   ... -177.26758\n",
      "    -177.26758   -177.26758  ]\n",
      "   [  -3.9332623   -3.9332623   -3.9332623 ...   -3.9332623\n",
      "      -3.9332623   -3.9332623]\n",
      "   [-120.5654    -120.5654    -120.5654    ... -120.5654\n",
      "    -120.5654    -120.5654   ]]\n",
      "\n",
      "  [[ -59.869713   -59.869713   -59.869713  ...  -59.869713\n",
      "     -59.869713   -59.869713 ]\n",
      "   [  60.67083     60.67083     60.67083   ...   60.67083\n",
      "      60.67083     60.67083  ]\n",
      "   [-114.85128   -114.85128   -114.85128   ... -114.85128\n",
      "    -114.85128   -114.85128  ]\n",
      "   ...\n",
      "   [-158.23898   -158.23898   -158.23898   ... -158.23898\n",
      "    -158.23898   -158.23898  ]\n",
      "   [ -33.137444   -33.137444   -33.137444  ...  -33.137444\n",
      "     -33.137444   -33.137444 ]\n",
      "   [-149.52202   -149.52202   -149.52202   ... -149.52202\n",
      "    -149.52202   -149.52202  ]]\n",
      "\n",
      "  [[ -35.417015   -35.417015   -35.417015  ...  -35.417015\n",
      "     -35.417015   -35.417015 ]\n",
      "   [  39.19624     39.19624     39.19624   ...   39.19624\n",
      "      39.19624     39.19624  ]\n",
      "   [ -76.20519    -76.20519    -76.20519   ...  -76.20519\n",
      "     -76.20519    -76.20519  ]\n",
      "   ...\n",
      "   [-157.4865    -157.4865    -157.4865    ... -157.4865\n",
      "    -157.4865    -157.4865   ]\n",
      "   [ -31.50871    -31.50871    -31.50871   ...  -31.50871\n",
      "     -31.50871    -31.50871  ]\n",
      "   [-136.0286    -136.0286    -136.0286    ... -136.0286\n",
      "    -136.0286    -136.0286   ]]]\n",
      "\n",
      "\n",
      " [[[ -97.81868    -97.81868    -97.81868   ...  -97.81868\n",
      "     -97.81868    -97.81868  ]\n",
      "   [  16.26568     16.26568     16.26568   ...   16.26568\n",
      "      16.26568     16.26568  ]\n",
      "   [ -76.155914   -76.155914   -76.155914  ...  -76.155914\n",
      "     -76.155914   -76.155914 ]\n",
      "   ...\n",
      "   [-222.50916   -222.50916   -222.50916   ... -222.50916\n",
      "    -222.50916   -222.50916  ]\n",
      "   [   6.9185386    6.9185386    6.9185386 ...    6.9185386\n",
      "       6.9185386    6.9185386]\n",
      "   [ -68.11211    -68.11211    -68.11211   ...  -68.11211\n",
      "     -68.11211    -68.11211  ]]\n",
      "\n",
      "  [[ -73.99485    -73.99485    -73.99485   ...  -73.99485\n",
      "     -73.99485    -73.99485  ]\n",
      "   [  34.57039     34.57039     34.57039   ...   34.57039\n",
      "      34.57039     34.57039  ]\n",
      "   [ -80.3951     -80.3951     -80.3951    ...  -80.3951\n",
      "     -80.3951     -80.3951   ]\n",
      "   ...\n",
      "   [-215.10489   -215.10489   -215.10489   ... -215.10489\n",
      "    -215.10489   -215.10489  ]\n",
      "   [ -46.69917    -46.69917    -46.69917   ...  -46.69917\n",
      "     -46.69917    -46.69917  ]\n",
      "   [-106.62421   -106.62421   -106.62421   ... -106.62421\n",
      "    -106.62421   -106.62421  ]]\n",
      "\n",
      "  [[ -38.120415   -38.120415   -38.120415  ...  -38.120415\n",
      "     -38.120415   -38.120415 ]\n",
      "   [   6.726944     6.726944     6.726944  ...    6.726944\n",
      "       6.726944     6.726944 ]\n",
      "   [ -35.73723    -35.73723    -35.73723   ...  -35.73723\n",
      "     -35.73723    -35.73723  ]\n",
      "   ...\n",
      "   [-223.96388   -223.96388   -223.96388   ... -223.96388\n",
      "    -223.96388   -223.96388  ]\n",
      "   [ -28.201765   -28.201765   -28.201765  ...  -28.201765\n",
      "     -28.201765   -28.201765 ]\n",
      "   [ -98.78143    -98.78143    -98.78143   ...  -98.78143\n",
      "     -98.78143    -98.78143  ]]]]\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape2-W_shape2-1-2] _\u001b[0m\n",
      "\n",
      "Z_shape = (3, 16, 16, 8), W_shape = (3, 3, 8, 16), stride = 1, padding = 2\n",
      "backward = True, device = cpu()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[  0.40910086  -0.64982927  11.320294   ...  -0.12077556\n",
      "      1.428692    -5.5845156 ]\n",
      "   [ -6.89178...-1.5437248  -10.136281  ]\n",
      "   [  1.1511405    0.7441038   16.463472   ...  -6.8931007\n",
      "     -0.5833115   -2.504636  ]]]])\n",
      "W_shape    = (3, 3, 8, 16)\n",
      "Wtch       = tensor([[[[  0.4091,  -0.6498,  11.3203,  ...,  -0.1208,   1.4287,  -5.5845],\n",
      "          [ -6.8918,  -9.3836,  10.6335,... -10.1363],\n",
      "          [  1.1511,   0.7441,  16.4635,  ...,  -6.8931,  -0.5833,  -2.5046]]]],\n",
      "       requires_grad=True)\n",
      "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
      "     4.75044203e+00 -7.56786048e...5e+00]\n",
      "   [ 6.10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
      "     3.33514667e+00 -1.35630560e+00]]]])\n",
      "Z_shape    = (3, 16, 16, 8)\n",
      "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
      "            4.7504e+00, -7.5679e-01],\n",
      "          [...[ 6.1037e+00, -2.0543e+00, -4.4138e+00,  ..., -6.1525e+00,\n",
      "            3.3351e+00, -1.3563e+00]]]], requires_grad=True)\n",
      "_W         = array([[[[  0.40910086,  -0.64982927,  11.320294  , ...,  -0.12077556,\n",
      "            1.428692  ,  -5.5845156 ],\n",
      "        ... ,  16.463472  , ...,  -6.8931007 ,\n",
      "           -0.5833115 ,  -2.504636  ]]]],\n",
      "      shape=(3, 3, 8, 16), dtype=float32)\n",
      "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
      "          -4.88638926e+00,  4.75044203e+00, -7.56786...6e+00, ...,\n",
      "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
      "      shape=(3, 16, 16, 8), dtype=float32)\n",
      "backward   = True\n",
      "device     = cpu()\n",
      "err1       = np.float32(0.0)\n",
      "err2       = np.float32(0.002184353)\n",
      "out        = tensor([[[[-6.3835e+01, -7.3393e+01,  7.0442e+01,  ..., -8.6601e+01,\n",
      "            2.9473e+01,  3.8723e+01],\n",
      "          [...,  8.9989e+01,  2.4763e+01,  ..., -2.3400e+02,\n",
      "            1.3548e+02, -2.8245e+01]]]], grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(23346.6914, grad_fn=<SumBackward0>)\n",
      "padding    = 2\n",
      "stride     = 1\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c5655d4890>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655d5d90>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655d5d90>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655d5d90>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655d5d90>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[ -48.62973    -48.62973    -48.62973   ...  -48.62973\n",
      "     -48.62973    -48.62973  ]\n",
      "   [  -7.4578705   -7.4578705   -7.4578705 ...   -7.4578705\n",
      "      -7.4578705   -7.4578705]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74806    -72.74806    -72.74806   ...  -72.74806\n",
      "     -72.74806    -72.74806  ]\n",
      "   [ -30.264532   -30.264532   -30.264532  ...  -30.264532\n",
      "     -30.264532   -30.264532 ]\n",
      "   [-223.74295   -223.74295   -223.74295   ... -223.74295\n",
      "    -223.74295   -223.74295  ]]\n",
      "\n",
      "  [[ -48.62973    -48.62973    -48.62973   ...  -48.62973\n",
      "     -48.62973    -48.62973  ]\n",
      "   [  -7.4578705   -7.4578705   -7.4578705 ...   -7.4578705\n",
      "      -7.4578705   -7.4578705]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74806    -72.74806    -72.74806   ...  -72.74806\n",
      "     -72.74806    -72.74806  ]\n",
      "   [ -30.264532   -30.264532   -30.264532  ...  -30.264532\n",
      "     -30.264532   -30.264532 ]\n",
      "   [-223.74295   -223.74295   -223.74295   ... -223.74295\n",
      "    -223.74295   -223.74295  ]]\n",
      "\n",
      "  [[ -48.62973    -48.62973    -48.62973   ...  -48.62973\n",
      "     -48.62973    -48.62973  ]\n",
      "   [  -7.4578705   -7.4578705   -7.4578705 ...   -7.4578705\n",
      "      -7.4578705   -7.4578705]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74806    -72.74806    -72.74806   ...  -72.74806\n",
      "     -72.74806    -72.74806  ]\n",
      "   [ -30.264532   -30.264532   -30.264532  ...  -30.264532\n",
      "     -30.264532   -30.264532 ]\n",
      "   [-223.74295   -223.74295   -223.74295   ... -223.74295\n",
      "    -223.74295   -223.74295  ]]]\n",
      "\n",
      "\n",
      " [[[ -48.62973    -48.62973    -48.62973   ...  -48.62973\n",
      "     -48.62973    -48.62973  ]\n",
      "   [  -7.4578705   -7.4578705   -7.4578705 ...   -7.4578705\n",
      "      -7.4578705   -7.4578705]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74806    -72.74806    -72.74806   ...  -72.74806\n",
      "     -72.74806    -72.74806  ]\n",
      "   [ -30.264532   -30.264532   -30.264532  ...  -30.264532\n",
      "     -30.264532   -30.264532 ]\n",
      "   [-223.74295   -223.74295   -223.74295   ... -223.74295\n",
      "    -223.74295   -223.74295  ]]\n",
      "\n",
      "  [[ -48.62973    -48.62973    -48.62973   ...  -48.62973\n",
      "     -48.62973    -48.62973  ]\n",
      "   [  -7.4578705   -7.4578705   -7.4578705 ...   -7.4578705\n",
      "      -7.4578705   -7.4578705]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74806    -72.74806    -72.74806   ...  -72.74806\n",
      "     -72.74806    -72.74806  ]\n",
      "   [ -30.264532   -30.264532   -30.264532  ...  -30.264532\n",
      "     -30.264532   -30.264532 ]\n",
      "   [-223.74295   -223.74295   -223.74295   ... -223.74295\n",
      "    -223.74295   -223.74295  ]]\n",
      "\n",
      "  [[ -48.62973    -48.62973    -48.62973   ...  -48.62973\n",
      "     -48.62973    -48.62973  ]\n",
      "   [  -7.4578705   -7.4578705   -7.4578705 ...   -7.4578705\n",
      "      -7.4578705   -7.4578705]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74806    -72.74806    -72.74806   ...  -72.74806\n",
      "     -72.74806    -72.74806  ]\n",
      "   [ -30.264532   -30.264532   -30.264532  ...  -30.264532\n",
      "     -30.264532   -30.264532 ]\n",
      "   [-223.74295   -223.74295   -223.74295   ... -223.74295\n",
      "    -223.74295   -223.74295  ]]]\n",
      "\n",
      "\n",
      " [[[ -48.62973    -48.62973    -48.62973   ...  -48.62973\n",
      "     -48.62973    -48.62973  ]\n",
      "   [  -7.4578705   -7.4578705   -7.4578705 ...   -7.4578705\n",
      "      -7.4578705   -7.4578705]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74806    -72.74806    -72.74806   ...  -72.74806\n",
      "     -72.74806    -72.74806  ]\n",
      "   [ -30.264532   -30.264532   -30.264532  ...  -30.264532\n",
      "     -30.264532   -30.264532 ]\n",
      "   [-223.74295   -223.74295   -223.74295   ... -223.74295\n",
      "    -223.74295   -223.74295  ]]\n",
      "\n",
      "  [[ -48.62973    -48.62973    -48.62973   ...  -48.62973\n",
      "     -48.62973    -48.62973  ]\n",
      "   [  -7.4578705   -7.4578705   -7.4578705 ...   -7.4578705\n",
      "      -7.4578705   -7.4578705]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74806    -72.74806    -72.74806   ...  -72.74806\n",
      "     -72.74806    -72.74806  ]\n",
      "   [ -30.264532   -30.264532   -30.264532  ...  -30.264532\n",
      "     -30.264532   -30.264532 ]\n",
      "   [-223.74295   -223.74295   -223.74295   ... -223.74295\n",
      "    -223.74295   -223.74295  ]]\n",
      "\n",
      "  [[ -48.62973    -48.62973    -48.62973   ...  -48.62973\n",
      "     -48.62973    -48.62973  ]\n",
      "   [  -7.4578705   -7.4578705   -7.4578705 ...   -7.4578705\n",
      "      -7.4578705   -7.4578705]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74806    -72.74806    -72.74806   ...  -72.74806\n",
      "     -72.74806    -72.74806  ]\n",
      "   [ -30.264532   -30.264532   -30.264532  ...  -30.264532\n",
      "     -30.264532   -30.264532 ]\n",
      "   [-223.74295   -223.74295   -223.74295   ... -223.74295\n",
      "    -223.74295   -223.74295  ]]]], W.grad.numpy(): [[[[ -48.62979    -48.62979    -48.62979   ...  -48.62979\n",
      "     -48.62979    -48.62979  ]\n",
      "   [  -7.4579277   -7.4579277   -7.4579277 ...   -7.4579277\n",
      "      -7.4579277   -7.4579277]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74812    -72.74812    -72.74812   ...  -72.74812\n",
      "     -72.74812    -72.74812  ]\n",
      "   [ -30.264448   -30.264448   -30.264448  ...  -30.264448\n",
      "     -30.264448   -30.264448 ]\n",
      "   [-223.74303   -223.74303   -223.74303   ... -223.74303\n",
      "    -223.74303   -223.74303  ]]\n",
      "\n",
      "  [[ -48.62979    -48.62979    -48.62979   ...  -48.62979\n",
      "     -48.62979    -48.62979  ]\n",
      "   [  -7.4579277   -7.4579277   -7.4579277 ...   -7.4579277\n",
      "      -7.4579277   -7.4579277]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74812    -72.74812    -72.74812   ...  -72.74812\n",
      "     -72.74812    -72.74812  ]\n",
      "   [ -30.264448   -30.264448   -30.264448  ...  -30.264448\n",
      "     -30.264448   -30.264448 ]\n",
      "   [-223.74303   -223.74303   -223.74303   ... -223.74303\n",
      "    -223.74303   -223.74303  ]]\n",
      "\n",
      "  [[ -48.62979    -48.62979    -48.62979   ...  -48.62979\n",
      "     -48.62979    -48.62979  ]\n",
      "   [  -7.4579277   -7.4579277   -7.4579277 ...   -7.4579277\n",
      "      -7.4579277   -7.4579277]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74812    -72.74812    -72.74812   ...  -72.74812\n",
      "     -72.74812    -72.74812  ]\n",
      "   [ -30.264448   -30.264448   -30.264448  ...  -30.264448\n",
      "     -30.264448   -30.264448 ]\n",
      "   [-223.74303   -223.74303   -223.74303   ... -223.74303\n",
      "    -223.74303   -223.74303  ]]]\n",
      "\n",
      "\n",
      " [[[ -48.62979    -48.62979    -48.62979   ...  -48.62979\n",
      "     -48.62979    -48.62979  ]\n",
      "   [  -7.4579277   -7.4579277   -7.4579277 ...   -7.4579277\n",
      "      -7.4579277   -7.4579277]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74812    -72.74812    -72.74812   ...  -72.74812\n",
      "     -72.74812    -72.74812  ]\n",
      "   [ -30.264448   -30.264448   -30.264448  ...  -30.264448\n",
      "     -30.264448   -30.264448 ]\n",
      "   [-223.74303   -223.74303   -223.74303   ... -223.74303\n",
      "    -223.74303   -223.74303  ]]\n",
      "\n",
      "  [[ -48.62979    -48.62979    -48.62979   ...  -48.62979\n",
      "     -48.62979    -48.62979  ]\n",
      "   [  -7.4579277   -7.4579277   -7.4579277 ...   -7.4579277\n",
      "      -7.4579277   -7.4579277]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74812    -72.74812    -72.74812   ...  -72.74812\n",
      "     -72.74812    -72.74812  ]\n",
      "   [ -30.264448   -30.264448   -30.264448  ...  -30.264448\n",
      "     -30.264448   -30.264448 ]\n",
      "   [-223.74303   -223.74303   -223.74303   ... -223.74303\n",
      "    -223.74303   -223.74303  ]]\n",
      "\n",
      "  [[ -48.62979    -48.62979    -48.62979   ...  -48.62979\n",
      "     -48.62979    -48.62979  ]\n",
      "   [  -7.4579277   -7.4579277   -7.4579277 ...   -7.4579277\n",
      "      -7.4579277   -7.4579277]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74812    -72.74812    -72.74812   ...  -72.74812\n",
      "     -72.74812    -72.74812  ]\n",
      "   [ -30.264448   -30.264448   -30.264448  ...  -30.264448\n",
      "     -30.264448   -30.264448 ]\n",
      "   [-223.74303   -223.74303   -223.74303   ... -223.74303\n",
      "    -223.74303   -223.74303  ]]]\n",
      "\n",
      "\n",
      " [[[ -48.62979    -48.62979    -48.62979   ...  -48.62979\n",
      "     -48.62979    -48.62979  ]\n",
      "   [  -7.4579277   -7.4579277   -7.4579277 ...   -7.4579277\n",
      "      -7.4579277   -7.4579277]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74812    -72.74812    -72.74812   ...  -72.74812\n",
      "     -72.74812    -72.74812  ]\n",
      "   [ -30.264448   -30.264448   -30.264448  ...  -30.264448\n",
      "     -30.264448   -30.264448 ]\n",
      "   [-223.74303   -223.74303   -223.74303   ... -223.74303\n",
      "    -223.74303   -223.74303  ]]\n",
      "\n",
      "  [[ -48.62979    -48.62979    -48.62979   ...  -48.62979\n",
      "     -48.62979    -48.62979  ]\n",
      "   [  -7.4579277   -7.4579277   -7.4579277 ...   -7.4579277\n",
      "      -7.4579277   -7.4579277]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74812    -72.74812    -72.74812   ...  -72.74812\n",
      "     -72.74812    -72.74812  ]\n",
      "   [ -30.264448   -30.264448   -30.264448  ...  -30.264448\n",
      "     -30.264448   -30.264448 ]\n",
      "   [-223.74303   -223.74303   -223.74303   ... -223.74303\n",
      "    -223.74303   -223.74303  ]]\n",
      "\n",
      "  [[ -48.62979    -48.62979    -48.62979   ...  -48.62979\n",
      "     -48.62979    -48.62979  ]\n",
      "   [  -7.4579277   -7.4579277   -7.4579277 ...   -7.4579277\n",
      "      -7.4579277   -7.4579277]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74812    -72.74812    -72.74812   ...  -72.74812\n",
      "     -72.74812    -72.74812  ]\n",
      "   [ -30.264448   -30.264448   -30.264448  ...  -30.264448\n",
      "     -30.264448   -30.264448 ]\n",
      "   [-223.74303   -223.74303   -223.74303   ... -223.74303\n",
      "    -223.74303   -223.74303  ]]]]\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape3-W_shape3-1-0] _\u001b[0m\n",
      "\n",
      "Z_shape = (3, 16, 16, 8), W_shape = (3, 3, 8, 14), stride = 1, padding = 0\n",
      "backward = True, device = cpu()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[ 4.09100860e-01 -6.49829268e-01  1.13202944e+01 ... -5.56089449e+00\n",
      "    -4.84385538e+00 -1.20775558e...5e+00]\n",
      "   [-1.10714078e+00  2.54448557e+00 -7.73867989e+00 ... -1.13336074e+00\n",
      "    -1.21658230e+00 -4.79330921e+00]]]])\n",
      "W_shape    = (3, 3, 8, 14)\n",
      "Wtch       = tensor([[[[ 4.0910e-01, -6.4983e-01,  1.1320e+01,  ..., -5.5609e+00,\n",
      "           -4.8439e+00, -1.2078e-01],\n",
      "          [...[-1.1071e+00,  2.5445e+00, -7.7387e+00,  ..., -1.1334e+00,\n",
      "           -1.2166e+00, -4.7933e+00]]]], requires_grad=True)\n",
      "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
      "     4.75044203e+00 -7.56786048e...5e+00]\n",
      "   [ 6.10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
      "     3.33514667e+00 -1.35630560e+00]]]])\n",
      "Z_shape    = (3, 16, 16, 8)\n",
      "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
      "            4.7504e+00, -7.5679e-01],\n",
      "          [...[ 6.1037e+00, -2.0543e+00, -4.4138e+00,  ..., -6.1525e+00,\n",
      "            3.3351e+00, -1.3563e+00]]]], requires_grad=True)\n",
      "_W         = array([[[[ 4.09100860e-01, -6.49829268e-01,  1.13202944e+01, ...,\n",
      "          -5.56089449e+00, -4.84385538e+00, -1.20775...89e+00, ...,\n",
      "          -1.13336074e+00, -1.21658230e+00, -4.79330921e+00]]]],\n",
      "      shape=(3, 3, 8, 14), dtype=float32)\n",
      "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
      "          -4.88638926e+00,  4.75044203e+00, -7.56786...6e+00, ...,\n",
      "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
      "      shape=(3, 16, 16, 8), dtype=float32)\n",
      "backward   = True\n",
      "device     = cpu()\n",
      "err1       = np.float32(0.0008252314)\n",
      "err2       = np.float32(0.0016137677)\n",
      "out        = tensor([[[[ 5.7346e+00, -2.1858e+02, -5.5911e+01,  ..., -8.9695e+01,\n",
      "            2.2620e+02,  3.4342e+02],\n",
      "          [...,  2.3405e+01, -2.1477e+01,  ...,  1.2947e+02,\n",
      "            1.2442e+02, -4.6003e+02]]]], grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(16161.7031, grad_fn=<SumBackward0>)\n",
      "padding    = 0\n",
      "stride     = 1\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c5655fdbb0>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655fdd30>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655fdd30>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655fdd30>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655fdd30>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[-201.79364   -201.79364   -201.79364   ... -201.79364\n",
      "    -201.79364   -201.79364  ]\n",
      "   [  95.072655    95.072655    95.072655  ...   95.072655\n",
      "      95.072655    95.072655 ]\n",
      "   [  34.098076    34.098076    34.098076  ...   34.098076\n",
      "      34.098076    34.098076 ]\n",
      "   ...\n",
      "   [ -47.259125   -47.259125   -47.259125  ...  -47.259125\n",
      "     -47.259125   -47.259125 ]\n",
      "   [  -2.0522346   -2.0522346   -2.0522346 ...   -2.0522346\n",
      "      -2.0522346   -2.0522346]\n",
      "   [-107.065674  -107.065674  -107.065674  ... -107.065674\n",
      "    -107.065674  -107.065674 ]]\n",
      "\n",
      "  [[-232.77994   -232.77994   -232.77994   ... -232.77994\n",
      "    -232.77994   -232.77994  ]\n",
      "   [ 101.72708    101.72708    101.72708   ...  101.72708\n",
      "     101.72708    101.72708  ]\n",
      "   [  43.494247    43.494247    43.494247  ...   43.494247\n",
      "      43.494247    43.494247 ]\n",
      "   ...\n",
      "   [  20.157448    20.157448    20.157448  ...   20.157448\n",
      "      20.157448    20.157448 ]\n",
      "   [ -43.416256   -43.416256   -43.416256  ...  -43.416256\n",
      "     -43.416256   -43.416256 ]\n",
      "   [-178.75519   -178.75519   -178.75519   ... -178.75519\n",
      "    -178.75519   -178.75519  ]]\n",
      "\n",
      "  [[-139.2617    -139.2617    -139.2617    ... -139.2617\n",
      "    -139.2617    -139.2617   ]\n",
      "   [  71.22569     71.22569     71.22569   ...   71.22569\n",
      "      71.22569     71.22569  ]\n",
      "   [ -32.495216   -32.495216   -32.495216  ...  -32.495216\n",
      "     -32.495216   -32.495216 ]\n",
      "   ...\n",
      "   [   6.2611504    6.2611504    6.2611504 ...    6.2611504\n",
      "       6.2611504    6.2611504]\n",
      "   [-124.56712   -124.56712   -124.56712   ... -124.56712\n",
      "    -124.56712   -124.56712  ]\n",
      "   [-189.20609   -189.20609   -189.20609   ... -189.20609\n",
      "    -189.20609   -189.20609  ]]]\n",
      "\n",
      "\n",
      " [[[-129.1484    -129.1484    -129.1484    ... -129.1484\n",
      "    -129.1484    -129.1484   ]\n",
      "   [  88.56199     88.56199     88.56199   ...   88.56199\n",
      "      88.56199     88.56199  ]\n",
      "   [  29.913506    29.913506    29.913506  ...   29.913506\n",
      "      29.913506    29.913506 ]\n",
      "   ...\n",
      "   [ -86.3288     -86.3288     -86.3288    ...  -86.3288\n",
      "     -86.3288     -86.3288   ]\n",
      "   [ -32.11608    -32.11608    -32.11608   ...  -32.11608\n",
      "     -32.11608    -32.11608  ]\n",
      "   [-191.25865   -191.25865   -191.25865   ... -191.25865\n",
      "    -191.25865   -191.25865  ]]\n",
      "\n",
      "  [[-118.70814   -118.70814   -118.70814   ... -118.70814\n",
      "    -118.70814   -118.70814  ]\n",
      "   [  96.96954     96.96954     96.96954   ...   96.96954\n",
      "      96.96954     96.96954  ]\n",
      "   [  44.443703    44.443703    44.443703  ...   44.443703\n",
      "      44.443703    44.443703 ]\n",
      "   ...\n",
      "   [ -13.089989   -13.089989   -13.089989  ...  -13.089989\n",
      "     -13.089989   -13.089989 ]\n",
      "   [ -77.29191    -77.29191    -77.29191   ...  -77.29191\n",
      "     -77.29191    -77.29191  ]\n",
      "   [-278.71997   -278.71997   -278.71997   ... -278.71997\n",
      "    -278.71997   -278.71997  ]]\n",
      "\n",
      "  [[ -44.439785   -44.439785   -44.439785  ...  -44.439785\n",
      "     -44.439785   -44.439785 ]\n",
      "   [  61.65576     61.65576     61.65576   ...   61.65576\n",
      "      61.65576     61.65576  ]\n",
      "   [ -40.48121    -40.48121    -40.48121   ...  -40.48121\n",
      "     -40.48121    -40.48121  ]\n",
      "   ...\n",
      "   [ -16.59602    -16.59602    -16.59602   ...  -16.59602\n",
      "     -16.59602    -16.59602  ]\n",
      "   [-133.24857   -133.24857   -133.24857   ... -133.24857\n",
      "    -133.24857   -133.24857  ]\n",
      "   [-323.14288   -323.14288   -323.14288   ... -323.14288\n",
      "    -323.14288   -323.14288  ]]]\n",
      "\n",
      "\n",
      " [[[ -47.0627     -47.0627     -47.0627    ...  -47.0627\n",
      "     -47.0627     -47.0627   ]\n",
      "   [  57.90393     57.90393     57.90393   ...   57.90393\n",
      "      57.90393     57.90393  ]\n",
      "   [ -24.880836   -24.880836   -24.880836  ...  -24.880836\n",
      "     -24.880836   -24.880836 ]\n",
      "   ...\n",
      "   [  -9.441906    -9.441906    -9.441906  ...   -9.441906\n",
      "      -9.441906    -9.441906 ]\n",
      "   [  29.061718    29.061718    29.061718  ...   29.061718\n",
      "      29.061718    29.061718 ]\n",
      "   [-166.67372   -166.67372   -166.67372   ... -166.67372\n",
      "    -166.67372   -166.67372  ]]\n",
      "\n",
      "  [[ -35.03288    -35.03288    -35.03288   ...  -35.03288\n",
      "     -35.03288    -35.03288  ]\n",
      "   [  75.41133     75.41133     75.41133   ...   75.41133\n",
      "      75.41133     75.41133  ]\n",
      "   [ -19.464973   -19.464973   -19.464973  ...  -19.464973\n",
      "     -19.464973   -19.464973 ]\n",
      "   ...\n",
      "   [  55.00097     55.00097     55.00097   ...   55.00097\n",
      "      55.00097     55.00097  ]\n",
      "   [ -44.410614   -44.410614   -44.410614  ...  -44.410614\n",
      "     -44.410614   -44.410614 ]\n",
      "   [-256.9889    -256.9889    -256.9889    ... -256.9889\n",
      "    -256.9889    -256.9889   ]]\n",
      "\n",
      "  [[  21.06859     21.06859     21.06859   ...   21.06859\n",
      "      21.06859     21.06859  ]\n",
      "   [  42.674404    42.674404    42.674404  ...   42.674404\n",
      "      42.674404    42.674404 ]\n",
      "   [-121.07211   -121.07211   -121.07211   ... -121.07211\n",
      "    -121.07211   -121.07211  ]\n",
      "   ...\n",
      "   [  44.29737     44.29737     44.29737   ...   44.29737\n",
      "      44.29737     44.29737  ]\n",
      "   [-113.24769   -113.24769   -113.24769   ... -113.24769\n",
      "    -113.24769   -113.24769  ]\n",
      "   [-282.69653   -282.69653   -282.69653   ... -282.69653\n",
      "    -282.69653   -282.69653  ]]]], W.grad.numpy(): [[[[-201.7937   -201.7937   -201.7937   ... -201.7937   -201.7937\n",
      "    -201.7937  ]\n",
      "   [  95.07266    95.07266    95.07266  ...   95.07266    95.07266\n",
      "      95.07266 ]\n",
      "   [  34.09809    34.09809    34.09809  ...   34.09809    34.09809\n",
      "      34.09809 ]\n",
      "   ...\n",
      "   [ -47.25914   -47.25914   -47.25914  ...  -47.25914   -47.25914\n",
      "     -47.25914 ]\n",
      "   [  -2.052239   -2.052239   -2.052239 ...   -2.052239   -2.052239\n",
      "      -2.052239]\n",
      "   [-107.065674 -107.065674 -107.065674 ... -107.065674 -107.065674\n",
      "    -107.065674]]\n",
      "\n",
      "  [[-232.78001  -232.78001  -232.78001  ... -232.78001  -232.78001\n",
      "    -232.78001 ]\n",
      "   [ 101.72707   101.72707   101.72707  ...  101.72707   101.72707\n",
      "     101.72707 ]\n",
      "   [  43.49426    43.49426    43.49426  ...   43.49426    43.49426\n",
      "      43.49426 ]\n",
      "   ...\n",
      "   [  20.157454   20.157454   20.157454 ...   20.157454   20.157454\n",
      "      20.157454]\n",
      "   [ -43.41613   -43.41613   -43.41613  ...  -43.41613   -43.41613\n",
      "     -43.41613 ]\n",
      "   [-178.75513  -178.75513  -178.75513  ... -178.75513  -178.75513\n",
      "    -178.75513 ]]\n",
      "\n",
      "  [[-139.26176  -139.26176  -139.26176  ... -139.26176  -139.26176\n",
      "    -139.26176 ]\n",
      "   [  71.22569    71.22569    71.22569  ...   71.22569    71.22569\n",
      "      71.22569 ]\n",
      "   [ -32.495262  -32.495262  -32.495262 ...  -32.495262  -32.495262\n",
      "     -32.495262]\n",
      "   ...\n",
      "   [   6.261143    6.261143    6.261143 ...    6.261143    6.261143\n",
      "       6.261143]\n",
      "   [-124.56705  -124.56705  -124.56705  ... -124.56705  -124.56705\n",
      "    -124.56705 ]\n",
      "   [-189.20601  -189.20601  -189.20601  ... -189.20601  -189.20601\n",
      "    -189.20601 ]]]\n",
      "\n",
      "\n",
      " [[[-129.14839  -129.14839  -129.14839  ... -129.14839  -129.14839\n",
      "    -129.14839 ]\n",
      "   [  88.562      88.562      88.562    ...   88.562      88.562\n",
      "      88.562   ]\n",
      "   [  29.91347    29.91347    29.91347  ...   29.91347    29.91347\n",
      "      29.91347 ]\n",
      "   ...\n",
      "   [ -86.32881   -86.32881   -86.32881  ...  -86.32881   -86.32881\n",
      "     -86.32881 ]\n",
      "   [ -32.116077  -32.116077  -32.116077 ...  -32.116077  -32.116077\n",
      "     -32.116077]\n",
      "   [-191.25864  -191.25864  -191.25864  ... -191.25864  -191.25864\n",
      "    -191.25864 ]]\n",
      "\n",
      "  [[-118.70813  -118.70813  -118.70813  ... -118.70813  -118.70813\n",
      "    -118.70813 ]\n",
      "   [  96.96952    96.96952    96.96952  ...   96.96952    96.96952\n",
      "      96.96952 ]\n",
      "   [  44.443657   44.443657   44.443657 ...   44.443657   44.443657\n",
      "      44.443657]\n",
      "   ...\n",
      "   [ -13.089987  -13.089987  -13.089987 ...  -13.089987  -13.089987\n",
      "     -13.089987]\n",
      "   [ -77.29176   -77.29176   -77.29176  ...  -77.29176   -77.29176\n",
      "     -77.29176 ]\n",
      "   [-278.71997  -278.71997  -278.71997  ... -278.71997  -278.71997\n",
      "    -278.71997 ]]\n",
      "\n",
      "  [[ -44.43978   -44.43978   -44.43978  ...  -44.43978   -44.43978\n",
      "     -44.43978 ]\n",
      "   [  61.65575    61.65575    61.65575  ...   61.65575    61.65575\n",
      "      61.65575 ]\n",
      "   [ -40.48122   -40.48122   -40.48122  ...  -40.48122   -40.48122\n",
      "     -40.48122 ]\n",
      "   ...\n",
      "   [ -16.595932  -16.595932  -16.595932 ...  -16.595932  -16.595932\n",
      "     -16.595932]\n",
      "   [-133.24866  -133.24866  -133.24866  ... -133.24866  -133.24866\n",
      "    -133.24866 ]\n",
      "   [-323.14285  -323.14285  -323.14285  ... -323.14285  -323.14285\n",
      "    -323.14285 ]]]\n",
      "\n",
      "\n",
      " [[[ -47.06269   -47.06269   -47.06269  ...  -47.06269   -47.06269\n",
      "     -47.06269 ]\n",
      "   [  57.903957   57.903957   57.903957 ...   57.903957   57.903957\n",
      "      57.903957]\n",
      "   [ -24.880894  -24.880894  -24.880894 ...  -24.880894  -24.880894\n",
      "     -24.880894]\n",
      "   ...\n",
      "   [  -9.441917   -9.441917   -9.441917 ...   -9.441917   -9.441917\n",
      "      -9.441917]\n",
      "   [  29.061699   29.061699   29.061699 ...   29.061699   29.061699\n",
      "      29.061699]\n",
      "   [-166.6737   -166.6737   -166.6737   ... -166.6737   -166.6737\n",
      "    -166.6737  ]]\n",
      "\n",
      "  [[ -35.032925  -35.032925  -35.032925 ...  -35.032925  -35.032925\n",
      "     -35.032925]\n",
      "   [  75.41132    75.41132    75.41132  ...   75.41132    75.41132\n",
      "      75.41132 ]\n",
      "   [ -19.465002  -19.465002  -19.465002 ...  -19.465002  -19.465002\n",
      "     -19.465002]\n",
      "   ...\n",
      "   [  55.000908   55.000908   55.000908 ...   55.000908   55.000908\n",
      "      55.000908]\n",
      "   [ -44.41051   -44.41051   -44.41051  ...  -44.41051   -44.41051\n",
      "     -44.41051 ]\n",
      "   [-256.9889   -256.9889   -256.9889   ... -256.9889   -256.9889\n",
      "    -256.9889  ]]\n",
      "\n",
      "  [[  21.068607   21.068607   21.068607 ...   21.068607   21.068607\n",
      "      21.068607]\n",
      "   [  42.6744     42.6744     42.6744   ...   42.6744     42.6744\n",
      "      42.6744  ]\n",
      "   [-121.07214  -121.07214  -121.07214  ... -121.07214  -121.07214\n",
      "    -121.07214 ]\n",
      "   ...\n",
      "   [  44.297386   44.297386   44.297386 ...   44.297386   44.297386\n",
      "      44.297386]\n",
      "   [-113.24764  -113.24764  -113.24764  ... -113.24764  -113.24764\n",
      "    -113.24764 ]\n",
      "   [-282.69644  -282.69644  -282.69644  ... -282.69644  -282.69644\n",
      "    -282.69644 ]]]]\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape4-W_shape4-1-0] _\u001b[0m\n",
      "\n",
      "Z_shape = (3, 16, 16, 2), W_shape = (3, 3, 2, 14), stride = 1, padding = 0\n",
      "backward = True, device = cpu()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[ -8.0968      -2.5552022    8.703147    -1.4674252    4.5861077\n",
      "     -0.28521433   4.383634    -9.13...727333   0.22582927   9.296732    -8.13161     -0.67411226\n",
      "     -2.9204676    1.675528   -12.187821     5.5746226 ]]]])\n",
      "W_shape    = (3, 3, 2, 14)\n",
      "Wtch       = tensor([[[[ -8.0968,  -2.5552,   8.7031,  -1.4674,   4.5861,  -0.2852,   4.3836,\n",
      "            -9.1346,  -2.0159,   4.74...0.2258,\n",
      "             9.2967,  -8.1316,  -0.6741,  -2.9205,   1.6755, -12.1878,   5.5746]]]],\n",
      "       requires_grad=True)\n",
      "Z          = needle.Tensor([[[[  8.820262     2.000786  ]\n",
      "   [  4.89369     11.204466  ]\n",
      "   [  9.33779     -4.8863893 ]\n",
      "   ...\n",
      "   [...   -5.112822  ]\n",
      "   ...\n",
      "   [ -7.922368     4.2222714 ]\n",
      "   [ -6.064339     1.4188478 ]\n",
      "   [ -1.4109794   -5.791016  ]]]])\n",
      "Z_shape    = (3, 16, 16, 2)\n",
      "Ztch       = tensor([[[[  8.8203,   2.0008],\n",
      "          [  4.8937,  11.2045],\n",
      "          [  9.3378,  -4.8864],\n",
      "          ...,\n",
      "       ...\n",
      "          [ -7.9224,   4.2223],\n",
      "          [ -6.0643,   1.4188],\n",
      "          [ -1.4110,  -5.7910]]]], requires_grad=True)\n",
      "_W         = array([[[[ -8.0968    ,  -2.5552022 ,   8.703147  ,  -1.4674252 ,\n",
      "            4.5861077 ,  -0.28521433,   4.383634  , ...        -8.13161   ,  -0.67411226,  -2.9204676 ,   1.675528  ,\n",
      "          -12.187821  ,   5.5746226 ]]]], dtype=float32)\n",
      "_Z         = array([[[[  8.820262  ,   2.000786  ],\n",
      "         [  4.89369   ,  11.204466  ],\n",
      "         [  9.33779   ,  -4.8863893 ],\n",
      " ...     [ -6.064339  ,   1.4188478 ],\n",
      "         [ -1.4109794 ,  -5.791016  ]]]],\n",
      "      shape=(3, 16, 16, 2), dtype=float32)\n",
      "backward   = True\n",
      "device     = cpu()\n",
      "err1       = np.float32(0.0002241043)\n",
      "err2       = np.float32(0.00065855857)\n",
      "out        = tensor([[[[-346.0716,  -28.1759,   63.5063,  ..., -158.1952,  -57.8746,\n",
      "             63.6776],\n",
      "          [  73.3426,  ...[  58.9731,    3.5575, -155.4996,  ...,  123.7366,   54.5836,\n",
      "             92.4735]]]], grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(-6321.1787, grad_fn=<SumBackward0>)\n",
      "padding    = 0\n",
      "stride     = 1\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c56558b470>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c56558a2d0>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c56558a2d0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c56558a2d0>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c56558a2d0>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[ -68.282936   -68.282936   -68.282936   -68.282936   -68.282936\n",
      "     -68.282936   -68.282936   -68.282936   -68.282936   -68.282936\n",
      "     -68.282936   -68.282936   -68.282936   -68.282936 ]\n",
      "   [-118.24972   -118.24972   -118.24972   -118.24972   -118.24972\n",
      "    -118.24972   -118.24972   -118.24972   -118.24972   -118.24972\n",
      "    -118.24972   -118.24972   -118.24972   -118.24972  ]]\n",
      "\n",
      "  [[ -67.852554   -67.852554   -67.852554   -67.852554   -67.852554\n",
      "     -67.852554   -67.852554   -67.852554   -67.852554   -67.852554\n",
      "     -67.852554   -67.852554   -67.852554   -67.852554 ]\n",
      "   [ -95.73945    -95.73945    -95.73945    -95.73945    -95.73945\n",
      "     -95.73945    -95.73945    -95.73945    -95.73945    -95.73945\n",
      "     -95.73945    -95.73945    -95.73945    -95.73945  ]]\n",
      "\n",
      "  [[ -45.030754   -45.030754   -45.030754   -45.030754   -45.030754\n",
      "     -45.030754   -45.030754   -45.030754   -45.030754   -45.030754\n",
      "     -45.030754   -45.030754   -45.030754   -45.030754 ]\n",
      "   [ -95.70444    -95.70444    -95.70444    -95.70444    -95.70444\n",
      "     -95.70444    -95.70444    -95.70444    -95.70444    -95.70444\n",
      "     -95.70444    -95.70444    -95.70444    -95.70444  ]]]\n",
      "\n",
      "\n",
      " [[[-148.68748   -148.68748   -148.68748   -148.68748   -148.68748\n",
      "    -148.68748   -148.68748   -148.68748   -148.68748   -148.68748\n",
      "    -148.68748   -148.68748   -148.68748   -148.68748  ]\n",
      "   [ -60.701717   -60.701717   -60.701717   -60.701717   -60.701717\n",
      "     -60.701717   -60.701717   -60.701717   -60.701717   -60.701717\n",
      "     -60.701717   -60.701717   -60.701717   -60.701717 ]]\n",
      "\n",
      "  [[-127.58233   -127.58233   -127.58233   -127.58233   -127.58233\n",
      "    -127.58233   -127.58233   -127.58233   -127.58233   -127.58233\n",
      "    -127.58233   -127.58233   -127.58233   -127.58233  ]\n",
      "   [ -65.67272    -65.67272    -65.67272    -65.67272    -65.67272\n",
      "     -65.67272    -65.67272    -65.67272    -65.67272    -65.67272\n",
      "     -65.67272    -65.67272    -65.67272    -65.67272  ]]\n",
      "\n",
      "  [[-110.33866   -110.33866   -110.33866   -110.33866   -110.33866\n",
      "    -110.33866   -110.33866   -110.33866   -110.33866   -110.33866\n",
      "    -110.33866   -110.33866   -110.33866   -110.33866  ]\n",
      "   [ -75.60977    -75.60977    -75.60977    -75.60977    -75.60977\n",
      "     -75.60977    -75.60977    -75.60977    -75.60977    -75.60977\n",
      "     -75.60977    -75.60977    -75.60977    -75.60977  ]]]\n",
      "\n",
      "\n",
      " [[[-114.61824   -114.61824   -114.61824   -114.61824   -114.61824\n",
      "    -114.61824   -114.61824   -114.61824   -114.61824   -114.61824\n",
      "    -114.61824   -114.61824   -114.61824   -114.61824  ]\n",
      "   [   5.206314     5.206314     5.206314     5.206314     5.206314\n",
      "       5.206314     5.206314     5.206314     5.206314     5.206314\n",
      "       5.206314     5.206314     5.206314     5.206314 ]]\n",
      "\n",
      "  [[-103.69658   -103.69658   -103.69658   -103.69658   -103.69658\n",
      "    -103.69658   -103.69658   -103.69658   -103.69658   -103.69658\n",
      "    -103.69658   -103.69658   -103.69658   -103.69658  ]\n",
      "   [  -1.2657585   -1.2657585   -1.2657585   -1.2657585   -1.2657585\n",
      "      -1.2657585   -1.2657585   -1.2657585   -1.2657585   -1.2657585\n",
      "      -1.2657585   -1.2657585   -1.2657585   -1.2657585]]\n",
      "\n",
      "  [[ -74.390564   -74.390564   -74.390564   -74.390564   -74.390564\n",
      "     -74.390564   -74.390564   -74.390564   -74.390564   -74.390564\n",
      "     -74.390564   -74.390564   -74.390564   -74.390564 ]\n",
      "   [ -17.11633    -17.11633    -17.11633    -17.11633    -17.11633\n",
      "     -17.11633    -17.11633    -17.11633    -17.11633    -17.11633\n",
      "     -17.11633    -17.11633    -17.11633    -17.11633  ]]]], W.grad.numpy(): [[[[ -68.28293    -68.28293    -68.28293    -68.28293    -68.28293\n",
      "     -68.28293    -68.28293    -68.28293    -68.28293    -68.28293\n",
      "     -68.28293    -68.28293    -68.28293    -68.28293  ]\n",
      "   [-118.24967   -118.24967   -118.24967   -118.24967   -118.24967\n",
      "    -118.24967   -118.24967   -118.24967   -118.24967   -118.24967\n",
      "    -118.24967   -118.24967   -118.24967   -118.24967  ]]\n",
      "\n",
      "  [[ -67.85252    -67.85252    -67.85252    -67.85252    -67.85252\n",
      "     -67.85252    -67.85252    -67.85252    -67.85252    -67.85252\n",
      "     -67.85252    -67.85252    -67.85252    -67.85252  ]\n",
      "   [ -95.73942    -95.73942    -95.73942    -95.73942    -95.73942\n",
      "     -95.73942    -95.73942    -95.73942    -95.73942    -95.73942\n",
      "     -95.73942    -95.73942    -95.73942    -95.73942  ]]\n",
      "\n",
      "  [[ -45.030693   -45.030693   -45.030693   -45.030693   -45.030693\n",
      "     -45.030693   -45.030693   -45.030693   -45.030693   -45.030693\n",
      "     -45.030693   -45.030693   -45.030693   -45.030693 ]\n",
      "   [ -95.70441    -95.70441    -95.70441    -95.70441    -95.70441\n",
      "     -95.70441    -95.70441    -95.70441    -95.70441    -95.70441\n",
      "     -95.70441    -95.70441    -95.70441    -95.70441  ]]]\n",
      "\n",
      "\n",
      " [[[-148.6875    -148.6875    -148.6875    -148.6875    -148.6875\n",
      "    -148.6875    -148.6875    -148.6875    -148.6875    -148.6875\n",
      "    -148.6875    -148.6875    -148.6875    -148.6875   ]\n",
      "   [ -60.701725   -60.701725   -60.701725   -60.701725   -60.701725\n",
      "     -60.701725   -60.701725   -60.701725   -60.701725   -60.701725\n",
      "     -60.701725   -60.701725   -60.701725   -60.701725 ]]\n",
      "\n",
      "  [[-127.58232   -127.58232   -127.58232   -127.58232   -127.58232\n",
      "    -127.58232   -127.58232   -127.58232   -127.58232   -127.58232\n",
      "    -127.58232   -127.58232   -127.58232   -127.58232  ]\n",
      "   [ -65.672676   -65.672676   -65.672676   -65.672676   -65.672676\n",
      "     -65.672676   -65.672676   -65.672676   -65.672676   -65.672676\n",
      "     -65.672676   -65.672676   -65.672676   -65.672676 ]]\n",
      "\n",
      "  [[-110.33859   -110.33859   -110.33859   -110.33859   -110.33859\n",
      "    -110.33859   -110.33859   -110.33859   -110.33859   -110.33859\n",
      "    -110.33859   -110.33859   -110.33859   -110.33859  ]\n",
      "   [ -75.60969    -75.60969    -75.60969    -75.60969    -75.60969\n",
      "     -75.60969    -75.60969    -75.60969    -75.60969    -75.60969\n",
      "     -75.60969    -75.60969    -75.60969    -75.60969  ]]]\n",
      "\n",
      "\n",
      " [[[-114.61822   -114.61822   -114.61822   -114.61822   -114.61822\n",
      "    -114.61822   -114.61822   -114.61822   -114.61822   -114.61822\n",
      "    -114.61822   -114.61822   -114.61822   -114.61822  ]\n",
      "   [   5.206311     5.206311     5.206311     5.206311     5.206311\n",
      "       5.206311     5.206311     5.206311     5.206311     5.206311\n",
      "       5.206311     5.206311     5.206311     5.206311 ]]\n",
      "\n",
      "  [[-103.69654   -103.69654   -103.69654   -103.69654   -103.69654\n",
      "    -103.69654   -103.69654   -103.69654   -103.69654   -103.69654\n",
      "    -103.69654   -103.69654   -103.69654   -103.69654  ]\n",
      "   [  -1.2658191   -1.2658191   -1.2658191   -1.2658191   -1.2658191\n",
      "      -1.2658191   -1.2658191   -1.2658191   -1.2658191   -1.2658191\n",
      "      -1.2658191   -1.2658191   -1.2658191   -1.2658191]]\n",
      "\n",
      "  [[ -74.39059    -74.39059    -74.39059    -74.39059    -74.39059\n",
      "     -74.39059    -74.39059    -74.39059    -74.39059    -74.39059\n",
      "     -74.39059    -74.39059    -74.39059    -74.39059  ]\n",
      "   [ -17.116373   -17.116373   -17.116373   -17.116373   -17.116373\n",
      "     -17.116373   -17.116373   -17.116373   -17.116373   -17.116373\n",
      "     -17.116373   -17.116373   -17.116373   -17.116373 ]]]]\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape5-W_shape5-2-0] _\u001b[0m\n",
      "\n",
      "Z_shape = (3, 14, 14, 8), W_shape = (3, 3, 8, 16), stride = 2, padding = 0\n",
      "backward = True, device = cpu()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
      "      2.1704152   -0.38803983]\n",
      "   [  2.245844...2.618842     0.71487164]\n",
      "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
      "      0.03223436   2.0512383 ]]]])\n",
      "W_shape    = (3, 3, 8, 16)\n",
      "Wtch       = tensor([[[[  4.2827,   8.1336,  -4.6223,  ...,   2.0798,   2.1704,  -0.3880],\n",
      "          [  2.2458,  -0.6565,  -3.7547,...   0.7149],\n",
      "          [ -4.0937,   3.7292, -10.5518,  ...,   0.3174,   0.0322,   2.0512]]]],\n",
      "       requires_grad=True)\n",
      "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
      "     4.75044203e+00 -7.56786048e...3e+00]\n",
      "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
      "    -8.48226726e-01 -2.29984760e+00]]]])\n",
      "Z_shape    = (3, 14, 14, 8)\n",
      "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
      "            4.7504e+00, -7.5679e-01],\n",
      "          [...[ 1.0991e+01,  2.2317e+00,  4.6206e+00,  ..., -6.2309e-01,\n",
      "           -8.4823e-01, -2.2998e+00]]]], requires_grad=True)\n",
      "_W         = array([[[[  4.282669  ,   8.133604  ,  -4.6223483 , ...,   2.0798197 ,\n",
      "            2.1704152 ,  -0.38803983],\n",
      "        ... , -10.551835  , ...,   0.31741843,\n",
      "            0.03223436,   2.0512383 ]]]],\n",
      "      shape=(3, 3, 8, 16), dtype=float32)\n",
      "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
      "          -4.88638926e+00,  4.75044203e+00, -7.56786...9e+00, ...,\n",
      "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
      "      shape=(3, 14, 14, 8), dtype=float32)\n",
      "backward   = True\n",
      "device     = cpu()\n",
      "err1       = np.float32(0.00024521773)\n",
      "err2       = np.float32(0.0004235205)\n",
      "out        = tensor([[[[ -21.8508, -294.9621, -318.0497,   -4.7934,   59.4825, -104.8043],\n",
      "          [  14.3621,  303.2643, -221.53...          [ 183.8510, -115.7199,  115.7395, -105.5507,   75.9456, -171.5427]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(-4902.2178, grad_fn=<SumBackward0>)\n",
      "padding    = 0\n",
      "stride     = 2\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c56558bec0>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c565589b80>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c565589b80>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c565589b80>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c565589b80>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[ -11.502274    -11.502274    -11.502274   ...  -11.502274\n",
      "     -11.502274    -11.502274  ]\n",
      "   [  62.8993       62.8993       62.8993     ...   62.8993\n",
      "      62.8993       62.8993    ]\n",
      "   [-100.44479    -100.44479    -100.44479    ... -100.44479\n",
      "    -100.44479    -100.44479   ]\n",
      "   ...\n",
      "   [ -13.736942    -13.736942    -13.736942   ...  -13.736942\n",
      "     -13.736942    -13.736942  ]\n",
      "   [  78.40697      78.40697      78.40697    ...   78.40697\n",
      "      78.40697      78.40697   ]\n",
      "   [  24.560968     24.560968     24.560968   ...   24.560968\n",
      "      24.560968     24.560968  ]]\n",
      "\n",
      "  [[ -27.166206    -27.166206    -27.166206   ...  -27.166206\n",
      "     -27.166206    -27.166206  ]\n",
      "   [  25.632101     25.632101     25.632101   ...   25.632101\n",
      "      25.632101     25.632101  ]\n",
      "   [   0.74779034    0.74779034    0.74779034 ...    0.74779034\n",
      "       0.74779034    0.74779034]\n",
      "   ...\n",
      "   [-103.41879    -103.41879    -103.41879    ... -103.41879\n",
      "    -103.41879    -103.41879   ]\n",
      "   [  58.430935     58.430935     58.430935   ...   58.430935\n",
      "      58.430935     58.430935  ]\n",
      "   [ -85.70644     -85.70644     -85.70644    ...  -85.70644\n",
      "     -85.70644     -85.70644   ]]\n",
      "\n",
      "  [[  -5.995693     -5.995693     -5.995693   ...   -5.995693\n",
      "      -5.995693     -5.995693  ]\n",
      "   [  85.216736     85.216736     85.216736   ...   85.216736\n",
      "      85.216736     85.216736  ]\n",
      "   [-124.07959    -124.07959    -124.07959    ... -124.07959\n",
      "    -124.07959    -124.07959   ]\n",
      "   ...\n",
      "   [  -4.409664     -4.409664     -4.409664   ...   -4.409664\n",
      "      -4.409664     -4.409664  ]\n",
      "   [  39.95012      39.95012      39.95012    ...   39.95012\n",
      "      39.95012      39.95012   ]\n",
      "   [  16.65237      16.65237      16.65237    ...   16.65237\n",
      "      16.65237      16.65237   ]]]\n",
      "\n",
      "\n",
      " [[[ -20.037218    -20.037218    -20.037218   ...  -20.037218\n",
      "     -20.037218    -20.037218  ]\n",
      "   [ -51.90564     -51.90564     -51.90564    ...  -51.90564\n",
      "     -51.90564     -51.90564   ]\n",
      "   [ -69.36232     -69.36232     -69.36232    ...  -69.36232\n",
      "     -69.36232     -69.36232   ]\n",
      "   ...\n",
      "   [  48.133972     48.133972     48.133972   ...   48.133972\n",
      "      48.133972     48.133972  ]\n",
      "   [ -49.624535    -49.624535    -49.624535   ...  -49.624535\n",
      "     -49.624535    -49.624535  ]\n",
      "   [ -29.244823    -29.244823    -29.244823   ...  -29.244823\n",
      "     -29.244823    -29.244823  ]]\n",
      "\n",
      "  [[ -59.15782     -59.15782     -59.15782    ...  -59.15782\n",
      "     -59.15782     -59.15782   ]\n",
      "   [ -54.930824    -54.930824    -54.930824   ...  -54.930824\n",
      "     -54.930824    -54.930824  ]\n",
      "   [  85.35348      85.35348      85.35348    ...   85.35348\n",
      "      85.35348      85.35348   ]\n",
      "   ...\n",
      "   [ -25.570671    -25.570671    -25.570671   ...  -25.570671\n",
      "     -25.570671    -25.570671  ]\n",
      "   [  26.286785     26.286785     26.286785   ...   26.286785\n",
      "      26.286785     26.286785  ]\n",
      "   [ -73.07514     -73.07514     -73.07514    ...  -73.07514\n",
      "     -73.07514     -73.07514   ]]\n",
      "\n",
      "  [[  19.932663     19.932663     19.932663   ...   19.932663\n",
      "      19.932663     19.932663  ]\n",
      "   [ -68.87308     -68.87308     -68.87308    ...  -68.87308\n",
      "     -68.87308     -68.87308   ]\n",
      "   [ -22.123959    -22.123959    -22.123959   ...  -22.123959\n",
      "     -22.123959    -22.123959  ]\n",
      "   ...\n",
      "   [  -1.5130348    -1.5130348    -1.5130348  ...   -1.5130348\n",
      "      -1.5130348    -1.5130348 ]\n",
      "   [ -66.619514    -66.619514    -66.619514   ...  -66.619514\n",
      "     -66.619514    -66.619514  ]\n",
      "   [  -7.8152523    -7.8152523    -7.8152523  ...   -7.8152523\n",
      "      -7.8152523    -7.8152523 ]]]\n",
      "\n",
      "\n",
      " [[[ -21.069193    -21.069193    -21.069193   ...  -21.069193\n",
      "     -21.069193    -21.069193  ]\n",
      "   [ 102.67703     102.67703     102.67703    ...  102.67703\n",
      "     102.67703     102.67703   ]\n",
      "   [ -80.154976    -80.154976    -80.154976   ...  -80.154976\n",
      "     -80.154976    -80.154976  ]\n",
      "   ...\n",
      "   [ -48.183594    -48.183594    -48.183594   ...  -48.183594\n",
      "     -48.183594    -48.183594  ]\n",
      "   [  35.556923     35.556923     35.556923   ...   35.556923\n",
      "      35.556923     35.556923  ]\n",
      "   [  32.271282     32.271282     32.271282   ...   32.271282\n",
      "      32.271282     32.271282  ]]\n",
      "\n",
      "  [[ -20.159918    -20.159918    -20.159918   ...  -20.159918\n",
      "     -20.159918    -20.159918  ]\n",
      "   [  32.194687     32.194687     32.194687   ...   32.194687\n",
      "      32.194687     32.194687  ]\n",
      "   [   2.9036512     2.9036512     2.9036512  ...    2.9036512\n",
      "       2.9036512     2.9036512 ]\n",
      "   ...\n",
      "   [-158.83664    -158.83664    -158.83664    ... -158.83664\n",
      "    -158.83664    -158.83664   ]\n",
      "   [  76.52881      76.52881      76.52881    ...   76.52881\n",
      "      76.52881      76.52881   ]\n",
      "   [ -23.696804    -23.696804    -23.696804   ...  -23.696804\n",
      "     -23.696804    -23.696804  ]]\n",
      "\n",
      "  [[  -4.9794235    -4.9794235    -4.9794235  ...   -4.9794235\n",
      "      -4.9794235    -4.9794235 ]\n",
      "   [  83.83303      83.83303      83.83303    ...   83.83303\n",
      "      83.83303      83.83303   ]\n",
      "   [-100.39087    -100.39087    -100.39087    ... -100.39087\n",
      "    -100.39087    -100.39087   ]\n",
      "   ...\n",
      "   [ -27.357765    -27.357765    -27.357765   ...  -27.357765\n",
      "     -27.357765    -27.357765  ]\n",
      "   [   2.9134874     2.9134874     2.9134874  ...    2.9134874\n",
      "       2.9134874     2.9134874 ]\n",
      "   [  10.759153     10.759153     10.759153   ...   10.759153\n",
      "      10.759153     10.759153  ]]]], W.grad.numpy(): [[[[ -11.502268   -11.502268   -11.502268  ...  -11.502268\n",
      "     -11.502268   -11.502268 ]\n",
      "   [  62.899284    62.899284    62.899284  ...   62.899284\n",
      "      62.899284    62.899284 ]\n",
      "   [-100.44482   -100.44482   -100.44482   ... -100.44482\n",
      "    -100.44482   -100.44482  ]\n",
      "   ...\n",
      "   [ -13.736955   -13.736955   -13.736955  ...  -13.736955\n",
      "     -13.736955   -13.736955 ]\n",
      "   [  78.406975    78.406975    78.406975  ...   78.406975\n",
      "      78.406975    78.406975 ]\n",
      "   [  24.560974    24.560974    24.560974  ...   24.560974\n",
      "      24.560974    24.560974 ]]\n",
      "\n",
      "  [[ -27.166191   -27.166191   -27.166191  ...  -27.166191\n",
      "     -27.166191   -27.166191 ]\n",
      "   [  25.632097    25.632097    25.632097  ...   25.632097\n",
      "      25.632097    25.632097 ]\n",
      "   [   0.7477932    0.7477932    0.7477932 ...    0.7477932\n",
      "       0.7477932    0.7477932]\n",
      "   ...\n",
      "   [-103.418755  -103.418755  -103.418755  ... -103.418755\n",
      "    -103.418755  -103.418755 ]\n",
      "   [  58.43092     58.43092     58.43092   ...   58.43092\n",
      "      58.43092     58.43092  ]\n",
      "   [ -85.70646    -85.70646    -85.70646   ...  -85.70646\n",
      "     -85.70646    -85.70646  ]]\n",
      "\n",
      "  [[  -5.995689    -5.995689    -5.995689  ...   -5.995689\n",
      "      -5.995689    -5.995689 ]\n",
      "   [  85.21674     85.21674     85.21674   ...   85.21674\n",
      "      85.21674     85.21674  ]\n",
      "   [-124.07961   -124.07961   -124.07961   ... -124.07961\n",
      "    -124.07961   -124.07961  ]\n",
      "   ...\n",
      "   [  -4.409664    -4.409664    -4.409664  ...   -4.409664\n",
      "      -4.409664    -4.409664 ]\n",
      "   [  39.95011     39.95011     39.95011   ...   39.95011\n",
      "      39.95011     39.95011  ]\n",
      "   [  16.652382    16.652382    16.652382  ...   16.652382\n",
      "      16.652382    16.652382 ]]]\n",
      "\n",
      "\n",
      " [[[ -20.03723    -20.03723    -20.03723   ...  -20.03723\n",
      "     -20.03723    -20.03723  ]\n",
      "   [ -51.905624   -51.905624   -51.905624  ...  -51.905624\n",
      "     -51.905624   -51.905624 ]\n",
      "   [ -69.36233    -69.36233    -69.36233   ...  -69.36233\n",
      "     -69.36233    -69.36233  ]\n",
      "   ...\n",
      "   [  48.13397     48.13397     48.13397   ...   48.13397\n",
      "      48.13397     48.13397  ]\n",
      "   [ -49.62454    -49.62454    -49.62454   ...  -49.62454\n",
      "     -49.62454    -49.62454  ]\n",
      "   [ -29.244816   -29.244816   -29.244816  ...  -29.244816\n",
      "     -29.244816   -29.244816 ]]\n",
      "\n",
      "  [[ -59.157806   -59.157806   -59.157806  ...  -59.157806\n",
      "     -59.157806   -59.157806 ]\n",
      "   [ -54.930824   -54.930824   -54.930824  ...  -54.930824\n",
      "     -54.930824   -54.930824 ]\n",
      "   [  85.35345     85.35345     85.35345   ...   85.35345\n",
      "      85.35345     85.35345  ]\n",
      "   ...\n",
      "   [ -25.57068    -25.57068    -25.57068   ...  -25.57068\n",
      "     -25.57068    -25.57068  ]\n",
      "   [  26.286789    26.286789    26.286789  ...   26.286789\n",
      "      26.286789    26.286789 ]\n",
      "   [ -73.075134   -73.075134   -73.075134  ...  -73.075134\n",
      "     -73.075134   -73.075134 ]]\n",
      "\n",
      "  [[  19.932655    19.932655    19.932655  ...   19.932655\n",
      "      19.932655    19.932655 ]\n",
      "   [ -68.87306    -68.87306    -68.87306   ...  -68.87306\n",
      "     -68.87306    -68.87306  ]\n",
      "   [ -22.123955   -22.123955   -22.123955  ...  -22.123955\n",
      "     -22.123955   -22.123955 ]\n",
      "   ...\n",
      "   [  -1.5130291   -1.5130291   -1.5130291 ...   -1.5130291\n",
      "      -1.5130291   -1.5130291]\n",
      "   [ -66.61953    -66.61953    -66.61953   ...  -66.61953\n",
      "     -66.61953    -66.61953  ]\n",
      "   [  -7.8152647   -7.8152647   -7.8152647 ...   -7.8152647\n",
      "      -7.8152647   -7.8152647]]]\n",
      "\n",
      "\n",
      " [[[ -21.069185   -21.069185   -21.069185  ...  -21.069185\n",
      "     -21.069185   -21.069185 ]\n",
      "   [ 102.677      102.677      102.677     ...  102.677\n",
      "     102.677      102.677    ]\n",
      "   [ -80.15498    -80.15498    -80.15498   ...  -80.15498\n",
      "     -80.15498    -80.15498  ]\n",
      "   ...\n",
      "   [ -48.183586   -48.183586   -48.183586  ...  -48.183586\n",
      "     -48.183586   -48.183586 ]\n",
      "   [  35.556923    35.556923    35.556923  ...   35.556923\n",
      "      35.556923    35.556923 ]\n",
      "   [  32.271282    32.271282    32.271282  ...   32.271282\n",
      "      32.271282    32.271282 ]]\n",
      "\n",
      "  [[ -20.159916   -20.159916   -20.159916  ...  -20.159916\n",
      "     -20.159916   -20.159916 ]\n",
      "   [  32.194683    32.194683    32.194683  ...   32.194683\n",
      "      32.194683    32.194683 ]\n",
      "   [   2.9036572    2.9036572    2.9036572 ...    2.9036572\n",
      "       2.9036572    2.9036572]\n",
      "   ...\n",
      "   [-158.83665   -158.83665   -158.83665   ... -158.83665\n",
      "    -158.83665   -158.83665  ]\n",
      "   [  76.5288      76.5288      76.5288    ...   76.5288\n",
      "      76.5288      76.5288   ]\n",
      "   [ -23.696812   -23.696812   -23.696812  ...  -23.696812\n",
      "     -23.696812   -23.696812 ]]\n",
      "\n",
      "  [[  -4.979428    -4.979428    -4.979428  ...   -4.979428\n",
      "      -4.979428    -4.979428 ]\n",
      "   [  83.833015    83.833015    83.833015  ...   83.833015\n",
      "      83.833015    83.833015 ]\n",
      "   [-100.390884  -100.390884  -100.390884  ... -100.390884\n",
      "    -100.390884  -100.390884 ]\n",
      "   ...\n",
      "   [ -27.35774    -27.35774    -27.35774   ...  -27.35774\n",
      "     -27.35774    -27.35774  ]\n",
      "   [   2.9134922    2.9134922    2.9134922 ...    2.9134922\n",
      "       2.9134922    2.9134922]\n",
      "   [  10.759179    10.759179    10.759179  ...   10.759179\n",
      "      10.759179    10.759179 ]]]]\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape6-W_shape6-2-1] _\u001b[0m\n",
      "\n",
      "Z_shape = (3, 14, 14, 8), W_shape = (3, 3, 8, 16), stride = 2, padding = 1\n",
      "backward = True, device = cpu()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
      "      2.1704152   -0.38803983]\n",
      "   [  2.245844...2.618842     0.71487164]\n",
      "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
      "      0.03223436   2.0512383 ]]]])\n",
      "W_shape    = (3, 3, 8, 16)\n",
      "Wtch       = tensor([[[[  4.2827,   8.1336,  -4.6223,  ...,   2.0798,   2.1704,  -0.3880],\n",
      "          [  2.2458,  -0.6565,  -3.7547,...   0.7149],\n",
      "          [ -4.0937,   3.7292, -10.5518,  ...,   0.3174,   0.0322,   2.0512]]]],\n",
      "       requires_grad=True)\n",
      "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
      "     4.75044203e+00 -7.56786048e...3e+00]\n",
      "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
      "    -8.48226726e-01 -2.29984760e+00]]]])\n",
      "Z_shape    = (3, 14, 14, 8)\n",
      "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
      "            4.7504e+00, -7.5679e-01],\n",
      "          [...[ 1.0991e+01,  2.2317e+00,  4.6206e+00,  ..., -6.2309e-01,\n",
      "           -8.4823e-01, -2.2998e+00]]]], requires_grad=True)\n",
      "_W         = array([[[[  4.282669  ,   8.133604  ,  -4.6223483 , ...,   2.0798197 ,\n",
      "            2.1704152 ,  -0.38803983],\n",
      "        ... , -10.551835  , ...,   0.31741843,\n",
      "            0.03223436,   2.0512383 ]]]],\n",
      "      shape=(3, 3, 8, 16), dtype=float32)\n",
      "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
      "          -4.88638926e+00,  4.75044203e+00, -7.56786...9e+00, ...,\n",
      "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
      "      shape=(3, 14, 14, 8), dtype=float32)\n",
      "backward   = True\n",
      "device     = cpu()\n",
      "err1       = np.float32(0.00028906864)\n",
      "err2       = np.float32(0.0004183153)\n",
      "out        = tensor([[[[ 1.0725e+02, -9.3744e+00,  2.7834e+02,  ..., -9.7155e+01,\n",
      "            1.3371e+02,  1.2725e+02],\n",
      "          [...,  5.7277e+02,  2.3476e+01,  ..., -2.1788e+02,\n",
      "           -1.8747e+02,  2.0660e+02]]]], grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(4313.9385, grad_fn=<SumBackward0>)\n",
      "padding    = 1\n",
      "stride     = 2\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c5655d6510>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655d77a0>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655d77a0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655d77a0>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655d77a0>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[ -59.15782    -59.15782    -59.15782   ...  -59.15782\n",
      "     -59.15782    -59.15782  ]\n",
      "   [ -54.930824   -54.930824   -54.930824  ...  -54.930824\n",
      "     -54.930824   -54.930824 ]\n",
      "   [  85.35348     85.35348     85.35348   ...   85.35348\n",
      "      85.35348     85.35348  ]\n",
      "   ...\n",
      "   [ -25.570671   -25.570671   -25.570671  ...  -25.570671\n",
      "     -25.570671   -25.570671 ]\n",
      "   [  26.286785    26.286785    26.286785  ...   26.286785\n",
      "      26.286785    26.286785 ]\n",
      "   [ -73.07514    -73.07514    -73.07514   ...  -73.07514\n",
      "     -73.07514    -73.07514  ]]\n",
      "\n",
      "  [[   4.4485264    4.4485264    4.4485264 ...    4.4485264\n",
      "       4.4485264    4.4485264]\n",
      "   [ -47.475483   -47.475483   -47.475483  ...  -47.475483\n",
      "     -47.475483   -47.475483 ]\n",
      "   [ -55.44758    -55.44758    -55.44758   ...  -55.44758\n",
      "     -55.44758    -55.44758  ]\n",
      "   ...\n",
      "   [  16.823595    16.823595    16.823595  ...   16.823595\n",
      "      16.823595    16.823595 ]\n",
      "   [ -76.023636   -76.023636   -76.023636  ...  -76.023636\n",
      "     -76.023636   -76.023636 ]\n",
      "   [ -42.504787   -42.504787   -42.504787  ...  -42.504787\n",
      "     -42.504787   -42.504787 ]]\n",
      "\n",
      "  [[ -54.476036   -54.476036   -54.476036  ...  -54.476036\n",
      "     -54.476036   -54.476036 ]\n",
      "   [ -39.680813   -39.680813   -39.680813  ...  -39.680813\n",
      "     -39.680813   -39.680813 ]\n",
      "   [  62.144325    62.144325    62.144325  ...   62.144325\n",
      "      62.144325    62.144325 ]\n",
      "   ...\n",
      "   [ -26.804808   -26.804808   -26.804808  ...  -26.804808\n",
      "     -26.804808   -26.804808 ]\n",
      "   [   7.073829     7.073829     7.073829  ...    7.073829\n",
      "       7.073829     7.073829 ]\n",
      "   [ -91.69252    -91.69252    -91.69252   ...  -91.69252\n",
      "     -91.69252    -91.69252  ]]]\n",
      "\n",
      "\n",
      " [[[  -2.852354    -2.852354    -2.852354  ...   -2.852354\n",
      "      -2.852354    -2.852354 ]\n",
      "   [  32.647278    32.647278    32.647278  ...   32.647278\n",
      "      32.647278    32.647278 ]\n",
      "   [ -12.749463   -12.749463   -12.749463  ...  -12.749463\n",
      "     -12.749463   -12.749463 ]\n",
      "   ...\n",
      "   [-127.388695  -127.388695  -127.388695  ... -127.388695\n",
      "    -127.388695  -127.388695 ]\n",
      "   [  64.75354     64.75354     64.75354   ...   64.75354\n",
      "      64.75354     64.75354  ]\n",
      "   [ -68.51874    -68.51874    -68.51874   ...  -68.51874\n",
      "     -68.51874    -68.51874  ]]\n",
      "\n",
      "  [[ -21.69799    -21.69799    -21.69799   ...  -21.69799\n",
      "     -21.69799    -21.69799  ]\n",
      "   [ 116.6776     116.6776     116.6776    ...  116.6776\n",
      "     116.6776     116.6776   ]\n",
      "   [-122.28533   -122.28533   -122.28533   ... -122.28533\n",
      "    -122.28533   -122.28533  ]\n",
      "   ...\n",
      "   [ -23.221539   -23.221539   -23.221539  ...  -23.221539\n",
      "     -23.221539   -23.221539 ]\n",
      "   [  -5.507147    -5.507147    -5.507147  ...   -5.507147\n",
      "      -5.507147    -5.507147 ]\n",
      "   [  32.978374    32.978374    32.978374  ...   32.978374\n",
      "      32.978374    32.978374 ]]\n",
      "\n",
      "  [[ -10.996902   -10.996902   -10.996902  ...  -10.996902\n",
      "     -10.996902   -10.996902 ]\n",
      "   [  45.05992     45.05992     45.05992   ...   45.05992\n",
      "      45.05992     45.05992  ]\n",
      "   [  12.558756    12.558756    12.558756  ...   12.558756\n",
      "      12.558756    12.558756 ]\n",
      "   ...\n",
      "   [-103.91963   -103.91963   -103.91963   ... -103.91963\n",
      "    -103.91963   -103.91963  ]\n",
      "   [  57.74255     57.74255     57.74255   ...   57.74255\n",
      "      57.74255     57.74255  ]\n",
      "   [ -70.708984   -70.708984   -70.708984  ...  -70.708984\n",
      "     -70.708984   -70.708984 ]]]\n",
      "\n",
      "\n",
      " [[[ -63.368553   -63.368553   -63.368553  ...  -63.368553\n",
      "     -63.368553   -63.368553 ]\n",
      "   [ -87.75679    -87.75679    -87.75679   ...  -87.75679\n",
      "     -87.75679    -87.75679  ]\n",
      "   [ 100.16784    100.16784    100.16784   ...  100.16784\n",
      "     100.16784    100.16784  ]\n",
      "   ...\n",
      "   [ -46.96363    -46.96363    -46.96363   ...  -46.96363\n",
      "     -46.96363    -46.96363  ]\n",
      "   [  38.047874    38.047874    38.047874  ...   38.047874\n",
      "      38.047874    38.047874 ]\n",
      "   [ -47.247185   -47.247185   -47.247185  ...  -47.247185\n",
      "     -47.247185   -47.247185 ]]\n",
      "\n",
      "  [[  12.512623    12.512623    12.512623  ...   12.512623\n",
      "      12.512623    12.512623 ]\n",
      "   [ -24.680618   -24.680618   -24.680618  ...  -24.680618\n",
      "     -24.680618   -24.680618 ]\n",
      "   [ -78.09189    -78.09189    -78.09189   ...  -78.09189\n",
      "     -78.09189    -78.09189  ]\n",
      "   ...\n",
      "   [  20.306242    20.306242    20.306242  ...   20.306242\n",
      "      20.306242    20.306242 ]\n",
      "   [-101.22749   -101.22749   -101.22749   ... -101.22749\n",
      "    -101.22749   -101.22749  ]\n",
      "   [ -37.777832   -37.777832   -37.777832  ...  -37.777832\n",
      "     -37.777832   -37.777832 ]]\n",
      "\n",
      "  [[ -39.68747    -39.68747    -39.68747   ...  -39.68747\n",
      "     -39.68747    -39.68747  ]\n",
      "   [ -76.38612    -76.38612    -76.38612   ...  -76.38612\n",
      "     -76.38612    -76.38612  ]\n",
      "   [  72.96721     72.96721     72.96721   ...   72.96721\n",
      "      72.96721     72.96721  ]\n",
      "   ...\n",
      "   [ -51.404034   -51.404034   -51.404034  ...  -51.404034\n",
      "     -51.404034   -51.404034 ]\n",
      "   [  15.85468     15.85468     15.85468   ...   15.85468\n",
      "      15.85468     15.85468  ]\n",
      "   [ -74.01355    -74.01355    -74.01355   ...  -74.01355\n",
      "     -74.01355    -74.01355  ]]]], W.grad.numpy(): [[[[ -59.157806   -59.157806   -59.157806  ...  -59.157806\n",
      "     -59.157806   -59.157806 ]\n",
      "   [ -54.930824   -54.930824   -54.930824  ...  -54.930824\n",
      "     -54.930824   -54.930824 ]\n",
      "   [  85.35345     85.35345     85.35345   ...   85.35345\n",
      "      85.35345     85.35345  ]\n",
      "   ...\n",
      "   [ -25.57068    -25.57068    -25.57068   ...  -25.57068\n",
      "     -25.57068    -25.57068  ]\n",
      "   [  26.286789    26.286789    26.286789  ...   26.286789\n",
      "      26.286789    26.286789 ]\n",
      "   [ -73.075134   -73.075134   -73.075134  ...  -73.075134\n",
      "     -73.075134   -73.075134 ]]\n",
      "\n",
      "  [[   4.448524     4.448524     4.448524  ...    4.448524\n",
      "       4.448524     4.448524 ]\n",
      "   [ -47.475468   -47.475468   -47.475468  ...  -47.475468\n",
      "     -47.475468   -47.475468 ]\n",
      "   [ -55.44758    -55.44758    -55.44758   ...  -55.44758\n",
      "     -55.44758    -55.44758  ]\n",
      "   ...\n",
      "   [  16.8236      16.8236      16.8236    ...   16.8236\n",
      "      16.8236      16.8236   ]\n",
      "   [ -76.023636   -76.023636   -76.023636  ...  -76.023636\n",
      "     -76.023636   -76.023636 ]\n",
      "   [ -42.504776   -42.504776   -42.504776  ...  -42.504776\n",
      "     -42.504776   -42.504776 ]]\n",
      "\n",
      "  [[ -54.476036   -54.476036   -54.476036  ...  -54.476036\n",
      "     -54.476036   -54.476036 ]\n",
      "   [ -39.680798   -39.680798   -39.680798  ...  -39.680798\n",
      "     -39.680798   -39.680798 ]\n",
      "   [  62.144302    62.144302    62.144302  ...   62.144302\n",
      "      62.144302    62.144302 ]\n",
      "   ...\n",
      "   [ -26.804815   -26.804815   -26.804815  ...  -26.804815\n",
      "     -26.804815   -26.804815 ]\n",
      "   [   7.073834     7.073834     7.073834  ...    7.073834\n",
      "       7.073834     7.073834 ]\n",
      "   [ -91.69253    -91.69253    -91.69253   ...  -91.69253\n",
      "     -91.69253    -91.69253  ]]]\n",
      "\n",
      "\n",
      " [[[  -2.8523357   -2.8523357   -2.8523357 ...   -2.8523357\n",
      "      -2.8523357   -2.8523357]\n",
      "   [  32.647274    32.647274    32.647274  ...   32.647274\n",
      "      32.647274    32.647274 ]\n",
      "   [ -12.749461   -12.749461   -12.749461  ...  -12.749461\n",
      "     -12.749461   -12.749461 ]\n",
      "   ...\n",
      "   [-127.388664  -127.388664  -127.388664  ... -127.388664\n",
      "    -127.388664  -127.388664 ]\n",
      "   [  64.75352     64.75352     64.75352   ...   64.75352\n",
      "      64.75352     64.75352  ]\n",
      "   [ -68.518745   -68.518745   -68.518745  ...  -68.518745\n",
      "     -68.518745   -68.518745 ]]\n",
      "\n",
      "  [[ -21.697983   -21.697983   -21.697983  ...  -21.697983\n",
      "     -21.697983   -21.697983 ]\n",
      "   [ 116.67762    116.67762    116.67762   ...  116.67762\n",
      "     116.67762    116.67762  ]\n",
      "   [-122.285324  -122.285324  -122.285324  ... -122.285324\n",
      "    -122.285324  -122.285324 ]\n",
      "   ...\n",
      "   [ -23.221544   -23.221544   -23.221544  ...  -23.221544\n",
      "     -23.221544   -23.221544 ]\n",
      "   [  -5.5071487   -5.5071487   -5.5071487 ...   -5.5071487\n",
      "      -5.5071487   -5.5071487]\n",
      "   [  32.97837     32.97837     32.97837   ...   32.97837\n",
      "      32.97837     32.97837  ]]\n",
      "\n",
      "  [[ -10.996884   -10.996884   -10.996884  ...  -10.996884\n",
      "     -10.996884   -10.996884 ]\n",
      "   [  45.059917    45.059917    45.059917  ...   45.059917\n",
      "      45.059917    45.059917 ]\n",
      "   [  12.558748    12.558748    12.558748  ...   12.558748\n",
      "      12.558748    12.558748 ]\n",
      "   ...\n",
      "   [-103.91965   -103.91965   -103.91965   ... -103.91965\n",
      "    -103.91965   -103.91965  ]\n",
      "   [  57.742542    57.742542    57.742542  ...   57.742542\n",
      "      57.742542    57.742542 ]\n",
      "   [ -70.708984   -70.708984   -70.708984  ...  -70.708984\n",
      "     -70.708984   -70.708984 ]]]\n",
      "\n",
      "\n",
      " [[[ -63.36854    -63.36854    -63.36854   ...  -63.36854\n",
      "     -63.36854    -63.36854  ]\n",
      "   [ -87.756805   -87.756805   -87.756805  ...  -87.756805\n",
      "     -87.756805   -87.756805 ]\n",
      "   [ 100.1678     100.1678     100.1678    ...  100.1678\n",
      "     100.1678     100.1678   ]\n",
      "   ...\n",
      "   [ -46.963646   -46.963646   -46.963646  ...  -46.963646\n",
      "     -46.963646   -46.963646 ]\n",
      "   [  38.047882    38.047882    38.047882  ...   38.047882\n",
      "      38.047882    38.047882 ]\n",
      "   [ -47.247173   -47.247173   -47.247173  ...  -47.247173\n",
      "     -47.247173   -47.247173 ]]\n",
      "\n",
      "  [[  12.512624    12.512624    12.512624  ...   12.512624\n",
      "      12.512624    12.512624 ]\n",
      "   [ -24.680601   -24.680601   -24.680601  ...  -24.680601\n",
      "     -24.680601   -24.680601 ]\n",
      "   [ -78.09188    -78.09188    -78.09188   ...  -78.09188\n",
      "     -78.09188    -78.09188  ]\n",
      "   ...\n",
      "   [  20.306244    20.306244    20.306244  ...   20.306244\n",
      "      20.306244    20.306244 ]\n",
      "   [-101.22749   -101.22749   -101.22749   ... -101.22749\n",
      "    -101.22749   -101.22749  ]\n",
      "   [ -37.777817   -37.777817   -37.777817  ...  -37.777817\n",
      "     -37.777817   -37.777817 ]]\n",
      "\n",
      "  [[ -39.687473   -39.687473   -39.687473  ...  -39.687473\n",
      "     -39.687473   -39.687473 ]\n",
      "   [ -76.38611    -76.38611    -76.38611   ...  -76.38611\n",
      "     -76.38611    -76.38611  ]\n",
      "   [  72.96718     72.96718     72.96718   ...   72.96718\n",
      "      72.96718     72.96718  ]\n",
      "   ...\n",
      "   [ -51.404037   -51.404037   -51.404037  ...  -51.404037\n",
      "     -51.404037   -51.404037 ]\n",
      "   [  15.854685    15.854685    15.854685  ...   15.854685\n",
      "      15.854685    15.854685 ]\n",
      "   [ -74.013565   -74.013565   -74.013565  ...  -74.013565\n",
      "     -74.013565   -74.013565 ]]]]\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape7-W_shape7-2-2] _\u001b[0m\n",
      "\n",
      "Z_shape = (3, 16, 16, 8), W_shape = (3, 3, 8, 16), stride = 2, padding = 2\n",
      "backward = True, device = cpu()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[  0.40910086  -0.64982927  11.320294   ...  -0.12077556\n",
      "      1.428692    -5.5845156 ]\n",
      "   [ -6.89178...-1.5437248  -10.136281  ]\n",
      "   [  1.1511405    0.7441038   16.463472   ...  -6.8931007\n",
      "     -0.5833115   -2.504636  ]]]])\n",
      "W_shape    = (3, 3, 8, 16)\n",
      "Wtch       = tensor([[[[  0.4091,  -0.6498,  11.3203,  ...,  -0.1208,   1.4287,  -5.5845],\n",
      "          [ -6.8918,  -9.3836,  10.6335,... -10.1363],\n",
      "          [  1.1511,   0.7441,  16.4635,  ...,  -6.8931,  -0.5833,  -2.5046]]]],\n",
      "       requires_grad=True)\n",
      "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
      "     4.75044203e+00 -7.56786048e...5e+00]\n",
      "   [ 6.10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
      "     3.33514667e+00 -1.35630560e+00]]]])\n",
      "Z_shape    = (3, 16, 16, 8)\n",
      "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
      "            4.7504e+00, -7.5679e-01],\n",
      "          [...[ 6.1037e+00, -2.0543e+00, -4.4138e+00,  ..., -6.1525e+00,\n",
      "            3.3351e+00, -1.3563e+00]]]], requires_grad=True)\n",
      "_W         = array([[[[  0.40910086,  -0.64982927,  11.320294  , ...,  -0.12077556,\n",
      "            1.428692  ,  -5.5845156 ],\n",
      "        ... ,  16.463472  , ...,  -6.8931007 ,\n",
      "           -0.5833115 ,  -2.504636  ]]]],\n",
      "      shape=(3, 3, 8, 16), dtype=float32)\n",
      "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
      "          -4.88638926e+00,  4.75044203e+00, -7.56786...6e+00, ...,\n",
      "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
      "      shape=(3, 16, 16, 8), dtype=float32)\n",
      "backward   = True\n",
      "device     = cpu()\n",
      "err1       = np.float32(0.00040186255)\n",
      "err2       = np.float32(0.0005360778)\n",
      "out        = tensor([[[[-6.3835e+01,  7.0442e+01, -1.5787e+02,  ..., -1.1571e+02,\n",
      "            2.7167e+02,  2.9473e+01],\n",
      "          [...,  1.5725e+02, -4.1424e+01,  ...,  1.6422e+02,\n",
      "            1.0298e+02,  8.0763e+01]]]], grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(-8988.4932, grad_fn=<SumBackward0>)\n",
      "padding    = 2\n",
      "stride     = 2\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c5655fdd60>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655fe7b0>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655fe7b0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655fe7b0>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655fe7b0>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[  23.270412     23.270412     23.270412   ...   23.270412\n",
      "      23.270412     23.270412  ]\n",
      "   [  47.964565     47.964565     47.964565   ...   47.964565\n",
      "      47.964565     47.964565  ]\n",
      "   [-199.55396    -199.55396    -199.55396    ... -199.55396\n",
      "    -199.55396    -199.55396   ]\n",
      "   ...\n",
      "   [ -20.288277    -20.288277    -20.288277   ...  -20.288277\n",
      "     -20.288277    -20.288277  ]\n",
      "   [  55.916107     55.916107     55.916107   ...   55.916107\n",
      "      55.916107     55.916107  ]\n",
      "   [ -74.69081     -74.69081     -74.69081    ...  -74.69081\n",
      "     -74.69081     -74.69081   ]]\n",
      "\n",
      "  [[  19.853985     19.853985     19.853985   ...   19.853985\n",
      "      19.853985     19.853985  ]\n",
      "   [ -55.841957    -55.841957    -55.841957   ...  -55.841957\n",
      "     -55.841957    -55.841957  ]\n",
      "   [  91.77676      91.77676      91.77676    ...   91.77676\n",
      "      91.77676      91.77676   ]\n",
      "   ...\n",
      "   [ -23.842733    -23.842733    -23.842733   ...  -23.842733\n",
      "     -23.842733    -23.842733  ]\n",
      "   [ -17.848866    -17.848866    -17.848866   ...  -17.848866\n",
      "     -17.848866    -17.848866  ]\n",
      "   [-139.37263    -139.37263    -139.37263    ... -139.37263\n",
      "    -139.37263    -139.37263   ]]\n",
      "\n",
      "  [[  23.270412     23.270412     23.270412   ...   23.270412\n",
      "      23.270412     23.270412  ]\n",
      "   [  47.964565     47.964565     47.964565   ...   47.964565\n",
      "      47.964565     47.964565  ]\n",
      "   [-199.55396    -199.55396    -199.55396    ... -199.55396\n",
      "    -199.55396    -199.55396   ]\n",
      "   ...\n",
      "   [ -20.288277    -20.288277    -20.288277   ...  -20.288277\n",
      "     -20.288277    -20.288277  ]\n",
      "   [  55.916107     55.916107     55.916107   ...   55.916107\n",
      "      55.916107     55.916107  ]\n",
      "   [ -74.69081     -74.69081     -74.69081    ...  -74.69081\n",
      "     -74.69081     -74.69081   ]]]\n",
      "\n",
      "\n",
      " [[[ -50.711723    -50.711723    -50.711723   ...  -50.711723\n",
      "     -50.711723    -50.711723  ]\n",
      "   [  26.546358     26.546358     26.546358   ...   26.546358\n",
      "      26.546358     26.546358  ]\n",
      "   [ -41.690857    -41.690857    -41.690857   ...  -41.690857\n",
      "     -41.690857    -41.690857  ]\n",
      "   ...\n",
      "   [  58.001217     58.001217     58.001217   ...   58.001217\n",
      "      58.001217     58.001217  ]\n",
      "   [-131.91515    -131.91515    -131.91515    ... -131.91515\n",
      "    -131.91515    -131.91515   ]\n",
      "   [  -0.42793083   -0.42793083   -0.42793083 ...   -0.42793083\n",
      "      -0.42793083   -0.42793083]]\n",
      "\n",
      "  [[ -41.042408    -41.042408    -41.042408   ...  -41.042408\n",
      "     -41.042408    -41.042408  ]\n",
      "   [ -26.126831    -26.126831    -26.126831   ...  -26.126831\n",
      "     -26.126831    -26.126831  ]\n",
      "   [  46.335087     46.335087     46.335087   ...   46.335087\n",
      "      46.335087     46.335087  ]\n",
      "   ...\n",
      "   [ -86.61835     -86.61835     -86.61835    ...  -86.61835\n",
      "     -86.61835     -86.61835   ]\n",
      "   [  63.583405     63.583405     63.583405   ...   63.583405\n",
      "      63.583405     63.583405  ]\n",
      "   [  -9.2516365    -9.2516365    -9.2516365  ...   -9.2516365\n",
      "      -9.2516365    -9.2516365 ]]\n",
      "\n",
      "  [[ -50.711723    -50.711723    -50.711723   ...  -50.711723\n",
      "     -50.711723    -50.711723  ]\n",
      "   [  26.546358     26.546358     26.546358   ...   26.546358\n",
      "      26.546358     26.546358  ]\n",
      "   [ -41.690857    -41.690857    -41.690857   ...  -41.690857\n",
      "     -41.690857    -41.690857  ]\n",
      "   ...\n",
      "   [  58.001217     58.001217     58.001217   ...   58.001217\n",
      "      58.001217     58.001217  ]\n",
      "   [-131.91515    -131.91515    -131.91515    ... -131.91515\n",
      "    -131.91515    -131.91515   ]\n",
      "   [  -0.42793083   -0.42793083   -0.42793083 ...   -0.42793083\n",
      "      -0.42793083   -0.42793083]]]\n",
      "\n",
      "\n",
      " [[[  23.270412     23.270412     23.270412   ...   23.270412\n",
      "      23.270412     23.270412  ]\n",
      "   [  47.964565     47.964565     47.964565   ...   47.964565\n",
      "      47.964565     47.964565  ]\n",
      "   [-199.55396    -199.55396    -199.55396    ... -199.55396\n",
      "    -199.55396    -199.55396   ]\n",
      "   ...\n",
      "   [ -20.288277    -20.288277    -20.288277   ...  -20.288277\n",
      "     -20.288277    -20.288277  ]\n",
      "   [  55.916107     55.916107     55.916107   ...   55.916107\n",
      "      55.916107     55.916107  ]\n",
      "   [ -74.69081     -74.69081     -74.69081    ...  -74.69081\n",
      "     -74.69081     -74.69081   ]]\n",
      "\n",
      "  [[  19.853985     19.853985     19.853985   ...   19.853985\n",
      "      19.853985     19.853985  ]\n",
      "   [ -55.841957    -55.841957    -55.841957   ...  -55.841957\n",
      "     -55.841957    -55.841957  ]\n",
      "   [  91.77676      91.77676      91.77676    ...   91.77676\n",
      "      91.77676      91.77676   ]\n",
      "   ...\n",
      "   [ -23.842733    -23.842733    -23.842733   ...  -23.842733\n",
      "     -23.842733    -23.842733  ]\n",
      "   [ -17.848866    -17.848866    -17.848866   ...  -17.848866\n",
      "     -17.848866    -17.848866  ]\n",
      "   [-139.37263    -139.37263    -139.37263    ... -139.37263\n",
      "    -139.37263    -139.37263   ]]\n",
      "\n",
      "  [[  23.270412     23.270412     23.270412   ...   23.270412\n",
      "      23.270412     23.270412  ]\n",
      "   [  47.964565     47.964565     47.964565   ...   47.964565\n",
      "      47.964565     47.964565  ]\n",
      "   [-199.55396    -199.55396    -199.55396    ... -199.55396\n",
      "    -199.55396    -199.55396   ]\n",
      "   ...\n",
      "   [ -20.288277    -20.288277    -20.288277   ...  -20.288277\n",
      "     -20.288277    -20.288277  ]\n",
      "   [  55.916107     55.916107     55.916107   ...   55.916107\n",
      "      55.916107     55.916107  ]\n",
      "   [ -74.69081     -74.69081     -74.69081    ...  -74.69081\n",
      "     -74.69081     -74.69081   ]]]], W.grad.numpy(): [[[[  23.270412    23.270412    23.270412  ...   23.270412\n",
      "      23.270412    23.270412 ]\n",
      "   [  47.964546    47.964546    47.964546  ...   47.964546\n",
      "      47.964546    47.964546 ]\n",
      "   [-199.55397   -199.55397   -199.55397   ... -199.55397\n",
      "    -199.55397   -199.55397  ]\n",
      "   ...\n",
      "   [ -20.288273   -20.288273   -20.288273  ...  -20.288273\n",
      "     -20.288273   -20.288273 ]\n",
      "   [  55.9161      55.9161      55.9161    ...   55.9161\n",
      "      55.9161      55.9161   ]\n",
      "   [ -74.69081    -74.69081    -74.69081   ...  -74.69081\n",
      "     -74.69081    -74.69081  ]]\n",
      "\n",
      "  [[  19.85399     19.85399     19.85399   ...   19.85399\n",
      "      19.85399     19.85399  ]\n",
      "   [ -55.841965   -55.841965   -55.841965  ...  -55.841965\n",
      "     -55.841965   -55.841965 ]\n",
      "   [  91.776764    91.776764    91.776764  ...   91.776764\n",
      "      91.776764    91.776764 ]\n",
      "   ...\n",
      "   [ -23.842733   -23.842733   -23.842733  ...  -23.842733\n",
      "     -23.842733   -23.842733 ]\n",
      "   [ -17.848883   -17.848883   -17.848883  ...  -17.848883\n",
      "     -17.848883   -17.848883 ]\n",
      "   [-139.37262   -139.37262   -139.37262   ... -139.37262\n",
      "    -139.37262   -139.37262  ]]\n",
      "\n",
      "  [[  23.270412    23.270412    23.270412  ...   23.270412\n",
      "      23.270412    23.270412 ]\n",
      "   [  47.964546    47.964546    47.964546  ...   47.964546\n",
      "      47.964546    47.964546 ]\n",
      "   [-199.55397   -199.55397   -199.55397   ... -199.55397\n",
      "    -199.55397   -199.55397  ]\n",
      "   ...\n",
      "   [ -20.288273   -20.288273   -20.288273  ...  -20.288273\n",
      "     -20.288273   -20.288273 ]\n",
      "   [  55.9161      55.9161      55.9161    ...   55.9161\n",
      "      55.9161      55.9161   ]\n",
      "   [ -74.69081    -74.69081    -74.69081   ...  -74.69081\n",
      "     -74.69081    -74.69081  ]]]\n",
      "\n",
      "\n",
      " [[[ -50.71173    -50.71173    -50.71173   ...  -50.71173\n",
      "     -50.71173    -50.71173  ]\n",
      "   [  26.546333    26.546333    26.546333  ...   26.546333\n",
      "      26.546333    26.546333 ]\n",
      "   [ -41.690865   -41.690865   -41.690865  ...  -41.690865\n",
      "     -41.690865   -41.690865 ]\n",
      "   ...\n",
      "   [  58.001232    58.001232    58.001232  ...   58.001232\n",
      "      58.001232    58.001232 ]\n",
      "   [-131.91515   -131.91515   -131.91515   ... -131.91515\n",
      "    -131.91515   -131.91515  ]\n",
      "   [  -0.4279189   -0.4279189   -0.4279189 ...   -0.4279189\n",
      "      -0.4279189   -0.4279189]]\n",
      "\n",
      "  [[ -41.04242    -41.04242    -41.04242   ...  -41.04242\n",
      "     -41.04242    -41.04242  ]\n",
      "   [ -26.126842   -26.126842   -26.126842  ...  -26.126842\n",
      "     -26.126842   -26.126842 ]\n",
      "   [  46.3351      46.3351      46.3351    ...   46.3351\n",
      "      46.3351      46.3351   ]\n",
      "   ...\n",
      "   [ -86.61837    -86.61837    -86.61837   ...  -86.61837\n",
      "     -86.61837    -86.61837  ]\n",
      "   [  63.58337     63.58337     63.58337   ...   63.58337\n",
      "      63.58337     63.58337  ]\n",
      "   [  -9.251638    -9.251638    -9.251638  ...   -9.251638\n",
      "      -9.251638    -9.251638 ]]\n",
      "\n",
      "  [[ -50.71173    -50.71173    -50.71173   ...  -50.71173\n",
      "     -50.71173    -50.71173  ]\n",
      "   [  26.546333    26.546333    26.546333  ...   26.546333\n",
      "      26.546333    26.546333 ]\n",
      "   [ -41.690865   -41.690865   -41.690865  ...  -41.690865\n",
      "     -41.690865   -41.690865 ]\n",
      "   ...\n",
      "   [  58.001232    58.001232    58.001232  ...   58.001232\n",
      "      58.001232    58.001232 ]\n",
      "   [-131.91515   -131.91515   -131.91515   ... -131.91515\n",
      "    -131.91515   -131.91515  ]\n",
      "   [  -0.4279189   -0.4279189   -0.4279189 ...   -0.4279189\n",
      "      -0.4279189   -0.4279189]]]\n",
      "\n",
      "\n",
      " [[[  23.270412    23.270412    23.270412  ...   23.270412\n",
      "      23.270412    23.270412 ]\n",
      "   [  47.964546    47.964546    47.964546  ...   47.964546\n",
      "      47.964546    47.964546 ]\n",
      "   [-199.55397   -199.55397   -199.55397   ... -199.55397\n",
      "    -199.55397   -199.55397  ]\n",
      "   ...\n",
      "   [ -20.288273   -20.288273   -20.288273  ...  -20.288273\n",
      "     -20.288273   -20.288273 ]\n",
      "   [  55.9161      55.9161      55.9161    ...   55.9161\n",
      "      55.9161      55.9161   ]\n",
      "   [ -74.69081    -74.69081    -74.69081   ...  -74.69081\n",
      "     -74.69081    -74.69081  ]]\n",
      "\n",
      "  [[  19.85399     19.85399     19.85399   ...   19.85399\n",
      "      19.85399     19.85399  ]\n",
      "   [ -55.841965   -55.841965   -55.841965  ...  -55.841965\n",
      "     -55.841965   -55.841965 ]\n",
      "   [  91.776764    91.776764    91.776764  ...   91.776764\n",
      "      91.776764    91.776764 ]\n",
      "   ...\n",
      "   [ -23.842733   -23.842733   -23.842733  ...  -23.842733\n",
      "     -23.842733   -23.842733 ]\n",
      "   [ -17.848883   -17.848883   -17.848883  ...  -17.848883\n",
      "     -17.848883   -17.848883 ]\n",
      "   [-139.37262   -139.37262   -139.37262   ... -139.37262\n",
      "    -139.37262   -139.37262  ]]\n",
      "\n",
      "  [[  23.270412    23.270412    23.270412  ...   23.270412\n",
      "      23.270412    23.270412 ]\n",
      "   [  47.964546    47.964546    47.964546  ...   47.964546\n",
      "      47.964546    47.964546 ]\n",
      "   [-199.55397   -199.55397   -199.55397   ... -199.55397\n",
      "    -199.55397   -199.55397  ]\n",
      "   ...\n",
      "   [ -20.288273   -20.288273   -20.288273  ...  -20.288273\n",
      "     -20.288273   -20.288273 ]\n",
      "   [  55.9161      55.9161      55.9161    ...   55.9161\n",
      "      55.9161      55.9161   ]\n",
      "   [ -74.69081    -74.69081    -74.69081   ...  -74.69081\n",
      "     -74.69081    -74.69081  ]]]]\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape8-W_shape8-2-0] _\u001b[0m\n",
      "\n",
      "Z_shape = (3, 16, 16, 8), W_shape = (3, 3, 8, 14), stride = 2, padding = 0\n",
      "backward = True, device = cpu()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[ 4.09100860e-01 -6.49829268e-01  1.13202944e+01 ... -5.56089449e+00\n",
      "    -4.84385538e+00 -1.20775558e...5e+00]\n",
      "   [-1.10714078e+00  2.54448557e+00 -7.73867989e+00 ... -1.13336074e+00\n",
      "    -1.21658230e+00 -4.79330921e+00]]]])\n",
      "W_shape    = (3, 3, 8, 14)\n",
      "Wtch       = tensor([[[[ 4.0910e-01, -6.4983e-01,  1.1320e+01,  ..., -5.5609e+00,\n",
      "           -4.8439e+00, -1.2078e-01],\n",
      "          [...[-1.1071e+00,  2.5445e+00, -7.7387e+00,  ..., -1.1334e+00,\n",
      "           -1.2166e+00, -4.7933e+00]]]], requires_grad=True)\n",
      "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
      "     4.75044203e+00 -7.56786048e...5e+00]\n",
      "   [ 6.10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
      "     3.33514667e+00 -1.35630560e+00]]]])\n",
      "Z_shape    = (3, 16, 16, 8)\n",
      "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
      "            4.7504e+00, -7.5679e-01],\n",
      "          [...[ 6.1037e+00, -2.0543e+00, -4.4138e+00,  ..., -6.1525e+00,\n",
      "            3.3351e+00, -1.3563e+00]]]], requires_grad=True)\n",
      "_W         = array([[[[ 4.09100860e-01, -6.49829268e-01,  1.13202944e+01, ...,\n",
      "          -5.56089449e+00, -4.84385538e+00, -1.20775...89e+00, ...,\n",
      "          -1.13336074e+00, -1.21658230e+00, -4.79330921e+00]]]],\n",
      "      shape=(3, 3, 8, 14), dtype=float32)\n",
      "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
      "          -4.88638926e+00,  4.75044203e+00, -7.56786...6e+00, ...,\n",
      "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
      "      shape=(3, 16, 16, 8), dtype=float32)\n",
      "backward   = True\n",
      "device     = cpu()\n",
      "err1       = np.float32(0.00026534157)\n",
      "err2       = np.float32(0.0005267183)\n",
      "out        = tensor([[[[   5.7346,  -55.9106,  320.3619,  ..., -472.6719,  -63.6798,\n",
      "            226.2005],\n",
      "          [ -39.7949, -...[ -34.6254, -262.0989, -192.8079,  ..., -480.3307,  172.4242,\n",
      "            163.7107]]]], grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(10302.4697, grad_fn=<SumBackward0>)\n",
      "padding    = 0\n",
      "stride     = 2\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c5655d5e80>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655d6270>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655d6270>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655d6270>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655d6270>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[  30.547173    30.547173    30.547173  ...   30.547173\n",
      "      30.547173    30.547173 ]\n",
      "   [  53.469177    53.469177    53.469177  ...   53.469177\n",
      "      53.469177    53.469177 ]\n",
      "   [-145.9325    -145.9325    -145.9325    ... -145.9325\n",
      "    -145.9325    -145.9325   ]\n",
      "   ...\n",
      "   [ -14.513361   -14.513361   -14.513361  ...  -14.513361\n",
      "     -14.513361   -14.513361 ]\n",
      "   [  15.266685    15.266685    15.266685  ...   15.266685\n",
      "      15.266685    15.266685 ]\n",
      "   [ -13.076628   -13.076628   -13.076628  ...  -13.076628\n",
      "     -13.076628   -13.076628 ]]\n",
      "\n",
      "  [[ -68.17785    -68.17785    -68.17785   ...  -68.17785\n",
      "     -68.17785    -68.17785  ]\n",
      "   [ -15.384946   -15.384946   -15.384946  ...  -15.384946\n",
      "     -15.384946   -15.384946 ]\n",
      "   [  83.73863     83.73863     83.73863   ...   83.73863\n",
      "      83.73863     83.73863  ]\n",
      "   ...\n",
      "   [  18.319536    18.319536    18.319536  ...   18.319536\n",
      "      18.319536    18.319536 ]\n",
      "   [  25.439444    25.439444    25.439444  ...   25.439444\n",
      "      25.439444    25.439444 ]\n",
      "   [ -96.62114    -96.62114    -96.62114   ...  -96.62114\n",
      "     -96.62114    -96.62114  ]]\n",
      "\n",
      "  [[   5.77079      5.77079      5.77079   ...    5.77079\n",
      "       5.77079      5.77079  ]\n",
      "   [  72.89382     72.89382     72.89382   ...   72.89382\n",
      "      72.89382     72.89382  ]\n",
      "   [-127.521706  -127.521706  -127.521706  ... -127.521706\n",
      "    -127.521706  -127.521706 ]\n",
      "   ...\n",
      "   [   4.302202     4.302202     4.302202  ...    4.302202\n",
      "       4.302202     4.302202 ]\n",
      "   [  -5.5214      -5.5214      -5.5214    ...   -5.5214\n",
      "      -5.5214      -5.5214   ]\n",
      "   [ -33.545734   -33.545734   -33.545734  ...  -33.545734\n",
      "     -33.545734   -33.545734 ]]]\n",
      "\n",
      "\n",
      " [[[ -73.30465    -73.30465    -73.30465   ...  -73.30465\n",
      "     -73.30465    -73.30465  ]\n",
      "   [  65.06516     65.06516     65.06516   ...   65.06516\n",
      "      65.06516     65.06516  ]\n",
      "   [  20.936012    20.936012    20.936012  ...   20.936012\n",
      "      20.936012    20.936012 ]\n",
      "   ...\n",
      "   [ -21.802673   -21.802673   -21.802673  ...  -21.802673\n",
      "     -21.802673   -21.802673 ]\n",
      "   [-117.2268    -117.2268    -117.2268    ... -117.2268\n",
      "    -117.2268    -117.2268   ]\n",
      "   [  17.847662    17.847662    17.847662  ...   17.847662\n",
      "      17.847662    17.847662 ]]\n",
      "\n",
      "  [[ -90.858345   -90.858345   -90.858345  ...  -90.858345\n",
      "     -90.858345   -90.858345 ]\n",
      "   [  -8.076708    -8.076708    -8.076708  ...   -8.076708\n",
      "      -8.076708    -8.076708 ]\n",
      "   [  75.35593     75.35593     75.35593   ...   75.35593\n",
      "      75.35593     75.35593  ]\n",
      "   ...\n",
      "   [ -29.262634   -29.262634   -29.262634  ...  -29.262634\n",
      "     -29.262634   -29.262634 ]\n",
      "   [  74.468475    74.468475    74.468475  ...   74.468475\n",
      "      74.468475    74.468475 ]\n",
      "   [ -15.215542   -15.215542   -15.215542  ...  -15.215542\n",
      "     -15.215542   -15.215542 ]]\n",
      "\n",
      "  [[ -79.51456    -79.51456    -79.51456   ...  -79.51456\n",
      "     -79.51456    -79.51456  ]\n",
      "   [  52.29492     52.29492     52.29492   ...   52.29492\n",
      "      52.29492     52.29492  ]\n",
      "   [  11.921398    11.921398    11.921398  ...   11.921398\n",
      "      11.921398    11.921398 ]\n",
      "   ...\n",
      "   [  26.79831     26.79831     26.79831   ...   26.79831\n",
      "      26.79831     26.79831  ]\n",
      "   [-137.8027    -137.8027    -137.8027    ... -137.8027\n",
      "    -137.8027    -137.8027   ]\n",
      "   [ -33.372818   -33.372818   -33.372818  ...  -33.372818\n",
      "     -33.372818   -33.372818 ]]]\n",
      "\n",
      "\n",
      " [[[  43.01931     43.01931     43.01931   ...   43.01931\n",
      "      43.01931     43.01931  ]\n",
      "   [  49.998737    49.998737    49.998737  ...   49.998737\n",
      "      49.998737    49.998737 ]\n",
      "   [-152.49677   -152.49677   -152.49677   ... -152.49677\n",
      "    -152.49677   -152.49677  ]\n",
      "   ...\n",
      "   [ -15.748844   -15.748844   -15.748844  ...  -15.748844\n",
      "     -15.748844   -15.748844 ]\n",
      "   [  31.96638     31.96638     31.96638   ...   31.96638\n",
      "      31.96638     31.96638  ]\n",
      "   [ -43.587334   -43.587334   -43.587334  ...  -43.587334\n",
      "     -43.587334   -43.587334 ]]\n",
      "\n",
      "  [[  -8.004757    -8.004757    -8.004757  ...   -8.004757\n",
      "      -8.004757    -8.004757 ]\n",
      "   [ -18.425175   -18.425175   -18.425175  ...  -18.425175\n",
      "     -18.425175   -18.425175 ]\n",
      "   [  86.11835     86.11835     86.11835   ...   86.11835\n",
      "      86.11835     86.11835  ]\n",
      "   ...\n",
      "   [ -19.514685   -19.514685   -19.514685  ...  -19.514685\n",
      "     -19.514685   -19.514685 ]\n",
      "   [ -21.324108   -21.324108   -21.324108  ...  -21.324108\n",
      "     -21.324108   -21.324108 ]\n",
      "   [-150.30342   -150.30342   -150.30342   ... -150.30342\n",
      "    -150.30342   -150.30342  ]]\n",
      "\n",
      "  [[  59.669495    59.669495    59.669495  ...   59.669495\n",
      "      59.669495    59.669495 ]\n",
      "   [  71.17648     71.17648     71.17648   ...   71.17648\n",
      "      71.17648     71.17648  ]\n",
      "   [-128.95201   -128.95201   -128.95201   ... -128.95201\n",
      "    -128.95201   -128.95201  ]\n",
      "   ...\n",
      "   [   8.888981     8.888981     8.888981  ...    8.888981\n",
      "       8.888981     8.888981 ]\n",
      "   [   7.3665056    7.3665056    7.3665056 ...    7.3665056\n",
      "       7.3665056    7.3665056]\n",
      "   [ -79.82819    -79.82819    -79.82819   ...  -79.82819\n",
      "     -79.82819    -79.82819  ]]]], W.grad.numpy(): [[[[  30.547167    30.547167    30.547167  ...   30.547167\n",
      "      30.547167    30.547167 ]\n",
      "   [  53.469166    53.469166    53.469166  ...   53.469166\n",
      "      53.469166    53.469166 ]\n",
      "   [-145.9325    -145.9325    -145.9325    ... -145.9325\n",
      "    -145.9325    -145.9325   ]\n",
      "   ...\n",
      "   [ -14.513368   -14.513368   -14.513368  ...  -14.513368\n",
      "     -14.513368   -14.513368 ]\n",
      "   [  15.266677    15.266677    15.266677  ...   15.266677\n",
      "      15.266677    15.266677 ]\n",
      "   [ -13.076618   -13.076618   -13.076618  ...  -13.076618\n",
      "     -13.076618   -13.076618 ]]\n",
      "\n",
      "  [[ -68.17786    -68.17786    -68.17786   ...  -68.17786\n",
      "     -68.17786    -68.17786  ]\n",
      "   [ -15.38494    -15.38494    -15.38494   ...  -15.38494\n",
      "     -15.38494    -15.38494  ]\n",
      "   [  83.738625    83.738625    83.738625  ...   83.738625\n",
      "      83.738625    83.738625 ]\n",
      "   ...\n",
      "   [  18.319536    18.319536    18.319536  ...   18.319536\n",
      "      18.319536    18.319536 ]\n",
      "   [  25.43943     25.43943     25.43943   ...   25.43943\n",
      "      25.43943     25.43943  ]\n",
      "   [ -96.62115    -96.62115    -96.62115   ...  -96.62115\n",
      "     -96.62115    -96.62115  ]]\n",
      "\n",
      "  [[   5.770788     5.770788     5.770788  ...    5.770788\n",
      "       5.770788     5.770788 ]\n",
      "   [  72.893814    72.893814    72.893814  ...   72.893814\n",
      "      72.893814    72.893814 ]\n",
      "   [-127.52174   -127.52174   -127.52174   ... -127.52174\n",
      "    -127.52174   -127.52174  ]\n",
      "   ...\n",
      "   [   4.302189     4.302189     4.302189  ...    4.302189\n",
      "       4.302189     4.302189 ]\n",
      "   [  -5.5214043   -5.5214043   -5.5214043 ...   -5.5214043\n",
      "      -5.5214043   -5.5214043]\n",
      "   [ -33.545734   -33.545734   -33.545734  ...  -33.545734\n",
      "     -33.545734   -33.545734 ]]]\n",
      "\n",
      "\n",
      " [[[ -73.30466    -73.30466    -73.30466   ...  -73.30466\n",
      "     -73.30466    -73.30466  ]\n",
      "   [  65.06517     65.06517     65.06517   ...   65.06517\n",
      "      65.06517     65.06517  ]\n",
      "   [  20.935993    20.935993    20.935993  ...   20.935993\n",
      "      20.935993    20.935993 ]\n",
      "   ...\n",
      "   [ -21.802668   -21.802668   -21.802668  ...  -21.802668\n",
      "     -21.802668   -21.802668 ]\n",
      "   [-117.22675   -117.22675   -117.22675   ... -117.22675\n",
      "    -117.22675   -117.22675  ]\n",
      "   [  17.847658    17.847658    17.847658  ...   17.847658\n",
      "      17.847658    17.847658 ]]\n",
      "\n",
      "  [[ -90.85834    -90.85834    -90.85834   ...  -90.85834\n",
      "     -90.85834    -90.85834  ]\n",
      "   [  -8.076723    -8.076723    -8.076723  ...   -8.076723\n",
      "      -8.076723    -8.076723 ]\n",
      "   [  75.3559      75.3559      75.3559    ...   75.3559\n",
      "      75.3559      75.3559   ]\n",
      "   ...\n",
      "   [ -29.262629   -29.262629   -29.262629  ...  -29.262629\n",
      "     -29.262629   -29.262629 ]\n",
      "   [  74.46847     74.46847     74.46847   ...   74.46847\n",
      "      74.46847     74.46847  ]\n",
      "   [ -15.215537   -15.215537   -15.215537  ...  -15.215537\n",
      "     -15.215537   -15.215537 ]]\n",
      "\n",
      "  [[ -79.51458    -79.51458    -79.51458   ...  -79.51458\n",
      "     -79.51458    -79.51458  ]\n",
      "   [  52.29493     52.29493     52.29493   ...   52.29493\n",
      "      52.29493     52.29493  ]\n",
      "   [  11.92141     11.92141     11.92141   ...   11.92141\n",
      "      11.92141     11.92141  ]\n",
      "   ...\n",
      "   [  26.798307    26.798307    26.798307  ...   26.798307\n",
      "      26.798307    26.798307 ]\n",
      "   [-137.80272   -137.80272   -137.80272   ... -137.80272\n",
      "    -137.80272   -137.80272  ]\n",
      "   [ -33.37282    -33.37282    -33.37282   ...  -33.37282\n",
      "     -33.37282    -33.37282  ]]]\n",
      "\n",
      "\n",
      " [[[  43.019302    43.019302    43.019302  ...   43.019302\n",
      "      43.019302    43.019302 ]\n",
      "   [  49.998714    49.998714    49.998714  ...   49.998714\n",
      "      49.998714    49.998714 ]\n",
      "   [-152.49683   -152.49683   -152.49683   ... -152.49683\n",
      "    -152.49683   -152.49683  ]\n",
      "   ...\n",
      "   [ -15.7488365  -15.7488365  -15.7488365 ...  -15.7488365\n",
      "     -15.7488365  -15.7488365]\n",
      "   [  31.966372    31.966372    31.966372  ...   31.966372\n",
      "      31.966372    31.966372 ]\n",
      "   [ -43.587345   -43.587345   -43.587345  ...  -43.587345\n",
      "     -43.587345   -43.587345 ]]\n",
      "\n",
      "  [[  -8.0047455   -8.0047455   -8.0047455 ...   -8.0047455\n",
      "      -8.0047455   -8.0047455]\n",
      "   [ -18.425167   -18.425167   -18.425167  ...  -18.425167\n",
      "     -18.425167   -18.425167 ]\n",
      "   [  86.11836     86.11836     86.11836   ...   86.11836\n",
      "      86.11836     86.11836  ]\n",
      "   ...\n",
      "   [ -19.51469    -19.51469    -19.51469   ...  -19.51469\n",
      "     -19.51469    -19.51469  ]\n",
      "   [ -21.32413    -21.32413    -21.32413   ...  -21.32413\n",
      "     -21.32413    -21.32413  ]\n",
      "   [-150.30345   -150.30345   -150.30345   ... -150.30345\n",
      "    -150.30345   -150.30345  ]]\n",
      "\n",
      "  [[  59.669487    59.669487    59.669487  ...   59.669487\n",
      "      59.669487    59.669487 ]\n",
      "   [  71.1765      71.1765      71.1765    ...   71.1765\n",
      "      71.1765      71.1765   ]\n",
      "   [-128.95201   -128.95201   -128.95201   ... -128.95201\n",
      "    -128.95201   -128.95201  ]\n",
      "   ...\n",
      "   [   8.888977     8.888977     8.888977  ...    8.888977\n",
      "       8.888977     8.888977 ]\n",
      "   [   7.3665347    7.3665347    7.3665347 ...    7.3665347\n",
      "       7.3665347    7.3665347]\n",
      "   [ -79.828186   -79.828186   -79.828186  ...  -79.828186\n",
      "     -79.828186   -79.828186 ]]]]\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape9-W_shape9-2-0] _\u001b[0m\n",
      "\n",
      "Z_shape = (3, 16, 16, 2), W_shape = (3, 3, 2, 14), stride = 2, padding = 0\n",
      "backward = True, device = cpu()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[ -8.0968      -2.5552022    8.703147    -1.4674252    4.5861077\n",
      "     -0.28521433   4.383634    -9.13...727333   0.22582927   9.296732    -8.13161     -0.67411226\n",
      "     -2.9204676    1.675528   -12.187821     5.5746226 ]]]])\n",
      "W_shape    = (3, 3, 2, 14)\n",
      "Wtch       = tensor([[[[ -8.0968,  -2.5552,   8.7031,  -1.4674,   4.5861,  -0.2852,   4.3836,\n",
      "            -9.1346,  -2.0159,   4.74...0.2258,\n",
      "             9.2967,  -8.1316,  -0.6741,  -2.9205,   1.6755, -12.1878,   5.5746]]]],\n",
      "       requires_grad=True)\n",
      "Z          = needle.Tensor([[[[  8.820262     2.000786  ]\n",
      "   [  4.89369     11.204466  ]\n",
      "   [  9.33779     -4.8863893 ]\n",
      "   ...\n",
      "   [...   -5.112822  ]\n",
      "   ...\n",
      "   [ -7.922368     4.2222714 ]\n",
      "   [ -6.064339     1.4188478 ]\n",
      "   [ -1.4109794   -5.791016  ]]]])\n",
      "Z_shape    = (3, 16, 16, 2)\n",
      "Ztch       = tensor([[[[  8.8203,   2.0008],\n",
      "          [  4.8937,  11.2045],\n",
      "          [  9.3378,  -4.8864],\n",
      "          ...,\n",
      "       ...\n",
      "          [ -7.9224,   4.2223],\n",
      "          [ -6.0643,   1.4188],\n",
      "          [ -1.4110,  -5.7910]]]], requires_grad=True)\n",
      "_W         = array([[[[ -8.0968    ,  -2.5552022 ,   8.703147  ,  -1.4674252 ,\n",
      "            4.5861077 ,  -0.28521433,   4.383634  , ...        -8.13161   ,  -0.67411226,  -2.9204676 ,   1.675528  ,\n",
      "          -12.187821  ,   5.5746226 ]]]], dtype=float32)\n",
      "_Z         = array([[[[  8.820262  ,   2.000786  ],\n",
      "         [  4.89369   ,  11.204466  ],\n",
      "         [  9.33779   ,  -4.8863893 ],\n",
      " ...     [ -6.064339  ,   1.4188478 ],\n",
      "         [ -1.4109794 ,  -5.791016  ]]]],\n",
      "      shape=(3, 16, 16, 2), dtype=float32)\n",
      "backward   = True\n",
      "device     = cpu()\n",
      "err1       = np.float32(0.00010036767)\n",
      "err2       = np.float32(0.0002815359)\n",
      "out        = tensor([[[[-3.4607e+02,  6.3506e+01, -3.3188e+01,  ...,  1.9525e+02,\n",
      "            1.2715e+02, -5.7875e+01],\n",
      "          [..., -1.1399e+02, -6.9067e+01,  ..., -1.4515e+02,\n",
      "            5.3236e+01,  3.2069e+00]]]], grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(-2297.1741, grad_fn=<SumBackward0>)\n",
      "padding    = 0\n",
      "stride     = 2\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c5655fc980>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655fd7c0>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655fd7c0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655fd7c0>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655fd7c0>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[ -31.111084  -31.111084  -31.111084  -31.111084  -31.111084\n",
      "     -31.111084  -31.111084  -31.111084  -31.111084  -31.111084\n",
      "     -31.111084  -31.111084  -31.111084  -31.111084]\n",
      "   [ -72.39707   -72.39707   -72.39707   -72.39707   -72.39707\n",
      "     -72.39707   -72.39707   -72.39707   -72.39707   -72.39707\n",
      "     -72.39707   -72.39707   -72.39707   -72.39707 ]]\n",
      "\n",
      "  [[  37.540268   37.540268   37.540268   37.540268   37.540268\n",
      "      37.540268   37.540268   37.540268   37.540268   37.540268\n",
      "      37.540268   37.540268   37.540268   37.540268]\n",
      "   [ -10.707729  -10.707729  -10.707729  -10.707729  -10.707729\n",
      "     -10.707729  -10.707729  -10.707729  -10.707729  -10.707729\n",
      "     -10.707729  -10.707729  -10.707729  -10.707729]]\n",
      "\n",
      "  [[ -44.690792  -44.690792  -44.690792  -44.690792  -44.690792\n",
      "     -44.690792  -44.690792  -44.690792  -44.690792  -44.690792\n",
      "     -44.690792  -44.690792  -44.690792  -44.690792]\n",
      "   [ -24.869858  -24.869858  -24.869858  -24.869858  -24.869858\n",
      "     -24.869858  -24.869858  -24.869858  -24.869858  -24.869858\n",
      "     -24.869858  -24.869858  -24.869858  -24.869858]]]\n",
      "\n",
      "\n",
      " [[[ -22.76244   -22.76244   -22.76244   -22.76244   -22.76244\n",
      "     -22.76244   -22.76244   -22.76244   -22.76244   -22.76244\n",
      "     -22.76244   -22.76244   -22.76244   -22.76244 ]\n",
      "   [ -81.52185   -81.52185   -81.52185   -81.52185   -81.52185\n",
      "     -81.52185   -81.52185   -81.52185   -81.52185   -81.52185\n",
      "     -81.52185   -81.52185   -81.52185   -81.52185 ]]\n",
      "\n",
      "  [[ -51.949696  -51.949696  -51.949696  -51.949696  -51.949696\n",
      "     -51.949696  -51.949696  -51.949696  -51.949696  -51.949696\n",
      "     -51.949696  -51.949696  -51.949696  -51.949696]\n",
      "   [  46.37689    46.37689    46.37689    46.37689    46.37689\n",
      "      46.37689    46.37689    46.37689    46.37689    46.37689\n",
      "      46.37689    46.37689    46.37689    46.37689 ]]\n",
      "\n",
      "  [[  -8.752304   -8.752304   -8.752304   -8.752304   -8.752304\n",
      "      -8.752304   -8.752304   -8.752304   -8.752304   -8.752304\n",
      "      -8.752304   -8.752304   -8.752304   -8.752304]\n",
      "   [-106.538734 -106.538734 -106.538734 -106.538734 -106.538734\n",
      "    -106.538734 -106.538734 -106.538734 -106.538734 -106.538734\n",
      "    -106.538734 -106.538734 -106.538734 -106.538734]]]\n",
      "\n",
      "\n",
      " [[[ -93.654     -93.654     -93.654     -93.654     -93.654\n",
      "     -93.654     -93.654     -93.654     -93.654     -93.654\n",
      "     -93.654     -93.654     -93.654     -93.654   ]\n",
      "   [ -47.379856  -47.379856  -47.379856  -47.379856  -47.379856\n",
      "     -47.379856  -47.379856  -47.379856  -47.379856  -47.379856\n",
      "     -47.379856  -47.379856  -47.379856  -47.379856]]\n",
      "\n",
      "  [[  19.678679   19.678679   19.678679   19.678679   19.678679\n",
      "      19.678679   19.678679   19.678679   19.678679   19.678679\n",
      "      19.678679   19.678679   19.678679   19.678679]\n",
      "   [  21.823034   21.823034   21.823034   21.823034   21.823034\n",
      "      21.823034   21.823034   21.823034   21.823034   21.823034\n",
      "      21.823034   21.823034   21.823034   21.823034]]\n",
      "\n",
      "  [[ -86.55904   -86.55904   -86.55904   -86.55904   -86.55904\n",
      "     -86.55904   -86.55904   -86.55904   -86.55904   -86.55904\n",
      "     -86.55904   -86.55904   -86.55904   -86.55904 ]\n",
      "   [ -27.33389   -27.33389   -27.33389   -27.33389   -27.33389\n",
      "     -27.33389   -27.33389   -27.33389   -27.33389   -27.33389\n",
      "     -27.33389   -27.33389   -27.33389   -27.33389 ]]]], W.grad.numpy(): [[[[ -31.11108   -31.11108   -31.11108   -31.11108   -31.11108\n",
      "     -31.11108   -31.11108   -31.11108   -31.11108   -31.11108\n",
      "     -31.11108   -31.11108   -31.11108   -31.11108 ]\n",
      "   [ -72.39707   -72.39707   -72.39707   -72.39707   -72.39707\n",
      "     -72.39707   -72.39707   -72.39707   -72.39707   -72.39707\n",
      "     -72.39707   -72.39707   -72.39707   -72.39707 ]]\n",
      "\n",
      "  [[  37.54029    37.54029    37.54029    37.54029    37.54029\n",
      "      37.54029    37.54029    37.54029    37.54029    37.54029\n",
      "      37.54029    37.54029    37.54029    37.54029 ]\n",
      "   [ -10.707729  -10.707729  -10.707729  -10.707729  -10.707729\n",
      "     -10.707729  -10.707729  -10.707729  -10.707729  -10.707729\n",
      "     -10.707729  -10.707729  -10.707729  -10.707729]]\n",
      "\n",
      "  [[ -44.6908    -44.6908    -44.6908    -44.6908    -44.6908\n",
      "     -44.6908    -44.6908    -44.6908    -44.6908    -44.6908\n",
      "     -44.6908    -44.6908    -44.6908    -44.6908  ]\n",
      "   [ -24.869854  -24.869854  -24.869854  -24.869854  -24.869854\n",
      "     -24.869854  -24.869854  -24.869854  -24.869854  -24.869854\n",
      "     -24.869854  -24.869854  -24.869854  -24.869854]]]\n",
      "\n",
      "\n",
      " [[[ -22.762438  -22.762438  -22.762438  -22.762438  -22.762438\n",
      "     -22.762438  -22.762438  -22.762438  -22.762438  -22.762438\n",
      "     -22.762438  -22.762438  -22.762438  -22.762438]\n",
      "   [ -81.52182   -81.52182   -81.52182   -81.52182   -81.52182\n",
      "     -81.52182   -81.52182   -81.52182   -81.52182   -81.52182\n",
      "     -81.52182   -81.52182   -81.52182   -81.52182 ]]\n",
      "\n",
      "  [[ -51.949703  -51.949703  -51.949703  -51.949703  -51.949703\n",
      "     -51.949703  -51.949703  -51.949703  -51.949703  -51.949703\n",
      "     -51.949703  -51.949703  -51.949703  -51.949703]\n",
      "   [  46.376892   46.376892   46.376892   46.376892   46.376892\n",
      "      46.376892   46.376892   46.376892   46.376892   46.376892\n",
      "      46.376892   46.376892   46.376892   46.376892]]\n",
      "\n",
      "  [[  -8.752316   -8.752316   -8.752316   -8.752316   -8.752316\n",
      "      -8.752316   -8.752316   -8.752316   -8.752316   -8.752316\n",
      "      -8.752316   -8.752316   -8.752316   -8.752316]\n",
      "   [-106.53872  -106.53872  -106.53872  -106.53872  -106.53872\n",
      "    -106.53872  -106.53872  -106.53872  -106.53872  -106.53872\n",
      "    -106.53872  -106.53872  -106.53872  -106.53872 ]]]\n",
      "\n",
      "\n",
      " [[[ -93.65402   -93.65402   -93.65402   -93.65402   -93.65402\n",
      "     -93.65402   -93.65402   -93.65402   -93.65402   -93.65402\n",
      "     -93.65402   -93.65402   -93.65402   -93.65402 ]\n",
      "   [ -47.37984   -47.37984   -47.37984   -47.37984   -47.37984\n",
      "     -47.37984   -47.37984   -47.37984   -47.37984   -47.37984\n",
      "     -47.37984   -47.37984   -47.37984   -47.37984 ]]\n",
      "\n",
      "  [[  19.678682   19.678682   19.678682   19.678682   19.678682\n",
      "      19.678682   19.678682   19.678682   19.678682   19.678682\n",
      "      19.678682   19.678682   19.678682   19.678682]\n",
      "   [  21.823029   21.823029   21.823029   21.823029   21.823029\n",
      "      21.823029   21.823029   21.823029   21.823029   21.823029\n",
      "      21.823029   21.823029   21.823029   21.823029]]\n",
      "\n",
      "  [[ -86.55898   -86.55898   -86.55898   -86.55898   -86.55898\n",
      "     -86.55898   -86.55898   -86.55898   -86.55898   -86.55898\n",
      "     -86.55898   -86.55898   -86.55898   -86.55898 ]\n",
      "   [ -27.33389   -27.33389   -27.33389   -27.33389   -27.33389\n",
      "     -27.33389   -27.33389   -27.33389   -27.33389   -27.33389\n",
      "     -27.33389   -27.33389   -27.33389   -27.33389 ]]]]\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape10-W_shape10-1-0] _\u001b[0m\n",
      "\n",
      "Z_shape = (3, 16, 16, 24), W_shape = (3, 3, 24, 14), stride = 1, padding = 0\n",
      "backward = True, device = cpu()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[ -1.3245817    1.0111231   -1.9236585  ...  -2.5907016\n",
      "     -0.36175704   4.6234684 ]\n",
      "   [  5.279258... -4.82095      4.98517   ]\n",
      "   [  3.2300415   -2.4161792   -3.420825   ...  -9.444658\n",
      "      8.537833     2.3818388 ]]]])\n",
      "W_shape    = (3, 3, 24, 14)\n",
      "Wtch       = tensor([[[[ -1.3246,   1.0111,  -1.9237,  ...,  -2.5907,  -0.3618,   4.6235],\n",
      "          [  5.2793,  -1.3090,   0.0500,...   4.9852],\n",
      "          [  3.2300,  -2.4162,  -3.4208,  ...,  -9.4447,   8.5378,   2.3818]]]],\n",
      "       requires_grad=True)\n",
      "Z          = needle.Tensor([[[[  8.820262     2.000786     4.89369    ...   3.2680929\n",
      "      4.322181    -3.7108252 ]\n",
      "   [ 11.348773...4.207389     8.935435  ]\n",
      "   [  2.5084004    3.1399443   -0.12958507 ...   0.13740699\n",
      "     -1.400853     0.07475674]]]])\n",
      "Z_shape    = (3, 16, 16, 24)\n",
      "Ztch       = tensor([[[[  8.8203,   2.0008,   4.8937,  ...,   3.2681,   4.3222,  -3.7108],\n",
      "          [ 11.3488,  -7.2718,   0.2288,...   8.9354],\n",
      "          [  2.5084,   3.1399,  -0.1296,  ...,   0.1374,  -1.4009,   0.0748]]]],\n",
      "       requires_grad=True)\n",
      "_W         = array([[[[ -1.3245817 ,   1.0111231 ,  -1.9236585 , ...,  -2.5907016 ,\n",
      "           -0.36175704,   4.6234684 ],\n",
      "        ...,  -3.420825  , ...,  -9.444658  ,\n",
      "            8.537833  ,   2.3818388 ]]]],\n",
      "      shape=(3, 3, 24, 14), dtype=float32)\n",
      "_Z         = array([[[[  8.820262  ,   2.000786  ,   4.89369   , ...,   3.2680929 ,\n",
      "            4.322181  ,  -3.7108252 ],\n",
      "        ...  -0.12958507, ...,   0.13740699,\n",
      "           -1.400853  ,   0.07475674]]]],\n",
      "      shape=(3, 16, 16, 24), dtype=float32)\n",
      "backward   = True\n",
      "device     = cpu()\n",
      "err1       = np.float32(0.001412236)\n",
      "err2       = np.float32(0.0039917207)\n",
      "out        = tensor([[[[ 5.9644e+02,  1.7622e+01, -3.8665e+02,  ..., -5.6437e+02,\n",
      "           -1.4383e+02, -1.2310e+02],\n",
      "          [..., -6.6977e+02,  7.6359e+00,  ...,  3.7344e+02,\n",
      "           -8.9822e+01,  1.5355e+02]]]], grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(-5941.3750, grad_fn=<SumBackward0>)\n",
      "padding    = 0\n",
      "stride     = 1\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c56558be90>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655895b0>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655895b0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655895b0>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655895b0>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[  99.66556     99.66556     99.66556   ...   99.66556\n",
      "      99.66556     99.66556  ]\n",
      "   [-104.73128   -104.73128   -104.73128   ... -104.73128\n",
      "    -104.73128   -104.73128  ]\n",
      "   [   6.4298763    6.4298763    6.4298763 ...    6.4298763\n",
      "       6.4298763    6.4298763]\n",
      "   ...\n",
      "   [ -61.407722   -61.407722   -61.407722  ...  -61.407722\n",
      "     -61.407722   -61.407722 ]\n",
      "   [ 164.9695     164.9695     164.9695    ...  164.9695\n",
      "     164.9695     164.9695   ]\n",
      "   [ -45.176285   -45.176285   -45.176285  ...  -45.176285\n",
      "     -45.176285   -45.176285 ]]\n",
      "\n",
      "  [[  36.721527    36.721527    36.721527  ...   36.721527\n",
      "      36.721527    36.721527 ]\n",
      "   [ -99.567825   -99.567825   -99.567825  ...  -99.567825\n",
      "     -99.567825   -99.567825 ]\n",
      "   [  45.52301     45.52301     45.52301   ...   45.52301\n",
      "      45.52301     45.52301  ]\n",
      "   ...\n",
      "   [ -15.012239   -15.012239   -15.012239  ...  -15.012239\n",
      "     -15.012239   -15.012239 ]\n",
      "   [ 151.13068    151.13068    151.13068   ...  151.13068\n",
      "     151.13068    151.13068  ]\n",
      "   [  11.02179     11.02179     11.02179   ...   11.02179\n",
      "      11.02179     11.02179  ]]\n",
      "\n",
      "  [[ -16.979103   -16.979103   -16.979103  ...  -16.979103\n",
      "     -16.979103   -16.979103 ]\n",
      "   [ -66.17146    -66.17146    -66.17146   ...  -66.17146\n",
      "     -66.17146    -66.17146  ]\n",
      "   [ -11.255241   -11.255241   -11.255241  ...  -11.255241\n",
      "     -11.255241   -11.255241 ]\n",
      "   ...\n",
      "   [ -29.803204   -29.803204   -29.803204  ...  -29.803204\n",
      "     -29.803204   -29.803204 ]\n",
      "   [ 104.24271    104.24271    104.24271   ...  104.24271\n",
      "     104.24271    104.24271  ]\n",
      "   [ -43.672226   -43.672226   -43.672226  ...  -43.672226\n",
      "     -43.672226   -43.672226 ]]]\n",
      "\n",
      "\n",
      " [[[  84.22443     84.22443     84.22443   ...   84.22443\n",
      "      84.22443     84.22443  ]\n",
      "   [-135.15842   -135.15842   -135.15842   ... -135.15842\n",
      "    -135.15842   -135.15842  ]\n",
      "   [-100.58326   -100.58326   -100.58326   ... -100.58326\n",
      "    -100.58326   -100.58326  ]\n",
      "   ...\n",
      "   [ -24.883554   -24.883554   -24.883554  ...  -24.883554\n",
      "     -24.883554   -24.883554 ]\n",
      "   [ 100.45781    100.45781    100.45781   ...  100.45781\n",
      "     100.45781    100.45781  ]\n",
      "   [ -85.92231    -85.92231    -85.92231   ...  -85.92231\n",
      "     -85.92231    -85.92231  ]]\n",
      "\n",
      "  [[  38.148136    38.148136    38.148136  ...   38.148136\n",
      "      38.148136    38.148136 ]\n",
      "   [ -94.912506   -94.912506   -94.912506  ...  -94.912506\n",
      "     -94.912506   -94.912506 ]\n",
      "   [ -47.50196    -47.50196    -47.50196   ...  -47.50196\n",
      "     -47.50196    -47.50196  ]\n",
      "   ...\n",
      "   [  31.187073    31.187073    31.187073  ...   31.187073\n",
      "      31.187073    31.187073 ]\n",
      "   [  82.53323     82.53323     82.53323   ...   82.53323\n",
      "      82.53323     82.53323  ]\n",
      "   [ -36.53698    -36.53698    -36.53698   ...  -36.53698\n",
      "     -36.53698    -36.53698  ]]\n",
      "\n",
      "  [[ -25.285572   -25.285572   -25.285572  ...  -25.285572\n",
      "     -25.285572   -25.285572 ]\n",
      "   [ -71.94115    -71.94115    -71.94115   ...  -71.94115\n",
      "     -71.94115    -71.94115  ]\n",
      "   [ -90.84924    -90.84924    -90.84924   ...  -90.84924\n",
      "     -90.84924    -90.84924  ]\n",
      "   ...\n",
      "   [  -9.12859     -9.12859     -9.12859   ...   -9.12859\n",
      "      -9.12859     -9.12859  ]\n",
      "   [  45.63051     45.63051     45.63051   ...   45.63051\n",
      "      45.63051     45.63051  ]\n",
      "   [ -75.96571    -75.96571    -75.96571   ...  -75.96571\n",
      "     -75.96571    -75.96571  ]]]\n",
      "\n",
      "\n",
      " [[[ 144.21216    144.21216    144.21216   ...  144.21216\n",
      "     144.21216    144.21216  ]\n",
      "   [ -84.14905    -84.14905    -84.14905   ...  -84.14905\n",
      "     -84.14905    -84.14905  ]\n",
      "   [ -88.05066    -88.05066    -88.05066   ...  -88.05066\n",
      "     -88.05066    -88.05066  ]\n",
      "   ...\n",
      "   [  19.75122     19.75122     19.75122   ...   19.75122\n",
      "      19.75122     19.75122  ]\n",
      "   [  23.33199     23.33199     23.33199   ...   23.33199\n",
      "      23.33199     23.33199  ]\n",
      "   [ -28.93097    -28.93097    -28.93097   ...  -28.93097\n",
      "     -28.93097    -28.93097  ]]\n",
      "\n",
      "  [[ 110.54175    110.54175    110.54175   ...  110.54175\n",
      "     110.54175    110.54175  ]\n",
      "   [ -76.64881    -76.64881    -76.64881   ...  -76.64881\n",
      "     -76.64881    -76.64881  ]\n",
      "   [ -39.343735   -39.343735   -39.343735  ...  -39.343735\n",
      "     -39.343735   -39.343735 ]\n",
      "   ...\n",
      "   [ 104.99714    104.99714    104.99714   ...  104.99714\n",
      "     104.99714    104.99714  ]\n",
      "   [  16.442848    16.442848    16.442848  ...   16.442848\n",
      "      16.442848    16.442848 ]\n",
      "   [  25.08516     25.08516     25.08516   ...   25.08516\n",
      "      25.08516     25.08516  ]]\n",
      "\n",
      "  [[  58.685844    58.685844    58.685844  ...   58.685844\n",
      "      58.685844    58.685844 ]\n",
      "   [ -54.270386   -54.270386   -54.270386  ...  -54.270386\n",
      "     -54.270386   -54.270386 ]\n",
      "   [ -98.79855    -98.79855    -98.79855   ...  -98.79855\n",
      "     -98.79855    -98.79855  ]\n",
      "   ...\n",
      "   [  55.918465    55.918465    55.918465  ...   55.918465\n",
      "      55.918465    55.918465 ]\n",
      "   [ -24.19175    -24.19175    -24.19175   ...  -24.19175\n",
      "     -24.19175    -24.19175  ]\n",
      "   [ -53.170853   -53.170853   -53.170853  ...  -53.170853\n",
      "     -53.170853   -53.170853 ]]]], W.grad.numpy(): [[[[  99.665535    99.665535    99.665535  ...   99.665535\n",
      "      99.665535    99.665535 ]\n",
      "   [-104.73127   -104.73127   -104.73127   ... -104.73127\n",
      "    -104.73127   -104.73127  ]\n",
      "   [   6.4298763    6.4298763    6.4298763 ...    6.4298763\n",
      "       6.4298763    6.4298763]\n",
      "   ...\n",
      "   [ -61.407658   -61.407658   -61.407658  ...  -61.407658\n",
      "     -61.407658   -61.407658 ]\n",
      "   [ 164.96954    164.96954    164.96954   ...  164.96954\n",
      "     164.96954    164.96954  ]\n",
      "   [ -45.176117   -45.176117   -45.176117  ...  -45.176117\n",
      "     -45.176117   -45.176117 ]]\n",
      "\n",
      "  [[  36.72144     36.72144     36.72144   ...   36.72144\n",
      "      36.72144     36.72144  ]\n",
      "   [ -99.567856   -99.567856   -99.567856  ...  -99.567856\n",
      "     -99.567856   -99.567856 ]\n",
      "   [  45.52297     45.52297     45.52297   ...   45.52297\n",
      "      45.52297     45.52297  ]\n",
      "   ...\n",
      "   [ -15.012265   -15.012265   -15.012265  ...  -15.012265\n",
      "     -15.012265   -15.012265 ]\n",
      "   [ 151.13083    151.13083    151.13083   ...  151.13083\n",
      "     151.13083    151.13083  ]\n",
      "   [  11.02182     11.02182     11.02182   ...   11.02182\n",
      "      11.02182     11.02182  ]]\n",
      "\n",
      "  [[ -16.979084   -16.979084   -16.979084  ...  -16.979084\n",
      "     -16.979084   -16.979084 ]\n",
      "   [ -66.17162    -66.17162    -66.17162   ...  -66.17162\n",
      "     -66.17162    -66.17162  ]\n",
      "   [ -11.255192   -11.255192   -11.255192  ...  -11.255192\n",
      "     -11.255192   -11.255192 ]\n",
      "   ...\n",
      "   [ -29.803177   -29.803177   -29.803177  ...  -29.803177\n",
      "     -29.803177   -29.803177 ]\n",
      "   [ 104.24278    104.24278    104.24278   ...  104.24278\n",
      "     104.24278    104.24278  ]\n",
      "   [ -43.6722     -43.6722     -43.6722    ...  -43.6722\n",
      "     -43.6722     -43.6722   ]]]\n",
      "\n",
      "\n",
      " [[[  84.224556    84.224556    84.224556  ...   84.224556\n",
      "      84.224556    84.224556 ]\n",
      "   [-135.15839   -135.15839   -135.15839   ... -135.15839\n",
      "    -135.15839   -135.15839  ]\n",
      "   [-100.583275  -100.583275  -100.583275  ... -100.583275\n",
      "    -100.583275  -100.583275 ]\n",
      "   ...\n",
      "   [ -24.883583   -24.883583   -24.883583  ...  -24.883583\n",
      "     -24.883583   -24.883583 ]\n",
      "   [ 100.45786    100.45786    100.45786   ...  100.45786\n",
      "     100.45786    100.45786  ]\n",
      "   [ -85.92214    -85.92214    -85.92214   ...  -85.92214\n",
      "     -85.92214    -85.92214  ]]\n",
      "\n",
      "  [[  38.148212    38.148212    38.148212  ...   38.148212\n",
      "      38.148212    38.148212 ]\n",
      "   [ -94.912384   -94.912384   -94.912384  ...  -94.912384\n",
      "     -94.912384   -94.912384 ]\n",
      "   [ -47.501945   -47.501945   -47.501945  ...  -47.501945\n",
      "     -47.501945   -47.501945 ]\n",
      "   ...\n",
      "   [  31.187088    31.187088    31.187088  ...   31.187088\n",
      "      31.187088    31.187088 ]\n",
      "   [  82.533356    82.533356    82.533356  ...   82.533356\n",
      "      82.533356    82.533356 ]\n",
      "   [ -36.536976   -36.536976   -36.536976  ...  -36.536976\n",
      "     -36.536976   -36.536976 ]]\n",
      "\n",
      "  [[ -25.28561    -25.28561    -25.28561   ...  -25.28561\n",
      "     -25.28561    -25.28561  ]\n",
      "   [ -71.9412     -71.9412     -71.9412    ...  -71.9412\n",
      "     -71.9412     -71.9412   ]\n",
      "   [ -90.849174   -90.849174   -90.849174  ...  -90.849174\n",
      "     -90.849174   -90.849174 ]\n",
      "   ...\n",
      "   [  -9.128554    -9.128554    -9.128554  ...   -9.128554\n",
      "      -9.128554    -9.128554 ]\n",
      "   [  45.630615    45.630615    45.630615  ...   45.630615\n",
      "      45.630615    45.630615 ]\n",
      "   [ -75.96561    -75.96561    -75.96561   ...  -75.96561\n",
      "     -75.96561    -75.96561  ]]]\n",
      "\n",
      "\n",
      " [[[ 144.2123     144.2123     144.2123    ...  144.2123\n",
      "     144.2123     144.2123   ]\n",
      "   [ -84.149055   -84.149055   -84.149055  ...  -84.149055\n",
      "     -84.149055   -84.149055 ]\n",
      "   [ -88.05058    -88.05058    -88.05058   ...  -88.05058\n",
      "     -88.05058    -88.05058  ]\n",
      "   ...\n",
      "   [  19.751228    19.751228    19.751228  ...   19.751228\n",
      "      19.751228    19.751228 ]\n",
      "   [  23.331924    23.331924    23.331924  ...   23.331924\n",
      "      23.331924    23.331924 ]\n",
      "   [ -28.930826   -28.930826   -28.930826  ...  -28.930826\n",
      "     -28.930826   -28.930826 ]]\n",
      "\n",
      "  [[ 110.54181    110.54181    110.54181   ...  110.54181\n",
      "     110.54181    110.54181  ]\n",
      "   [ -76.6487     -76.6487     -76.6487    ...  -76.6487\n",
      "     -76.6487     -76.6487   ]\n",
      "   [ -39.343678   -39.343678   -39.343678  ...  -39.343678\n",
      "     -39.343678   -39.343678 ]\n",
      "   ...\n",
      "   [ 104.99721    104.99721    104.99721   ...  104.99721\n",
      "     104.99721    104.99721  ]\n",
      "   [  16.44289     16.44289     16.44289   ...   16.44289\n",
      "      16.44289     16.44289  ]\n",
      "   [  25.085155    25.085155    25.085155  ...   25.085155\n",
      "      25.085155    25.085155 ]]\n",
      "\n",
      "  [[  58.68582     58.68582     58.68582   ...   58.68582\n",
      "      58.68582     58.68582  ]\n",
      "   [ -54.270306   -54.270306   -54.270306  ...  -54.270306\n",
      "     -54.270306   -54.270306 ]\n",
      "   [ -98.798485   -98.798485   -98.798485  ...  -98.798485\n",
      "     -98.798485   -98.798485 ]\n",
      "   ...\n",
      "   [  55.91839     55.91839     55.91839   ...   55.91839\n",
      "      55.91839     55.91839  ]\n",
      "   [ -24.19169    -24.19169    -24.19169   ...  -24.19169\n",
      "     -24.19169    -24.19169  ]\n",
      "   [ -53.170704   -53.170704   -53.170704  ...  -53.170704\n",
      "     -53.170704   -53.170704 ]]]]\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape11-W_shape11-1-0] _\u001b[0m\n",
      "\n",
      "Z_shape = (3, 14, 14, 8), W_shape = (5, 5, 8, 16), stride = 1, padding = 0\n",
      "backward = True, device = cpu()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[ 4.28266907e+00  8.13360405e+00 -4.62234831e+00 ...  2.07981968e+00\n",
      "     2.17041516e+00 -3.88039827e...7e+00]\n",
      "   [-7.86027253e-01  4.30947495e+00 -4.97804356e+00 ... -5.69430470e-01\n",
      "     4.27775383e-01 -3.84437203e+00]]]])\n",
      "W_shape    = (5, 5, 8, 16)\n",
      "Wtch       = tensor([[[[ 4.2827e+00,  8.1336e+00, -4.6223e+00,  ...,  2.0798e+00,\n",
      "            2.1704e+00, -3.8804e-01],\n",
      "          [...[-7.8603e-01,  4.3095e+00, -4.9780e+00,  ..., -5.6943e-01,\n",
      "            4.2778e-01, -3.8444e+00]]]], requires_grad=True)\n",
      "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
      "     4.75044203e+00 -7.56786048e...3e+00]\n",
      "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
      "    -8.48226726e-01 -2.29984760e+00]]]])\n",
      "Z_shape    = (3, 14, 14, 8)\n",
      "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
      "            4.7504e+00, -7.5679e-01],\n",
      "          [...[ 1.0991e+01,  2.2317e+00,  4.6206e+00,  ..., -6.2309e-01,\n",
      "           -8.4823e-01, -2.2998e+00]]]], requires_grad=True)\n",
      "_W         = array([[[[ 4.28266907e+00,  8.13360405e+00, -4.62234831e+00, ...,\n",
      "           2.07981968e+00,  2.17041516e+00, -3.88039...56e+00, ...,\n",
      "          -5.69430470e-01,  4.27775383e-01, -3.84437203e+00]]]],\n",
      "      shape=(5, 5, 8, 16), dtype=float32)\n",
      "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
      "          -4.88638926e+00,  4.75044203e+00, -7.56786...9e+00, ...,\n",
      "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
      "      shape=(3, 14, 14, 8), dtype=float32)\n",
      "backward   = True\n",
      "device     = cpu()\n",
      "err1       = np.float32(0.0018357928)\n",
      "err2       = np.float32(0.0014858997)\n",
      "out        = tensor([[[[ 1.7557e+02,  1.3950e+02,  4.5144e+02,  ...,  1.9506e+01,\n",
      "           -5.7378e+01, -2.2967e+02],\n",
      "          [...,  3.1106e+02,  4.1425e+02,  ...,  3.3462e+02,\n",
      "           -1.0345e+02,  2.4403e+02]]]], grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(-10705.7383, grad_fn=<SumBackward0>)\n",
      "padding    = 0\n",
      "stride     = 1\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c5655d42f0>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655d49e0>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655d49e0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655d49e0>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655d49e0>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[-1.16245209e+02 -1.16245209e+02 -1.16245209e+02 ... -1.16245209e+02\n",
      "    -1.16245209e+02 -1.16245209e+02]\n",
      "   [-3.44621315e+01 -3.44621315e+01 -3.44621315e+01 ... -3.44621315e+01\n",
      "    -3.44621315e+01 -3.44621315e+01]\n",
      "   [-1.64758881e+02 -1.64758881e+02 -1.64758881e+02 ... -1.64758881e+02\n",
      "    -1.64758881e+02 -1.64758881e+02]\n",
      "   ...\n",
      "   [-3.16865826e+01 -3.16865826e+01 -3.16865826e+01 ... -3.16865826e+01\n",
      "    -3.16865826e+01 -3.16865826e+01]\n",
      "   [ 8.40804977e+01  8.40804977e+01  8.40804977e+01 ...  8.40804977e+01\n",
      "     8.40804977e+01  8.40804977e+01]\n",
      "   [-9.92724152e+01 -9.92724152e+01 -9.92724152e+01 ... -9.92724152e+01\n",
      "    -9.92724152e+01 -9.92724152e+01]]\n",
      "\n",
      "  [[-1.12383026e+02 -1.12383026e+02 -1.12383026e+02 ... -1.12383026e+02\n",
      "    -1.12383026e+02 -1.12383026e+02]\n",
      "   [-2.81658592e+01 -2.81658592e+01 -2.81658592e+01 ... -2.81658592e+01\n",
      "    -2.81658592e+01 -2.81658592e+01]\n",
      "   [-1.70100220e+02 -1.70100220e+02 -1.70100220e+02 ... -1.70100220e+02\n",
      "    -1.70100220e+02 -1.70100220e+02]\n",
      "   ...\n",
      "   [-1.26563873e+01 -1.26563873e+01 -1.26563873e+01 ... -1.26563873e+01\n",
      "    -1.26563873e+01 -1.26563873e+01]\n",
      "   [ 1.16309891e+02  1.16309891e+02  1.16309891e+02 ...  1.16309891e+02\n",
      "     1.16309891e+02  1.16309891e+02]\n",
      "   [-9.04269104e+01 -9.04269104e+01 -9.04269104e+01 ... -9.04269104e+01\n",
      "    -9.04269104e+01 -9.04269104e+01]]\n",
      "\n",
      "  [[-5.86221962e+01 -5.86221962e+01 -5.86221962e+01 ... -5.86221962e+01\n",
      "    -5.86221962e+01 -5.86221962e+01]\n",
      "   [ 2.15058517e+00  2.15058517e+00  2.15058517e+00 ...  2.15058517e+00\n",
      "     2.15058517e+00  2.15058517e+00]\n",
      "   [-9.45261383e+01 -9.45261383e+01 -9.45261383e+01 ... -9.45261383e+01\n",
      "    -9.45261383e+01 -9.45261383e+01]\n",
      "   ...\n",
      "   [-1.06377201e+01 -1.06377201e+01 -1.06377201e+01 ... -1.06377201e+01\n",
      "    -1.06377201e+01 -1.06377201e+01]\n",
      "   [ 8.25016632e+01  8.25016632e+01  8.25016632e+01 ...  8.25016632e+01\n",
      "     8.25016632e+01  8.25016632e+01]\n",
      "   [-8.38581314e+01 -8.38581314e+01 -8.38581314e+01 ... -8.38581314e+01\n",
      "    -8.38581314e+01 -8.38581314e+01]]\n",
      "\n",
      "  [[-6.70073090e+01 -6.70073090e+01 -6.70073090e+01 ... -6.70073090e+01\n",
      "    -6.70073090e+01 -6.70073090e+01]\n",
      "   [ 4.87934113e-01  4.87934113e-01  4.87934113e-01 ...  4.87934113e-01\n",
      "     4.87934113e-01  4.87934113e-01]\n",
      "   [-8.68875732e+01 -8.68875732e+01 -8.68875732e+01 ... -8.68875732e+01\n",
      "    -8.68875732e+01 -8.68875732e+01]\n",
      "   ...\n",
      "   [-1.43081284e+01 -1.43081284e+01 -1.43081284e+01 ... -1.43081284e+01\n",
      "    -1.43081284e+01 -1.43081284e+01]\n",
      "   [ 3.96485863e+01  3.96485863e+01  3.96485863e+01 ...  3.96485863e+01\n",
      "     3.96485863e+01  3.96485863e+01]\n",
      "   [-1.05648560e+02 -1.05648560e+02 -1.05648560e+02 ... -1.05648560e+02\n",
      "    -1.05648560e+02 -1.05648560e+02]]\n",
      "\n",
      "  [[-5.62348137e+01 -5.62348137e+01 -5.62348137e+01 ... -5.62348137e+01\n",
      "    -5.62348137e+01 -5.62348137e+01]\n",
      "   [ 2.50358200e+01  2.50358200e+01  2.50358200e+01 ...  2.50358200e+01\n",
      "     2.50358200e+01  2.50358200e+01]\n",
      "   [-9.68896866e+01 -9.68896866e+01 -9.68896866e+01 ... -9.68896866e+01\n",
      "    -9.68896866e+01 -9.68896866e+01]\n",
      "   ...\n",
      "   [-1.26439514e+01 -1.26439514e+01 -1.26439514e+01 ... -1.26439514e+01\n",
      "    -1.26439514e+01 -1.26439514e+01]\n",
      "   [ 1.62703705e+00  1.62703705e+00  1.62703705e+00 ...  1.62703705e+00\n",
      "     1.62703705e+00  1.62703705e+00]\n",
      "   [-1.81933929e+02 -1.81933929e+02 -1.81933929e+02 ... -1.81933929e+02\n",
      "    -1.81933929e+02 -1.81933929e+02]]]\n",
      "\n",
      "\n",
      " [[[-1.17615128e+02 -1.17615128e+02 -1.17615128e+02 ... -1.17615128e+02\n",
      "    -1.17615128e+02 -1.17615128e+02]\n",
      "   [ 5.95184898e+00  5.95184898e+00  5.95184898e+00 ...  5.95184898e+00\n",
      "     5.95184898e+00  5.95184898e+00]\n",
      "   [-8.92560120e+01 -8.92560120e+01 -8.92560120e+01 ... -8.92560120e+01\n",
      "    -8.92560120e+01 -8.92560120e+01]\n",
      "   ...\n",
      "   [-1.20959213e+02 -1.20959213e+02 -1.20959213e+02 ... -1.20959213e+02\n",
      "    -1.20959213e+02 -1.20959213e+02]\n",
      "   [ 1.06997871e+02  1.06997871e+02  1.06997871e+02 ...  1.06997871e+02\n",
      "     1.06997871e+02  1.06997871e+02]\n",
      "   [-5.44203796e+01 -5.44203796e+01 -5.44203796e+01 ... -5.44203796e+01\n",
      "    -5.44203796e+01 -5.44203796e+01]]\n",
      "\n",
      "  [[-1.07528992e+02 -1.07528992e+02 -1.07528992e+02 ... -1.07528992e+02\n",
      "    -1.07528992e+02 -1.07528992e+02]\n",
      "   [-2.63620777e+01 -2.63620777e+01 -2.63620777e+01 ... -2.63620777e+01\n",
      "    -2.63620777e+01 -2.63620777e+01]\n",
      "   [-8.02585983e+01 -8.02585983e+01 -8.02585983e+01 ... -8.02585983e+01\n",
      "    -8.02585983e+01 -8.02585983e+01]\n",
      "   ...\n",
      "   [-1.30162384e+02 -1.30162384e+02 -1.30162384e+02 ... -1.30162384e+02\n",
      "    -1.30162384e+02 -1.30162384e+02]\n",
      "   [ 1.58434586e+02  1.58434586e+02  1.58434586e+02 ...  1.58434586e+02\n",
      "     1.58434586e+02  1.58434586e+02]\n",
      "   [-5.02668991e+01 -5.02668991e+01 -5.02668991e+01 ... -5.02668991e+01\n",
      "    -5.02668991e+01 -5.02668991e+01]]\n",
      "\n",
      "  [[-3.91359787e+01 -3.91359787e+01 -3.91359787e+01 ... -3.91359787e+01\n",
      "    -3.91359787e+01 -3.91359787e+01]\n",
      "   [ 2.53128986e+01  2.53128986e+01  2.53128986e+01 ...  2.53128986e+01\n",
      "     2.53128986e+01  2.53128986e+01]\n",
      "   [-7.78603745e+00 -7.78603745e+00 -7.78603745e+00 ... -7.78603745e+00\n",
      "    -7.78603745e+00 -7.78603745e+00]\n",
      "   ...\n",
      "   [-1.23830475e+02 -1.23830475e+02 -1.23830475e+02 ... -1.23830475e+02\n",
      "    -1.23830475e+02 -1.23830475e+02]\n",
      "   [ 1.20911484e+02  1.20911484e+02  1.20911484e+02 ...  1.20911484e+02\n",
      "     1.20911484e+02  1.20911484e+02]\n",
      "   [-5.19391441e+01 -5.19391441e+01 -5.19391441e+01 ... -5.19391441e+01\n",
      "    -5.19391441e+01 -5.19391441e+01]]\n",
      "\n",
      "  [[-4.20618286e+01 -4.20618286e+01 -4.20618286e+01 ... -4.20618286e+01\n",
      "    -4.20618286e+01 -4.20618286e+01]\n",
      "   [ 1.26867943e+01  1.26867943e+01  1.26867943e+01 ...  1.26867943e+01\n",
      "     1.26867943e+01  1.26867943e+01]\n",
      "   [-2.25820427e+01 -2.25820427e+01 -2.25820427e+01 ... -2.25820427e+01\n",
      "    -2.25820427e+01 -2.25820427e+01]\n",
      "   ...\n",
      "   [-9.31390762e+01 -9.31390762e+01 -9.31390762e+01 ... -9.31390762e+01\n",
      "    -9.31390762e+01 -9.31390762e+01]\n",
      "   [ 1.04962341e+02  1.04962341e+02  1.04962341e+02 ...  1.04962341e+02\n",
      "     1.04962341e+02  1.04962341e+02]\n",
      "   [-7.80756454e+01 -7.80756454e+01 -7.80756454e+01 ... -7.80756454e+01\n",
      "    -7.80756454e+01 -7.80756454e+01]]\n",
      "\n",
      "  [[-1.09563560e+01 -1.09563560e+01 -1.09563560e+01 ... -1.09563560e+01\n",
      "    -1.09563560e+01 -1.09563560e+01]\n",
      "   [ 3.37870865e+01  3.37870865e+01  3.37870865e+01 ...  3.37870865e+01\n",
      "     3.37870865e+01  3.37870865e+01]\n",
      "   [-1.52067757e+01 -1.52067757e+01 -1.52067757e+01 ... -1.52067757e+01\n",
      "    -1.52067757e+01 -1.52067757e+01]\n",
      "   ...\n",
      "   [-6.06810417e+01 -6.06810417e+01 -6.06810417e+01 ... -6.06810417e+01\n",
      "    -6.06810417e+01 -6.06810417e+01]\n",
      "   [ 4.86012001e+01  4.86012001e+01  4.86012001e+01 ...  4.86012001e+01\n",
      "     4.86012001e+01  4.86012001e+01]\n",
      "   [-1.48817383e+02 -1.48817383e+02 -1.48817383e+02 ... -1.48817383e+02\n",
      "    -1.48817383e+02 -1.48817383e+02]]]\n",
      "\n",
      "\n",
      " [[[-1.26848694e+02 -1.26848694e+02 -1.26848694e+02 ... -1.26848694e+02\n",
      "    -1.26848694e+02 -1.26848694e+02]\n",
      "   [ 1.36254635e+01  1.36254635e+01  1.36254635e+01 ...  1.36254635e+01\n",
      "     1.36254635e+01  1.36254635e+01]\n",
      "   [-7.57005005e+01 -7.57005005e+01 -7.57005005e+01 ... -7.57005005e+01\n",
      "    -7.57005005e+01 -7.57005005e+01]\n",
      "   ...\n",
      "   [-1.24673889e+02 -1.24673889e+02 -1.24673889e+02 ... -1.24673889e+02\n",
      "    -1.24673889e+02 -1.24673889e+02]\n",
      "   [ 6.19116325e+01  6.19116325e+01  6.19116325e+01 ...  6.19116325e+01\n",
      "     6.19116325e+01  6.19116325e+01]\n",
      "   [-7.19311447e+01 -7.19311447e+01 -7.19311447e+01 ... -7.19311447e+01\n",
      "    -7.19311447e+01 -7.19311447e+01]]\n",
      "\n",
      "  [[-1.12900421e+02 -1.12900421e+02 -1.12900421e+02 ... -1.12900421e+02\n",
      "    -1.12900421e+02 -1.12900421e+02]\n",
      "   [-1.10641861e+01 -1.10641861e+01 -1.10641861e+01 ... -1.10641861e+01\n",
      "    -1.10641861e+01 -1.10641861e+01]\n",
      "   [-4.78104820e+01 -4.78104820e+01 -4.78104820e+01 ... -4.78104820e+01\n",
      "    -4.78104820e+01 -4.78104820e+01]\n",
      "   ...\n",
      "   [-1.48546387e+02 -1.48546387e+02 -1.48546387e+02 ... -1.48546387e+02\n",
      "    -1.48546387e+02 -1.48546387e+02]\n",
      "   [ 1.17091370e+02  1.17091370e+02  1.17091370e+02 ...  1.17091370e+02\n",
      "     1.17091370e+02  1.17091370e+02]\n",
      "   [-8.47998123e+01 -8.47998123e+01 -8.47998123e+01 ... -8.47998123e+01\n",
      "    -8.47998123e+01 -8.47998123e+01]]\n",
      "\n",
      "  [[-4.45975990e+01 -4.45975990e+01 -4.45975990e+01 ... -4.45975990e+01\n",
      "    -4.45975990e+01 -4.45975990e+01]\n",
      "   [ 7.07967567e+00  7.07967567e+00  7.07967567e+00 ...  7.07967567e+00\n",
      "     7.07967567e+00  7.07967567e+00]\n",
      "   [ 1.15620651e+01  1.15620651e+01  1.15620651e+01 ...  1.15620651e+01\n",
      "     1.15620651e+01  1.15620651e+01]\n",
      "   ...\n",
      "   [-1.26221176e+02 -1.26221176e+02 -1.26221176e+02 ... -1.26221176e+02\n",
      "    -1.26221176e+02 -1.26221176e+02]\n",
      "   [ 9.70882034e+01  9.70882034e+01  9.70882034e+01 ...  9.70882034e+01\n",
      "     9.70882034e+01  9.70882034e+01]\n",
      "   [-8.03393860e+01 -8.03393860e+01 -8.03393860e+01 ... -8.03393860e+01\n",
      "    -8.03393860e+01 -8.03393860e+01]]\n",
      "\n",
      "  [[-4.61898727e+01 -4.61898727e+01 -4.61898727e+01 ... -4.61898727e+01\n",
      "    -4.61898727e+01 -4.61898727e+01]\n",
      "   [ 3.04283905e+00  3.04283905e+00  3.04283905e+00 ...  3.04283905e+00\n",
      "     3.04283905e+00  3.04283905e+00]\n",
      "   [ 9.44609070e+00  9.44609070e+00  9.44609070e+00 ...  9.44609070e+00\n",
      "     9.44609070e+00  9.44609070e+00]\n",
      "   ...\n",
      "   [-1.36858246e+02 -1.36858246e+02 -1.36858246e+02 ... -1.36858246e+02\n",
      "    -1.36858246e+02 -1.36858246e+02]\n",
      "   [ 7.66677246e+01  7.66677246e+01  7.66677246e+01 ...  7.66677246e+01\n",
      "     7.66677246e+01  7.66677246e+01]\n",
      "   [-9.62865448e+01 -9.62865448e+01 -9.62865448e+01 ... -9.62865448e+01\n",
      "    -9.62865448e+01 -9.62865448e+01]]\n",
      "\n",
      "  [[-6.22673988e+00 -6.22673988e+00 -6.22673988e+00 ... -6.22673988e+00\n",
      "    -6.22673988e+00 -6.22673988e+00]\n",
      "   [ 1.91820450e+01  1.91820450e+01  1.91820450e+01 ...  1.91820450e+01\n",
      "     1.91820450e+01  1.91820450e+01]\n",
      "   [-9.85822296e+00 -9.85822296e+00 -9.85822296e+00 ... -9.85822296e+00\n",
      "    -9.85822296e+00 -9.85822296e+00]\n",
      "   ...\n",
      "   [-7.14098740e+01 -7.14098740e+01 -7.14098740e+01 ... -7.14098740e+01\n",
      "    -7.14098740e+01 -7.14098740e+01]\n",
      "   [ 4.94573364e+01  4.94573364e+01  4.94573364e+01 ...  4.94573364e+01\n",
      "     4.94573364e+01  4.94573364e+01]\n",
      "   [-1.89678497e+02 -1.89678497e+02 -1.89678497e+02 ... -1.89678497e+02\n",
      "    -1.89678497e+02 -1.89678497e+02]]]\n",
      "\n",
      "\n",
      " [[[-7.13851089e+01 -7.13851089e+01 -7.13851089e+01 ... -7.13851089e+01\n",
      "    -7.13851089e+01 -7.13851089e+01]\n",
      "   [ 4.19347305e+01  4.19347305e+01  4.19347305e+01 ...  4.19347305e+01\n",
      "     4.19347305e+01  4.19347305e+01]\n",
      "   [-4.58315659e+01 -4.58315659e+01 -4.58315659e+01 ... -4.58315659e+01\n",
      "    -4.58315659e+01 -4.58315659e+01]\n",
      "   ...\n",
      "   [-1.21203827e+02 -1.21203827e+02 -1.21203827e+02 ... -1.21203827e+02\n",
      "    -1.21203827e+02 -1.21203827e+02]\n",
      "   [ 7.28883133e+01  7.28883133e+01  7.28883133e+01 ...  7.28883133e+01\n",
      "     7.28883133e+01  7.28883133e+01]\n",
      "   [-2.14865799e+01 -2.14865799e+01 -2.14865799e+01 ... -2.14865799e+01\n",
      "    -2.14865799e+01 -2.14865799e+01]]\n",
      "\n",
      "  [[-7.61646957e+01 -7.61646957e+01 -7.61646957e+01 ... -7.61646957e+01\n",
      "    -7.61646957e+01 -7.61646957e+01]\n",
      "   [ 1.62770462e+01  1.62770462e+01  1.62770462e+01 ...  1.62770462e+01\n",
      "     1.62770462e+01  1.62770462e+01]\n",
      "   [-1.02499542e+01 -1.02499542e+01 -1.02499542e+01 ... -1.02499542e+01\n",
      "    -1.02499542e+01 -1.02499542e+01]\n",
      "   ...\n",
      "   [-1.29019180e+02 -1.29019180e+02 -1.29019180e+02 ... -1.29019180e+02\n",
      "    -1.29019180e+02 -1.29019180e+02]\n",
      "   [ 1.09344589e+02  1.09344589e+02  1.09344589e+02 ...  1.09344589e+02\n",
      "     1.09344589e+02  1.09344589e+02]\n",
      "   [-6.96123505e+01 -6.96123505e+01 -6.96123505e+01 ... -6.96123505e+01\n",
      "    -6.96123505e+01 -6.96123505e+01]]\n",
      "\n",
      "  [[-2.29666405e+01 -2.29666405e+01 -2.29666405e+01 ... -2.29666405e+01\n",
      "    -2.29666405e+01 -2.29666405e+01]\n",
      "   [ 2.46142731e+01  2.46142731e+01  2.46142731e+01 ...  2.46142731e+01\n",
      "     2.46142731e+01  2.46142731e+01]\n",
      "   [ 3.10823975e+01  3.10823975e+01  3.10823975e+01 ...  3.10823975e+01\n",
      "     3.10823975e+01  3.10823975e+01]\n",
      "   ...\n",
      "   [-1.14508492e+02 -1.14508492e+02 -1.14508492e+02 ... -1.14508492e+02\n",
      "    -1.14508492e+02 -1.14508492e+02]\n",
      "   [ 1.11675400e+02  1.11675400e+02  1.11675400e+02 ...  1.11675400e+02\n",
      "     1.11675400e+02  1.11675400e+02]\n",
      "   [-6.20354652e+01 -6.20354652e+01 -6.20354652e+01 ... -6.20354652e+01\n",
      "    -6.20354652e+01 -6.20354652e+01]]\n",
      "\n",
      "  [[-3.52518730e+01 -3.52518730e+01 -3.52518730e+01 ... -3.52518730e+01\n",
      "    -3.52518730e+01 -3.52518730e+01]\n",
      "   [ 1.19222536e+01  1.19222536e+01  1.19222536e+01 ...  1.19222536e+01\n",
      "     1.19222536e+01  1.19222536e+01]\n",
      "   [ 2.78897705e+01  2.78897705e+01  2.78897705e+01 ...  2.78897705e+01\n",
      "     2.78897705e+01  2.78897705e+01]\n",
      "   ...\n",
      "   [-1.23644325e+02 -1.23644325e+02 -1.23644325e+02 ... -1.23644325e+02\n",
      "    -1.23644325e+02 -1.23644325e+02]\n",
      "   [ 9.16775665e+01  9.16775665e+01  9.16775665e+01 ...  9.16775665e+01\n",
      "     9.16775665e+01  9.16775665e+01]\n",
      "   [-7.70715942e+01 -7.70715942e+01 -7.70715942e+01 ... -7.70715942e+01\n",
      "    -7.70715942e+01 -7.70715942e+01]]\n",
      "\n",
      "  [[-2.90821934e+00 -2.90821934e+00 -2.90821934e+00 ... -2.90821934e+00\n",
      "    -2.90821934e+00 -2.90821934e+00]\n",
      "   [ 1.50837154e+01  1.50837154e+01  1.50837154e+01 ...  1.50837154e+01\n",
      "     1.50837154e+01  1.50837154e+01]\n",
      "   [ 1.51008606e-01  1.51008606e-01  1.51008606e-01 ...  1.51008606e-01\n",
      "     1.51008606e-01  1.51008606e-01]\n",
      "   ...\n",
      "   [-7.35042648e+01 -7.35042648e+01 -7.35042648e+01 ... -7.35042648e+01\n",
      "    -7.35042648e+01 -7.35042648e+01]\n",
      "   [ 8.44047699e+01  8.44047699e+01  8.44047699e+01 ...  8.44047699e+01\n",
      "     8.44047699e+01  8.44047699e+01]\n",
      "   [-1.77175781e+02 -1.77175781e+02 -1.77175781e+02 ... -1.77175781e+02\n",
      "    -1.77175781e+02 -1.77175781e+02]]]\n",
      "\n",
      "\n",
      " [[[-5.48747063e+01 -5.48747063e+01 -5.48747063e+01 ... -5.48747063e+01\n",
      "    -5.48747063e+01 -5.48747063e+01]\n",
      "   [ 6.71577225e+01  6.71577225e+01  6.71577225e+01 ...  6.71577225e+01\n",
      "     6.71577225e+01  6.71577225e+01]\n",
      "   [-8.42740936e+01 -8.42740936e+01 -8.42740936e+01 ... -8.42740936e+01\n",
      "    -8.42740936e+01 -8.42740936e+01]\n",
      "   ...\n",
      "   [-1.33038605e+02 -1.33038605e+02 -1.33038605e+02 ... -1.33038605e+02\n",
      "    -1.33038605e+02 -1.33038605e+02]\n",
      "   [ 2.63858604e+01  2.63858604e+01  2.63858604e+01 ...  2.63858604e+01\n",
      "     2.63858604e+01  2.63858604e+01]\n",
      "   [-1.84680748e+00 -1.84680748e+00 -1.84680748e+00 ... -1.84680748e+00\n",
      "    -1.84680748e+00 -1.84680748e+00]]\n",
      "\n",
      "  [[-7.81479187e+01 -7.81479187e+01 -7.81479187e+01 ... -7.81479187e+01\n",
      "    -7.81479187e+01 -7.81479187e+01]\n",
      "   [ 5.98763428e+01  5.98763428e+01  5.98763428e+01 ...  5.98763428e+01\n",
      "     5.98763428e+01  5.98763428e+01]\n",
      "   [-5.36792297e+01 -5.36792297e+01 -5.36792297e+01 ... -5.36792297e+01\n",
      "    -5.36792297e+01 -5.36792297e+01]\n",
      "   ...\n",
      "   [-1.45820892e+02 -1.45820892e+02 -1.45820892e+02 ... -1.45820892e+02\n",
      "    -1.45820892e+02 -1.45820892e+02]\n",
      "   [ 7.88428574e+01  7.88428574e+01  7.88428574e+01 ...  7.88428574e+01\n",
      "     7.88428574e+01  7.88428574e+01]\n",
      "   [-7.27277527e+01 -7.27277527e+01 -7.27277527e+01 ... -7.27277527e+01\n",
      "    -7.27277527e+01 -7.27277527e+01]]\n",
      "\n",
      "  [[-3.96777382e+01 -3.96777382e+01 -3.96777382e+01 ... -3.96777382e+01\n",
      "    -3.96777382e+01 -3.96777382e+01]\n",
      "   [ 6.11086349e+01  6.11086349e+01  6.11086349e+01 ...  6.11086349e+01\n",
      "     6.11086349e+01  6.11086349e+01]\n",
      "   [-1.43451614e+01 -1.43451614e+01 -1.43451614e+01 ... -1.43451614e+01\n",
      "    -1.43451614e+01 -1.43451614e+01]\n",
      "   ...\n",
      "   [-1.30441879e+02 -1.30441879e+02 -1.30441879e+02 ... -1.30441879e+02\n",
      "    -1.30441879e+02 -1.30441879e+02]\n",
      "   [ 1.08515823e+02  1.08515823e+02  1.08515823e+02 ...  1.08515823e+02\n",
      "     1.08515823e+02  1.08515823e+02]\n",
      "   [-5.35747337e+01 -5.35747337e+01 -5.35747337e+01 ... -5.35747337e+01\n",
      "    -5.35747337e+01 -5.35747337e+01]]\n",
      "\n",
      "  [[-4.10589294e+01 -4.10589294e+01 -4.10589294e+01 ... -4.10589294e+01\n",
      "    -4.10589294e+01 -4.10589294e+01]\n",
      "   [ 4.04711456e+01  4.04711456e+01  4.04711456e+01 ...  4.04711456e+01\n",
      "     4.04711456e+01  4.04711456e+01]\n",
      "   [-1.92358284e+01 -1.92358284e+01 -1.92358284e+01 ... -1.92358284e+01\n",
      "    -1.92358284e+01 -1.92358284e+01]\n",
      "   ...\n",
      "   [-1.45154953e+02 -1.45154953e+02 -1.45154953e+02 ... -1.45154953e+02\n",
      "    -1.45154953e+02 -1.45154953e+02]\n",
      "   [ 7.30680237e+01  7.30680237e+01  7.30680237e+01 ...  7.30680237e+01\n",
      "     7.30680237e+01  7.30680237e+01]\n",
      "   [-5.29791145e+01 -5.29791145e+01 -5.29791145e+01 ... -5.29791145e+01\n",
      "    -5.29791145e+01 -5.29791145e+01]]\n",
      "\n",
      "  [[ 3.63612270e+00  3.63612270e+00  3.63612270e+00 ...  3.63612270e+00\n",
      "     3.63612270e+00  3.63612270e+00]\n",
      "   [ 5.11792603e+01  5.11792603e+01  5.11792603e+01 ...  5.11792603e+01\n",
      "     5.11792603e+01  5.11792603e+01]\n",
      "   [-3.99396896e+01 -3.99396896e+01 -3.99396896e+01 ... -3.99396896e+01\n",
      "    -3.99396896e+01 -3.99396896e+01]\n",
      "   ...\n",
      "   [-9.13451843e+01 -9.13451843e+01 -9.13451843e+01 ... -9.13451843e+01\n",
      "    -9.13451843e+01 -9.13451843e+01]\n",
      "   [ 6.85575409e+01  6.85575409e+01  6.85575409e+01 ...  6.85575409e+01\n",
      "     6.85575409e+01  6.85575409e+01]\n",
      "   [-1.46652435e+02 -1.46652435e+02 -1.46652435e+02 ... -1.46652435e+02\n",
      "    -1.46652435e+02 -1.46652435e+02]]]], W.grad.numpy(): [[[[-1.16245270e+02 -1.16245270e+02 -1.16245270e+02 ... -1.16245270e+02\n",
      "    -1.16245270e+02 -1.16245270e+02]\n",
      "   [-3.44621201e+01 -3.44621201e+01 -3.44621201e+01 ... -3.44621201e+01\n",
      "    -3.44621201e+01 -3.44621201e+01]\n",
      "   [-1.64758835e+02 -1.64758835e+02 -1.64758835e+02 ... -1.64758835e+02\n",
      "    -1.64758835e+02 -1.64758835e+02]\n",
      "   ...\n",
      "   [-3.16865616e+01 -3.16865616e+01 -3.16865616e+01 ... -3.16865616e+01\n",
      "    -3.16865616e+01 -3.16865616e+01]\n",
      "   [ 8.40804901e+01  8.40804901e+01  8.40804901e+01 ...  8.40804901e+01\n",
      "     8.40804901e+01  8.40804901e+01]\n",
      "   [-9.92724228e+01 -9.92724228e+01 -9.92724228e+01 ... -9.92724228e+01\n",
      "    -9.92724228e+01 -9.92724228e+01]]\n",
      "\n",
      "  [[-1.12383057e+02 -1.12383057e+02 -1.12383057e+02 ... -1.12383057e+02\n",
      "    -1.12383057e+02 -1.12383057e+02]\n",
      "   [-2.81658459e+01 -2.81658459e+01 -2.81658459e+01 ... -2.81658459e+01\n",
      "    -2.81658459e+01 -2.81658459e+01]\n",
      "   [-1.70100220e+02 -1.70100220e+02 -1.70100220e+02 ... -1.70100220e+02\n",
      "    -1.70100220e+02 -1.70100220e+02]\n",
      "   ...\n",
      "   [-1.26563616e+01 -1.26563616e+01 -1.26563616e+01 ... -1.26563616e+01\n",
      "    -1.26563616e+01 -1.26563616e+01]\n",
      "   [ 1.16309853e+02  1.16309853e+02  1.16309853e+02 ...  1.16309853e+02\n",
      "     1.16309853e+02  1.16309853e+02]\n",
      "   [-9.04269562e+01 -9.04269562e+01 -9.04269562e+01 ... -9.04269562e+01\n",
      "    -9.04269562e+01 -9.04269562e+01]]\n",
      "\n",
      "  [[-5.86222191e+01 -5.86222191e+01 -5.86222191e+01 ... -5.86222191e+01\n",
      "    -5.86222191e+01 -5.86222191e+01]\n",
      "   [ 2.15059662e+00  2.15059662e+00  2.15059662e+00 ...  2.15059662e+00\n",
      "     2.15059662e+00  2.15059662e+00]\n",
      "   [-9.45261765e+01 -9.45261765e+01 -9.45261765e+01 ... -9.45261765e+01\n",
      "    -9.45261765e+01 -9.45261765e+01]\n",
      "   ...\n",
      "   [-1.06377125e+01 -1.06377125e+01 -1.06377125e+01 ... -1.06377125e+01\n",
      "    -1.06377125e+01 -1.06377125e+01]\n",
      "   [ 8.25016479e+01  8.25016479e+01  8.25016479e+01 ...  8.25016479e+01\n",
      "     8.25016479e+01  8.25016479e+01]\n",
      "   [-8.38581696e+01 -8.38581696e+01 -8.38581696e+01 ... -8.38581696e+01\n",
      "    -8.38581696e+01 -8.38581696e+01]]\n",
      "\n",
      "  [[-6.70073318e+01 -6.70073318e+01 -6.70073318e+01 ... -6.70073318e+01\n",
      "    -6.70073318e+01 -6.70073318e+01]\n",
      "   [ 4.87926006e-01  4.87926006e-01  4.87926006e-01 ...  4.87926006e-01\n",
      "     4.87926006e-01  4.87926006e-01]\n",
      "   [-8.68875809e+01 -8.68875809e+01 -8.68875809e+01 ... -8.68875809e+01\n",
      "    -8.68875809e+01 -8.68875809e+01]\n",
      "   ...\n",
      "   [-1.43081293e+01 -1.43081293e+01 -1.43081293e+01 ... -1.43081293e+01\n",
      "    -1.43081293e+01 -1.43081293e+01]\n",
      "   [ 3.96485748e+01  3.96485748e+01  3.96485748e+01 ...  3.96485748e+01\n",
      "     3.96485748e+01  3.96485748e+01]\n",
      "   [-1.05648605e+02 -1.05648605e+02 -1.05648605e+02 ... -1.05648605e+02\n",
      "    -1.05648605e+02 -1.05648605e+02]]\n",
      "\n",
      "  [[-5.62348061e+01 -5.62348061e+01 -5.62348061e+01 ... -5.62348061e+01\n",
      "    -5.62348061e+01 -5.62348061e+01]\n",
      "   [ 2.50358467e+01  2.50358467e+01  2.50358467e+01 ...  2.50358467e+01\n",
      "     2.50358467e+01  2.50358467e+01]\n",
      "   [-9.68896790e+01 -9.68896790e+01 -9.68896790e+01 ... -9.68896790e+01\n",
      "    -9.68896790e+01 -9.68896790e+01]\n",
      "   ...\n",
      "   [-1.26439657e+01 -1.26439657e+01 -1.26439657e+01 ... -1.26439657e+01\n",
      "    -1.26439657e+01 -1.26439657e+01]\n",
      "   [ 1.62705123e+00  1.62705123e+00  1.62705123e+00 ...  1.62705123e+00\n",
      "     1.62705123e+00  1.62705123e+00]\n",
      "   [-1.81934006e+02 -1.81934006e+02 -1.81934006e+02 ... -1.81934006e+02\n",
      "    -1.81934006e+02 -1.81934006e+02]]]\n",
      "\n",
      "\n",
      " [[[-1.17615143e+02 -1.17615143e+02 -1.17615143e+02 ... -1.17615143e+02\n",
      "    -1.17615143e+02 -1.17615143e+02]\n",
      "   [ 5.95184326e+00  5.95184326e+00  5.95184326e+00 ...  5.95184326e+00\n",
      "     5.95184326e+00  5.95184326e+00]\n",
      "   [-8.92560120e+01 -8.92560120e+01 -8.92560120e+01 ... -8.92560120e+01\n",
      "    -8.92560120e+01 -8.92560120e+01]\n",
      "   ...\n",
      "   [-1.20959198e+02 -1.20959198e+02 -1.20959198e+02 ... -1.20959198e+02\n",
      "    -1.20959198e+02 -1.20959198e+02]\n",
      "   [ 1.06997864e+02  1.06997864e+02  1.06997864e+02 ...  1.06997864e+02\n",
      "     1.06997864e+02  1.06997864e+02]\n",
      "   [-5.44203606e+01 -5.44203606e+01 -5.44203606e+01 ... -5.44203606e+01\n",
      "    -5.44203606e+01 -5.44203606e+01]]\n",
      "\n",
      "  [[-1.07529015e+02 -1.07529015e+02 -1.07529015e+02 ... -1.07529015e+02\n",
      "    -1.07529015e+02 -1.07529015e+02]\n",
      "   [-2.63620720e+01 -2.63620720e+01 -2.63620720e+01 ... -2.63620720e+01\n",
      "    -2.63620720e+01 -2.63620720e+01]\n",
      "   [-8.02586517e+01 -8.02586517e+01 -8.02586517e+01 ... -8.02586517e+01\n",
      "    -8.02586517e+01 -8.02586517e+01]\n",
      "   ...\n",
      "   [-1.30162415e+02 -1.30162415e+02 -1.30162415e+02 ... -1.30162415e+02\n",
      "    -1.30162415e+02 -1.30162415e+02]\n",
      "   [ 1.58434586e+02  1.58434586e+02  1.58434586e+02 ...  1.58434586e+02\n",
      "     1.58434586e+02  1.58434586e+02]\n",
      "   [-5.02669182e+01 -5.02669182e+01 -5.02669182e+01 ... -5.02669182e+01\n",
      "    -5.02669182e+01 -5.02669182e+01]]\n",
      "\n",
      "  [[-3.91359596e+01 -3.91359596e+01 -3.91359596e+01 ... -3.91359596e+01\n",
      "    -3.91359596e+01 -3.91359596e+01]\n",
      "   [ 2.53129139e+01  2.53129139e+01  2.53129139e+01 ...  2.53129139e+01\n",
      "     2.53129139e+01  2.53129139e+01]\n",
      "   [-7.78604126e+00 -7.78604126e+00 -7.78604126e+00 ... -7.78604126e+00\n",
      "    -7.78604126e+00 -7.78604126e+00]\n",
      "   ...\n",
      "   [-1.23830452e+02 -1.23830452e+02 -1.23830452e+02 ... -1.23830452e+02\n",
      "    -1.23830452e+02 -1.23830452e+02]\n",
      "   [ 1.20911415e+02  1.20911415e+02  1.20911415e+02 ...  1.20911415e+02\n",
      "     1.20911415e+02  1.20911415e+02]\n",
      "   [-5.19391327e+01 -5.19391327e+01 -5.19391327e+01 ... -5.19391327e+01\n",
      "    -5.19391327e+01 -5.19391327e+01]]\n",
      "\n",
      "  [[-4.20618248e+01 -4.20618248e+01 -4.20618248e+01 ... -4.20618248e+01\n",
      "    -4.20618248e+01 -4.20618248e+01]\n",
      "   [ 1.26868229e+01  1.26868229e+01  1.26868229e+01 ...  1.26868229e+01\n",
      "     1.26868229e+01  1.26868229e+01]\n",
      "   [-2.25820465e+01 -2.25820465e+01 -2.25820465e+01 ... -2.25820465e+01\n",
      "    -2.25820465e+01 -2.25820465e+01]\n",
      "   ...\n",
      "   [-9.31390533e+01 -9.31390533e+01 -9.31390533e+01 ... -9.31390533e+01\n",
      "    -9.31390533e+01 -9.31390533e+01]\n",
      "   [ 1.04962318e+02  1.04962318e+02  1.04962318e+02 ...  1.04962318e+02\n",
      "     1.04962318e+02  1.04962318e+02]\n",
      "   [-7.80756378e+01 -7.80756378e+01 -7.80756378e+01 ... -7.80756378e+01\n",
      "    -7.80756378e+01 -7.80756378e+01]]\n",
      "\n",
      "  [[-1.09563522e+01 -1.09563522e+01 -1.09563522e+01 ... -1.09563522e+01\n",
      "    -1.09563522e+01 -1.09563522e+01]\n",
      "   [ 3.37870750e+01  3.37870750e+01  3.37870750e+01 ...  3.37870750e+01\n",
      "     3.37870750e+01  3.37870750e+01]\n",
      "   [-1.52067833e+01 -1.52067833e+01 -1.52067833e+01 ... -1.52067833e+01\n",
      "    -1.52067833e+01 -1.52067833e+01]\n",
      "   ...\n",
      "   [-6.06810684e+01 -6.06810684e+01 -6.06810684e+01 ... -6.06810684e+01\n",
      "    -6.06810684e+01 -6.06810684e+01]\n",
      "   [ 4.86012497e+01  4.86012497e+01  4.86012497e+01 ...  4.86012497e+01\n",
      "     4.86012497e+01  4.86012497e+01]\n",
      "   [-1.48817474e+02 -1.48817474e+02 -1.48817474e+02 ... -1.48817474e+02\n",
      "    -1.48817474e+02 -1.48817474e+02]]]\n",
      "\n",
      "\n",
      " [[[-1.26848717e+02 -1.26848717e+02 -1.26848717e+02 ... -1.26848717e+02\n",
      "    -1.26848717e+02 -1.26848717e+02]\n",
      "   [ 1.36254711e+01  1.36254711e+01  1.36254711e+01 ...  1.36254711e+01\n",
      "     1.36254711e+01  1.36254711e+01]\n",
      "   [-7.57005386e+01 -7.57005386e+01 -7.57005386e+01 ... -7.57005386e+01\n",
      "    -7.57005386e+01 -7.57005386e+01]\n",
      "   ...\n",
      "   [-1.24673882e+02 -1.24673882e+02 -1.24673882e+02 ... -1.24673882e+02\n",
      "    -1.24673882e+02 -1.24673882e+02]\n",
      "   [ 6.19115868e+01  6.19115868e+01  6.19115868e+01 ...  6.19115868e+01\n",
      "     6.19115868e+01  6.19115868e+01]\n",
      "   [-7.19311523e+01 -7.19311523e+01 -7.19311523e+01 ... -7.19311523e+01\n",
      "    -7.19311523e+01 -7.19311523e+01]]\n",
      "\n",
      "  [[-1.12900391e+02 -1.12900391e+02 -1.12900391e+02 ... -1.12900391e+02\n",
      "    -1.12900391e+02 -1.12900391e+02]\n",
      "   [-1.10641861e+01 -1.10641861e+01 -1.10641861e+01 ... -1.10641861e+01\n",
      "    -1.10641861e+01 -1.10641861e+01]\n",
      "   [-4.78105011e+01 -4.78105011e+01 -4.78105011e+01 ... -4.78105011e+01\n",
      "    -4.78105011e+01 -4.78105011e+01]\n",
      "   ...\n",
      "   [-1.48546432e+02 -1.48546432e+02 -1.48546432e+02 ... -1.48546432e+02\n",
      "    -1.48546432e+02 -1.48546432e+02]\n",
      "   [ 1.17091347e+02  1.17091347e+02  1.17091347e+02 ...  1.17091347e+02\n",
      "     1.17091347e+02  1.17091347e+02]\n",
      "   [-8.47998199e+01 -8.47998199e+01 -8.47998199e+01 ... -8.47998199e+01\n",
      "    -8.47998199e+01 -8.47998199e+01]]\n",
      "\n",
      "  [[-4.45975952e+01 -4.45975952e+01 -4.45975952e+01 ... -4.45975952e+01\n",
      "    -4.45975952e+01 -4.45975952e+01]\n",
      "   [ 7.07967281e+00  7.07967281e+00  7.07967281e+00 ...  7.07967281e+00\n",
      "     7.07967281e+00  7.07967281e+00]\n",
      "   [ 1.15620632e+01  1.15620632e+01  1.15620632e+01 ...  1.15620632e+01\n",
      "     1.15620632e+01  1.15620632e+01]\n",
      "   ...\n",
      "   [-1.26221176e+02 -1.26221176e+02 -1.26221176e+02 ... -1.26221176e+02\n",
      "    -1.26221176e+02 -1.26221176e+02]\n",
      "   [ 9.70881882e+01  9.70881882e+01  9.70881882e+01 ...  9.70881882e+01\n",
      "     9.70881882e+01  9.70881882e+01]\n",
      "   [-8.03393402e+01 -8.03393402e+01 -8.03393402e+01 ... -8.03393402e+01\n",
      "    -8.03393402e+01 -8.03393402e+01]]\n",
      "\n",
      "  [[-4.61899071e+01 -4.61899071e+01 -4.61899071e+01 ... -4.61899071e+01\n",
      "    -4.61899071e+01 -4.61899071e+01]\n",
      "   [ 3.04286289e+00  3.04286289e+00  3.04286289e+00 ...  3.04286289e+00\n",
      "     3.04286289e+00  3.04286289e+00]\n",
      "   [ 9.44606209e+00  9.44606209e+00  9.44606209e+00 ...  9.44606209e+00\n",
      "     9.44606209e+00  9.44606209e+00]\n",
      "   ...\n",
      "   [-1.36858292e+02 -1.36858292e+02 -1.36858292e+02 ... -1.36858292e+02\n",
      "    -1.36858292e+02 -1.36858292e+02]\n",
      "   [ 7.66677399e+01  7.66677399e+01  7.66677399e+01 ...  7.66677399e+01\n",
      "     7.66677399e+01  7.66677399e+01]\n",
      "   [-9.62865601e+01 -9.62865601e+01 -9.62865601e+01 ... -9.62865601e+01\n",
      "    -9.62865601e+01 -9.62865601e+01]]\n",
      "\n",
      "  [[-6.22671700e+00 -6.22671700e+00 -6.22671700e+00 ... -6.22671700e+00\n",
      "    -6.22671700e+00 -6.22671700e+00]\n",
      "   [ 1.91820202e+01  1.91820202e+01  1.91820202e+01 ...  1.91820202e+01\n",
      "     1.91820202e+01  1.91820202e+01]\n",
      "   [-9.85820389e+00 -9.85820389e+00 -9.85820389e+00 ... -9.85820389e+00\n",
      "    -9.85820389e+00 -9.85820389e+00]\n",
      "   ...\n",
      "   [-7.14098663e+01 -7.14098663e+01 -7.14098663e+01 ... -7.14098663e+01\n",
      "    -7.14098663e+01 -7.14098663e+01]\n",
      "   [ 4.94573631e+01  4.94573631e+01  4.94573631e+01 ...  4.94573631e+01\n",
      "     4.94573631e+01  4.94573631e+01]\n",
      "   [-1.89678574e+02 -1.89678574e+02 -1.89678574e+02 ... -1.89678574e+02\n",
      "    -1.89678574e+02 -1.89678574e+02]]]\n",
      "\n",
      "\n",
      " [[[-7.13851395e+01 -7.13851395e+01 -7.13851395e+01 ... -7.13851395e+01\n",
      "    -7.13851395e+01 -7.13851395e+01]\n",
      "   [ 4.19347229e+01  4.19347229e+01  4.19347229e+01 ...  4.19347229e+01\n",
      "     4.19347229e+01  4.19347229e+01]\n",
      "   [-4.58315964e+01 -4.58315964e+01 -4.58315964e+01 ... -4.58315964e+01\n",
      "    -4.58315964e+01 -4.58315964e+01]\n",
      "   ...\n",
      "   [-1.21203835e+02 -1.21203835e+02 -1.21203835e+02 ... -1.21203835e+02\n",
      "    -1.21203835e+02 -1.21203835e+02]\n",
      "   [ 7.28882828e+01  7.28882828e+01  7.28882828e+01 ...  7.28882828e+01\n",
      "     7.28882828e+01  7.28882828e+01]\n",
      "   [-2.14865780e+01 -2.14865780e+01 -2.14865780e+01 ... -2.14865780e+01\n",
      "    -2.14865780e+01 -2.14865780e+01]]\n",
      "\n",
      "  [[-7.61646957e+01 -7.61646957e+01 -7.61646957e+01 ... -7.61646957e+01\n",
      "    -7.61646957e+01 -7.61646957e+01]\n",
      "   [ 1.62770348e+01  1.62770348e+01  1.62770348e+01 ...  1.62770348e+01\n",
      "     1.62770348e+01  1.62770348e+01]\n",
      "   [-1.02499657e+01 -1.02499657e+01 -1.02499657e+01 ... -1.02499657e+01\n",
      "    -1.02499657e+01 -1.02499657e+01]\n",
      "   ...\n",
      "   [-1.29019150e+02 -1.29019150e+02 -1.29019150e+02 ... -1.29019150e+02\n",
      "    -1.29019150e+02 -1.29019150e+02]\n",
      "   [ 1.09344612e+02  1.09344612e+02  1.09344612e+02 ...  1.09344612e+02\n",
      "     1.09344612e+02  1.09344612e+02]\n",
      "   [-6.96123047e+01 -6.96123047e+01 -6.96123047e+01 ... -6.96123047e+01\n",
      "    -6.96123047e+01 -6.96123047e+01]]\n",
      "\n",
      "  [[-2.29666557e+01 -2.29666557e+01 -2.29666557e+01 ... -2.29666557e+01\n",
      "    -2.29666557e+01 -2.29666557e+01]\n",
      "   [ 2.46142788e+01  2.46142788e+01  2.46142788e+01 ...  2.46142788e+01\n",
      "     2.46142788e+01  2.46142788e+01]\n",
      "   [ 3.10823860e+01  3.10823860e+01  3.10823860e+01 ...  3.10823860e+01\n",
      "     3.10823860e+01  3.10823860e+01]\n",
      "   ...\n",
      "   [-1.14508507e+02 -1.14508507e+02 -1.14508507e+02 ... -1.14508507e+02\n",
      "    -1.14508507e+02 -1.14508507e+02]\n",
      "   [ 1.11675385e+02  1.11675385e+02  1.11675385e+02 ...  1.11675385e+02\n",
      "     1.11675385e+02  1.11675385e+02]\n",
      "   [-6.20354843e+01 -6.20354843e+01 -6.20354843e+01 ... -6.20354843e+01\n",
      "    -6.20354843e+01 -6.20354843e+01]]\n",
      "\n",
      "  [[-3.52519035e+01 -3.52519035e+01 -3.52519035e+01 ... -3.52519035e+01\n",
      "    -3.52519035e+01 -3.52519035e+01]\n",
      "   [ 1.19222498e+01  1.19222498e+01  1.19222498e+01 ...  1.19222498e+01\n",
      "     1.19222498e+01  1.19222498e+01]\n",
      "   [ 2.78897743e+01  2.78897743e+01  2.78897743e+01 ...  2.78897743e+01\n",
      "     2.78897743e+01  2.78897743e+01]\n",
      "   ...\n",
      "   [-1.23644302e+02 -1.23644302e+02 -1.23644302e+02 ... -1.23644302e+02\n",
      "    -1.23644302e+02 -1.23644302e+02]\n",
      "   [ 9.16775131e+01  9.16775131e+01  9.16775131e+01 ...  9.16775131e+01\n",
      "     9.16775131e+01  9.16775131e+01]\n",
      "   [-7.70716171e+01 -7.70716171e+01 -7.70716171e+01 ... -7.70716171e+01\n",
      "    -7.70716171e+01 -7.70716171e+01]]\n",
      "\n",
      "  [[-2.90820122e+00 -2.90820122e+00 -2.90820122e+00 ... -2.90820122e+00\n",
      "    -2.90820122e+00 -2.90820122e+00]\n",
      "   [ 1.50837240e+01  1.50837240e+01  1.50837240e+01 ...  1.50837240e+01\n",
      "     1.50837240e+01  1.50837240e+01]\n",
      "   [ 1.50992870e-01  1.50992870e-01  1.50992870e-01 ...  1.50992870e-01\n",
      "     1.50992870e-01  1.50992870e-01]\n",
      "   ...\n",
      "   [-7.35042877e+01 -7.35042877e+01 -7.35042877e+01 ... -7.35042877e+01\n",
      "    -7.35042877e+01 -7.35042877e+01]\n",
      "   [ 8.44047775e+01  8.44047775e+01  8.44047775e+01 ...  8.44047775e+01\n",
      "     8.44047775e+01  8.44047775e+01]\n",
      "   [-1.77175797e+02 -1.77175797e+02 -1.77175797e+02 ... -1.77175797e+02\n",
      "    -1.77175797e+02 -1.77175797e+02]]]\n",
      "\n",
      "\n",
      " [[[-5.48747063e+01 -5.48747063e+01 -5.48747063e+01 ... -5.48747063e+01\n",
      "    -5.48747063e+01 -5.48747063e+01]\n",
      "   [ 6.71577148e+01  6.71577148e+01  6.71577148e+01 ...  6.71577148e+01\n",
      "     6.71577148e+01  6.71577148e+01]\n",
      "   [-8.42740784e+01 -8.42740784e+01 -8.42740784e+01 ... -8.42740784e+01\n",
      "    -8.42740784e+01 -8.42740784e+01]\n",
      "   ...\n",
      "   [-1.33038651e+02 -1.33038651e+02 -1.33038651e+02 ... -1.33038651e+02\n",
      "    -1.33038651e+02 -1.33038651e+02]\n",
      "   [ 2.63858166e+01  2.63858166e+01  2.63858166e+01 ...  2.63858166e+01\n",
      "     2.63858166e+01  2.63858166e+01]\n",
      "   [-1.84679961e+00 -1.84679961e+00 -1.84679961e+00 ... -1.84679961e+00\n",
      "    -1.84679961e+00 -1.84679961e+00]]\n",
      "\n",
      "  [[-7.81479187e+01 -7.81479187e+01 -7.81479187e+01 ... -7.81479187e+01\n",
      "    -7.81479187e+01 -7.81479187e+01]\n",
      "   [ 5.98763008e+01  5.98763008e+01  5.98763008e+01 ...  5.98763008e+01\n",
      "     5.98763008e+01  5.98763008e+01]\n",
      "   [-5.36792336e+01 -5.36792336e+01 -5.36792336e+01 ... -5.36792336e+01\n",
      "    -5.36792336e+01 -5.36792336e+01]\n",
      "   ...\n",
      "   [-1.45820877e+02 -1.45820877e+02 -1.45820877e+02 ... -1.45820877e+02\n",
      "    -1.45820877e+02 -1.45820877e+02]\n",
      "   [ 7.88428955e+01  7.88428955e+01  7.88428955e+01 ...  7.88428955e+01\n",
      "     7.88428955e+01  7.88428955e+01]\n",
      "   [-7.27277527e+01 -7.27277527e+01 -7.27277527e+01 ... -7.27277527e+01\n",
      "    -7.27277527e+01 -7.27277527e+01]]\n",
      "\n",
      "  [[-3.96777382e+01 -3.96777382e+01 -3.96777382e+01 ... -3.96777382e+01\n",
      "    -3.96777382e+01 -3.96777382e+01]\n",
      "   [ 6.11086273e+01  6.11086273e+01  6.11086273e+01 ...  6.11086273e+01\n",
      "     6.11086273e+01  6.11086273e+01]\n",
      "   [-1.43451614e+01 -1.43451614e+01 -1.43451614e+01 ... -1.43451614e+01\n",
      "    -1.43451614e+01 -1.43451614e+01]\n",
      "   ...\n",
      "   [-1.30441895e+02 -1.30441895e+02 -1.30441895e+02 ... -1.30441895e+02\n",
      "    -1.30441895e+02 -1.30441895e+02]\n",
      "   [ 1.08515816e+02  1.08515816e+02  1.08515816e+02 ...  1.08515816e+02\n",
      "     1.08515816e+02  1.08515816e+02]\n",
      "   [-5.35747871e+01 -5.35747871e+01 -5.35747871e+01 ... -5.35747871e+01\n",
      "    -5.35747871e+01 -5.35747871e+01]]\n",
      "\n",
      "  [[-4.10589485e+01 -4.10589485e+01 -4.10589485e+01 ... -4.10589485e+01\n",
      "    -4.10589485e+01 -4.10589485e+01]\n",
      "   [ 4.04711304e+01  4.04711304e+01  4.04711304e+01 ...  4.04711304e+01\n",
      "     4.04711304e+01  4.04711304e+01]\n",
      "   [-1.92358437e+01 -1.92358437e+01 -1.92358437e+01 ... -1.92358437e+01\n",
      "    -1.92358437e+01 -1.92358437e+01]\n",
      "   ...\n",
      "   [-1.45154907e+02 -1.45154907e+02 -1.45154907e+02 ... -1.45154907e+02\n",
      "    -1.45154907e+02 -1.45154907e+02]\n",
      "   [ 7.30679855e+01  7.30679855e+01  7.30679855e+01 ...  7.30679855e+01\n",
      "     7.30679855e+01  7.30679855e+01]\n",
      "   [-5.29791298e+01 -5.29791298e+01 -5.29791298e+01 ... -5.29791298e+01\n",
      "    -5.29791298e+01 -5.29791298e+01]]\n",
      "\n",
      "  [[ 3.63614941e+00  3.63614941e+00  3.63614941e+00 ...  3.63614941e+00\n",
      "     3.63614941e+00  3.63614941e+00]\n",
      "   [ 5.11792679e+01  5.11792679e+01  5.11792679e+01 ...  5.11792679e+01\n",
      "     5.11792679e+01  5.11792679e+01]\n",
      "   [-3.99397011e+01 -3.99397011e+01 -3.99397011e+01 ... -3.99397011e+01\n",
      "    -3.99397011e+01 -3.99397011e+01]\n",
      "   ...\n",
      "   [-9.13452225e+01 -9.13452225e+01 -9.13452225e+01 ... -9.13452225e+01\n",
      "    -9.13452225e+01 -9.13452225e+01]\n",
      "   [ 6.85575027e+01  6.85575027e+01  6.85575027e+01 ...  6.85575027e+01\n",
      "     6.85575027e+01  6.85575027e+01]\n",
      "   [-1.46652481e+02 -1.46652481e+02 -1.46652481e+02 ... -1.46652481e+02\n",
      "    -1.46652481e+02 -1.46652481e+02]]]]\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape12-W_shape12-1-0] _\u001b[0m\n",
      "\n",
      "Z_shape = (3, 17, 17, 8), W_shape = (5, 5, 8, 16), stride = 1, padding = 0\n",
      "backward = True, device = cpu()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[ 5.93117094e+00 -4.61600447e+00 -7.43411541e+00 ...  9.49053860e+00\n",
      "     6.47611380e+00 -3.38525438e...7e+00]\n",
      "   [-3.93575430e+00 -6.98609781e+00  1.63659811e+00 ...  8.22474575e+00\n",
      "     2.56555057e+00  1.63004756e+00]]]])\n",
      "W_shape    = (5, 5, 8, 16)\n",
      "Wtch       = tensor([[[[ 5.9312e+00, -4.6160e+00, -7.4341e+00,  ...,  9.4905e+00,\n",
      "            6.4761e+00, -3.3853e+00],\n",
      "          [...[-3.9358e+00, -6.9861e+00,  1.6366e+00,  ...,  8.2247e+00,\n",
      "            2.5656e+00,  1.6300e+00]]]], requires_grad=True)\n",
      "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
      "     4.75044203e+00 -7.56786048e...8e+00]\n",
      "   [ 2.80155873e+00  3.11298299e+00 -3.24756050e+00 ... -7.96233535e-01\n",
      "     4.72636795e+00 -5.75466204e+00]]]])\n",
      "Z_shape    = (3, 17, 17, 8)\n",
      "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
      "            4.7504e+00, -7.5679e-01],\n",
      "          [...[ 2.8016e+00,  3.1130e+00, -3.2476e+00,  ..., -7.9623e-01,\n",
      "            4.7264e+00, -5.7547e+00]]]], requires_grad=True)\n",
      "_W         = array([[[[ 5.93117094e+00, -4.61600447e+00, -7.43411541e+00, ...,\n",
      "           9.49053860e+00,  6.47611380e+00, -3.38525...11e+00, ...,\n",
      "           8.22474575e+00,  2.56555057e+00,  1.63004756e+00]]]],\n",
      "      shape=(5, 5, 8, 16), dtype=float32)\n",
      "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
      "          -4.88638926e+00,  4.75044203e+00, -7.56786...0e+00, ...,\n",
      "          -7.96233535e-01,  4.72636795e+00, -5.75466204e+00]]]],\n",
      "      shape=(3, 17, 17, 8), dtype=float32)\n",
      "backward   = True\n",
      "device     = cpu()\n",
      "err1       = np.float32(0.0016586707)\n",
      "err2       = np.float32(0.0030867655)\n",
      "out        = tensor([[[[ 5.8605e+02,  6.5851e+02,  3.1471e+01,  ..., -2.0572e+02,\n",
      "           -5.6982e+02, -7.7784e+02],\n",
      "          [...,  1.3106e+02, -3.2224e+02,  ...,  7.1755e+01,\n",
      "           -5.2006e+02, -6.5310e+01]]]], grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(50567.7344, grad_fn=<SumBackward0>)\n",
      "padding    = 0\n",
      "stride     = 1\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c5655d5400>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655d48f0>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655d48f0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655d48f0>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655d48f0>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[  37.84839     37.84839     37.84839   ...   37.84839\n",
      "      37.84839     37.84839  ]\n",
      "   [ -33.60088    -33.60088    -33.60088   ...  -33.60088\n",
      "     -33.60088    -33.60088  ]\n",
      "   [ -36.00153    -36.00153    -36.00153   ...  -36.00153\n",
      "     -36.00153    -36.00153  ]\n",
      "   ...\n",
      "   [  36.27931     36.27931     36.27931   ...   36.27931\n",
      "      36.27931     36.27931  ]\n",
      "   [  -8.610425    -8.610425    -8.610425  ...   -8.610425\n",
      "      -8.610425    -8.610425 ]\n",
      "   [-214.67365   -214.67365   -214.67365   ... -214.67365\n",
      "    -214.67365   -214.67365  ]]\n",
      "\n",
      "  [[  45.22556     45.22556     45.22556   ...   45.22556\n",
      "      45.22556     45.22556  ]\n",
      "   [ -13.485558   -13.485558   -13.485558  ...  -13.485558\n",
      "     -13.485558   -13.485558 ]\n",
      "   [ -29.072964   -29.072964   -29.072964  ...  -29.072964\n",
      "     -29.072964   -29.072964 ]\n",
      "   ...\n",
      "   [  73.40308     73.40308     73.40308   ...   73.40308\n",
      "      73.40308     73.40308  ]\n",
      "   [ -15.808004   -15.808004   -15.808004  ...  -15.808004\n",
      "     -15.808004   -15.808004 ]\n",
      "   [-163.33002   -163.33002   -163.33002   ... -163.33002\n",
      "    -163.33002   -163.33002  ]]\n",
      "\n",
      "  [[  13.053932    13.053932    13.053932  ...   13.053932\n",
      "      13.053932    13.053932 ]\n",
      "   [ -78.65258    -78.65258    -78.65258   ...  -78.65258\n",
      "     -78.65258    -78.65258  ]\n",
      "   [  10.061691    10.061691    10.061691  ...   10.061691\n",
      "      10.061691    10.061691 ]\n",
      "   ...\n",
      "   [  -2.7422943   -2.7422943   -2.7422943 ...   -2.7422943\n",
      "      -2.7422943   -2.7422943]\n",
      "   [ -17.210348   -17.210348   -17.210348  ...  -17.210348\n",
      "     -17.210348   -17.210348 ]\n",
      "   [-192.476     -192.476     -192.476     ... -192.476\n",
      "    -192.476     -192.476    ]]\n",
      "\n",
      "  [[ -38.955643   -38.955643   -38.955643  ...  -38.955643\n",
      "     -38.955643   -38.955643 ]\n",
      "   [ -22.549774   -22.549774   -22.549774  ...  -22.549774\n",
      "     -22.549774   -22.549774 ]\n",
      "   [  -7.3511505   -7.3511505   -7.3511505 ...   -7.3511505\n",
      "      -7.3511505   -7.3511505]\n",
      "   ...\n",
      "   [ -11.800983   -11.800983   -11.800983  ...  -11.800983\n",
      "     -11.800983   -11.800983 ]\n",
      "   [   9.1125       9.1125       9.1125    ...    9.1125\n",
      "       9.1125       9.1125   ]\n",
      "   [-109.37804   -109.37804   -109.37804   ... -109.37804\n",
      "    -109.37804   -109.37804  ]]\n",
      "\n",
      "  [[ -47.215958   -47.215958   -47.215958  ...  -47.215958\n",
      "     -47.215958   -47.215958 ]\n",
      "   [  23.65165     23.65165     23.65165   ...   23.65165\n",
      "      23.65165     23.65165  ]\n",
      "   [ -58.59626    -58.59626    -58.59626   ...  -58.59626\n",
      "     -58.59626    -58.59626  ]\n",
      "   ...\n",
      "   [-122.06634   -122.06634   -122.06634   ... -122.06634\n",
      "    -122.06634   -122.06634  ]\n",
      "   [  -2.0951347   -2.0951347   -2.0951347 ...   -2.0951347\n",
      "      -2.0951347   -2.0951347]\n",
      "   [-111.00746   -111.00746   -111.00746   ... -111.00746\n",
      "    -111.00746   -111.00746  ]]]\n",
      "\n",
      "\n",
      " [[[  -1.2779949   -1.2779949   -1.2779949 ...   -1.2779949\n",
      "      -1.2779949   -1.2779949]\n",
      "   [  -7.0218735   -7.0218735   -7.0218735 ...   -7.0218735\n",
      "      -7.0218735   -7.0218735]\n",
      "   [ -64.33977    -64.33977    -64.33977   ...  -64.33977\n",
      "     -64.33977    -64.33977  ]\n",
      "   ...\n",
      "   [   7.7821045    7.7821045    7.7821045 ...    7.7821045\n",
      "       7.7821045    7.7821045]\n",
      "   [  36.20109     36.20109     36.20109   ...   36.20109\n",
      "      36.20109     36.20109  ]\n",
      "   [-186.4855    -186.4855    -186.4855    ... -186.4855\n",
      "    -186.4855    -186.4855   ]]\n",
      "\n",
      "  [[   7.297121     7.297121     7.297121  ...    7.297121\n",
      "       7.297121     7.297121 ]\n",
      "   [ -11.920391   -11.920391   -11.920391  ...  -11.920391\n",
      "     -11.920391   -11.920391 ]\n",
      "   [ -43.225067   -43.225067   -43.225067  ...  -43.225067\n",
      "     -43.225067   -43.225067 ]\n",
      "   ...\n",
      "   [  12.711544    12.711544    12.711544  ...   12.711544\n",
      "      12.711544    12.711544 ]\n",
      "   [  51.456886    51.456886    51.456886  ...   51.456886\n",
      "      51.456886    51.456886 ]\n",
      "   [-135.76584   -135.76584   -135.76584   ... -135.76584\n",
      "    -135.76584   -135.76584  ]]\n",
      "\n",
      "  [[ -23.308205   -23.308205   -23.308205  ...  -23.308205\n",
      "     -23.308205   -23.308205 ]\n",
      "   [ -53.463135   -53.463135   -53.463135  ...  -53.463135\n",
      "     -53.463135   -53.463135 ]\n",
      "   [ -13.30697    -13.30697    -13.30697   ...  -13.30697\n",
      "     -13.30697    -13.30697  ]\n",
      "   ...\n",
      "   [ -68.48101    -68.48101    -68.48101   ...  -68.48101\n",
      "     -68.48101    -68.48101  ]\n",
      "   [  37.520813    37.520813    37.520813  ...   37.520813\n",
      "      37.520813    37.520813 ]\n",
      "   [-172.19931   -172.19931   -172.19931   ... -172.19931\n",
      "    -172.19931   -172.19931  ]]\n",
      "\n",
      "  [[ -53.48913    -53.48913    -53.48913   ...  -53.48913\n",
      "     -53.48913    -53.48913  ]\n",
      "   [  20.761837    20.761837    20.761837  ...   20.761837\n",
      "      20.761837    20.761837 ]\n",
      "   [ -59.05236    -59.05236    -59.05236   ...  -59.05236\n",
      "     -59.05236    -59.05236  ]\n",
      "   ...\n",
      "   [ -64.18131    -64.18131    -64.18131   ...  -64.18131\n",
      "     -64.18131    -64.18131  ]\n",
      "   [  75.395935    75.395935    75.395935  ...   75.395935\n",
      "      75.395935    75.395935 ]\n",
      "   [-118.91438   -118.91438   -118.91438   ... -118.91438\n",
      "    -118.91438   -118.91438  ]]\n",
      "\n",
      "  [[ -44.630768   -44.630768   -44.630768  ...  -44.630768\n",
      "     -44.630768   -44.630768 ]\n",
      "   [  24.693897    24.693897    24.693897  ...   24.693897\n",
      "      24.693897    24.693897 ]\n",
      "   [ -92.68728    -92.68728    -92.68728   ...  -92.68728\n",
      "     -92.68728    -92.68728  ]\n",
      "   ...\n",
      "   [-154.33562   -154.33562   -154.33562   ... -154.33562\n",
      "    -154.33562   -154.33562  ]\n",
      "   [  35.56113     35.56113     35.56113   ...   35.56113\n",
      "      35.56113     35.56113  ]\n",
      "   [-142.5783    -142.5783    -142.5783    ... -142.5783\n",
      "    -142.5783    -142.5783   ]]]\n",
      "\n",
      "\n",
      " [[[  20.505566    20.505566    20.505566  ...   20.505566\n",
      "      20.505566    20.505566 ]\n",
      "   [  22.888199    22.888199    22.888199  ...   22.888199\n",
      "      22.888199    22.888199 ]\n",
      "   [-102.739334  -102.739334  -102.739334  ... -102.739334\n",
      "    -102.739334  -102.739334 ]\n",
      "   ...\n",
      "   [ -40.526775   -40.526775   -40.526775  ...  -40.526775\n",
      "     -40.526775   -40.526775 ]\n",
      "   [  55.49948     55.49948     55.49948   ...   55.49948\n",
      "      55.49948     55.49948  ]\n",
      "   [-166.16568   -166.16568   -166.16568   ... -166.16568\n",
      "    -166.16568   -166.16568  ]]\n",
      "\n",
      "  [[  32.04589     32.04589     32.04589   ...   32.04589\n",
      "      32.04589     32.04589  ]\n",
      "   [  39.361004    39.361004    39.361004  ...   39.361004\n",
      "      39.361004    39.361004 ]\n",
      "   [ -63.935757   -63.935757   -63.935757  ...  -63.935757\n",
      "     -63.935757   -63.935757 ]\n",
      "   ...\n",
      "   [  -9.228447    -9.228447    -9.228447  ...   -9.228447\n",
      "      -9.228447    -9.228447 ]\n",
      "   [  65.521286    65.521286    65.521286  ...   65.521286\n",
      "      65.521286    65.521286 ]\n",
      "   [-117.32037   -117.32037   -117.32037   ... -117.32037\n",
      "    -117.32037   -117.32037  ]]\n",
      "\n",
      "  [[  28.711174    28.711174    28.711174  ...   28.711174\n",
      "      28.711174    28.711174 ]\n",
      "   [   6.415102     6.415102     6.415102  ...    6.415102\n",
      "       6.415102     6.415102 ]\n",
      "   [ -72.76602    -72.76602    -72.76602   ...  -72.76602\n",
      "     -72.76602    -72.76602  ]\n",
      "   ...\n",
      "   [ -64.881874   -64.881874   -64.881874  ...  -64.881874\n",
      "     -64.881874   -64.881874 ]\n",
      "   [  25.8516      25.8516      25.8516    ...   25.8516\n",
      "      25.8516      25.8516   ]\n",
      "   [-133.74744   -133.74744   -133.74744   ... -133.74744\n",
      "    -133.74744   -133.74744  ]]\n",
      "\n",
      "  [[  26.208084    26.208084    26.208084  ...   26.208084\n",
      "      26.208084    26.208084 ]\n",
      "   [  67.0835      67.0835      67.0835    ...   67.0835\n",
      "      67.0835      67.0835   ]\n",
      "   [-117.0288    -117.0288    -117.0288    ... -117.0288\n",
      "    -117.0288    -117.0288   ]\n",
      "   ...\n",
      "   [ -53.710926   -53.710926   -53.710926  ...  -53.710926\n",
      "     -53.710926   -53.710926 ]\n",
      "   [  89.51799     89.51799     89.51799   ...   89.51799\n",
      "      89.51799     89.51799  ]\n",
      "   [-112.57427   -112.57427   -112.57427   ... -112.57427\n",
      "    -112.57427   -112.57427  ]]\n",
      "\n",
      "  [[  25.827133    25.827133    25.827133  ...   25.827133\n",
      "      25.827133    25.827133 ]\n",
      "   [  70.78707     70.78707     70.78707   ...   70.78707\n",
      "      70.78707     70.78707  ]\n",
      "   [-136.19943   -136.19943   -136.19943   ... -136.19943\n",
      "    -136.19943   -136.19943  ]\n",
      "   ...\n",
      "   [-138.49365   -138.49365   -138.49365   ... -138.49365\n",
      "    -138.49365   -138.49365  ]\n",
      "   [  64.13403     64.13403     64.13403   ...   64.13403\n",
      "      64.13403     64.13403  ]\n",
      "   [-131.67484   -131.67484   -131.67484   ... -131.67484\n",
      "    -131.67484   -131.67484  ]]]\n",
      "\n",
      "\n",
      " [[[ -38.771248   -38.771248   -38.771248  ...  -38.771248\n",
      "     -38.771248   -38.771248 ]\n",
      "   [  55.660534    55.660534    55.660534  ...   55.660534\n",
      "      55.660534    55.660534 ]\n",
      "   [ -58.84326    -58.84326    -58.84326   ...  -58.84326\n",
      "     -58.84326    -58.84326  ]\n",
      "   ...\n",
      "   [ -68.098465   -68.098465   -68.098465  ...  -68.098465\n",
      "     -68.098465   -68.098465 ]\n",
      "   [ 105.072464   105.072464   105.072464  ...  105.072464\n",
      "     105.072464   105.072464 ]\n",
      "   [-172.75125   -172.75125   -172.75125   ... -172.75125\n",
      "    -172.75125   -172.75125  ]]\n",
      "\n",
      "  [[ -19.080677   -19.080677   -19.080677  ...  -19.080677\n",
      "     -19.080677   -19.080677 ]\n",
      "   [  75.96222     75.96222     75.96222   ...   75.96222\n",
      "      75.96222     75.96222  ]\n",
      "   [  -6.3991375   -6.3991375   -6.3991375 ...   -6.3991375\n",
      "      -6.3991375   -6.3991375]\n",
      "   ...\n",
      "   [ -38.36323    -38.36323    -38.36323   ...  -38.36323\n",
      "     -38.36323    -38.36323  ]\n",
      "   [  94.805756    94.805756    94.805756  ...   94.805756\n",
      "      94.805756    94.805756 ]\n",
      "   [-151.25008   -151.25008   -151.25008   ... -151.25008\n",
      "    -151.25008   -151.25008  ]]\n",
      "\n",
      "  [[ -28.224709   -28.224709   -28.224709  ...  -28.224709\n",
      "     -28.224709   -28.224709 ]\n",
      "   [  61.893845    61.893845    61.893845  ...   61.893845\n",
      "      61.893845    61.893845 ]\n",
      "   [ -23.010807   -23.010807   -23.010807  ...  -23.010807\n",
      "     -23.010807   -23.010807 ]\n",
      "   ...\n",
      "   [ -85.93101    -85.93101    -85.93101   ...  -85.93101\n",
      "     -85.93101    -85.93101  ]\n",
      "   [  12.877844    12.877844    12.877844  ...   12.877844\n",
      "      12.877844    12.877844 ]\n",
      "   [-182.13937   -182.13937   -182.13937   ... -182.13937\n",
      "    -182.13937   -182.13937  ]]\n",
      "\n",
      "  [[  -7.8191986   -7.8191986   -7.8191986 ...   -7.8191986\n",
      "      -7.8191986   -7.8191986]\n",
      "   [ 130.69197    130.69197    130.69197   ...  130.69197\n",
      "     130.69197    130.69197  ]\n",
      "   [ -90.35755    -90.35755    -90.35755   ...  -90.35755\n",
      "     -90.35755    -90.35755  ]\n",
      "   ...\n",
      "   [-101.219124  -101.219124  -101.219124  ... -101.219124\n",
      "    -101.219124  -101.219124 ]\n",
      "   [  83.750465    83.750465    83.750465  ...   83.750465\n",
      "      83.750465    83.750465 ]\n",
      "   [-145.51433   -145.51433   -145.51433   ... -145.51433\n",
      "    -145.51433   -145.51433  ]]\n",
      "\n",
      "  [[  -4.4875793   -4.4875793   -4.4875793 ...   -4.4875793\n",
      "      -4.4875793   -4.4875793]\n",
      "   [ 135.53217    135.53217    135.53217   ...  135.53217\n",
      "     135.53217    135.53217  ]\n",
      "   [-105.655136  -105.655136  -105.655136  ... -105.655136\n",
      "    -105.655136  -105.655136 ]\n",
      "   ...\n",
      "   [-196.41483   -196.41483   -196.41483   ... -196.41483\n",
      "    -196.41483   -196.41483  ]\n",
      "   [  44.195637    44.195637    44.195637  ...   44.195637\n",
      "      44.195637    44.195637 ]\n",
      "   [-182.15768   -182.15768   -182.15768   ... -182.15768\n",
      "    -182.15768   -182.15768  ]]]\n",
      "\n",
      "\n",
      " [[[ -42.303696   -42.303696   -42.303696  ...  -42.303696\n",
      "     -42.303696   -42.303696 ]\n",
      "   [  65.14844     65.14844     65.14844   ...   65.14844\n",
      "      65.14844     65.14844  ]\n",
      "   [ -37.44847    -37.44847    -37.44847   ...  -37.44847\n",
      "     -37.44847    -37.44847  ]\n",
      "   ...\n",
      "   [  -8.610771    -8.610771    -8.610771  ...   -8.610771\n",
      "      -8.610771    -8.610771 ]\n",
      "   [  60.187237    60.187237    60.187237  ...   60.187237\n",
      "      60.187237    60.187237 ]\n",
      "   [-136.29202   -136.29202   -136.29202   ... -136.29202\n",
      "    -136.29202   -136.29202  ]]\n",
      "\n",
      "  [[ -28.928822   -28.928822   -28.928822  ...  -28.928822\n",
      "     -28.928822   -28.928822 ]\n",
      "   [ 109.613174   109.613174   109.613174  ...  109.613174\n",
      "     109.613174   109.613174 ]\n",
      "   [   3.8004622    3.8004622    3.8004622 ...    3.8004622\n",
      "       3.8004622    3.8004622]\n",
      "   ...\n",
      "   [  -6.9245186   -6.9245186   -6.9245186 ...   -6.9245186\n",
      "      -6.9245186   -6.9245186]\n",
      "   [  76.35927     76.35927     76.35927   ...   76.35927\n",
      "      76.35927     76.35927  ]\n",
      "   [-122.47401   -122.47401   -122.47401   ... -122.47401\n",
      "    -122.47401   -122.47401  ]]\n",
      "\n",
      "  [[ -24.669014   -24.669014   -24.669014  ...  -24.669014\n",
      "     -24.669014   -24.669014 ]\n",
      "   [ 105.10323    105.10323    105.10323   ...  105.10323\n",
      "     105.10323    105.10323  ]\n",
      "   [ -13.3821945  -13.3821945  -13.3821945 ...  -13.3821945\n",
      "     -13.3821945  -13.3821945]\n",
      "   ...\n",
      "   [ -42.399345   -42.399345   -42.399345  ...  -42.399345\n",
      "     -42.399345   -42.399345 ]\n",
      "   [  -6.947056    -6.947056    -6.947056  ...   -6.947056\n",
      "      -6.947056    -6.947056 ]\n",
      "   [-146.68968   -146.68968   -146.68968   ... -146.68968\n",
      "    -146.68968   -146.68968  ]]\n",
      "\n",
      "  [[  11.993847    11.993847    11.993847  ...   11.993847\n",
      "      11.993847    11.993847 ]\n",
      "   [ 167.03633    167.03633    167.03633   ...  167.03633\n",
      "     167.03633    167.03633  ]\n",
      "   [ -48.706627   -48.706627   -48.706627  ...  -48.706627\n",
      "     -48.706627   -48.706627 ]\n",
      "   ...\n",
      "   [ -66.51558    -66.51558    -66.51558   ...  -66.51558\n",
      "     -66.51558    -66.51558  ]\n",
      "   [  74.40559     74.40559     74.40559   ...   74.40559\n",
      "      74.40559     74.40559  ]\n",
      "   [-126.74048   -126.74048   -126.74048   ... -126.74048\n",
      "    -126.74048   -126.74048  ]]\n",
      "\n",
      "  [[  45.36252     45.36252     45.36252   ...   45.36252\n",
      "      45.36252     45.36252  ]\n",
      "   [ 162.20001    162.20001    162.20001   ...  162.20001\n",
      "     162.20001    162.20001  ]\n",
      "   [ -79.81204    -79.81204    -79.81204   ...  -79.81204\n",
      "     -79.81204    -79.81204  ]\n",
      "   ...\n",
      "   [-187.95674   -187.95674   -187.95674   ... -187.95674\n",
      "    -187.95674   -187.95674  ]\n",
      "   [  17.109993    17.109993    17.109993  ...   17.109993\n",
      "      17.109993    17.109993 ]\n",
      "   [-145.3532    -145.3532    -145.3532    ... -145.3532\n",
      "    -145.3532    -145.3532   ]]]], W.grad.numpy(): [[[[  37.848366    37.848366    37.848366  ...   37.848366\n",
      "      37.848366    37.848366 ]\n",
      "   [ -33.600903   -33.600903   -33.600903  ...  -33.600903\n",
      "     -33.600903   -33.600903 ]\n",
      "   [ -36.001495   -36.001495   -36.001495  ...  -36.001495\n",
      "     -36.001495   -36.001495 ]\n",
      "   ...\n",
      "   [  36.279297    36.279297    36.279297  ...   36.279297\n",
      "      36.279297    36.279297 ]\n",
      "   [  -8.610411    -8.610411    -8.610411  ...   -8.610411\n",
      "      -8.610411    -8.610411 ]\n",
      "   [-214.67365   -214.67365   -214.67365   ... -214.67365\n",
      "    -214.67365   -214.67365  ]]\n",
      "\n",
      "  [[  45.22555     45.22555     45.22555   ...   45.22555\n",
      "      45.22555     45.22555  ]\n",
      "   [ -13.485528   -13.485528   -13.485528  ...  -13.485528\n",
      "     -13.485528   -13.485528 ]\n",
      "   [ -29.072966   -29.072966   -29.072966  ...  -29.072966\n",
      "     -29.072966   -29.072966 ]\n",
      "   ...\n",
      "   [  73.4031      73.4031      73.4031    ...   73.4031\n",
      "      73.4031      73.4031   ]\n",
      "   [ -15.807903   -15.807903   -15.807903  ...  -15.807903\n",
      "     -15.807903   -15.807903 ]\n",
      "   [-163.33008   -163.33008   -163.33008   ... -163.33008\n",
      "    -163.33008   -163.33008  ]]\n",
      "\n",
      "  [[  13.053965    13.053965    13.053965  ...   13.053965\n",
      "      13.053965    13.053965 ]\n",
      "   [ -78.65251    -78.65251    -78.65251   ...  -78.65251\n",
      "     -78.65251    -78.65251  ]\n",
      "   [  10.06167     10.06167     10.06167   ...   10.06167\n",
      "      10.06167     10.06167  ]\n",
      "   ...\n",
      "   [  -2.7423272   -2.7423272   -2.7423272 ...   -2.7423272\n",
      "      -2.7423272   -2.7423272]\n",
      "   [ -17.210379   -17.210379   -17.210379  ...  -17.210379\n",
      "     -17.210379   -17.210379 ]\n",
      "   [-192.47601   -192.47601   -192.47601   ... -192.47601\n",
      "    -192.47601   -192.47601  ]]\n",
      "\n",
      "  [[ -38.955738   -38.955738   -38.955738  ...  -38.955738\n",
      "     -38.955738   -38.955738 ]\n",
      "   [ -22.5498     -22.5498     -22.5498    ...  -22.5498\n",
      "     -22.5498     -22.5498   ]\n",
      "   [  -7.3511524   -7.3511524   -7.3511524 ...   -7.3511524\n",
      "      -7.3511524   -7.3511524]\n",
      "   ...\n",
      "   [ -11.800994   -11.800994   -11.800994  ...  -11.800994\n",
      "     -11.800994   -11.800994 ]\n",
      "   [   9.112514     9.112514     9.112514  ...    9.112514\n",
      "       9.112514     9.112514 ]\n",
      "   [-109.3781    -109.3781    -109.3781    ... -109.3781\n",
      "    -109.3781    -109.3781   ]]\n",
      "\n",
      "  [[ -47.215862   -47.215862   -47.215862  ...  -47.215862\n",
      "     -47.215862   -47.215862 ]\n",
      "   [  23.651663    23.651663    23.651663  ...   23.651663\n",
      "      23.651663    23.651663 ]\n",
      "   [ -58.596237   -58.596237   -58.596237  ...  -58.596237\n",
      "     -58.596237   -58.596237 ]\n",
      "   ...\n",
      "   [-122.06638   -122.06638   -122.06638   ... -122.06638\n",
      "    -122.06638   -122.06638  ]\n",
      "   [  -2.0951338   -2.0951338   -2.0951338 ...   -2.0951338\n",
      "      -2.0951338   -2.0951338]\n",
      "   [-111.007484  -111.007484  -111.007484  ... -111.007484\n",
      "    -111.007484  -111.007484 ]]]\n",
      "\n",
      "\n",
      " [[[  -1.2779698   -1.2779698   -1.2779698 ...   -1.2779698\n",
      "      -1.2779698   -1.2779698]\n",
      "   [  -7.021856    -7.021856    -7.021856  ...   -7.021856\n",
      "      -7.021856    -7.021856 ]\n",
      "   [ -64.339775   -64.339775   -64.339775  ...  -64.339775\n",
      "     -64.339775   -64.339775 ]\n",
      "   ...\n",
      "   [   7.782082     7.782082     7.782082  ...    7.782082\n",
      "       7.782082     7.782082 ]\n",
      "   [  36.201096    36.201096    36.201096  ...   36.201096\n",
      "      36.201096    36.201096 ]\n",
      "   [-186.4855    -186.4855    -186.4855    ... -186.4855\n",
      "    -186.4855    -186.4855   ]]\n",
      "\n",
      "  [[   7.297106     7.297106     7.297106  ...    7.297106\n",
      "       7.297106     7.297106 ]\n",
      "   [ -11.920423   -11.920423   -11.920423  ...  -11.920423\n",
      "     -11.920423   -11.920423 ]\n",
      "   [ -43.22507    -43.22507    -43.22507   ...  -43.22507\n",
      "     -43.22507    -43.22507  ]\n",
      "   ...\n",
      "   [  12.711528    12.711528    12.711528  ...   12.711528\n",
      "      12.711528    12.711528 ]\n",
      "   [  51.456947    51.456947    51.456947  ...   51.456947\n",
      "      51.456947    51.456947 ]\n",
      "   [-135.76595   -135.76595   -135.76595   ... -135.76595\n",
      "    -135.76595   -135.76595  ]]\n",
      "\n",
      "  [[ -23.308178   -23.308178   -23.308178  ...  -23.308178\n",
      "     -23.308178   -23.308178 ]\n",
      "   [ -53.46307    -53.46307    -53.46307   ...  -53.46307\n",
      "     -53.46307    -53.46307  ]\n",
      "   [ -13.306931   -13.306931   -13.306931  ...  -13.306931\n",
      "     -13.306931   -13.306931 ]\n",
      "   ...\n",
      "   [ -68.48108    -68.48108    -68.48108   ...  -68.48108\n",
      "     -68.48108    -68.48108  ]\n",
      "   [  37.520813    37.520813    37.520813  ...   37.520813\n",
      "      37.520813    37.520813 ]\n",
      "   [-172.19933   -172.19933   -172.19933   ... -172.19933\n",
      "    -172.19933   -172.19933  ]]\n",
      "\n",
      "  [[ -53.489227   -53.489227   -53.489227  ...  -53.489227\n",
      "     -53.489227   -53.489227 ]\n",
      "   [  20.761784    20.761784    20.761784  ...   20.761784\n",
      "      20.761784    20.761784 ]\n",
      "   [ -59.052353   -59.052353   -59.052353  ...  -59.052353\n",
      "     -59.052353   -59.052353 ]\n",
      "   ...\n",
      "   [ -64.18136    -64.18136    -64.18136   ...  -64.18136\n",
      "     -64.18136    -64.18136  ]\n",
      "   [  75.39585     75.39585     75.39585   ...   75.39585\n",
      "      75.39585     75.39585  ]\n",
      "   [-118.91447   -118.91447   -118.91447   ... -118.91447\n",
      "    -118.91447   -118.91447  ]]\n",
      "\n",
      "  [[ -44.630737   -44.630737   -44.630737  ...  -44.630737\n",
      "     -44.630737   -44.630737 ]\n",
      "   [  24.693851    24.693851    24.693851  ...   24.693851\n",
      "      24.693851    24.693851 ]\n",
      "   [ -92.687256   -92.687256   -92.687256  ...  -92.687256\n",
      "     -92.687256   -92.687256 ]\n",
      "   ...\n",
      "   [-154.33566   -154.33566   -154.33566   ... -154.33566\n",
      "    -154.33566   -154.33566  ]\n",
      "   [  35.56114     35.56114     35.56114   ...   35.56114\n",
      "      35.56114     35.56114  ]\n",
      "   [-142.57841   -142.57841   -142.57841   ... -142.57841\n",
      "    -142.57841   -142.57841  ]]]\n",
      "\n",
      "\n",
      " [[[  20.505552    20.505552    20.505552  ...   20.505552\n",
      "      20.505552    20.505552 ]\n",
      "   [  22.88821     22.88821     22.88821   ...   22.88821\n",
      "      22.88821     22.88821  ]\n",
      "   [-102.73929   -102.73929   -102.73929   ... -102.73929\n",
      "    -102.73929   -102.73929  ]\n",
      "   ...\n",
      "   [ -40.526764   -40.526764   -40.526764  ...  -40.526764\n",
      "     -40.526764   -40.526764 ]\n",
      "   [  55.499443    55.499443    55.499443  ...   55.499443\n",
      "      55.499443    55.499443 ]\n",
      "   [-166.16582   -166.16582   -166.16582   ... -166.16582\n",
      "    -166.16582   -166.16582  ]]\n",
      "\n",
      "  [[  32.045937    32.045937    32.045937  ...   32.045937\n",
      "      32.045937    32.045937 ]\n",
      "   [  39.360985    39.360985    39.360985  ...   39.360985\n",
      "      39.360985    39.360985 ]\n",
      "   [ -63.935753   -63.935753   -63.935753  ...  -63.935753\n",
      "     -63.935753   -63.935753 ]\n",
      "   ...\n",
      "   [  -9.228405    -9.228405    -9.228405  ...   -9.228405\n",
      "      -9.228405    -9.228405 ]\n",
      "   [  65.5213      65.5213      65.5213    ...   65.5213\n",
      "      65.5213      65.5213   ]\n",
      "   [-117.32046   -117.32046   -117.32046   ... -117.32046\n",
      "    -117.32046   -117.32046  ]]\n",
      "\n",
      "  [[  28.711185    28.711185    28.711185  ...   28.711185\n",
      "      28.711185    28.711185 ]\n",
      "   [   6.415094     6.415094     6.415094  ...    6.415094\n",
      "       6.415094     6.415094 ]\n",
      "   [ -72.766014   -72.766014   -72.766014  ...  -72.766014\n",
      "     -72.766014   -72.766014 ]\n",
      "   ...\n",
      "   [ -64.88187    -64.88187    -64.88187   ...  -64.88187\n",
      "     -64.88187    -64.88187  ]\n",
      "   [  25.851608    25.851608    25.851608  ...   25.851608\n",
      "      25.851608    25.851608 ]\n",
      "   [-133.74748   -133.74748   -133.74748   ... -133.74748\n",
      "    -133.74748   -133.74748  ]]\n",
      "\n",
      "  [[  26.208073    26.208073    26.208073  ...   26.208073\n",
      "      26.208073    26.208073 ]\n",
      "   [  67.08351     67.08351     67.08351   ...   67.08351\n",
      "      67.08351     67.08351  ]\n",
      "   [-117.02879   -117.02879   -117.02879   ... -117.02879\n",
      "    -117.02879   -117.02879  ]\n",
      "   ...\n",
      "   [ -53.710922   -53.710922   -53.710922  ...  -53.710922\n",
      "     -53.710922   -53.710922 ]\n",
      "   [  89.51796     89.51796     89.51796   ...   89.51796\n",
      "      89.51796     89.51796  ]\n",
      "   [-112.57429   -112.57429   -112.57429   ... -112.57429\n",
      "    -112.57429   -112.57429  ]]\n",
      "\n",
      "  [[  25.827087    25.827087    25.827087  ...   25.827087\n",
      "      25.827087    25.827087 ]\n",
      "   [  70.786995    70.786995    70.786995  ...   70.786995\n",
      "      70.786995    70.786995 ]\n",
      "   [-136.1994    -136.1994    -136.1994    ... -136.1994\n",
      "    -136.1994    -136.1994   ]\n",
      "   ...\n",
      "   [-138.49368   -138.49368   -138.49368   ... -138.49368\n",
      "    -138.49368   -138.49368  ]\n",
      "   [  64.13405     64.13405     64.13405   ...   64.13405\n",
      "      64.13405     64.13405  ]\n",
      "   [-131.67485   -131.67485   -131.67485   ... -131.67485\n",
      "    -131.67485   -131.67485  ]]]\n",
      "\n",
      "\n",
      " [[[ -38.771248   -38.771248   -38.771248  ...  -38.771248\n",
      "     -38.771248   -38.771248 ]\n",
      "   [  55.660515    55.660515    55.660515  ...   55.660515\n",
      "      55.660515    55.660515 ]\n",
      "   [ -58.843227   -58.843227   -58.843227  ...  -58.843227\n",
      "     -58.843227   -58.843227 ]\n",
      "   ...\n",
      "   [ -68.098495   -68.098495   -68.098495  ...  -68.098495\n",
      "     -68.098495   -68.098495 ]\n",
      "   [ 105.07254    105.07254    105.07254   ...  105.07254\n",
      "     105.07254    105.07254  ]\n",
      "   [-172.75133   -172.75133   -172.75133   ... -172.75133\n",
      "    -172.75133   -172.75133  ]]\n",
      "\n",
      "  [[ -19.080675   -19.080675   -19.080675  ...  -19.080675\n",
      "     -19.080675   -19.080675 ]\n",
      "   [  75.96222     75.96222     75.96222   ...   75.96222\n",
      "      75.96222     75.96222  ]\n",
      "   [  -6.3991485   -6.3991485   -6.3991485 ...   -6.3991485\n",
      "      -6.3991485   -6.3991485]\n",
      "   ...\n",
      "   [ -38.36324    -38.36324    -38.36324   ...  -38.36324\n",
      "     -38.36324    -38.36324  ]\n",
      "   [  94.80576     94.80576     94.80576   ...   94.80576\n",
      "      94.80576     94.80576  ]\n",
      "   [-151.25017   -151.25017   -151.25017   ... -151.25017\n",
      "    -151.25017   -151.25017  ]]\n",
      "\n",
      "  [[ -28.224741   -28.224741   -28.224741  ...  -28.224741\n",
      "     -28.224741   -28.224741 ]\n",
      "   [  61.89383     61.89383     61.89383   ...   61.89383\n",
      "      61.89383     61.89383  ]\n",
      "   [ -23.010817   -23.010817   -23.010817  ...  -23.010817\n",
      "     -23.010817   -23.010817 ]\n",
      "   ...\n",
      "   [ -85.93102    -85.93102    -85.93102   ...  -85.93102\n",
      "     -85.93102    -85.93102  ]\n",
      "   [  12.877874    12.877874    12.877874  ...   12.877874\n",
      "      12.877874    12.877874 ]\n",
      "   [-182.13948   -182.13948   -182.13948   ... -182.13948\n",
      "    -182.13948   -182.13948  ]]\n",
      "\n",
      "  [[  -7.819177    -7.819177    -7.819177  ...   -7.819177\n",
      "      -7.819177    -7.819177 ]\n",
      "   [ 130.69185    130.69185    130.69185   ...  130.69185\n",
      "     130.69185    130.69185  ]\n",
      "   [ -90.35754    -90.35754    -90.35754   ...  -90.35754\n",
      "     -90.35754    -90.35754  ]\n",
      "   ...\n",
      "   [-101.21911   -101.21911   -101.21911   ... -101.21911\n",
      "    -101.21911   -101.21911  ]\n",
      "   [  83.75045     83.75045     83.75045   ...   83.75045\n",
      "      83.75045     83.75045  ]\n",
      "   [-145.51437   -145.51437   -145.51437   ... -145.51437\n",
      "    -145.51437   -145.51437  ]]\n",
      "\n",
      "  [[  -4.4876738   -4.4876738   -4.4876738 ...   -4.4876738\n",
      "      -4.4876738   -4.4876738]\n",
      "   [ 135.53204    135.53204    135.53204   ...  135.53204\n",
      "     135.53204    135.53204  ]\n",
      "   [-105.65515   -105.65515   -105.65515   ... -105.65515\n",
      "    -105.65515   -105.65515  ]\n",
      "   ...\n",
      "   [-196.41483   -196.41483   -196.41483   ... -196.41483\n",
      "    -196.41483   -196.41483  ]\n",
      "   [  44.195614    44.195614    44.195614  ...   44.195614\n",
      "      44.195614    44.195614 ]\n",
      "   [-182.15776   -182.15776   -182.15776   ... -182.15776\n",
      "    -182.15776   -182.15776  ]]]\n",
      "\n",
      "\n",
      " [[[ -42.3037     -42.3037     -42.3037    ...  -42.3037\n",
      "     -42.3037     -42.3037   ]\n",
      "   [  65.14845     65.14845     65.14845   ...   65.14845\n",
      "      65.14845     65.14845  ]\n",
      "   [ -37.448483   -37.448483   -37.448483  ...  -37.448483\n",
      "     -37.448483   -37.448483 ]\n",
      "   ...\n",
      "   [  -8.6107855   -8.6107855   -8.6107855 ...   -8.6107855\n",
      "      -8.6107855   -8.6107855]\n",
      "   [  60.187218    60.187218    60.187218  ...   60.187218\n",
      "      60.187218    60.187218 ]\n",
      "   [-136.2921    -136.2921    -136.2921    ... -136.2921\n",
      "    -136.2921    -136.2921   ]]\n",
      "\n",
      "  [[ -28.928797   -28.928797   -28.928797  ...  -28.928797\n",
      "     -28.928797   -28.928797 ]\n",
      "   [ 109.61315    109.61315    109.61315   ...  109.61315\n",
      "     109.61315    109.61315  ]\n",
      "   [   3.8004546    3.8004546    3.8004546 ...    3.8004546\n",
      "       3.8004546    3.8004546]\n",
      "   ...\n",
      "   [  -6.924535    -6.924535    -6.924535  ...   -6.924535\n",
      "      -6.924535    -6.924535 ]\n",
      "   [  76.35929     76.35929     76.35929   ...   76.35929\n",
      "      76.35929     76.35929  ]\n",
      "   [-122.47409   -122.47409   -122.47409   ... -122.47409\n",
      "    -122.47409   -122.47409  ]]\n",
      "\n",
      "  [[ -24.668985   -24.668985   -24.668985  ...  -24.668985\n",
      "     -24.668985   -24.668985 ]\n",
      "   [ 105.10323    105.10323    105.10323   ...  105.10323\n",
      "     105.10323    105.10323  ]\n",
      "   [ -13.382187   -13.382187   -13.382187  ...  -13.382187\n",
      "     -13.382187   -13.382187 ]\n",
      "   ...\n",
      "   [ -42.399326   -42.399326   -42.399326  ...  -42.399326\n",
      "     -42.399326   -42.399326 ]\n",
      "   [  -6.9470625   -6.9470625   -6.9470625 ...   -6.9470625\n",
      "      -6.9470625   -6.9470625]\n",
      "   [-146.68968   -146.68968   -146.68968   ... -146.68968\n",
      "    -146.68968   -146.68968  ]]\n",
      "\n",
      "  [[  11.993857    11.993857    11.993857  ...   11.993857\n",
      "      11.993857    11.993857 ]\n",
      "   [ 167.03622    167.03622    167.03622   ...  167.03622\n",
      "     167.03622    167.03622  ]\n",
      "   [ -48.706654   -48.706654   -48.706654  ...  -48.706654\n",
      "     -48.706654   -48.706654 ]\n",
      "   ...\n",
      "   [ -66.515594   -66.515594   -66.515594  ...  -66.515594\n",
      "     -66.515594   -66.515594 ]\n",
      "   [  74.40558     74.40558     74.40558   ...   74.40558\n",
      "      74.40558     74.40558  ]\n",
      "   [-126.74044   -126.74044   -126.74044   ... -126.74044\n",
      "    -126.74044   -126.74044  ]]\n",
      "\n",
      "  [[  45.362568    45.362568    45.362568  ...   45.362568\n",
      "      45.362568    45.362568 ]\n",
      "   [ 162.19994    162.19994    162.19994   ...  162.19994\n",
      "     162.19994    162.19994  ]\n",
      "   [ -79.812065   -79.812065   -79.812065  ...  -79.812065\n",
      "     -79.812065   -79.812065 ]\n",
      "   ...\n",
      "   [-187.9567    -187.9567    -187.9567    ... -187.9567\n",
      "    -187.9567    -187.9567   ]\n",
      "   [  17.109974    17.109974    17.109974  ...   17.109974\n",
      "      17.109974    17.109974 ]\n",
      "   [-145.35323   -145.35323   -145.35323   ... -145.35323\n",
      "    -145.35323   -145.35323  ]]]]\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape13-W_shape13-1-0] _\u001b[0m\n",
      "\n",
      "Z_shape = (3, 17, 17, 1), W_shape = (5, 5, 1, 16), stride = 1, padding = 0\n",
      "backward = True, device = cpu()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[  1.5437562   -6.8538       4.3282647    5.4068804   -3.15688\n",
      "     -1.206689    -4.3909516    3.4969...448   -2.242325     0.6578698\n",
      "     -7.0278      -1.7489109   10.11736      2.5269346    1.7962458\n",
      "     -7.9124722 ]]]])\n",
      "W_shape    = (5, 5, 1, 16)\n",
      "Wtch       = tensor([[[[  1.5438,  -6.8538,   4.3283,   5.4069,  -3.1569,  -1.2067,  -4.3910,\n",
      "             3.4969,  -5.3061,  -1.11...461,  -2.2423,   0.6579,  -7.0278,  -1.7489,  10.1174,   2.5269,\n",
      "             1.7962,  -7.9125]]]], requires_grad=True)\n",
      "Z          = needle.Tensor([[[[ 8.82026196e+00]\n",
      "   [ 2.00078607e+00]\n",
      "   [ 4.89369011e+00]\n",
      "   [ 1.12044659e+01]\n",
      "   [ 9.33778954e+00]...22066e-01]\n",
      "   [ 1.05310105e-01]\n",
      "   [ 4.97272283e-01]\n",
      "   [ 1.13696384e+00]\n",
      "   [-5.08369303e+00]\n",
      "   [-5.73876619e-01]]]])\n",
      "Z_shape    = (3, 17, 17, 1)\n",
      "Ztch       = tensor([[[[ 8.8203e+00],\n",
      "          [ 2.0008e+00],\n",
      "          [ 4.8937e+00],\n",
      "          [ 1.1204e+01],\n",
      "          [ 9.3378...       [ 4.9727e-01],\n",
      "          [ 1.1370e+00],\n",
      "          [-5.0837e+00],\n",
      "          [-5.7388e-01]]]], requires_grad=True)\n",
      "_W         = array([[[[  1.5437562 ,  -6.8538    ,   4.3282647 ,   5.4068804 ,\n",
      "           -3.15688   ,  -1.206689  ,  -4.3909516 , ...  -7.0278    ,  -1.7489109 ,\n",
      "           10.11736   ,   2.5269346 ,   1.7962458 ,  -7.9124722 ]]]],\n",
      "      dtype=float32)\n",
      "_Z         = array([[[[ 8.82026196e+00],\n",
      "         [ 2.00078607e+00],\n",
      "         [ 4.89369011e+00],\n",
      "         [ 1.12044659e+01],\n",
      "      ... 4.97272283e-01],\n",
      "         [ 1.13696384e+00],\n",
      "         [-5.08369303e+00],\n",
      "         [-5.73876619e-01]]]], dtype=float32)\n",
      "backward   = True\n",
      "device     = cpu()\n",
      "err1       = np.float32(0.00040977314)\n",
      "err2       = np.float32(0.0014183288)\n",
      "out        = tensor([[[[ 4.1444e+01,  7.2539e+01, -1.2076e+02,  ...,  5.7938e+01,\n",
      "           -1.5660e+01, -6.3388e+00],\n",
      "          [...,  1.4962e+02,  3.9613e+01,  ...,  6.5264e+01,\n",
      "            1.5128e+01, -1.2588e+02]]]], grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(-27459.7266, grad_fn=<SumBackward0>)\n",
      "padding    = 0\n",
      "stride     = 1\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c5655fc5c0>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655fe780>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655fe780>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655fe780>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655fe780>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[-103.754875 -103.754875 -103.754875 -103.754875 -103.754875\n",
      "    -103.754875 -103.754875 -103.754875 -103.754875 -103.754875\n",
      "    -103.754875 -103.754875 -103.754875 -103.754875 -103.754875\n",
      "    -103.754875]]\n",
      "\n",
      "  [[-180.10439  -180.10439  -180.10439  -180.10439  -180.10439\n",
      "    -180.10439  -180.10439  -180.10439  -180.10439  -180.10439\n",
      "    -180.10439  -180.10439  -180.10439  -180.10439  -180.10439\n",
      "    -180.10439 ]]\n",
      "\n",
      "  [[-190.08365  -190.08365  -190.08365  -190.08365  -190.08365\n",
      "    -190.08365  -190.08365  -190.08365  -190.08365  -190.08365\n",
      "    -190.08365  -190.08365  -190.08365  -190.08365  -190.08365\n",
      "    -190.08365 ]]\n",
      "\n",
      "  [[-174.23862  -174.23862  -174.23862  -174.23862  -174.23862\n",
      "    -174.23862  -174.23862  -174.23862  -174.23862  -174.23862\n",
      "    -174.23862  -174.23862  -174.23862  -174.23862  -174.23862\n",
      "    -174.23862 ]]\n",
      "\n",
      "  [[-175.81735  -175.81735  -175.81735  -175.81735  -175.81735\n",
      "    -175.81735  -175.81735  -175.81735  -175.81735  -175.81735\n",
      "    -175.81735  -175.81735  -175.81735  -175.81735  -175.81735\n",
      "    -175.81735 ]]]\n",
      "\n",
      "\n",
      " [[[-161.4056   -161.4056   -161.4056   -161.4056   -161.4056\n",
      "    -161.4056   -161.4056   -161.4056   -161.4056   -161.4056\n",
      "    -161.4056   -161.4056   -161.4056   -161.4056   -161.4056\n",
      "    -161.4056  ]]\n",
      "\n",
      "  [[-229.05672  -229.05672  -229.05672  -229.05672  -229.05672\n",
      "    -229.05672  -229.05672  -229.05672  -229.05672  -229.05672\n",
      "    -229.05672  -229.05672  -229.05672  -229.05672  -229.05672\n",
      "    -229.05672 ]]\n",
      "\n",
      "  [[-242.01685  -242.01685  -242.01685  -242.01685  -242.01685\n",
      "    -242.01685  -242.01685  -242.01685  -242.01685  -242.01685\n",
      "    -242.01685  -242.01685  -242.01685  -242.01685  -242.01685\n",
      "    -242.01685 ]]\n",
      "\n",
      "  [[-227.32703  -227.32703  -227.32703  -227.32703  -227.32703\n",
      "    -227.32703  -227.32703  -227.32703  -227.32703  -227.32703\n",
      "    -227.32703  -227.32703  -227.32703  -227.32703  -227.32703\n",
      "    -227.32703 ]]\n",
      "\n",
      "  [[-195.55923  -195.55923  -195.55923  -195.55923  -195.55923\n",
      "    -195.55923  -195.55923  -195.55923  -195.55923  -195.55923\n",
      "    -195.55923  -195.55923  -195.55923  -195.55923  -195.55923\n",
      "    -195.55923 ]]]\n",
      "\n",
      "\n",
      " [[[-127.323654 -127.323654 -127.323654 -127.323654 -127.323654\n",
      "    -127.323654 -127.323654 -127.323654 -127.323654 -127.323654\n",
      "    -127.323654 -127.323654 -127.323654 -127.323654 -127.323654\n",
      "    -127.323654]]\n",
      "\n",
      "  [[-211.80472  -211.80472  -211.80472  -211.80472  -211.80472\n",
      "    -211.80472  -211.80472  -211.80472  -211.80472  -211.80472\n",
      "    -211.80472  -211.80472  -211.80472  -211.80472  -211.80472\n",
      "    -211.80472 ]]\n",
      "\n",
      "  [[-232.33528  -232.33528  -232.33528  -232.33528  -232.33528\n",
      "    -232.33528  -232.33528  -232.33528  -232.33528  -232.33528\n",
      "    -232.33528  -232.33528  -232.33528  -232.33528  -232.33528\n",
      "    -232.33528 ]]\n",
      "\n",
      "  [[-197.0064   -197.0064   -197.0064   -197.0064   -197.0064\n",
      "    -197.0064   -197.0064   -197.0064   -197.0064   -197.0064\n",
      "    -197.0064   -197.0064   -197.0064   -197.0064   -197.0064\n",
      "    -197.0064  ]]\n",
      "\n",
      "  [[-144.13293  -144.13293  -144.13293  -144.13293  -144.13293\n",
      "    -144.13293  -144.13293  -144.13293  -144.13293  -144.13293\n",
      "    -144.13293  -144.13293  -144.13293  -144.13293  -144.13293\n",
      "    -144.13293 ]]]\n",
      "\n",
      "\n",
      " [[[-129.75711  -129.75711  -129.75711  -129.75711  -129.75711\n",
      "    -129.75711  -129.75711  -129.75711  -129.75711  -129.75711\n",
      "    -129.75711  -129.75711  -129.75711  -129.75711  -129.75711\n",
      "    -129.75711 ]]\n",
      "\n",
      "  [[-205.2602   -205.2602   -205.2602   -205.2602   -205.2602\n",
      "    -205.2602   -205.2602   -205.2602   -205.2602   -205.2602\n",
      "    -205.2602   -205.2602   -205.2602   -205.2602   -205.2602\n",
      "    -205.2602  ]]\n",
      "\n",
      "  [[-224.77884  -224.77884  -224.77884  -224.77884  -224.77884\n",
      "    -224.77884  -224.77884  -224.77884  -224.77884  -224.77884\n",
      "    -224.77884  -224.77884  -224.77884  -224.77884  -224.77884\n",
      "    -224.77884 ]]\n",
      "\n",
      "  [[-197.76212  -197.76212  -197.76212  -197.76212  -197.76212\n",
      "    -197.76212  -197.76212  -197.76212  -197.76212  -197.76212\n",
      "    -197.76212  -197.76212  -197.76212  -197.76212  -197.76212\n",
      "    -197.76212 ]]\n",
      "\n",
      "  [[-119.871445 -119.871445 -119.871445 -119.871445 -119.871445\n",
      "    -119.871445 -119.871445 -119.871445 -119.871445 -119.871445\n",
      "    -119.871445 -119.871445 -119.871445 -119.871445 -119.871445\n",
      "    -119.871445]]]\n",
      "\n",
      "\n",
      " [[[-131.72517  -131.72517  -131.72517  -131.72517  -131.72517\n",
      "    -131.72517  -131.72517  -131.72517  -131.72517  -131.72517\n",
      "    -131.72517  -131.72517  -131.72517  -131.72517  -131.72517\n",
      "    -131.72517 ]]\n",
      "\n",
      "  [[-192.7218   -192.7218   -192.7218   -192.7218   -192.7218\n",
      "    -192.7218   -192.7218   -192.7218   -192.7218   -192.7218\n",
      "    -192.7218   -192.7218   -192.7218   -192.7218   -192.7218\n",
      "    -192.7218  ]]\n",
      "\n",
      "  [[-213.31113  -213.31113  -213.31113  -213.31113  -213.31113\n",
      "    -213.31113  -213.31113  -213.31113  -213.31113  -213.31113\n",
      "    -213.31113  -213.31113  -213.31113  -213.31113  -213.31113\n",
      "    -213.31113 ]]\n",
      "\n",
      "  [[-168.52386  -168.52386  -168.52386  -168.52386  -168.52386\n",
      "    -168.52386  -168.52386  -168.52386  -168.52386  -168.52386\n",
      "    -168.52386  -168.52386  -168.52386  -168.52386  -168.52386\n",
      "    -168.52386 ]]\n",
      "\n",
      "  [[ -76.436874  -76.436874  -76.436874  -76.436874  -76.436874\n",
      "     -76.436874  -76.436874  -76.436874  -76.436874  -76.436874\n",
      "     -76.436874  -76.436874  -76.436874  -76.436874  -76.436874\n",
      "     -76.436874]]]], W.grad.numpy(): [[[[-103.75482  -103.75482  -103.75482  -103.75482  -103.75482\n",
      "    -103.75482  -103.75482  -103.75482  -103.75482  -103.75482\n",
      "    -103.75482  -103.75482  -103.75482  -103.75482  -103.75482\n",
      "    -103.75482 ]]\n",
      "\n",
      "  [[-180.10437  -180.10437  -180.10437  -180.10437  -180.10437\n",
      "    -180.10437  -180.10437  -180.10437  -180.10437  -180.10437\n",
      "    -180.10437  -180.10437  -180.10437  -180.10437  -180.10437\n",
      "    -180.10437 ]]\n",
      "\n",
      "  [[-190.08366  -190.08366  -190.08366  -190.08366  -190.08366\n",
      "    -190.08366  -190.08366  -190.08366  -190.08366  -190.08366\n",
      "    -190.08366  -190.08366  -190.08366  -190.08366  -190.08366\n",
      "    -190.08366 ]]\n",
      "\n",
      "  [[-174.23856  -174.23856  -174.23856  -174.23856  -174.23856\n",
      "    -174.23856  -174.23856  -174.23856  -174.23856  -174.23856\n",
      "    -174.23856  -174.23856  -174.23856  -174.23856  -174.23856\n",
      "    -174.23856 ]]\n",
      "\n",
      "  [[-175.81732  -175.81732  -175.81732  -175.81732  -175.81732\n",
      "    -175.81732  -175.81732  -175.81732  -175.81732  -175.81732\n",
      "    -175.81732  -175.81732  -175.81732  -175.81732  -175.81732\n",
      "    -175.81732 ]]]\n",
      "\n",
      "\n",
      " [[[-161.40565  -161.40565  -161.40565  -161.40565  -161.40565\n",
      "    -161.40565  -161.40565  -161.40565  -161.40565  -161.40565\n",
      "    -161.40565  -161.40565  -161.40565  -161.40565  -161.40565\n",
      "    -161.40565 ]]\n",
      "\n",
      "  [[-229.0568   -229.0568   -229.0568   -229.0568   -229.0568\n",
      "    -229.0568   -229.0568   -229.0568   -229.0568   -229.0568\n",
      "    -229.0568   -229.0568   -229.0568   -229.0568   -229.0568\n",
      "    -229.0568  ]]\n",
      "\n",
      "  [[-242.01685  -242.01685  -242.01685  -242.01685  -242.01685\n",
      "    -242.01685  -242.01685  -242.01685  -242.01685  -242.01685\n",
      "    -242.01685  -242.01685  -242.01685  -242.01685  -242.01685\n",
      "    -242.01685 ]]\n",
      "\n",
      "  [[-227.32701  -227.32701  -227.32701  -227.32701  -227.32701\n",
      "    -227.32701  -227.32701  -227.32701  -227.32701  -227.32701\n",
      "    -227.32701  -227.32701  -227.32701  -227.32701  -227.32701\n",
      "    -227.32701 ]]\n",
      "\n",
      "  [[-195.55927  -195.55927  -195.55927  -195.55927  -195.55927\n",
      "    -195.55927  -195.55927  -195.55927  -195.55927  -195.55927\n",
      "    -195.55927  -195.55927  -195.55927  -195.55927  -195.55927\n",
      "    -195.55927 ]]]\n",
      "\n",
      "\n",
      " [[[-127.323616 -127.323616 -127.323616 -127.323616 -127.323616\n",
      "    -127.323616 -127.323616 -127.323616 -127.323616 -127.323616\n",
      "    -127.323616 -127.323616 -127.323616 -127.323616 -127.323616\n",
      "    -127.323616]]\n",
      "\n",
      "  [[-211.80469  -211.80469  -211.80469  -211.80469  -211.80469\n",
      "    -211.80469  -211.80469  -211.80469  -211.80469  -211.80469\n",
      "    -211.80469  -211.80469  -211.80469  -211.80469  -211.80469\n",
      "    -211.80469 ]]\n",
      "\n",
      "  [[-232.3352   -232.3352   -232.3352   -232.3352   -232.3352\n",
      "    -232.3352   -232.3352   -232.3352   -232.3352   -232.3352\n",
      "    -232.3352   -232.3352   -232.3352   -232.3352   -232.3352\n",
      "    -232.3352  ]]\n",
      "\n",
      "  [[-197.0063   -197.0063   -197.0063   -197.0063   -197.0063\n",
      "    -197.0063   -197.0063   -197.0063   -197.0063   -197.0063\n",
      "    -197.0063   -197.0063   -197.0063   -197.0063   -197.0063\n",
      "    -197.0063  ]]\n",
      "\n",
      "  [[-144.13295  -144.13295  -144.13295  -144.13295  -144.13295\n",
      "    -144.13295  -144.13295  -144.13295  -144.13295  -144.13295\n",
      "    -144.13295  -144.13295  -144.13295  -144.13295  -144.13295\n",
      "    -144.13295 ]]]\n",
      "\n",
      "\n",
      " [[[-129.75711  -129.75711  -129.75711  -129.75711  -129.75711\n",
      "    -129.75711  -129.75711  -129.75711  -129.75711  -129.75711\n",
      "    -129.75711  -129.75711  -129.75711  -129.75711  -129.75711\n",
      "    -129.75711 ]]\n",
      "\n",
      "  [[-205.26006  -205.26006  -205.26006  -205.26006  -205.26006\n",
      "    -205.26006  -205.26006  -205.26006  -205.26006  -205.26006\n",
      "    -205.26006  -205.26006  -205.26006  -205.26006  -205.26006\n",
      "    -205.26006 ]]\n",
      "\n",
      "  [[-224.77878  -224.77878  -224.77878  -224.77878  -224.77878\n",
      "    -224.77878  -224.77878  -224.77878  -224.77878  -224.77878\n",
      "    -224.77878  -224.77878  -224.77878  -224.77878  -224.77878\n",
      "    -224.77878 ]]\n",
      "\n",
      "  [[-197.76195  -197.76195  -197.76195  -197.76195  -197.76195\n",
      "    -197.76195  -197.76195  -197.76195  -197.76195  -197.76195\n",
      "    -197.76195  -197.76195  -197.76195  -197.76195  -197.76195\n",
      "    -197.76195 ]]\n",
      "\n",
      "  [[-119.87145  -119.87145  -119.87145  -119.87145  -119.87145\n",
      "    -119.87145  -119.87145  -119.87145  -119.87145  -119.87145\n",
      "    -119.87145  -119.87145  -119.87145  -119.87145  -119.87145\n",
      "    -119.87145 ]]]\n",
      "\n",
      "\n",
      " [[[-131.7252   -131.7252   -131.7252   -131.7252   -131.7252\n",
      "    -131.7252   -131.7252   -131.7252   -131.7252   -131.7252\n",
      "    -131.7252   -131.7252   -131.7252   -131.7252   -131.7252\n",
      "    -131.7252  ]]\n",
      "\n",
      "  [[-192.72165  -192.72165  -192.72165  -192.72165  -192.72165\n",
      "    -192.72165  -192.72165  -192.72165  -192.72165  -192.72165\n",
      "    -192.72165  -192.72165  -192.72165  -192.72165  -192.72165\n",
      "    -192.72165 ]]\n",
      "\n",
      "  [[-213.311    -213.311    -213.311    -213.311    -213.311\n",
      "    -213.311    -213.311    -213.311    -213.311    -213.311\n",
      "    -213.311    -213.311    -213.311    -213.311    -213.311\n",
      "    -213.311   ]]\n",
      "\n",
      "  [[-168.52388  -168.52388  -168.52388  -168.52388  -168.52388\n",
      "    -168.52388  -168.52388  -168.52388  -168.52388  -168.52388\n",
      "    -168.52388  -168.52388  -168.52388  -168.52388  -168.52388\n",
      "    -168.52388 ]]\n",
      "\n",
      "  [[ -76.43688   -76.43688   -76.43688   -76.43688   -76.43688\n",
      "     -76.43688   -76.43688   -76.43688   -76.43688   -76.43688\n",
      "     -76.43688   -76.43688   -76.43688   -76.43688   -76.43688\n",
      "     -76.43688 ]]]]\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape14-W_shape14-1-0] _\u001b[0m\n",
      "\n",
      "Z_shape = (3, 17, 17, 16), W_shape = (5, 5, 16, 1), stride = 1, padding = 0\n",
      "backward = True, device = cpu()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[ 1.55579513e-02]\n",
      "   [-3.04658723e+00]\n",
      "   [ 4.09725952e+00]\n",
      "   [ 1.29906273e+00]\n",
      "   [-7.50546598e+00]...75421e+00]\n",
      "   [ 3.02805209e+00]\n",
      "   [-4.20992136e+00]\n",
      "   [ 4.11707735e+00]\n",
      "   [ 4.99041653e+00]\n",
      "   [ 5.11040497e+00]]]])\n",
      "W_shape    = (5, 5, 16, 1)\n",
      "Wtch       = tensor([[[[ 1.5558e-02],\n",
      "          [-3.0466e+00],\n",
      "          [ 4.0973e+00],\n",
      "          [ 1.2991e+00],\n",
      "          [-7.5055...       [-4.2099e+00],\n",
      "          [ 4.1171e+00],\n",
      "          [ 4.9904e+00],\n",
      "          [ 5.1104e+00]]]], requires_grad=True)\n",
      "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ...  6.08375072e-01\n",
      "     2.21931624e+00  1.66837168e...3e+00]\n",
      "   [-1.25365603e+00 -1.71452928e+00  1.35930243e+01 ...  3.13170171e+00\n",
      "    -1.35708165e+00  1.29997072e+01]]]])\n",
      "Z_shape    = (3, 17, 17, 16)\n",
      "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ...,  6.0838e-01,\n",
      "            2.2193e+00,  1.6684e+00],\n",
      "          [...[-1.2537e+00, -1.7145e+00,  1.3593e+01,  ...,  3.1317e+00,\n",
      "           -1.3571e+00,  1.3000e+01]]]], requires_grad=True)\n",
      "_W         = array([[[[ 1.55579513e-02],\n",
      "         [-3.04658723e+00],\n",
      "         [ 4.09725952e+00],\n",
      "         [ 1.29906273e+00],\n",
      "      ...-4.20992136e+00],\n",
      "         [ 4.11707735e+00],\n",
      "         [ 4.99041653e+00],\n",
      "         [ 5.11040497e+00]]]], dtype=float32)\n",
      "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
      "           6.08375072e-01,  2.21931624e+00,  1.66837...e+01, ...,\n",
      "           3.13170171e+00, -1.35708165e+00,  1.29997072e+01]]]],\n",
      "      shape=(3, 17, 17, 16), dtype=float32)\n",
      "backward   = True\n",
      "device     = cpu()\n",
      "err1       = np.float32(0.00026052116)\n",
      "err2       = np.float32(0.0009914576)\n",
      "out        = tensor([[[[  173.2376,  -598.2368, -1057.3813,   300.5164,   -78.8975,\n",
      "             272.9615,  -484.4884,   -84.3478, ...4923,  -241.7713,   538.5468,\n",
      "             257.2256,   163.9202,  1022.2947]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(-8337.0508, grad_fn=<SumBackward0>)\n",
      "padding    = 0\n",
      "stride     = 1\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c565604d70>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5656054f0>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5656054f0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5656054f0>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5656054f0>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[-1.05645676e+02]\n",
      "   [-2.01233444e+01]\n",
      "   [-1.49882324e+02]\n",
      "   [ 2.06188095e+02]\n",
      "   [-1.35001236e+02]\n",
      "   [-2.34928131e-01]\n",
      "   [-3.76055069e+01]\n",
      "   [ 3.27950478e+00]\n",
      "   [ 1.12367420e+01]\n",
      "   [ 4.94731102e+01]\n",
      "   [ 9.88436050e+01]\n",
      "   [ 1.26689705e+02]\n",
      "   [-6.32781334e+01]\n",
      "   [-1.41452454e+02]\n",
      "   [ 8.20149460e+01]\n",
      "   [-2.11831238e+02]]\n",
      "\n",
      "  [[-8.49279556e+01]\n",
      "   [-2.75491333e+01]\n",
      "   [-2.05616409e+02]\n",
      "   [ 1.50188782e+02]\n",
      "   [-1.33572311e+02]\n",
      "   [ 2.57772121e+01]\n",
      "   [-1.11375771e+01]\n",
      "   [-6.65546417e+00]\n",
      "   [ 1.65217648e+01]\n",
      "   [-2.94588890e+01]\n",
      "   [ 1.34262085e+02]\n",
      "   [ 4.88686790e+01]\n",
      "   [-1.13592529e+00]\n",
      "   [-1.99641006e+02]\n",
      "   [ 6.50487747e+01]\n",
      "   [-2.95012939e+02]]\n",
      "\n",
      "  [[-6.90266418e+01]\n",
      "   [-4.15997925e+01]\n",
      "   [-2.57041748e+02]\n",
      "   [ 2.30137726e+02]\n",
      "   [-1.08954964e+02]\n",
      "   [ 5.65249634e+00]\n",
      "   [ 3.30040359e+01]\n",
      "   [-3.96655464e+01]\n",
      "   [ 5.29014397e+00]\n",
      "   [-4.12875137e+01]\n",
      "   [ 1.68186310e+02]\n",
      "   [ 4.47323647e+01]\n",
      "   [ 5.60536957e+01]\n",
      "   [-1.86990753e+02]\n",
      "   [ 7.51118565e+00]\n",
      "   [-2.69889038e+02]]\n",
      "\n",
      "  [[-4.90958595e+01]\n",
      "   [-3.52368851e+01]\n",
      "   [-2.34394928e+02]\n",
      "   [ 2.24959808e+02]\n",
      "   [-1.33998230e+02]\n",
      "   [-3.78519287e+01]\n",
      "   [ 6.25473976e+01]\n",
      "   [-9.65747986e+01]\n",
      "   [-1.04519157e+01]\n",
      "   [-5.41348000e+01]\n",
      "   [ 1.50591003e+02]\n",
      "   [ 1.25959396e+00]\n",
      "   [ 5.39370918e+01]\n",
      "   [-1.30859909e+02]\n",
      "   [-5.90740128e+01]\n",
      "   [-2.57829193e+02]]\n",
      "\n",
      "  [[-9.34716873e+01]\n",
      "   [ 3.94592476e+00]\n",
      "   [-2.59044647e+02]\n",
      "   [ 2.11363220e+02]\n",
      "   [-1.24154709e+02]\n",
      "   [-9.59835052e+00]\n",
      "   [ 2.54309120e+01]\n",
      "   [-1.28694855e+02]\n",
      "   [ 3.11064320e+01]\n",
      "   [-3.63582268e+01]\n",
      "   [ 1.91347946e+02]\n",
      "   [ 1.28790474e+01]\n",
      "   [ 6.02757797e+01]\n",
      "   [-1.43611069e+02]\n",
      "   [-2.12342987e+01]\n",
      "   [-3.02779114e+02]]]\n",
      "\n",
      "\n",
      " [[[-1.30759583e+02]\n",
      "   [-5.30780487e+01]\n",
      "   [-3.65081177e+01]\n",
      "   [ 1.16226929e+02]\n",
      "   [-1.43968109e+02]\n",
      "   [ 2.62289505e+01]\n",
      "   [-4.83289680e+01]\n",
      "   [-4.52546740e+00]\n",
      "   [-1.54871845e+01]\n",
      "   [ 1.65274841e+02]\n",
      "   [ 6.37024536e+01]\n",
      "   [ 1.20104134e+02]\n",
      "   [-6.70979233e+01]\n",
      "   [-1.77250320e+02]\n",
      "   [ 9.24350739e+01]\n",
      "   [-1.95128540e+02]]\n",
      "\n",
      "  [[-1.16220718e+02]\n",
      "   [-3.30083237e+01]\n",
      "   [-1.03258156e+02]\n",
      "   [ 5.67695160e+01]\n",
      "   [-1.42624527e+02]\n",
      "   [ 4.47735291e+01]\n",
      "   [-1.14148540e+01]\n",
      "   [-2.06628742e+01]\n",
      "   [-4.33662987e+01]\n",
      "   [ 9.86896973e+01]\n",
      "   [ 8.88732147e+01]\n",
      "   [ 5.40591049e+01]\n",
      "   [ 2.64871216e+00]\n",
      "   [-2.29597626e+02]\n",
      "   [ 1.02947128e+02]\n",
      "   [-2.64780121e+02]]\n",
      "\n",
      "  [[-9.37098465e+01]\n",
      "   [-8.36794472e+00]\n",
      "   [-1.61437607e+02]\n",
      "   [ 1.25073807e+02]\n",
      "   [-1.41490036e+02]\n",
      "   [ 1.70049286e+01]\n",
      "   [ 4.18273125e+01]\n",
      "   [-5.35076942e+01]\n",
      "   [-2.52867661e+01]\n",
      "   [ 6.81087189e+01]\n",
      "   [ 9.66426697e+01]\n",
      "   [ 3.23420486e+01]\n",
      "   [ 9.01497040e+01]\n",
      "   [-1.88990189e+02]\n",
      "   [ 2.60766754e+01]\n",
      "   [-2.34107742e+02]]\n",
      "\n",
      "  [[-5.85137558e+01]\n",
      "   [-2.33966064e+00]\n",
      "   [-1.52788696e+02]\n",
      "   [ 1.25451736e+02]\n",
      "   [-1.37870880e+02]\n",
      "   [-5.23325348e+00]\n",
      "   [ 5.57009888e+01]\n",
      "   [-1.10888382e+02]\n",
      "   [-5.09408836e+01]\n",
      "   [ 9.69206238e+00]\n",
      "   [ 7.61016083e+01]\n",
      "   [ 4.83363342e+00]\n",
      "   [ 7.97956619e+01]\n",
      "   [-1.32182144e+02]\n",
      "   [-3.02678833e+01]\n",
      "   [-2.18942780e+02]]\n",
      "\n",
      "  [[-1.21423080e+02]\n",
      "   [ 4.10961990e+01]\n",
      "   [-1.86889618e+02]\n",
      "   [ 1.26133331e+02]\n",
      "   [-1.17518356e+02]\n",
      "   [ 4.11687164e+01]\n",
      "   [-2.13943481e-01]\n",
      "   [-1.13331619e+02]\n",
      "   [ 9.72501564e+00]\n",
      "   [ 3.09898376e+00]\n",
      "   [ 1.06382553e+02]\n",
      "   [ 1.49877357e+00]\n",
      "   [ 7.09051056e+01]\n",
      "   [-1.29133743e+02]\n",
      "   [-1.71551762e+01]\n",
      "   [-2.63589874e+02]]]\n",
      "\n",
      "\n",
      " [[[-7.35902710e+01]\n",
      "   [-3.58177185e+01]\n",
      "   [-3.91609955e+01]\n",
      "   [ 9.34227524e+01]\n",
      "   [-2.34856689e+02]\n",
      "   [-1.34908752e+01]\n",
      "   [-2.10024605e+01]\n",
      "   [-7.26594849e+01]\n",
      "   [-3.30976562e+01]\n",
      "   [ 1.88550934e+02]\n",
      "   [ 8.42464066e+01]\n",
      "   [ 8.25404816e+01]\n",
      "   [-3.08872375e+01]\n",
      "   [-2.25946472e+02]\n",
      "   [ 1.05908890e+02]\n",
      "   [-1.99482315e+02]]\n",
      "\n",
      "  [[-4.86232986e+01]\n",
      "   [-2.93912888e+01]\n",
      "   [-1.08916702e+02]\n",
      "   [ 5.14841843e+01]\n",
      "   [-2.17893280e+02]\n",
      "   [ 2.58462753e+01]\n",
      "   [ 1.49251270e+01]\n",
      "   [-6.35332642e+01]\n",
      "   [-4.49299622e+01]\n",
      "   [ 1.38390854e+02]\n",
      "   [ 1.41977051e+02]\n",
      "   [ 2.77889214e+01]\n",
      "   [ 5.09371300e+01]\n",
      "   [-2.80378052e+02]\n",
      "   [ 8.05643463e+01]\n",
      "   [-2.19628311e+02]]\n",
      "\n",
      "  [[-2.75799179e+01]\n",
      "   [ 7.72900772e+00]\n",
      "   [-1.96252747e+02]\n",
      "   [ 1.15850616e+02]\n",
      "   [-2.17371368e+02]\n",
      "   [ 2.22289505e+01]\n",
      "   [ 6.18700638e+01]\n",
      "   [-9.50438995e+01]\n",
      "   [-4.10829773e+01]\n",
      "   [ 1.38915436e+02]\n",
      "   [ 1.76892029e+02]\n",
      "   [ 2.75100040e+01]\n",
      "   [ 1.36497986e+02]\n",
      "   [-2.32300034e+02]\n",
      "   [-2.27395172e+01]\n",
      "   [-1.75595825e+02]]\n",
      "\n",
      "  [[-1.20369625e+00]\n",
      "   [ 3.28416443e+01]\n",
      "   [-1.74532135e+02]\n",
      "   [ 9.16016083e+01]\n",
      "   [-1.88469650e+02]\n",
      "   [-7.50865936e+00]\n",
      "   [ 9.53312759e+01]\n",
      "   [-1.50747742e+02]\n",
      "   [-5.55727577e+01]\n",
      "   [ 9.05028687e+01]\n",
      "   [ 1.57531250e+02]\n",
      "   [-1.13201141e-02]\n",
      "   [ 1.29644974e+02]\n",
      "   [-1.74706711e+02]\n",
      "   [-7.50932617e+01]\n",
      "   [-1.73175659e+02]]\n",
      "\n",
      "  [[-8.27279510e+01]\n",
      "   [ 9.17663116e+01]\n",
      "   [-2.11898956e+02]\n",
      "   [ 8.55281982e+01]\n",
      "   [-1.51297256e+02]\n",
      "   [ 3.81872406e+01]\n",
      "   [ 3.21424026e+01]\n",
      "   [-1.30792511e+02]\n",
      "   [-5.38527822e+00]\n",
      "   [ 8.17421722e+01]\n",
      "   [ 1.57631378e+02]\n",
      "   [ 9.59311485e+00]\n",
      "   [ 1.16108604e+02]\n",
      "   [-1.72706970e+02]\n",
      "   [-9.88096313e+01]\n",
      "   [-2.33995575e+02]]]\n",
      "\n",
      "\n",
      " [[[-6.85261688e+01]\n",
      "   [ 8.99101257e+00]\n",
      "   [-2.81572075e+01]\n",
      "   [ 1.15900055e+02]\n",
      "   [-2.29621170e+02]\n",
      "   [-5.39785233e+01]\n",
      "   [-9.98587799e+01]\n",
      "   [-2.90465508e+01]\n",
      "   [-2.23617859e+01]\n",
      "   [ 9.50817871e+01]\n",
      "   [-1.11478958e+01]\n",
      "   [ 5.28827400e+01]\n",
      "   [ 5.54485626e+01]\n",
      "   [-2.22198471e+02]\n",
      "   [ 5.97513809e+01]\n",
      "   [-1.49237839e+02]]\n",
      "\n",
      "  [[-4.44186172e+01]\n",
      "   [ 2.82013512e+01]\n",
      "   [-9.02769165e+01]\n",
      "   [ 5.59393349e+01]\n",
      "   [-2.21031433e+02]\n",
      "   [-7.60000610e+00]\n",
      "   [-6.08905563e+01]\n",
      "   [-2.28381844e+01]\n",
      "   [-3.46667328e+01]\n",
      "   [ 6.92671814e+01]\n",
      "   [ 2.38992043e+01]\n",
      "   [-3.00072479e+00]\n",
      "   [ 9.71094818e+01]\n",
      "   [-2.89730530e+02]\n",
      "   [ 2.70176888e+01]\n",
      "   [-1.93462585e+02]]\n",
      "\n",
      "  [[-3.01555920e+01]\n",
      "   [ 8.00485611e+01]\n",
      "   [-1.68488037e+02]\n",
      "   [ 1.12476364e+02]\n",
      "   [-2.13198593e+02]\n",
      "   [ 6.55252838e+00]\n",
      "   [-1.75311756e+01]\n",
      "   [-6.33629837e+01]\n",
      "   [-1.79664097e+01]\n",
      "   [ 7.39581451e+01]\n",
      "   [ 9.30036621e+01]\n",
      "   [-3.75135002e+01]\n",
      "   [ 1.58500153e+02]\n",
      "   [-2.49379181e+02]\n",
      "   [-8.68544464e+01]\n",
      "   [-1.36189758e+02]]\n",
      "\n",
      "  [[-2.60655174e+01]\n",
      "   [ 9.56661072e+01]\n",
      "   [-1.25311806e+02]\n",
      "   [ 6.70733643e+01]\n",
      "   [-1.81189484e+02]\n",
      "   [ 5.58429718e+00]\n",
      "   [-3.89003754e-02]\n",
      "   [-1.07580338e+02]\n",
      "   [-1.93449421e+01]\n",
      "   [ 2.14163094e+01]\n",
      "   [ 8.63074799e+01]\n",
      "   [-7.84052734e+01]\n",
      "   [ 1.52514069e+02]\n",
      "   [-2.33951828e+02]\n",
      "   [-1.25663284e+02]\n",
      "   [-9.89776077e+01]]\n",
      "\n",
      "  [[-1.14351440e+02]\n",
      "   [ 1.39550461e+02]\n",
      "   [-1.41039001e+02]\n",
      "   [ 6.27747612e+01]\n",
      "   [-1.49565582e+02]\n",
      "   [ 2.90751648e+01]\n",
      "   [-9.58589478e+01]\n",
      "   [-8.81796417e+01]\n",
      "   [ 6.13546677e+01]\n",
      "   [ 1.70148468e+00]\n",
      "   [ 1.09770325e+02]\n",
      "   [-7.64088898e+01]\n",
      "   [ 1.27648277e+02]\n",
      "   [-2.48892548e+02]\n",
      "   [-1.67490875e+02]\n",
      "   [-1.71769913e+02]]]\n",
      "\n",
      "\n",
      " [[[-3.71691055e+01]\n",
      "   [ 6.06578712e+01]\n",
      "   [ 2.86122398e+01]\n",
      "   [ 7.48125992e+01]\n",
      "   [-2.52475082e+02]\n",
      "   [-5.52984543e+01]\n",
      "   [-1.09553833e+02]\n",
      "   [ 1.29867363e+00]\n",
      "   [ 5.50941849e+00]\n",
      "   [ 8.60286713e+01]\n",
      "   [-2.11065903e+01]\n",
      "   [ 2.94571571e+01]\n",
      "   [ 6.11403198e+01]\n",
      "   [-2.93847198e+02]\n",
      "   [ 5.16431427e+01]\n",
      "   [-1.63697815e+02]]\n",
      "\n",
      "  [[-5.56609650e+01]\n",
      "   [ 8.81326294e+01]\n",
      "   [-4.71937599e+01]\n",
      "   [ 2.38224106e+01]\n",
      "   [-2.36439178e+02]\n",
      "   [-2.61135483e+01]\n",
      "   [-1.09901421e+02]\n",
      "   [-2.84123573e+01]\n",
      "   [-2.24042225e+01]\n",
      "   [ 8.58246155e+01]\n",
      "   [ 6.00190544e+00]\n",
      "   [-5.53628159e+00]\n",
      "   [ 9.65991516e+01]\n",
      "   [-3.83463318e+02]\n",
      "   [ 1.29948807e+01]\n",
      "   [-2.15638977e+02]]\n",
      "\n",
      "  [[-3.15154362e+01]\n",
      "   [ 1.02364609e+02]\n",
      "   [-1.43450378e+02]\n",
      "   [ 8.59698944e+01]\n",
      "   [-2.52504684e+02]\n",
      "   [ 3.67879486e+00]\n",
      "   [-5.47437515e+01]\n",
      "   [-8.35332947e+01]\n",
      "   [ 4.11245108e+00]\n",
      "   [ 9.98336105e+01]\n",
      "   [ 7.23171844e+01]\n",
      "   [-2.81989632e+01]\n",
      "   [ 1.53107117e+02]\n",
      "   [-3.52592896e+02]\n",
      "   [-1.03662476e+02]\n",
      "   [-1.72460007e+02]]\n",
      "\n",
      "  [[-3.39471397e+01]\n",
      "   [ 1.18370895e+02]\n",
      "   [-1.01947884e+02]\n",
      "   [ 3.66761017e+01]\n",
      "   [-2.13524948e+02]\n",
      "   [ 1.20986099e+01]\n",
      "   [-6.58131332e+01]\n",
      "   [-1.23648956e+02]\n",
      "   [-1.59972591e+01]\n",
      "   [ 3.64599190e+01]\n",
      "   [ 6.14349861e+01]\n",
      "   [-6.69352722e+01]\n",
      "   [ 1.50962967e+02]\n",
      "   [-3.50062439e+02]\n",
      "   [-1.37491165e+02]\n",
      "   [-1.09821625e+02]]\n",
      "\n",
      "  [[-1.25043159e+02]\n",
      "   [ 1.49498444e+02]\n",
      "   [-9.47135086e+01]\n",
      "   [ 4.55731354e+01]\n",
      "   [-1.88620514e+02]\n",
      "   [ 6.57851257e+01]\n",
      "   [-1.30634857e+02]\n",
      "   [-1.11287056e+02]\n",
      "   [ 5.90753975e+01]\n",
      "   [-1.45174065e+01]\n",
      "   [ 9.58364029e+01]\n",
      "   [-6.84039536e+01]\n",
      "   [ 1.24927536e+02]\n",
      "   [-3.46854065e+02]\n",
      "   [-1.64414337e+02]\n",
      "   [-1.52620514e+02]]]], W.grad.numpy(): [[[[-1.05645691e+02]\n",
      "   [-2.01233635e+01]\n",
      "   [-1.49882278e+02]\n",
      "   [ 2.06188095e+02]\n",
      "   [-1.35001266e+02]\n",
      "   [-2.34929562e-01]\n",
      "   [-3.76054802e+01]\n",
      "   [ 3.27953625e+00]\n",
      "   [ 1.12367458e+01]\n",
      "   [ 4.94730835e+01]\n",
      "   [ 9.88435898e+01]\n",
      "   [ 1.26689674e+02]\n",
      "   [-6.32781029e+01]\n",
      "   [-1.41452454e+02]\n",
      "   [ 8.20149231e+01]\n",
      "   [-2.11831131e+02]]\n",
      "\n",
      "  [[-8.49279404e+01]\n",
      "   [-2.75491028e+01]\n",
      "   [-2.05616425e+02]\n",
      "   [ 1.50188751e+02]\n",
      "   [-1.33572327e+02]\n",
      "   [ 2.57772083e+01]\n",
      "   [-1.11375246e+01]\n",
      "   [-6.65546417e+00]\n",
      "   [ 1.65217152e+01]\n",
      "   [-2.94589367e+01]\n",
      "   [ 1.34262085e+02]\n",
      "   [ 4.88686790e+01]\n",
      "   [-1.13591099e+00]\n",
      "   [-1.99641098e+02]\n",
      "   [ 6.50487442e+01]\n",
      "   [-2.95012909e+02]]\n",
      "\n",
      "  [[-6.90266495e+01]\n",
      "   [-4.15998268e+01]\n",
      "   [-2.57041779e+02]\n",
      "   [ 2.30137833e+02]\n",
      "   [-1.08955025e+02]\n",
      "   [ 5.65249825e+00]\n",
      "   [ 3.30039291e+01]\n",
      "   [-3.96655273e+01]\n",
      "   [ 5.29015827e+00]\n",
      "   [-4.12875557e+01]\n",
      "   [ 1.68186295e+02]\n",
      "   [ 4.47323456e+01]\n",
      "   [ 5.60536690e+01]\n",
      "   [-1.86990860e+02]\n",
      "   [ 7.51116705e+00]\n",
      "   [-2.69889038e+02]]\n",
      "\n",
      "  [[-4.90958710e+01]\n",
      "   [-3.52368660e+01]\n",
      "   [-2.34394928e+02]\n",
      "   [ 2.24959946e+02]\n",
      "   [-1.33998215e+02]\n",
      "   [-3.78519363e+01]\n",
      "   [ 6.25472870e+01]\n",
      "   [-9.65747910e+01]\n",
      "   [-1.04518909e+01]\n",
      "   [-5.41348114e+01]\n",
      "   [ 1.50591019e+02]\n",
      "   [ 1.25958347e+00]\n",
      "   [ 5.39370422e+01]\n",
      "   [-1.30859909e+02]\n",
      "   [-5.90739632e+01]\n",
      "   [-2.57829102e+02]]\n",
      "\n",
      "  [[-9.34716721e+01]\n",
      "   [ 3.94591999e+00]\n",
      "   [-2.59044708e+02]\n",
      "   [ 2.11363235e+02]\n",
      "   [-1.24154663e+02]\n",
      "   [-9.59835625e+00]\n",
      "   [ 2.54309349e+01]\n",
      "   [-1.28695007e+02]\n",
      "   [ 3.11065025e+01]\n",
      "   [-3.63582687e+01]\n",
      "   [ 1.91348022e+02]\n",
      "   [ 1.28790646e+01]\n",
      "   [ 6.02757530e+01]\n",
      "   [-1.43611084e+02]\n",
      "   [-2.12342758e+01]\n",
      "   [-3.02779022e+02]]]\n",
      "\n",
      "\n",
      " [[[-1.30759598e+02]\n",
      "   [-5.30780144e+01]\n",
      "   [-3.65081406e+01]\n",
      "   [ 1.16226929e+02]\n",
      "   [-1.43968079e+02]\n",
      "   [ 2.62289371e+01]\n",
      "   [-4.83289413e+01]\n",
      "   [-4.52541113e+00]\n",
      "   [-1.54871950e+01]\n",
      "   [ 1.65274841e+02]\n",
      "   [ 6.37024689e+01]\n",
      "   [ 1.20104179e+02]\n",
      "   [-6.70979309e+01]\n",
      "   [-1.77250290e+02]\n",
      "   [ 9.24349976e+01]\n",
      "   [-1.95128494e+02]]\n",
      "\n",
      "  [[-1.16220749e+02]\n",
      "   [-3.30083466e+01]\n",
      "   [-1.03258072e+02]\n",
      "   [ 5.67695122e+01]\n",
      "   [-1.42624481e+02]\n",
      "   [ 4.47735443e+01]\n",
      "   [-1.14147892e+01]\n",
      "   [-2.06628780e+01]\n",
      "   [-4.33663559e+01]\n",
      "   [ 9.86896820e+01]\n",
      "   [ 8.88731918e+01]\n",
      "   [ 5.40590668e+01]\n",
      "   [ 2.64875650e+00]\n",
      "   [-2.29597656e+02]\n",
      "   [ 1.02947083e+02]\n",
      "   [-2.64780060e+02]]\n",
      "\n",
      "  [[-9.37098083e+01]\n",
      "   [-8.36794472e+00]\n",
      "   [-1.61437592e+02]\n",
      "   [ 1.25073792e+02]\n",
      "   [-1.41489975e+02]\n",
      "   [ 1.70049362e+01]\n",
      "   [ 4.18273544e+01]\n",
      "   [-5.35077095e+01]\n",
      "   [-2.52867470e+01]\n",
      "   [ 6.81087036e+01]\n",
      "   [ 9.66426849e+01]\n",
      "   [ 3.23420296e+01]\n",
      "   [ 9.01497269e+01]\n",
      "   [-1.88990158e+02]\n",
      "   [ 2.60766048e+01]\n",
      "   [-2.34107651e+02]]\n",
      "\n",
      "  [[-5.85138016e+01]\n",
      "   [-2.33964562e+00]\n",
      "   [-1.52788635e+02]\n",
      "   [ 1.25451736e+02]\n",
      "   [-1.37870758e+02]\n",
      "   [-5.23326015e+00]\n",
      "   [ 5.57009163e+01]\n",
      "   [-1.10888412e+02]\n",
      "   [-5.09408722e+01]\n",
      "   [ 9.69201374e+00]\n",
      "   [ 7.61016159e+01]\n",
      "   [ 4.83366203e+00]\n",
      "   [ 7.97956543e+01]\n",
      "   [-1.32182144e+02]\n",
      "   [-3.02678795e+01]\n",
      "   [-2.18942764e+02]]\n",
      "\n",
      "  [[-1.21423073e+02]\n",
      "   [ 4.10962067e+01]\n",
      "   [-1.86889618e+02]\n",
      "   [ 1.26133377e+02]\n",
      "   [-1.17518234e+02]\n",
      "   [ 4.11687317e+01]\n",
      "   [-2.13897467e-01]\n",
      "   [-1.13331795e+02]\n",
      "   [ 9.72499943e+00]\n",
      "   [ 3.09898901e+00]\n",
      "   [ 1.06382538e+02]\n",
      "   [ 1.49879825e+00]\n",
      "   [ 7.09051208e+01]\n",
      "   [-1.29133682e+02]\n",
      "   [-1.71551418e+01]\n",
      "   [-2.63589844e+02]]]\n",
      "\n",
      "\n",
      " [[[-7.35902939e+01]\n",
      "   [-3.58176994e+01]\n",
      "   [-3.91610184e+01]\n",
      "   [ 9.34227600e+01]\n",
      "   [-2.34856644e+02]\n",
      "   [-1.34909077e+01]\n",
      "   [-2.10024471e+01]\n",
      "   [-7.26594772e+01]\n",
      "   [-3.30976982e+01]\n",
      "   [ 1.88550903e+02]\n",
      "   [ 8.42464371e+01]\n",
      "   [ 8.25404968e+01]\n",
      "   [-3.08872318e+01]\n",
      "   [-2.25946426e+02]\n",
      "   [ 1.05908760e+02]\n",
      "   [-1.99482285e+02]]\n",
      "\n",
      "  [[-4.86233177e+01]\n",
      "   [-2.93912754e+01]\n",
      "   [-1.08916718e+02]\n",
      "   [ 5.14841805e+01]\n",
      "   [-2.17893204e+02]\n",
      "   [ 2.58462696e+01]\n",
      "   [ 1.49251928e+01]\n",
      "   [-6.35331993e+01]\n",
      "   [-4.49299583e+01]\n",
      "   [ 1.38390915e+02]\n",
      "   [ 1.41977020e+02]\n",
      "   [ 2.77888927e+01]\n",
      "   [ 5.09371300e+01]\n",
      "   [-2.80378174e+02]\n",
      "   [ 8.05642776e+01]\n",
      "   [-2.19628326e+02]]\n",
      "\n",
      "  [[-2.75799141e+01]\n",
      "   [ 7.72902632e+00]\n",
      "   [-1.96252594e+02]\n",
      "   [ 1.15850624e+02]\n",
      "   [-2.17371338e+02]\n",
      "   [ 2.22289600e+01]\n",
      "   [ 6.18699608e+01]\n",
      "   [-9.50439224e+01]\n",
      "   [-4.10830002e+01]\n",
      "   [ 1.38915527e+02]\n",
      "   [ 1.76892029e+02]\n",
      "   [ 2.75099983e+01]\n",
      "   [ 1.36497986e+02]\n",
      "   [-2.32300049e+02]\n",
      "   [-2.27395325e+01]\n",
      "   [-1.75595795e+02]]\n",
      "\n",
      "  [[-1.20376694e+00]\n",
      "   [ 3.28416061e+01]\n",
      "   [-1.74532043e+02]\n",
      "   [ 9.16015930e+01]\n",
      "   [-1.88469589e+02]\n",
      "   [-7.50869465e+00]\n",
      "   [ 9.53311615e+01]\n",
      "   [-1.50747940e+02]\n",
      "   [-5.55728226e+01]\n",
      "   [ 9.05029755e+01]\n",
      "   [ 1.57531174e+02]\n",
      "   [-1.13067478e-02]\n",
      "   [ 1.29644882e+02]\n",
      "   [-1.74706665e+02]\n",
      "   [-7.50932388e+01]\n",
      "   [-1.73175674e+02]]\n",
      "\n",
      "  [[-8.27279892e+01]\n",
      "   [ 9.17663345e+01]\n",
      "   [-2.11898926e+02]\n",
      "   [ 8.55282059e+01]\n",
      "   [-1.51297302e+02]\n",
      "   [ 3.81872597e+01]\n",
      "   [ 3.21423988e+01]\n",
      "   [-1.30792694e+02]\n",
      "   [-5.38524199e+00]\n",
      "   [ 8.17423019e+01]\n",
      "   [ 1.57631317e+02]\n",
      "   [ 9.59306526e+00]\n",
      "   [ 1.16108559e+02]\n",
      "   [-1.72706940e+02]\n",
      "   [-9.88096619e+01]\n",
      "   [-2.33995529e+02]]]\n",
      "\n",
      "\n",
      " [[[-6.85262146e+01]\n",
      "   [ 8.99102688e+00]\n",
      "   [-2.81572704e+01]\n",
      "   [ 1.15900093e+02]\n",
      "   [-2.29621170e+02]\n",
      "   [-5.39785194e+01]\n",
      "   [-9.98587036e+01]\n",
      "   [-2.90465279e+01]\n",
      "   [-2.23618031e+01]\n",
      "   [ 9.50817947e+01]\n",
      "   [-1.11478710e+01]\n",
      "   [ 5.28827477e+01]\n",
      "   [ 5.54485245e+01]\n",
      "   [-2.22198456e+02]\n",
      "   [ 5.97512474e+01]\n",
      "   [-1.49237808e+02]]\n",
      "\n",
      "  [[-4.44186554e+01]\n",
      "   [ 2.82013912e+01]\n",
      "   [-9.02769470e+01]\n",
      "   [ 5.59393463e+01]\n",
      "   [-2.21031433e+02]\n",
      "   [-7.59994698e+00]\n",
      "   [-6.08904991e+01]\n",
      "   [-2.28381920e+01]\n",
      "   [-3.46667175e+01]\n",
      "   [ 6.92672653e+01]\n",
      "   [ 2.38991852e+01]\n",
      "   [-3.00068474e+00]\n",
      "   [ 9.71094894e+01]\n",
      "   [-2.89730560e+02]\n",
      "   [ 2.70176468e+01]\n",
      "   [-1.93462601e+02]]\n",
      "\n",
      "  [[-3.01555843e+01]\n",
      "   [ 8.00485687e+01]\n",
      "   [-1.68487930e+02]\n",
      "   [ 1.12476326e+02]\n",
      "   [-2.13198685e+02]\n",
      "   [ 6.55252790e+00]\n",
      "   [-1.75311279e+01]\n",
      "   [-6.33630104e+01]\n",
      "   [-1.79664211e+01]\n",
      "   [ 7.39582291e+01]\n",
      "   [ 9.30036774e+01]\n",
      "   [-3.75135269e+01]\n",
      "   [ 1.58500168e+02]\n",
      "   [-2.49379196e+02]\n",
      "   [-8.68544693e+01]\n",
      "   [-1.36189743e+02]]\n",
      "\n",
      "  [[-2.60655365e+01]\n",
      "   [ 9.56660767e+01]\n",
      "   [-1.25311752e+02]\n",
      "   [ 6.70733109e+01]\n",
      "   [-1.81189468e+02]\n",
      "   [ 5.58428907e+00]\n",
      "   [-3.88610959e-02]\n",
      "   [-1.07580330e+02]\n",
      "   [-1.93448830e+01]\n",
      "   [ 2.14163246e+01]\n",
      "   [ 8.63074722e+01]\n",
      "   [-7.84052734e+01]\n",
      "   [ 1.52513947e+02]\n",
      "   [-2.33951843e+02]\n",
      "   [-1.25663277e+02]\n",
      "   [-9.89775620e+01]]\n",
      "\n",
      "  [[-1.14351463e+02]\n",
      "   [ 1.39550476e+02]\n",
      "   [-1.41038986e+02]\n",
      "   [ 6.27747345e+01]\n",
      "   [-1.49565643e+02]\n",
      "   [ 2.90752068e+01]\n",
      "   [-9.58589859e+01]\n",
      "   [-8.81796570e+01]\n",
      "   [ 6.13546944e+01]\n",
      "   [ 1.70150375e+00]\n",
      "   [ 1.09770340e+02]\n",
      "   [-7.64088745e+01]\n",
      "   [ 1.27648170e+02]\n",
      "   [-2.48892548e+02]\n",
      "   [-1.67490860e+02]\n",
      "   [-1.71769913e+02]]]\n",
      "\n",
      "\n",
      " [[[-3.71691208e+01]\n",
      "   [ 6.06578369e+01]\n",
      "   [ 2.86121750e+01]\n",
      "   [ 7.48125916e+01]\n",
      "   [-2.52475189e+02]\n",
      "   [-5.52984734e+01]\n",
      "   [-1.09553802e+02]\n",
      "   [ 1.29864430e+00]\n",
      "   [ 5.50939941e+00]\n",
      "   [ 8.60286255e+01]\n",
      "   [-2.11065712e+01]\n",
      "   [ 2.94571457e+01]\n",
      "   [ 6.11403580e+01]\n",
      "   [-2.93847137e+02]\n",
      "   [ 5.16430550e+01]\n",
      "   [-1.63697739e+02]]\n",
      "\n",
      "  [[-5.56609879e+01]\n",
      "   [ 8.81326065e+01]\n",
      "   [-4.71938210e+01]\n",
      "   [ 2.38223972e+01]\n",
      "   [-2.36439331e+02]\n",
      "   [-2.61135597e+01]\n",
      "   [-1.09901405e+02]\n",
      "   [-2.84123058e+01]\n",
      "   [-2.24042530e+01]\n",
      "   [ 8.58246155e+01]\n",
      "   [ 6.00187540e+00]\n",
      "   [-5.53630495e+00]\n",
      "   [ 9.65991669e+01]\n",
      "   [-3.83463318e+02]\n",
      "   [ 1.29948740e+01]\n",
      "   [-2.15639008e+02]]\n",
      "\n",
      "  [[-3.15154762e+01]\n",
      "   [ 1.02364578e+02]\n",
      "   [-1.43450241e+02]\n",
      "   [ 8.59699097e+01]\n",
      "   [-2.52504745e+02]\n",
      "   [ 3.67876625e+00]\n",
      "   [-5.47436943e+01]\n",
      "   [-8.35332642e+01]\n",
      "   [ 4.11248875e+00]\n",
      "   [ 9.98335953e+01]\n",
      "   [ 7.23172607e+01]\n",
      "   [-2.81989555e+01]\n",
      "   [ 1.53107147e+02]\n",
      "   [-3.52592834e+02]\n",
      "   [-1.03662437e+02]\n",
      "   [-1.72459976e+02]]\n",
      "\n",
      "  [[-3.39471626e+01]\n",
      "   [ 1.18370903e+02]\n",
      "   [-1.01947792e+02]\n",
      "   [ 3.66761398e+01]\n",
      "   [-2.13524933e+02]\n",
      "   [ 1.20985832e+01]\n",
      "   [-6.58130722e+01]\n",
      "   [-1.23648987e+02]\n",
      "   [-1.59971714e+01]\n",
      "   [ 3.64600220e+01]\n",
      "   [ 6.14349976e+01]\n",
      "   [-6.69352951e+01]\n",
      "   [ 1.50962952e+02]\n",
      "   [-3.50062347e+02]\n",
      "   [-1.37491211e+02]\n",
      "   [-1.09821609e+02]]\n",
      "\n",
      "  [[-1.25043182e+02]\n",
      "   [ 1.49498459e+02]\n",
      "   [-9.47134552e+01]\n",
      "   [ 4.55731850e+01]\n",
      "   [-1.88620590e+02]\n",
      "   [ 6.57851181e+01]\n",
      "   [-1.30634872e+02]\n",
      "   [-1.11287102e+02]\n",
      "   [ 5.90754128e+01]\n",
      "   [-1.45173502e+01]\n",
      "   [ 9.58364258e+01]\n",
      "   [-6.84039917e+01]\n",
      "   [ 1.24927521e+02]\n",
      "   [-3.46853943e+02]\n",
      "   [-1.64414398e+02]\n",
      "   [-1.52620514e+02]]]]\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape15-W_shape15-1-0] _\u001b[0m\n",
      "\n",
      "Z_shape = (3, 17, 17, 16), W_shape = (1, 1, 16, 1), stride = 1, padding = 0\n",
      "backward = True, device = cpu()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[ 0.01555795]\n",
      "   [-3.0465872 ]\n",
      "   [ 4.0972595 ]\n",
      "   [ 1.2990627 ]\n",
      "   [-7.505466  ]\n",
      "   [-1.7335238 ]\n",
      "  ...[ 5.6893935 ]\n",
      "   [ 2.267663  ]\n",
      "   [-1.0709513 ]\n",
      "   [-5.0566583 ]\n",
      "   [-0.23777105]\n",
      "   [-9.931785  ]\n",
      "   [-0.44905776]]]])\n",
      "W_shape    = (1, 1, 16, 1)\n",
      "Wtch       = tensor([[[[ 0.0156],\n",
      "          [-3.0466],\n",
      "          [ 4.0973],\n",
      "          [ 1.2991],\n",
      "          [-7.5055],\n",
      "          [-1...  [-1.0710],\n",
      "          [-5.0567],\n",
      "          [-0.2378],\n",
      "          [-9.9318],\n",
      "          [-0.4491]]]], requires_grad=True)\n",
      "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ...  6.08375072e-01\n",
      "     2.21931624e+00  1.66837168e...3e+00]\n",
      "   [-1.25365603e+00 -1.71452928e+00  1.35930243e+01 ...  3.13170171e+00\n",
      "    -1.35708165e+00  1.29997072e+01]]]])\n",
      "Z_shape    = (3, 17, 17, 16)\n",
      "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ...,  6.0838e-01,\n",
      "            2.2193e+00,  1.6684e+00],\n",
      "          [...[-1.2537e+00, -1.7145e+00,  1.3593e+01,  ...,  3.1317e+00,\n",
      "           -1.3571e+00,  1.3000e+01]]]], requires_grad=True)\n",
      "_W         = array([[[[ 0.01555795],\n",
      "         [-3.0465872 ],\n",
      "         [ 4.0972595 ],\n",
      "         [ 1.2990627 ],\n",
      "         [-7.505466  ]...13 ],\n",
      "         [-5.0566583 ],\n",
      "         [-0.23777105],\n",
      "         [-9.931785  ],\n",
      "         [-0.44905776]]]], dtype=float32)\n",
      "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
      "           6.08375072e-01,  2.21931624e+00,  1.66837...e+01, ...,\n",
      "           3.13170171e+00, -1.35708165e+00,  1.29997072e+01]]]],\n",
      "      shape=(3, 17, 17, 16), dtype=float32)\n",
      "backward   = True\n",
      "device     = cpu()\n",
      "err1       = np.float32(0.0)\n",
      "err2       = np.float32(0.00029865085)\n",
      "out        = tensor([[[[ -89.1888,   65.9584,  -71.3126,   94.1300,   58.1957, -154.0715,\n",
      "           -179.3213,  -36.3653,   84.003... -53.1932,\n",
      "             18.7652,    0.4121, -161.6255,   16.9990,  227.2095]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(2183.7771, grad_fn=<SumBackward0>)\n",
      "padding    = 0\n",
      "stride     = 1\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c5655e1280>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655e1670>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655e1670>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655e1670>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655e1670>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[ -98.53308 ]\n",
      "   [ 116.89258 ]\n",
      "   [-204.87402 ]\n",
      "   [ 196.45303 ]\n",
      "   [-292.5897  ]\n",
      "   [ -45.538574]\n",
      "   [ -92.34815 ]\n",
      "   [ -49.117893]\n",
      "   [  18.121897]\n",
      "   [ -97.632866]\n",
      "   [ 158.6374  ]\n",
      "   [ -19.121422]\n",
      "   [  87.739204]\n",
      "   [-367.89557 ]\n",
      "   [-107.21064 ]\n",
      "   [-347.36365 ]]]], W.grad.numpy(): [[[[ -98.53316 ]\n",
      "   [ 116.89256 ]\n",
      "   [-204.87398 ]\n",
      "   [ 196.45316 ]\n",
      "   [-292.5897  ]\n",
      "   [ -45.5386  ]\n",
      "   [ -92.34817 ]\n",
      "   [ -49.118015]\n",
      "   [  18.121944]\n",
      "   [ -97.63288 ]\n",
      "   [ 158.63751 ]\n",
      "   [ -19.121498]\n",
      "   [  87.73919 ]\n",
      "   [-367.89545 ]\n",
      "   [-107.210556]\n",
      "   [-347.36356 ]]]]\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape16-W_shape16-1-0] _\u001b[0m\n",
      "\n",
      "Z_shape = (1, 14, 14, 2), W_shape = (3, 3, 2, 2), stride = 1, padding = 0\n",
      "backward = True, device = cpu()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[ -1.7671587   -8.082371  ]\n",
      "   [ -1.4591868   -3.807461  ]]\n",
      "\n",
      "  [[  4.2896194    5.705509  ]\n",
      "   [  7.3...7526     2.911123  ]\n",
      "   [-10.473016     0.61860955]]\n",
      "\n",
      "  [[ -0.65053475   0.46976614]\n",
      "   [  4.7152305  -13.698386  ]]]])\n",
      "W_shape    = (3, 3, 2, 2)\n",
      "Wtch       = tensor([[[[ -1.7672,  -8.0824],\n",
      "          [ -1.4592,  -3.8075]],\n",
      "\n",
      "         [[  4.2896,   5.7055],\n",
      "          [  7.3329,...         [-10.4730,   0.6186]],\n",
      "\n",
      "         [[ -0.6505,   0.4698],\n",
      "          [  4.7152, -13.6984]]]], requires_grad=True)\n",
      "Z          = needle.Tensor([[[[  8.820262     2.000786  ]\n",
      "   [  4.89369     11.204466  ]\n",
      "   [  9.33779     -4.8863893 ]\n",
      "   [  4.750...19315276  -8.283575  ]\n",
      "   [ -4.9275537   -7.359175  ]\n",
      "   [  8.240675     0.8211388 ]\n",
      "   [  2.8364513   -1.1133755 ]]]])\n",
      "Z_shape    = (1, 14, 14, 2)\n",
      "Ztch       = tensor([[[[  8.8203,   2.0008],\n",
      "          [  4.8937,  11.2045],\n",
      "          [  9.3378,  -4.8864],\n",
      "          [  4.7504,  ...\n",
      "          [ -4.9276,  -7.3592],\n",
      "          [  8.2407,   0.8211],\n",
      "          [  2.8365,  -1.1134]]]], requires_grad=True)\n",
      "_W         = array([[[[ -1.7671587 ,  -8.082371  ],\n",
      "         [ -1.4591868 ,  -3.807461  ]],\n",
      "\n",
      "        [[  4.2896194 ,   5.705509  ],...016  ,   0.61860955]],\n",
      "\n",
      "        [[ -0.65053475,   0.46976614],\n",
      "         [  4.7152305 , -13.698386  ]]]], dtype=float32)\n",
      "_Z         = array([[[[  8.820262  ,   2.000786  ],\n",
      "         [  4.89369   ,  11.204466  ],\n",
      "         [  9.33779   ,  -4.8863893 ],\n",
      " ...275537 ,  -7.359175  ],\n",
      "         [  8.240675  ,   0.8211388 ],\n",
      "         [  2.8364513 ,  -1.1133755 ]]]], dtype=float32)\n",
      "backward   = True\n",
      "device     = cpu()\n",
      "err1       = np.float32(1.2557781e-05)\n",
      "err2       = np.float32(8.0786966e-05)\n",
      "out        = tensor([[[[ -83.1438,   -6.3602,   93.8760,  -41.2035,  -96.8909,  152.8543,\n",
      "           -101.4654,  259.1811,    7.015...            -60.5771,   13.6480,  228.9975,    8.4413, -121.9792,   26.1601]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(2243.9304, grad_fn=<SumBackward0>)\n",
      "padding    = 0\n",
      "stride     = 1\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c6ac9169c0>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c6ac917950>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c6ac917950>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c6ac917950>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c6ac917950>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[ -48.98436   -48.98436 ]\n",
      "   [  89.055916   89.055916]]\n",
      "\n",
      "  [[ -57.23758   -57.23758 ]\n",
      "   [  26.450378   26.450378]]\n",
      "\n",
      "  [[ -99.13748   -99.13748 ]\n",
      "   [ -26.94374   -26.94374 ]]]\n",
      "\n",
      "\n",
      " [[[-106.9129   -106.9129  ]\n",
      "   [  66.44665    66.44665 ]]\n",
      "\n",
      "  [[-105.4229   -105.4229  ]\n",
      "   [  10.877884   10.877884]]\n",
      "\n",
      "  [[-134.57861  -134.57861 ]\n",
      "   [ -36.973785  -36.973785]]]\n",
      "\n",
      "\n",
      " [[[ -97.087906  -97.087906]\n",
      "   [  23.784714   23.784714]]\n",
      "\n",
      "  [[ -77.06088   -77.06088 ]\n",
      "   [ -18.51759   -18.51759 ]]\n",
      "\n",
      "  [[-101.51124  -101.51124 ]\n",
      "   [ -65.75924   -65.75924 ]]]], W.grad.numpy(): [[[[ -48.984367  -48.984367]\n",
      "   [  89.05592    89.05592 ]]\n",
      "\n",
      "  [[ -57.23759   -57.23759 ]\n",
      "   [  26.450375   26.450375]]\n",
      "\n",
      "  [[ -99.137474  -99.137474]\n",
      "   [ -26.94374   -26.94374 ]]]\n",
      "\n",
      "\n",
      " [[[-106.91289  -106.91289 ]\n",
      "   [  66.44665    66.44665 ]]\n",
      "\n",
      "  [[-105.42286  -105.42286 ]\n",
      "   [  10.877888   10.877888]]\n",
      "\n",
      "  [[-134.57863  -134.57863 ]\n",
      "   [ -36.973785  -36.973785]]]\n",
      "\n",
      "\n",
      " [[[ -97.08791   -97.08791 ]\n",
      "   [  23.784695   23.784695]]\n",
      "\n",
      "  [[ -77.060905  -77.060905]\n",
      "   [ -18.517588  -18.517588]]\n",
      "\n",
      "  [[-101.51124  -101.51124 ]\n",
      "   [ -65.75923   -65.75923 ]]]]\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape0-W_shape0-1-0] _\u001b[0m\n",
      "\n",
      "Z_shape = (3, 14, 14, 8), W_shape = (3, 3, 8, 16), stride = 1, padding = 0\n",
      "backward = True, device = cuda()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
      "      2.1704152   -0.38803983]\n",
      "   [  2.245844...2.618842     0.71487164]\n",
      "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
      "      0.03223436   2.0512383 ]]]])\n",
      "W_shape    = (3, 3, 8, 16)\n",
      "Wtch       = tensor([[[[  4.2827,   8.1336,  -4.6223,  ...,   2.0798,   2.1704,  -0.3880],\n",
      "          [  2.2458,  -0.6565,  -3.7547,...   0.7149],\n",
      "          [ -4.0937,   3.7292, -10.5518,  ...,   0.3174,   0.0322,   2.0512]]]],\n",
      "       requires_grad=True)\n",
      "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
      "     4.75044203e+00 -7.56786048e...3e+00]\n",
      "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
      "    -8.48226726e-01 -2.29984760e+00]]]])\n",
      "Z_shape    = (3, 14, 14, 8)\n",
      "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
      "            4.7504e+00, -7.5679e-01],\n",
      "          [...[ 1.0991e+01,  2.2317e+00,  4.6206e+00,  ..., -6.2309e-01,\n",
      "           -8.4823e-01, -2.2998e+00]]]], requires_grad=True)\n",
      "_W         = array([[[[  4.282669  ,   8.133604  ,  -4.6223483 , ...,   2.0798197 ,\n",
      "            2.1704152 ,  -0.38803983],\n",
      "        ... , -10.551835  , ...,   0.31741843,\n",
      "            0.03223436,   2.0512383 ]]]],\n",
      "      shape=(3, 3, 8, 16), dtype=float32)\n",
      "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
      "          -4.88638926e+00,  4.75044203e+00, -7.56786...9e+00, ...,\n",
      "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
      "      shape=(3, 14, 14, 8), dtype=float32)\n",
      "backward   = True\n",
      "device     = cuda()\n",
      "err1       = np.float32(0.00073335366)\n",
      "err2       = np.float32(0.0013963837)\n",
      "out        = tensor([[[[-2.1851e+01, -1.8266e+02, -2.9496e+02,  ...,  9.3036e+01,\n",
      "           -1.0480e+02,  1.1030e+02],\n",
      "          [...,  5.7277e+02, -9.0837e+01,  ..., -1.8747e+02,\n",
      "           -1.1281e+02,  2.0660e+02]]]], grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(-6614.2402, grad_fn=<SumBackward0>)\n",
      "padding    = 0\n",
      "stride     = 1\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c5655c57f0>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655c4230>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655c4230>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655c4230>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655c4230>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[-117.863464 -117.863464 -117.863464 ... -117.863464 -117.863464\n",
      "    -117.863464]\n",
      "   [ -18.305077  -18.305077  -18.305077 ...  -18.305077  -18.305077\n",
      "     -18.305077]\n",
      "   [ -83.70589   -83.70589   -83.70589  ...  -83.70589   -83.70589\n",
      "     -83.70589 ]\n",
      "   ...\n",
      "   [ -94.59245   -94.59245   -94.59245  ...  -94.59245   -94.59245\n",
      "     -94.59245 ]\n",
      "   [ 113.50016   113.50016   113.50016  ...  113.50016   113.50016\n",
      "     113.50016 ]\n",
      "   [-163.46542  -163.46542  -163.46542  ... -163.46542  -163.46542\n",
      "    -163.46542 ]]\n",
      "\n",
      "  [[ -72.387054  -72.387054  -72.387054 ...  -72.387054  -72.387054\n",
      "     -72.387054]\n",
      "   [ -12.95504   -12.95504   -12.95504  ...  -12.95504   -12.95504\n",
      "     -12.95504 ]\n",
      "   [ -60.1023    -60.1023    -60.1023   ...  -60.1023    -60.1023\n",
      "     -60.1023  ]\n",
      "   ...\n",
      "   [-134.91211  -134.91211  -134.91211  ... -134.91211  -134.91211\n",
      "    -134.91211 ]\n",
      "   [  58.04833    58.04833    58.04833  ...   58.04833    58.04833\n",
      "      58.04833 ]\n",
      "   [-149.94443  -149.94443  -149.94443  ... -149.94443  -149.94443\n",
      "    -149.94443 ]]\n",
      "\n",
      "  [[ -31.305983  -31.305983  -31.305983 ...  -31.305983  -31.305983\n",
      "     -31.305983]\n",
      "   [  41.738014   41.738014   41.738014 ...   41.738014   41.738014\n",
      "      41.738014]\n",
      "   [ -41.51856   -41.51856   -41.51856  ...  -41.51856   -41.51856\n",
      "     -41.51856 ]\n",
      "   ...\n",
      "   [ -55.21545   -55.21545   -55.21545  ...  -55.21545   -55.21545\n",
      "     -55.21545 ]\n",
      "   [  26.683502   26.683502   26.683502 ...   26.683502   26.683502\n",
      "      26.683502]\n",
      "   [-130.78413  -130.78413  -130.78413  ... -130.78413  -130.78413\n",
      "    -130.78413 ]]]\n",
      "\n",
      "\n",
      " [[[-120.4241   -120.4241   -120.4241   ... -120.4241   -120.4241\n",
      "    -120.4241  ]\n",
      "   [  28.03527    28.03527    28.03527  ...   28.03527    28.03527\n",
      "      28.03527 ]\n",
      "   [ -61.260155  -61.260155  -61.260155 ...  -61.260155  -61.260155\n",
      "     -61.260155]\n",
      "   ...\n",
      "   [-184.45692  -184.45692  -184.45692  ... -184.45692  -184.45692\n",
      "    -184.45692 ]\n",
      "   [  88.74799    88.74799    88.74799  ...   88.74799    88.74799\n",
      "      88.74799 ]\n",
      "   [ -93.74545   -93.74545   -93.74545  ...  -93.74545   -93.74545\n",
      "     -93.74545 ]]\n",
      "\n",
      "  [[ -64.364494  -64.364494  -64.364494 ...  -64.364494  -64.364494\n",
      "     -64.364494]\n",
      "   [  -7.776188   -7.776188   -7.776188 ...   -7.776188   -7.776188\n",
      "      -7.776188]\n",
      "   [ -34.25772   -34.25772   -34.25772  ...  -34.25772   -34.25772\n",
      "     -34.25772 ]\n",
      "   ...\n",
      "   [-213.2781   -213.2781   -213.2781   ... -213.2781   -213.2781\n",
      "    -213.2781  ]\n",
      "   [  39.10958    39.10958    39.10958  ...   39.10958    39.10958\n",
      "      39.10958 ]\n",
      "   [ -93.828     -93.828     -93.828    ...  -93.828     -93.828\n",
      "     -93.828   ]]\n",
      "\n",
      "  [[ -20.186165  -20.186165  -20.186165 ...  -20.186165  -20.186165\n",
      "     -20.186165]\n",
      "   [  41.759117   41.759117   41.759117 ...   41.759117   41.759117\n",
      "      41.759117]\n",
      "   [ -30.735855  -30.735855  -30.735855 ...  -30.735855  -30.735855\n",
      "     -30.735855]\n",
      "   ...\n",
      "   [-137.9915   -137.9915   -137.9915   ... -137.9915   -137.9915\n",
      "    -137.9915  ]\n",
      "   [ -15.200287  -15.200287  -15.200287 ...  -15.200287  -15.200287\n",
      "     -15.200287]\n",
      "   [ -82.541794  -82.541794  -82.541794 ...  -82.541794  -82.541794\n",
      "     -82.541794]]]\n",
      "\n",
      "\n",
      " [[[-100.66364  -100.66364  -100.66364  ... -100.66364  -100.66364\n",
      "    -100.66364 ]\n",
      "   [  20.235909   20.235909   20.235909 ...   20.235909   20.235909\n",
      "      20.235909]\n",
      "   [ -66.781624  -66.781624  -66.781624 ...  -66.781624  -66.781624\n",
      "     -66.781624]\n",
      "   ...\n",
      "   [-212.27026  -212.27026  -212.27026  ... -212.27026  -212.27026\n",
      "    -212.27026 ]\n",
      "   [  55.76574    55.76574    55.76574  ...   55.76574    55.76574\n",
      "      55.76574 ]\n",
      "   [ -91.51832   -91.51832   -91.51832  ...  -91.51832   -91.51832\n",
      "     -91.51832 ]]\n",
      "\n",
      "  [[ -73.383575  -73.383575  -73.383575 ...  -73.383575  -73.383575\n",
      "     -73.383575]\n",
      "   [  12.9244     12.9244     12.9244   ...   12.9244     12.9244\n",
      "      12.9244  ]\n",
      "   [ -18.37703   -18.37703   -18.37703  ...  -18.37703   -18.37703\n",
      "     -18.37703 ]\n",
      "   ...\n",
      "   [-257.76913  -257.76913  -257.76913  ... -257.76913  -257.76913\n",
      "    -257.76913 ]\n",
      "   [  16.773888   16.773888   16.773888 ...   16.773888   16.773888\n",
      "      16.773888]\n",
      "   [ -82.270966  -82.270966  -82.270966 ...  -82.270966  -82.270966\n",
      "     -82.270966]]\n",
      "\n",
      "  [[ -11.111122  -11.111122  -11.111122 ...  -11.111122  -11.111122\n",
      "     -11.111122]\n",
      "   [  44.496124   44.496124   44.496124 ...   44.496124   44.496124\n",
      "      44.496124]\n",
      "   [ -27.203125  -27.203125  -27.203125 ...  -27.203125  -27.203125\n",
      "     -27.203125]\n",
      "   ...\n",
      "   [-158.30197  -158.30197  -158.30197  ... -158.30197  -158.30197\n",
      "    -158.30197 ]\n",
      "   [ -20.719353  -20.719353  -20.719353 ...  -20.719353  -20.719353\n",
      "     -20.719353]\n",
      "   [ -93.38875   -93.38875   -93.38875  ...  -93.38875   -93.38875\n",
      "     -93.38875 ]]]], W.grad.numpy(): [[[[-117.86352  -117.86352  -117.86352  ... -117.86352  -117.86352\n",
      "    -117.86352 ]\n",
      "   [ -18.30505   -18.30505   -18.30505  ...  -18.30505   -18.30505\n",
      "     -18.30505 ]\n",
      "   [ -83.7058    -83.7058    -83.7058   ...  -83.7058    -83.7058\n",
      "     -83.7058  ]\n",
      "   ...\n",
      "   [ -94.59242   -94.59242   -94.59242  ...  -94.59242   -94.59242\n",
      "     -94.59242 ]\n",
      "   [ 113.50013   113.50013   113.50013  ...  113.50013   113.50013\n",
      "     113.50013 ]\n",
      "   [-163.46544  -163.46544  -163.46544  ... -163.46544  -163.46544\n",
      "    -163.46544 ]]\n",
      "\n",
      "  [[ -72.38704   -72.38704   -72.38704  ...  -72.38704   -72.38704\n",
      "     -72.38704 ]\n",
      "   [ -12.955032  -12.955032  -12.955032 ...  -12.955032  -12.955032\n",
      "     -12.955032]\n",
      "   [ -60.102333  -60.102333  -60.102333 ...  -60.102333  -60.102333\n",
      "     -60.102333]\n",
      "   ...\n",
      "   [-134.91219  -134.91219  -134.91219  ... -134.91219  -134.91219\n",
      "    -134.91219 ]\n",
      "   [  58.048294   58.048294   58.048294 ...   58.048294   58.048294\n",
      "      58.048294]\n",
      "   [-149.9445   -149.9445   -149.9445   ... -149.9445   -149.9445\n",
      "    -149.9445  ]]\n",
      "\n",
      "  [[ -31.30602   -31.30602   -31.30602  ...  -31.30602   -31.30602\n",
      "     -31.30602 ]\n",
      "   [  41.738      41.738      41.738    ...   41.738      41.738\n",
      "      41.738   ]\n",
      "   [ -41.518616  -41.518616  -41.518616 ...  -41.518616  -41.518616\n",
      "     -41.518616]\n",
      "   ...\n",
      "   [ -55.215454  -55.215454  -55.215454 ...  -55.215454  -55.215454\n",
      "     -55.215454]\n",
      "   [  26.683535   26.683535   26.683535 ...   26.683535   26.683535\n",
      "      26.683535]\n",
      "   [-130.7842   -130.7842   -130.7842   ... -130.7842   -130.7842\n",
      "    -130.7842  ]]]\n",
      "\n",
      "\n",
      " [[[-120.42416  -120.42416  -120.42416  ... -120.42416  -120.42416\n",
      "    -120.42416 ]\n",
      "   [  28.035273   28.035273   28.035273 ...   28.035273   28.035273\n",
      "      28.035273]\n",
      "   [ -61.260204  -61.260204  -61.260204 ...  -61.260204  -61.260204\n",
      "     -61.260204]\n",
      "   ...\n",
      "   [-184.457    -184.457    -184.457    ... -184.457    -184.457\n",
      "    -184.457   ]\n",
      "   [  88.747925   88.747925   88.747925 ...   88.747925   88.747925\n",
      "      88.747925]\n",
      "   [ -93.745514  -93.745514  -93.745514 ...  -93.745514  -93.745514\n",
      "     -93.745514]]\n",
      "\n",
      "  [[ -64.364494  -64.364494  -64.364494 ...  -64.364494  -64.364494\n",
      "     -64.364494]\n",
      "   [  -7.776159   -7.776159   -7.776159 ...   -7.776159   -7.776159\n",
      "      -7.776159]\n",
      "   [ -34.25773   -34.25773   -34.25773  ...  -34.25773   -34.25773\n",
      "     -34.25773 ]\n",
      "   ...\n",
      "   [-213.27806  -213.27806  -213.27806  ... -213.27806  -213.27806\n",
      "    -213.27806 ]\n",
      "   [  39.109554   39.109554   39.109554 ...   39.109554   39.109554\n",
      "      39.109554]\n",
      "   [ -93.82804   -93.82804   -93.82804  ...  -93.82804   -93.82804\n",
      "     -93.82804 ]]\n",
      "\n",
      "  [[ -20.186209  -20.186209  -20.186209 ...  -20.186209  -20.186209\n",
      "     -20.186209]\n",
      "   [  41.759132   41.759132   41.759132 ...   41.759132   41.759132\n",
      "      41.759132]\n",
      "   [ -30.73585   -30.73585   -30.73585  ...  -30.73585   -30.73585\n",
      "     -30.73585 ]\n",
      "   ...\n",
      "   [-137.99155  -137.99155  -137.99155  ... -137.99155  -137.99155\n",
      "    -137.99155 ]\n",
      "   [ -15.200264  -15.200264  -15.200264 ...  -15.200264  -15.200264\n",
      "     -15.200264]\n",
      "   [ -82.54181   -82.54181   -82.54181  ...  -82.54181   -82.54181\n",
      "     -82.54181 ]]]\n",
      "\n",
      "\n",
      " [[[-100.663704 -100.663704 -100.663704 ... -100.663704 -100.663704\n",
      "    -100.663704]\n",
      "   [  20.235903   20.235903   20.235903 ...   20.235903   20.235903\n",
      "      20.235903]\n",
      "   [ -66.78166   -66.78166   -66.78166  ...  -66.78166   -66.78166\n",
      "     -66.78166 ]\n",
      "   ...\n",
      "   [-212.27031  -212.27031  -212.27031  ... -212.27031  -212.27031\n",
      "    -212.27031 ]\n",
      "   [  55.765717   55.765717   55.765717 ...   55.765717   55.765717\n",
      "      55.765717]\n",
      "   [ -91.51837   -91.51837   -91.51837  ...  -91.51837   -91.51837\n",
      "     -91.51837 ]]\n",
      "\n",
      "  [[ -73.383575  -73.383575  -73.383575 ...  -73.383575  -73.383575\n",
      "     -73.383575]\n",
      "   [  12.92442    12.92442    12.92442  ...   12.92442    12.92442\n",
      "      12.92442 ]\n",
      "   [ -18.377075  -18.377075  -18.377075 ...  -18.377075  -18.377075\n",
      "     -18.377075]\n",
      "   ...\n",
      "   [-257.76904  -257.76904  -257.76904  ... -257.76904  -257.76904\n",
      "    -257.76904 ]\n",
      "   [  16.773893   16.773893   16.773893 ...   16.773893   16.773893\n",
      "      16.773893]\n",
      "   [ -82.27101   -82.27101   -82.27101  ...  -82.27101   -82.27101\n",
      "     -82.27101 ]]\n",
      "\n",
      "  [[ -11.111122  -11.111122  -11.111122 ...  -11.111122  -11.111122\n",
      "     -11.111122]\n",
      "   [  44.49609    44.49609    44.49609  ...   44.49609    44.49609\n",
      "      44.49609 ]\n",
      "   [ -27.20313   -27.20313   -27.20313  ...  -27.20313   -27.20313\n",
      "     -27.20313 ]\n",
      "   ...\n",
      "   [-158.3019   -158.3019   -158.3019   ... -158.3019   -158.3019\n",
      "    -158.3019  ]\n",
      "   [ -20.719355  -20.719355  -20.719355 ...  -20.719355  -20.719355\n",
      "     -20.719355]\n",
      "   [ -93.38881   -93.38881   -93.38881  ...  -93.38881   -93.38881\n",
      "     -93.38881 ]]]]\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape1-W_shape1-1-1] _\u001b[0m\n",
      "\n",
      "Z_shape = (3, 14, 14, 8), W_shape = (3, 3, 8, 16), stride = 1, padding = 1\n",
      "backward = True, device = cuda()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
      "      2.1704152   -0.38803983]\n",
      "   [  2.245844...2.618842     0.71487164]\n",
      "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
      "      0.03223436   2.0512383 ]]]])\n",
      "W_shape    = (3, 3, 8, 16)\n",
      "Wtch       = tensor([[[[  4.2827,   8.1336,  -4.6223,  ...,   2.0798,   2.1704,  -0.3880],\n",
      "          [  2.2458,  -0.6565,  -3.7547,...   0.7149],\n",
      "          [ -4.0937,   3.7292, -10.5518,  ...,   0.3174,   0.0322,   2.0512]]]],\n",
      "       requires_grad=True)\n",
      "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
      "     4.75044203e+00 -7.56786048e...3e+00]\n",
      "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
      "    -8.48226726e-01 -2.29984760e+00]]]])\n",
      "Z_shape    = (3, 14, 14, 8)\n",
      "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
      "            4.7504e+00, -7.5679e-01],\n",
      "          [...[ 1.0991e+01,  2.2317e+00,  4.6206e+00,  ..., -6.2309e-01,\n",
      "           -8.4823e-01, -2.2998e+00]]]], requires_grad=True)\n",
      "_W         = array([[[[  4.282669  ,   8.133604  ,  -4.6223483 , ...,   2.0798197 ,\n",
      "            2.1704152 ,  -0.38803983],\n",
      "        ... , -10.551835  , ...,   0.31741843,\n",
      "            0.03223436,   2.0512383 ]]]],\n",
      "      shape=(3, 3, 8, 16), dtype=float32)\n",
      "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
      "          -4.88638926e+00,  4.75044203e+00, -7.56786...9e+00, ...,\n",
      "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
      "      shape=(3, 14, 14, 8), dtype=float32)\n",
      "backward   = True\n",
      "device     = cuda()\n",
      "err1       = np.float32(0.0)\n",
      "err2       = np.float32(0.0018022073)\n",
      "out        = tensor([[[[ 107.2545, -109.1249,   -9.3744,  ...,  118.7832,  127.2525,\n",
      "           -146.6358],\n",
      "          [-296.2552,  ...[-107.9026,   -8.9582,  137.1271,  ..., -355.2759,  128.8402,\n",
      "             28.4111]]]], grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(-12155.8203, grad_fn=<SumBackward0>)\n",
      "padding    = 1\n",
      "stride     = 1\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c565606360>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c565605070>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c565605070>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c565605070>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c565605070>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[ -79.25961    -79.25961    -79.25961   ...  -79.25961\n",
      "     -79.25961    -79.25961  ]\n",
      "   [  46.918587    46.918587    46.918587  ...   46.918587\n",
      "      46.918587    46.918587 ]\n",
      "   [-105.12892   -105.12892   -105.12892   ... -105.12892\n",
      "    -105.12892   -105.12892  ]\n",
      "   ...\n",
      "   [-159.3573    -159.3573    -159.3573    ... -159.3573\n",
      "    -159.3573    -159.3573   ]\n",
      "   [   9.509541     9.509541     9.509541  ...    9.509541\n",
      "       9.509541     9.509541 ]\n",
      "   [-151.12027   -151.12027   -151.12027   ... -151.12027\n",
      "    -151.12027   -151.12027  ]]\n",
      "\n",
      "  [[ -82.72235    -82.72235    -82.72235   ...  -82.72235\n",
      "     -82.72235    -82.72235  ]\n",
      "   [  74.58126     74.58126     74.58126   ...   74.58126\n",
      "      74.58126     74.58126  ]\n",
      "   [-103.02985   -103.02985   -103.02985   ... -103.02985\n",
      "    -103.02985   -103.02985  ]\n",
      "   ...\n",
      "   [-137.12236   -137.12236   -137.12236   ... -137.12236\n",
      "    -137.12236   -137.12236  ]\n",
      "   [ -16.714417   -16.714417   -16.714417  ...  -16.714417\n",
      "     -16.714417   -16.714417 ]\n",
      "   [-171.92789   -171.92789   -171.92789   ... -171.92789\n",
      "    -171.92789   -171.92789  ]]\n",
      "\n",
      "  [[ -56.836605   -56.836605   -56.836605  ...  -56.836605\n",
      "     -56.836605   -56.836605 ]\n",
      "   [  46.877205    46.877205    46.877205  ...   46.877205\n",
      "      46.877205    46.877205 ]\n",
      "   [ -74.973366   -74.973366   -74.973366  ...  -74.973366\n",
      "     -74.973366   -74.973366 ]\n",
      "   ...\n",
      "   [-136.1901    -136.1901    -136.1901    ... -136.1901\n",
      "    -136.1901    -136.1901   ]\n",
      "   [ -14.834892   -14.834892   -14.834892  ...  -14.834892\n",
      "     -14.834892   -14.834892 ]\n",
      "   [-161.43825   -161.43825   -161.43825   ... -161.43825\n",
      "    -161.43825   -161.43825  ]]]\n",
      "\n",
      "\n",
      " [[[ -75.40626    -75.40626    -75.40626   ...  -75.40626\n",
      "     -75.40626    -75.40626  ]\n",
      "   [  36.887493    36.887493    36.887493  ...   36.887493\n",
      "      36.887493    36.887493 ]\n",
      "   [-112.95888   -112.95888   -112.95888   ... -112.95888\n",
      "    -112.95888   -112.95888  ]\n",
      "   ...\n",
      "   [-177.26762   -177.26762   -177.26762   ... -177.26762\n",
      "    -177.26762   -177.26762  ]\n",
      "   [  -3.9332294   -3.9332294   -3.9332294 ...   -3.9332294\n",
      "      -3.9332294   -3.9332294]\n",
      "   [-120.56535   -120.56535   -120.56535   ... -120.56535\n",
      "    -120.56535   -120.56535  ]]\n",
      "\n",
      "  [[ -59.869705   -59.869705   -59.869705  ...  -59.869705\n",
      "     -59.869705   -59.869705 ]\n",
      "   [  60.670822    60.670822    60.670822  ...   60.670822\n",
      "      60.670822    60.670822 ]\n",
      "   [-114.85127   -114.85127   -114.85127   ... -114.85127\n",
      "    -114.85127   -114.85127  ]\n",
      "   ...\n",
      "   [-158.23895   -158.23895   -158.23895   ... -158.23895\n",
      "    -158.23895   -158.23895  ]\n",
      "   [ -33.13743    -33.13743    -33.13743   ...  -33.13743\n",
      "     -33.13743    -33.13743  ]\n",
      "   [-149.52196   -149.52196   -149.52196   ... -149.52196\n",
      "    -149.52196   -149.52196  ]]\n",
      "\n",
      "  [[ -35.41703    -35.41703    -35.41703   ...  -35.41703\n",
      "     -35.41703    -35.41703  ]\n",
      "   [  39.196243    39.196243    39.196243  ...   39.196243\n",
      "      39.196243    39.196243 ]\n",
      "   [ -76.205154   -76.205154   -76.205154  ...  -76.205154\n",
      "     -76.205154   -76.205154 ]\n",
      "   ...\n",
      "   [-157.48651   -157.48651   -157.48651   ... -157.48651\n",
      "    -157.48651   -157.48651  ]\n",
      "   [ -31.508728   -31.508728   -31.508728  ...  -31.508728\n",
      "     -31.508728   -31.508728 ]\n",
      "   [-136.02847   -136.02847   -136.02847   ... -136.02847\n",
      "    -136.02847   -136.02847  ]]]\n",
      "\n",
      "\n",
      " [[[ -97.8186     -97.8186     -97.8186    ...  -97.8186\n",
      "     -97.8186     -97.8186   ]\n",
      "   [  16.265648    16.265648    16.265648  ...   16.265648\n",
      "      16.265648    16.265648 ]\n",
      "   [ -76.15587    -76.15587    -76.15587   ...  -76.15587\n",
      "     -76.15587    -76.15587  ]\n",
      "   ...\n",
      "   [-222.50916   -222.50916   -222.50916   ... -222.50916\n",
      "    -222.50916   -222.50916  ]\n",
      "   [   6.9185753    6.9185753    6.9185753 ...    6.9185753\n",
      "       6.9185753    6.9185753]\n",
      "   [ -68.112045   -68.112045   -68.112045  ...  -68.112045\n",
      "     -68.112045   -68.112045 ]]\n",
      "\n",
      "  [[ -73.99478    -73.99478    -73.99478   ...  -73.99478\n",
      "     -73.99478    -73.99478  ]\n",
      "   [  34.570396    34.570396    34.570396  ...   34.570396\n",
      "      34.570396    34.570396 ]\n",
      "   [ -80.39506    -80.39506    -80.39506   ...  -80.39506\n",
      "     -80.39506    -80.39506  ]\n",
      "   ...\n",
      "   [-215.1049    -215.1049    -215.1049    ... -215.1049\n",
      "    -215.1049    -215.1049   ]\n",
      "   [ -46.699192   -46.699192   -46.699192  ...  -46.699192\n",
      "     -46.699192   -46.699192 ]\n",
      "   [-106.62414   -106.62414   -106.62414   ... -106.62414\n",
      "    -106.62414   -106.62414  ]]\n",
      "\n",
      "  [[ -38.120407   -38.120407   -38.120407  ...  -38.120407\n",
      "     -38.120407   -38.120407 ]\n",
      "   [   6.7269135    6.7269135    6.7269135 ...    6.7269135\n",
      "       6.7269135    6.7269135]\n",
      "   [ -35.737206   -35.737206   -35.737206  ...  -35.737206\n",
      "     -35.737206   -35.737206 ]\n",
      "   ...\n",
      "   [-223.96396   -223.96396   -223.96396   ... -223.96396\n",
      "    -223.96396   -223.96396  ]\n",
      "   [ -28.201767   -28.201767   -28.201767  ...  -28.201767\n",
      "     -28.201767   -28.201767 ]\n",
      "   [ -98.7813     -98.7813     -98.7813    ...  -98.7813\n",
      "     -98.7813     -98.7813   ]]]], W.grad.numpy(): [[[[ -79.25961    -79.25961    -79.25961   ...  -79.25961\n",
      "     -79.25961    -79.25961  ]\n",
      "   [  46.918587    46.918587    46.918587  ...   46.918587\n",
      "      46.918587    46.918587 ]\n",
      "   [-105.12889   -105.12889   -105.12889   ... -105.12889\n",
      "    -105.12889   -105.12889  ]\n",
      "   ...\n",
      "   [-159.35725   -159.35725   -159.35725   ... -159.35725\n",
      "    -159.35725   -159.35725  ]\n",
      "   [   9.509503     9.509503     9.509503  ...    9.509503\n",
      "       9.509503     9.509503 ]\n",
      "   [-151.12033   -151.12033   -151.12033   ... -151.12033\n",
      "    -151.12033   -151.12033  ]]\n",
      "\n",
      "  [[ -82.72238    -82.72238    -82.72238   ...  -82.72238\n",
      "     -82.72238    -82.72238  ]\n",
      "   [  74.58125     74.58125     74.58125   ...   74.58125\n",
      "      74.58125     74.58125  ]\n",
      "   [-103.02983   -103.02983   -103.02983   ... -103.02983\n",
      "    -103.02983   -103.02983  ]\n",
      "   ...\n",
      "   [-137.1224    -137.1224    -137.1224    ... -137.1224\n",
      "    -137.1224    -137.1224   ]\n",
      "   [ -16.714432   -16.714432   -16.714432  ...  -16.714432\n",
      "     -16.714432   -16.714432 ]\n",
      "   [-171.92796   -171.92796   -171.92796   ... -171.92796\n",
      "    -171.92796   -171.92796  ]]\n",
      "\n",
      "  [[ -56.836594   -56.836594   -56.836594  ...  -56.836594\n",
      "     -56.836594   -56.836594 ]\n",
      "   [  46.877205    46.877205    46.877205  ...   46.877205\n",
      "      46.877205    46.877205 ]\n",
      "   [ -74.973404   -74.973404   -74.973404  ...  -74.973404\n",
      "     -74.973404   -74.973404 ]\n",
      "   ...\n",
      "   [-136.1901    -136.1901    -136.1901    ... -136.1901\n",
      "    -136.1901    -136.1901   ]\n",
      "   [ -14.834877   -14.834877   -14.834877  ...  -14.834877\n",
      "     -14.834877   -14.834877 ]\n",
      "   [-161.43837   -161.43837   -161.43837   ... -161.43837\n",
      "    -161.43837   -161.43837  ]]]\n",
      "\n",
      "\n",
      " [[[ -75.406235   -75.406235   -75.406235  ...  -75.406235\n",
      "     -75.406235   -75.406235 ]\n",
      "   [  36.88748     36.88748     36.88748   ...   36.88748\n",
      "      36.88748     36.88748  ]\n",
      "   [-112.95888   -112.95888   -112.95888   ... -112.95888\n",
      "    -112.95888   -112.95888  ]\n",
      "   ...\n",
      "   [-177.26758   -177.26758   -177.26758   ... -177.26758\n",
      "    -177.26758   -177.26758  ]\n",
      "   [  -3.9332623   -3.9332623   -3.9332623 ...   -3.9332623\n",
      "      -3.9332623   -3.9332623]\n",
      "   [-120.5654    -120.5654    -120.5654    ... -120.5654\n",
      "    -120.5654    -120.5654   ]]\n",
      "\n",
      "  [[ -59.869713   -59.869713   -59.869713  ...  -59.869713\n",
      "     -59.869713   -59.869713 ]\n",
      "   [  60.67083     60.67083     60.67083   ...   60.67083\n",
      "      60.67083     60.67083  ]\n",
      "   [-114.85128   -114.85128   -114.85128   ... -114.85128\n",
      "    -114.85128   -114.85128  ]\n",
      "   ...\n",
      "   [-158.23898   -158.23898   -158.23898   ... -158.23898\n",
      "    -158.23898   -158.23898  ]\n",
      "   [ -33.137444   -33.137444   -33.137444  ...  -33.137444\n",
      "     -33.137444   -33.137444 ]\n",
      "   [-149.52202   -149.52202   -149.52202   ... -149.52202\n",
      "    -149.52202   -149.52202  ]]\n",
      "\n",
      "  [[ -35.417015   -35.417015   -35.417015  ...  -35.417015\n",
      "     -35.417015   -35.417015 ]\n",
      "   [  39.19624     39.19624     39.19624   ...   39.19624\n",
      "      39.19624     39.19624  ]\n",
      "   [ -76.20519    -76.20519    -76.20519   ...  -76.20519\n",
      "     -76.20519    -76.20519  ]\n",
      "   ...\n",
      "   [-157.4865    -157.4865    -157.4865    ... -157.4865\n",
      "    -157.4865    -157.4865   ]\n",
      "   [ -31.50871    -31.50871    -31.50871   ...  -31.50871\n",
      "     -31.50871    -31.50871  ]\n",
      "   [-136.0286    -136.0286    -136.0286    ... -136.0286\n",
      "    -136.0286    -136.0286   ]]]\n",
      "\n",
      "\n",
      " [[[ -97.81868    -97.81868    -97.81868   ...  -97.81868\n",
      "     -97.81868    -97.81868  ]\n",
      "   [  16.26568     16.26568     16.26568   ...   16.26568\n",
      "      16.26568     16.26568  ]\n",
      "   [ -76.155914   -76.155914   -76.155914  ...  -76.155914\n",
      "     -76.155914   -76.155914 ]\n",
      "   ...\n",
      "   [-222.50916   -222.50916   -222.50916   ... -222.50916\n",
      "    -222.50916   -222.50916  ]\n",
      "   [   6.9185386    6.9185386    6.9185386 ...    6.9185386\n",
      "       6.9185386    6.9185386]\n",
      "   [ -68.11211    -68.11211    -68.11211   ...  -68.11211\n",
      "     -68.11211    -68.11211  ]]\n",
      "\n",
      "  [[ -73.99485    -73.99485    -73.99485   ...  -73.99485\n",
      "     -73.99485    -73.99485  ]\n",
      "   [  34.57039     34.57039     34.57039   ...   34.57039\n",
      "      34.57039     34.57039  ]\n",
      "   [ -80.3951     -80.3951     -80.3951    ...  -80.3951\n",
      "     -80.3951     -80.3951   ]\n",
      "   ...\n",
      "   [-215.10489   -215.10489   -215.10489   ... -215.10489\n",
      "    -215.10489   -215.10489  ]\n",
      "   [ -46.69917    -46.69917    -46.69917   ...  -46.69917\n",
      "     -46.69917    -46.69917  ]\n",
      "   [-106.62421   -106.62421   -106.62421   ... -106.62421\n",
      "    -106.62421   -106.62421  ]]\n",
      "\n",
      "  [[ -38.120415   -38.120415   -38.120415  ...  -38.120415\n",
      "     -38.120415   -38.120415 ]\n",
      "   [   6.726944     6.726944     6.726944  ...    6.726944\n",
      "       6.726944     6.726944 ]\n",
      "   [ -35.73723    -35.73723    -35.73723   ...  -35.73723\n",
      "     -35.73723    -35.73723  ]\n",
      "   ...\n",
      "   [-223.96388   -223.96388   -223.96388   ... -223.96388\n",
      "    -223.96388   -223.96388  ]\n",
      "   [ -28.201765   -28.201765   -28.201765  ...  -28.201765\n",
      "     -28.201765   -28.201765 ]\n",
      "   [ -98.78143    -98.78143    -98.78143   ...  -98.78143\n",
      "     -98.78143    -98.78143  ]]]]\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape2-W_shape2-1-2] _\u001b[0m\n",
      "\n",
      "Z_shape = (3, 16, 16, 8), W_shape = (3, 3, 8, 16), stride = 1, padding = 2\n",
      "backward = True, device = cuda()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[  0.40910086  -0.64982927  11.320294   ...  -0.12077556\n",
      "      1.428692    -5.5845156 ]\n",
      "   [ -6.89178...-1.5437248  -10.136281  ]\n",
      "   [  1.1511405    0.7441038   16.463472   ...  -6.8931007\n",
      "     -0.5833115   -2.504636  ]]]])\n",
      "W_shape    = (3, 3, 8, 16)\n",
      "Wtch       = tensor([[[[  0.4091,  -0.6498,  11.3203,  ...,  -0.1208,   1.4287,  -5.5845],\n",
      "          [ -6.8918,  -9.3836,  10.6335,... -10.1363],\n",
      "          [  1.1511,   0.7441,  16.4635,  ...,  -6.8931,  -0.5833,  -2.5046]]]],\n",
      "       requires_grad=True)\n",
      "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
      "     4.75044203e+00 -7.56786048e...5e+00]\n",
      "   [ 6.10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
      "     3.33514667e+00 -1.35630560e+00]]]])\n",
      "Z_shape    = (3, 16, 16, 8)\n",
      "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
      "            4.7504e+00, -7.5679e-01],\n",
      "          [...[ 6.1037e+00, -2.0543e+00, -4.4138e+00,  ..., -6.1525e+00,\n",
      "            3.3351e+00, -1.3563e+00]]]], requires_grad=True)\n",
      "_W         = array([[[[  0.40910086,  -0.64982927,  11.320294  , ...,  -0.12077556,\n",
      "            1.428692  ,  -5.5845156 ],\n",
      "        ... ,  16.463472  , ...,  -6.8931007 ,\n",
      "           -0.5833115 ,  -2.504636  ]]]],\n",
      "      shape=(3, 3, 8, 16), dtype=float32)\n",
      "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
      "          -4.88638926e+00,  4.75044203e+00, -7.56786...6e+00, ...,\n",
      "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
      "      shape=(3, 16, 16, 8), dtype=float32)\n",
      "backward   = True\n",
      "device     = cuda()\n",
      "err1       = np.float32(0.0)\n",
      "err2       = np.float32(0.002184353)\n",
      "out        = tensor([[[[-6.3835e+01, -7.3393e+01,  7.0442e+01,  ..., -8.6601e+01,\n",
      "            2.9473e+01,  3.8723e+01],\n",
      "          [...,  8.9989e+01,  2.4763e+01,  ..., -2.3400e+02,\n",
      "            1.3548e+02, -2.8245e+01]]]], grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(23346.6914, grad_fn=<SumBackward0>)\n",
      "padding    = 2\n",
      "stride     = 1\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c565604ec0>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c565606e70>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c565606e70>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c565606e70>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c565606e70>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[ -48.62973    -48.62973    -48.62973   ...  -48.62973\n",
      "     -48.62973    -48.62973  ]\n",
      "   [  -7.4578705   -7.4578705   -7.4578705 ...   -7.4578705\n",
      "      -7.4578705   -7.4578705]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74806    -72.74806    -72.74806   ...  -72.74806\n",
      "     -72.74806    -72.74806  ]\n",
      "   [ -30.264532   -30.264532   -30.264532  ...  -30.264532\n",
      "     -30.264532   -30.264532 ]\n",
      "   [-223.74295   -223.74295   -223.74295   ... -223.74295\n",
      "    -223.74295   -223.74295  ]]\n",
      "\n",
      "  [[ -48.62973    -48.62973    -48.62973   ...  -48.62973\n",
      "     -48.62973    -48.62973  ]\n",
      "   [  -7.4578705   -7.4578705   -7.4578705 ...   -7.4578705\n",
      "      -7.4578705   -7.4578705]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74806    -72.74806    -72.74806   ...  -72.74806\n",
      "     -72.74806    -72.74806  ]\n",
      "   [ -30.264532   -30.264532   -30.264532  ...  -30.264532\n",
      "     -30.264532   -30.264532 ]\n",
      "   [-223.74295   -223.74295   -223.74295   ... -223.74295\n",
      "    -223.74295   -223.74295  ]]\n",
      "\n",
      "  [[ -48.62973    -48.62973    -48.62973   ...  -48.62973\n",
      "     -48.62973    -48.62973  ]\n",
      "   [  -7.4578705   -7.4578705   -7.4578705 ...   -7.4578705\n",
      "      -7.4578705   -7.4578705]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74806    -72.74806    -72.74806   ...  -72.74806\n",
      "     -72.74806    -72.74806  ]\n",
      "   [ -30.264532   -30.264532   -30.264532  ...  -30.264532\n",
      "     -30.264532   -30.264532 ]\n",
      "   [-223.74295   -223.74295   -223.74295   ... -223.74295\n",
      "    -223.74295   -223.74295  ]]]\n",
      "\n",
      "\n",
      " [[[ -48.62973    -48.62973    -48.62973   ...  -48.62973\n",
      "     -48.62973    -48.62973  ]\n",
      "   [  -7.4578705   -7.4578705   -7.4578705 ...   -7.4578705\n",
      "      -7.4578705   -7.4578705]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74806    -72.74806    -72.74806   ...  -72.74806\n",
      "     -72.74806    -72.74806  ]\n",
      "   [ -30.264532   -30.264532   -30.264532  ...  -30.264532\n",
      "     -30.264532   -30.264532 ]\n",
      "   [-223.74295   -223.74295   -223.74295   ... -223.74295\n",
      "    -223.74295   -223.74295  ]]\n",
      "\n",
      "  [[ -48.62973    -48.62973    -48.62973   ...  -48.62973\n",
      "     -48.62973    -48.62973  ]\n",
      "   [  -7.4578705   -7.4578705   -7.4578705 ...   -7.4578705\n",
      "      -7.4578705   -7.4578705]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74806    -72.74806    -72.74806   ...  -72.74806\n",
      "     -72.74806    -72.74806  ]\n",
      "   [ -30.264532   -30.264532   -30.264532  ...  -30.264532\n",
      "     -30.264532   -30.264532 ]\n",
      "   [-223.74295   -223.74295   -223.74295   ... -223.74295\n",
      "    -223.74295   -223.74295  ]]\n",
      "\n",
      "  [[ -48.62973    -48.62973    -48.62973   ...  -48.62973\n",
      "     -48.62973    -48.62973  ]\n",
      "   [  -7.4578705   -7.4578705   -7.4578705 ...   -7.4578705\n",
      "      -7.4578705   -7.4578705]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74806    -72.74806    -72.74806   ...  -72.74806\n",
      "     -72.74806    -72.74806  ]\n",
      "   [ -30.264532   -30.264532   -30.264532  ...  -30.264532\n",
      "     -30.264532   -30.264532 ]\n",
      "   [-223.74295   -223.74295   -223.74295   ... -223.74295\n",
      "    -223.74295   -223.74295  ]]]\n",
      "\n",
      "\n",
      " [[[ -48.62973    -48.62973    -48.62973   ...  -48.62973\n",
      "     -48.62973    -48.62973  ]\n",
      "   [  -7.4578705   -7.4578705   -7.4578705 ...   -7.4578705\n",
      "      -7.4578705   -7.4578705]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74806    -72.74806    -72.74806   ...  -72.74806\n",
      "     -72.74806    -72.74806  ]\n",
      "   [ -30.264532   -30.264532   -30.264532  ...  -30.264532\n",
      "     -30.264532   -30.264532 ]\n",
      "   [-223.74295   -223.74295   -223.74295   ... -223.74295\n",
      "    -223.74295   -223.74295  ]]\n",
      "\n",
      "  [[ -48.62973    -48.62973    -48.62973   ...  -48.62973\n",
      "     -48.62973    -48.62973  ]\n",
      "   [  -7.4578705   -7.4578705   -7.4578705 ...   -7.4578705\n",
      "      -7.4578705   -7.4578705]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74806    -72.74806    -72.74806   ...  -72.74806\n",
      "     -72.74806    -72.74806  ]\n",
      "   [ -30.264532   -30.264532   -30.264532  ...  -30.264532\n",
      "     -30.264532   -30.264532 ]\n",
      "   [-223.74295   -223.74295   -223.74295   ... -223.74295\n",
      "    -223.74295   -223.74295  ]]\n",
      "\n",
      "  [[ -48.62973    -48.62973    -48.62973   ...  -48.62973\n",
      "     -48.62973    -48.62973  ]\n",
      "   [  -7.4578705   -7.4578705   -7.4578705 ...   -7.4578705\n",
      "      -7.4578705   -7.4578705]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74806    -72.74806    -72.74806   ...  -72.74806\n",
      "     -72.74806    -72.74806  ]\n",
      "   [ -30.264532   -30.264532   -30.264532  ...  -30.264532\n",
      "     -30.264532   -30.264532 ]\n",
      "   [-223.74295   -223.74295   -223.74295   ... -223.74295\n",
      "    -223.74295   -223.74295  ]]]], W.grad.numpy(): [[[[ -48.62979    -48.62979    -48.62979   ...  -48.62979\n",
      "     -48.62979    -48.62979  ]\n",
      "   [  -7.4579277   -7.4579277   -7.4579277 ...   -7.4579277\n",
      "      -7.4579277   -7.4579277]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74812    -72.74812    -72.74812   ...  -72.74812\n",
      "     -72.74812    -72.74812  ]\n",
      "   [ -30.264448   -30.264448   -30.264448  ...  -30.264448\n",
      "     -30.264448   -30.264448 ]\n",
      "   [-223.74303   -223.74303   -223.74303   ... -223.74303\n",
      "    -223.74303   -223.74303  ]]\n",
      "\n",
      "  [[ -48.62979    -48.62979    -48.62979   ...  -48.62979\n",
      "     -48.62979    -48.62979  ]\n",
      "   [  -7.4579277   -7.4579277   -7.4579277 ...   -7.4579277\n",
      "      -7.4579277   -7.4579277]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74812    -72.74812    -72.74812   ...  -72.74812\n",
      "     -72.74812    -72.74812  ]\n",
      "   [ -30.264448   -30.264448   -30.264448  ...  -30.264448\n",
      "     -30.264448   -30.264448 ]\n",
      "   [-223.74303   -223.74303   -223.74303   ... -223.74303\n",
      "    -223.74303   -223.74303  ]]\n",
      "\n",
      "  [[ -48.62979    -48.62979    -48.62979   ...  -48.62979\n",
      "     -48.62979    -48.62979  ]\n",
      "   [  -7.4579277   -7.4579277   -7.4579277 ...   -7.4579277\n",
      "      -7.4579277   -7.4579277]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74812    -72.74812    -72.74812   ...  -72.74812\n",
      "     -72.74812    -72.74812  ]\n",
      "   [ -30.264448   -30.264448   -30.264448  ...  -30.264448\n",
      "     -30.264448   -30.264448 ]\n",
      "   [-223.74303   -223.74303   -223.74303   ... -223.74303\n",
      "    -223.74303   -223.74303  ]]]\n",
      "\n",
      "\n",
      " [[[ -48.62979    -48.62979    -48.62979   ...  -48.62979\n",
      "     -48.62979    -48.62979  ]\n",
      "   [  -7.4579277   -7.4579277   -7.4579277 ...   -7.4579277\n",
      "      -7.4579277   -7.4579277]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74812    -72.74812    -72.74812   ...  -72.74812\n",
      "     -72.74812    -72.74812  ]\n",
      "   [ -30.264448   -30.264448   -30.264448  ...  -30.264448\n",
      "     -30.264448   -30.264448 ]\n",
      "   [-223.74303   -223.74303   -223.74303   ... -223.74303\n",
      "    -223.74303   -223.74303  ]]\n",
      "\n",
      "  [[ -48.62979    -48.62979    -48.62979   ...  -48.62979\n",
      "     -48.62979    -48.62979  ]\n",
      "   [  -7.4579277   -7.4579277   -7.4579277 ...   -7.4579277\n",
      "      -7.4579277   -7.4579277]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74812    -72.74812    -72.74812   ...  -72.74812\n",
      "     -72.74812    -72.74812  ]\n",
      "   [ -30.264448   -30.264448   -30.264448  ...  -30.264448\n",
      "     -30.264448   -30.264448 ]\n",
      "   [-223.74303   -223.74303   -223.74303   ... -223.74303\n",
      "    -223.74303   -223.74303  ]]\n",
      "\n",
      "  [[ -48.62979    -48.62979    -48.62979   ...  -48.62979\n",
      "     -48.62979    -48.62979  ]\n",
      "   [  -7.4579277   -7.4579277   -7.4579277 ...   -7.4579277\n",
      "      -7.4579277   -7.4579277]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74812    -72.74812    -72.74812   ...  -72.74812\n",
      "     -72.74812    -72.74812  ]\n",
      "   [ -30.264448   -30.264448   -30.264448  ...  -30.264448\n",
      "     -30.264448   -30.264448 ]\n",
      "   [-223.74303   -223.74303   -223.74303   ... -223.74303\n",
      "    -223.74303   -223.74303  ]]]\n",
      "\n",
      "\n",
      " [[[ -48.62979    -48.62979    -48.62979   ...  -48.62979\n",
      "     -48.62979    -48.62979  ]\n",
      "   [  -7.4579277   -7.4579277   -7.4579277 ...   -7.4579277\n",
      "      -7.4579277   -7.4579277]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74812    -72.74812    -72.74812   ...  -72.74812\n",
      "     -72.74812    -72.74812  ]\n",
      "   [ -30.264448   -30.264448   -30.264448  ...  -30.264448\n",
      "     -30.264448   -30.264448 ]\n",
      "   [-223.74303   -223.74303   -223.74303   ... -223.74303\n",
      "    -223.74303   -223.74303  ]]\n",
      "\n",
      "  [[ -48.62979    -48.62979    -48.62979   ...  -48.62979\n",
      "     -48.62979    -48.62979  ]\n",
      "   [  -7.4579277   -7.4579277   -7.4579277 ...   -7.4579277\n",
      "      -7.4579277   -7.4579277]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74812    -72.74812    -72.74812   ...  -72.74812\n",
      "     -72.74812    -72.74812  ]\n",
      "   [ -30.264448   -30.264448   -30.264448  ...  -30.264448\n",
      "     -30.264448   -30.264448 ]\n",
      "   [-223.74303   -223.74303   -223.74303   ... -223.74303\n",
      "    -223.74303   -223.74303  ]]\n",
      "\n",
      "  [[ -48.62979    -48.62979    -48.62979   ...  -48.62979\n",
      "     -48.62979    -48.62979  ]\n",
      "   [  -7.4579277   -7.4579277   -7.4579277 ...   -7.4579277\n",
      "      -7.4579277   -7.4579277]\n",
      "   [-103.13295   -103.13295   -103.13295   ... -103.13295\n",
      "    -103.13295   -103.13295  ]\n",
      "   ...\n",
      "   [ -72.74812    -72.74812    -72.74812   ...  -72.74812\n",
      "     -72.74812    -72.74812  ]\n",
      "   [ -30.264448   -30.264448   -30.264448  ...  -30.264448\n",
      "     -30.264448   -30.264448 ]\n",
      "   [-223.74303   -223.74303   -223.74303   ... -223.74303\n",
      "    -223.74303   -223.74303  ]]]]\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape3-W_shape3-1-0] _\u001b[0m\n",
      "\n",
      "Z_shape = (3, 16, 16, 8), W_shape = (3, 3, 8, 14), stride = 1, padding = 0\n",
      "backward = True, device = cuda()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[ 4.09100860e-01 -6.49829268e-01  1.13202944e+01 ... -5.56089449e+00\n",
      "    -4.84385538e+00 -1.20775558e...5e+00]\n",
      "   [-1.10714078e+00  2.54448557e+00 -7.73867989e+00 ... -1.13336074e+00\n",
      "    -1.21658230e+00 -4.79330921e+00]]]])\n",
      "W_shape    = (3, 3, 8, 14)\n",
      "Wtch       = tensor([[[[ 4.0910e-01, -6.4983e-01,  1.1320e+01,  ..., -5.5609e+00,\n",
      "           -4.8439e+00, -1.2078e-01],\n",
      "          [...[-1.1071e+00,  2.5445e+00, -7.7387e+00,  ..., -1.1334e+00,\n",
      "           -1.2166e+00, -4.7933e+00]]]], requires_grad=True)\n",
      "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
      "     4.75044203e+00 -7.56786048e...5e+00]\n",
      "   [ 6.10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
      "     3.33514667e+00 -1.35630560e+00]]]])\n",
      "Z_shape    = (3, 16, 16, 8)\n",
      "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
      "            4.7504e+00, -7.5679e-01],\n",
      "          [...[ 6.1037e+00, -2.0543e+00, -4.4138e+00,  ..., -6.1525e+00,\n",
      "            3.3351e+00, -1.3563e+00]]]], requires_grad=True)\n",
      "_W         = array([[[[ 4.09100860e-01, -6.49829268e-01,  1.13202944e+01, ...,\n",
      "          -5.56089449e+00, -4.84385538e+00, -1.20775...89e+00, ...,\n",
      "          -1.13336074e+00, -1.21658230e+00, -4.79330921e+00]]]],\n",
      "      shape=(3, 3, 8, 14), dtype=float32)\n",
      "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
      "          -4.88638926e+00,  4.75044203e+00, -7.56786...6e+00, ...,\n",
      "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
      "      shape=(3, 16, 16, 8), dtype=float32)\n",
      "backward   = True\n",
      "device     = cuda()\n",
      "err1       = np.float32(0.0008252314)\n",
      "err2       = np.float32(0.0016137677)\n",
      "out        = tensor([[[[ 5.7346e+00, -2.1858e+02, -5.5911e+01,  ..., -8.9695e+01,\n",
      "            2.2620e+02,  3.4342e+02],\n",
      "          [...,  2.3405e+01, -2.1477e+01,  ...,  1.2947e+02,\n",
      "            1.2442e+02, -4.6003e+02]]]], grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(16161.7031, grad_fn=<SumBackward0>)\n",
      "padding    = 0\n",
      "stride     = 1\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c5655d6870>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655d4ce0>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655d4ce0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655d4ce0>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655d4ce0>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[-201.79364   -201.79364   -201.79364   ... -201.79364\n",
      "    -201.79364   -201.79364  ]\n",
      "   [  95.072655    95.072655    95.072655  ...   95.072655\n",
      "      95.072655    95.072655 ]\n",
      "   [  34.098076    34.098076    34.098076  ...   34.098076\n",
      "      34.098076    34.098076 ]\n",
      "   ...\n",
      "   [ -47.259125   -47.259125   -47.259125  ...  -47.259125\n",
      "     -47.259125   -47.259125 ]\n",
      "   [  -2.0522346   -2.0522346   -2.0522346 ...   -2.0522346\n",
      "      -2.0522346   -2.0522346]\n",
      "   [-107.065674  -107.065674  -107.065674  ... -107.065674\n",
      "    -107.065674  -107.065674 ]]\n",
      "\n",
      "  [[-232.77994   -232.77994   -232.77994   ... -232.77994\n",
      "    -232.77994   -232.77994  ]\n",
      "   [ 101.72708    101.72708    101.72708   ...  101.72708\n",
      "     101.72708    101.72708  ]\n",
      "   [  43.494247    43.494247    43.494247  ...   43.494247\n",
      "      43.494247    43.494247 ]\n",
      "   ...\n",
      "   [  20.157448    20.157448    20.157448  ...   20.157448\n",
      "      20.157448    20.157448 ]\n",
      "   [ -43.416256   -43.416256   -43.416256  ...  -43.416256\n",
      "     -43.416256   -43.416256 ]\n",
      "   [-178.75519   -178.75519   -178.75519   ... -178.75519\n",
      "    -178.75519   -178.75519  ]]\n",
      "\n",
      "  [[-139.2617    -139.2617    -139.2617    ... -139.2617\n",
      "    -139.2617    -139.2617   ]\n",
      "   [  71.22569     71.22569     71.22569   ...   71.22569\n",
      "      71.22569     71.22569  ]\n",
      "   [ -32.495216   -32.495216   -32.495216  ...  -32.495216\n",
      "     -32.495216   -32.495216 ]\n",
      "   ...\n",
      "   [   6.2611504    6.2611504    6.2611504 ...    6.2611504\n",
      "       6.2611504    6.2611504]\n",
      "   [-124.56712   -124.56712   -124.56712   ... -124.56712\n",
      "    -124.56712   -124.56712  ]\n",
      "   [-189.20609   -189.20609   -189.20609   ... -189.20609\n",
      "    -189.20609   -189.20609  ]]]\n",
      "\n",
      "\n",
      " [[[-129.1484    -129.1484    -129.1484    ... -129.1484\n",
      "    -129.1484    -129.1484   ]\n",
      "   [  88.56199     88.56199     88.56199   ...   88.56199\n",
      "      88.56199     88.56199  ]\n",
      "   [  29.913506    29.913506    29.913506  ...   29.913506\n",
      "      29.913506    29.913506 ]\n",
      "   ...\n",
      "   [ -86.3288     -86.3288     -86.3288    ...  -86.3288\n",
      "     -86.3288     -86.3288   ]\n",
      "   [ -32.11608    -32.11608    -32.11608   ...  -32.11608\n",
      "     -32.11608    -32.11608  ]\n",
      "   [-191.25865   -191.25865   -191.25865   ... -191.25865\n",
      "    -191.25865   -191.25865  ]]\n",
      "\n",
      "  [[-118.70814   -118.70814   -118.70814   ... -118.70814\n",
      "    -118.70814   -118.70814  ]\n",
      "   [  96.96954     96.96954     96.96954   ...   96.96954\n",
      "      96.96954     96.96954  ]\n",
      "   [  44.443703    44.443703    44.443703  ...   44.443703\n",
      "      44.443703    44.443703 ]\n",
      "   ...\n",
      "   [ -13.089989   -13.089989   -13.089989  ...  -13.089989\n",
      "     -13.089989   -13.089989 ]\n",
      "   [ -77.29191    -77.29191    -77.29191   ...  -77.29191\n",
      "     -77.29191    -77.29191  ]\n",
      "   [-278.71997   -278.71997   -278.71997   ... -278.71997\n",
      "    -278.71997   -278.71997  ]]\n",
      "\n",
      "  [[ -44.439785   -44.439785   -44.439785  ...  -44.439785\n",
      "     -44.439785   -44.439785 ]\n",
      "   [  61.65576     61.65576     61.65576   ...   61.65576\n",
      "      61.65576     61.65576  ]\n",
      "   [ -40.48121    -40.48121    -40.48121   ...  -40.48121\n",
      "     -40.48121    -40.48121  ]\n",
      "   ...\n",
      "   [ -16.59602    -16.59602    -16.59602   ...  -16.59602\n",
      "     -16.59602    -16.59602  ]\n",
      "   [-133.24857   -133.24857   -133.24857   ... -133.24857\n",
      "    -133.24857   -133.24857  ]\n",
      "   [-323.14288   -323.14288   -323.14288   ... -323.14288\n",
      "    -323.14288   -323.14288  ]]]\n",
      "\n",
      "\n",
      " [[[ -47.0627     -47.0627     -47.0627    ...  -47.0627\n",
      "     -47.0627     -47.0627   ]\n",
      "   [  57.90393     57.90393     57.90393   ...   57.90393\n",
      "      57.90393     57.90393  ]\n",
      "   [ -24.880836   -24.880836   -24.880836  ...  -24.880836\n",
      "     -24.880836   -24.880836 ]\n",
      "   ...\n",
      "   [  -9.441906    -9.441906    -9.441906  ...   -9.441906\n",
      "      -9.441906    -9.441906 ]\n",
      "   [  29.061718    29.061718    29.061718  ...   29.061718\n",
      "      29.061718    29.061718 ]\n",
      "   [-166.67372   -166.67372   -166.67372   ... -166.67372\n",
      "    -166.67372   -166.67372  ]]\n",
      "\n",
      "  [[ -35.03288    -35.03288    -35.03288   ...  -35.03288\n",
      "     -35.03288    -35.03288  ]\n",
      "   [  75.41133     75.41133     75.41133   ...   75.41133\n",
      "      75.41133     75.41133  ]\n",
      "   [ -19.464973   -19.464973   -19.464973  ...  -19.464973\n",
      "     -19.464973   -19.464973 ]\n",
      "   ...\n",
      "   [  55.00097     55.00097     55.00097   ...   55.00097\n",
      "      55.00097     55.00097  ]\n",
      "   [ -44.410614   -44.410614   -44.410614  ...  -44.410614\n",
      "     -44.410614   -44.410614 ]\n",
      "   [-256.9889    -256.9889    -256.9889    ... -256.9889\n",
      "    -256.9889    -256.9889   ]]\n",
      "\n",
      "  [[  21.06859     21.06859     21.06859   ...   21.06859\n",
      "      21.06859     21.06859  ]\n",
      "   [  42.674404    42.674404    42.674404  ...   42.674404\n",
      "      42.674404    42.674404 ]\n",
      "   [-121.07211   -121.07211   -121.07211   ... -121.07211\n",
      "    -121.07211   -121.07211  ]\n",
      "   ...\n",
      "   [  44.29737     44.29737     44.29737   ...   44.29737\n",
      "      44.29737     44.29737  ]\n",
      "   [-113.24769   -113.24769   -113.24769   ... -113.24769\n",
      "    -113.24769   -113.24769  ]\n",
      "   [-282.69653   -282.69653   -282.69653   ... -282.69653\n",
      "    -282.69653   -282.69653  ]]]], W.grad.numpy(): [[[[-201.7937   -201.7937   -201.7937   ... -201.7937   -201.7937\n",
      "    -201.7937  ]\n",
      "   [  95.07266    95.07266    95.07266  ...   95.07266    95.07266\n",
      "      95.07266 ]\n",
      "   [  34.09809    34.09809    34.09809  ...   34.09809    34.09809\n",
      "      34.09809 ]\n",
      "   ...\n",
      "   [ -47.25914   -47.25914   -47.25914  ...  -47.25914   -47.25914\n",
      "     -47.25914 ]\n",
      "   [  -2.052239   -2.052239   -2.052239 ...   -2.052239   -2.052239\n",
      "      -2.052239]\n",
      "   [-107.065674 -107.065674 -107.065674 ... -107.065674 -107.065674\n",
      "    -107.065674]]\n",
      "\n",
      "  [[-232.78001  -232.78001  -232.78001  ... -232.78001  -232.78001\n",
      "    -232.78001 ]\n",
      "   [ 101.72707   101.72707   101.72707  ...  101.72707   101.72707\n",
      "     101.72707 ]\n",
      "   [  43.49426    43.49426    43.49426  ...   43.49426    43.49426\n",
      "      43.49426 ]\n",
      "   ...\n",
      "   [  20.157454   20.157454   20.157454 ...   20.157454   20.157454\n",
      "      20.157454]\n",
      "   [ -43.41613   -43.41613   -43.41613  ...  -43.41613   -43.41613\n",
      "     -43.41613 ]\n",
      "   [-178.75513  -178.75513  -178.75513  ... -178.75513  -178.75513\n",
      "    -178.75513 ]]\n",
      "\n",
      "  [[-139.26176  -139.26176  -139.26176  ... -139.26176  -139.26176\n",
      "    -139.26176 ]\n",
      "   [  71.22569    71.22569    71.22569  ...   71.22569    71.22569\n",
      "      71.22569 ]\n",
      "   [ -32.495262  -32.495262  -32.495262 ...  -32.495262  -32.495262\n",
      "     -32.495262]\n",
      "   ...\n",
      "   [   6.261143    6.261143    6.261143 ...    6.261143    6.261143\n",
      "       6.261143]\n",
      "   [-124.56705  -124.56705  -124.56705  ... -124.56705  -124.56705\n",
      "    -124.56705 ]\n",
      "   [-189.20601  -189.20601  -189.20601  ... -189.20601  -189.20601\n",
      "    -189.20601 ]]]\n",
      "\n",
      "\n",
      " [[[-129.14839  -129.14839  -129.14839  ... -129.14839  -129.14839\n",
      "    -129.14839 ]\n",
      "   [  88.562      88.562      88.562    ...   88.562      88.562\n",
      "      88.562   ]\n",
      "   [  29.91347    29.91347    29.91347  ...   29.91347    29.91347\n",
      "      29.91347 ]\n",
      "   ...\n",
      "   [ -86.32881   -86.32881   -86.32881  ...  -86.32881   -86.32881\n",
      "     -86.32881 ]\n",
      "   [ -32.116077  -32.116077  -32.116077 ...  -32.116077  -32.116077\n",
      "     -32.116077]\n",
      "   [-191.25864  -191.25864  -191.25864  ... -191.25864  -191.25864\n",
      "    -191.25864 ]]\n",
      "\n",
      "  [[-118.70813  -118.70813  -118.70813  ... -118.70813  -118.70813\n",
      "    -118.70813 ]\n",
      "   [  96.96952    96.96952    96.96952  ...   96.96952    96.96952\n",
      "      96.96952 ]\n",
      "   [  44.443657   44.443657   44.443657 ...   44.443657   44.443657\n",
      "      44.443657]\n",
      "   ...\n",
      "   [ -13.089987  -13.089987  -13.089987 ...  -13.089987  -13.089987\n",
      "     -13.089987]\n",
      "   [ -77.29176   -77.29176   -77.29176  ...  -77.29176   -77.29176\n",
      "     -77.29176 ]\n",
      "   [-278.71997  -278.71997  -278.71997  ... -278.71997  -278.71997\n",
      "    -278.71997 ]]\n",
      "\n",
      "  [[ -44.43978   -44.43978   -44.43978  ...  -44.43978   -44.43978\n",
      "     -44.43978 ]\n",
      "   [  61.65575    61.65575    61.65575  ...   61.65575    61.65575\n",
      "      61.65575 ]\n",
      "   [ -40.48122   -40.48122   -40.48122  ...  -40.48122   -40.48122\n",
      "     -40.48122 ]\n",
      "   ...\n",
      "   [ -16.595932  -16.595932  -16.595932 ...  -16.595932  -16.595932\n",
      "     -16.595932]\n",
      "   [-133.24866  -133.24866  -133.24866  ... -133.24866  -133.24866\n",
      "    -133.24866 ]\n",
      "   [-323.14285  -323.14285  -323.14285  ... -323.14285  -323.14285\n",
      "    -323.14285 ]]]\n",
      "\n",
      "\n",
      " [[[ -47.06269   -47.06269   -47.06269  ...  -47.06269   -47.06269\n",
      "     -47.06269 ]\n",
      "   [  57.903957   57.903957   57.903957 ...   57.903957   57.903957\n",
      "      57.903957]\n",
      "   [ -24.880894  -24.880894  -24.880894 ...  -24.880894  -24.880894\n",
      "     -24.880894]\n",
      "   ...\n",
      "   [  -9.441917   -9.441917   -9.441917 ...   -9.441917   -9.441917\n",
      "      -9.441917]\n",
      "   [  29.061699   29.061699   29.061699 ...   29.061699   29.061699\n",
      "      29.061699]\n",
      "   [-166.6737   -166.6737   -166.6737   ... -166.6737   -166.6737\n",
      "    -166.6737  ]]\n",
      "\n",
      "  [[ -35.032925  -35.032925  -35.032925 ...  -35.032925  -35.032925\n",
      "     -35.032925]\n",
      "   [  75.41132    75.41132    75.41132  ...   75.41132    75.41132\n",
      "      75.41132 ]\n",
      "   [ -19.465002  -19.465002  -19.465002 ...  -19.465002  -19.465002\n",
      "     -19.465002]\n",
      "   ...\n",
      "   [  55.000908   55.000908   55.000908 ...   55.000908   55.000908\n",
      "      55.000908]\n",
      "   [ -44.41051   -44.41051   -44.41051  ...  -44.41051   -44.41051\n",
      "     -44.41051 ]\n",
      "   [-256.9889   -256.9889   -256.9889   ... -256.9889   -256.9889\n",
      "    -256.9889  ]]\n",
      "\n",
      "  [[  21.068607   21.068607   21.068607 ...   21.068607   21.068607\n",
      "      21.068607]\n",
      "   [  42.6744     42.6744     42.6744   ...   42.6744     42.6744\n",
      "      42.6744  ]\n",
      "   [-121.07214  -121.07214  -121.07214  ... -121.07214  -121.07214\n",
      "    -121.07214 ]\n",
      "   ...\n",
      "   [  44.297386   44.297386   44.297386 ...   44.297386   44.297386\n",
      "      44.297386]\n",
      "   [-113.24764  -113.24764  -113.24764  ... -113.24764  -113.24764\n",
      "    -113.24764 ]\n",
      "   [-282.69644  -282.69644  -282.69644  ... -282.69644  -282.69644\n",
      "    -282.69644 ]]]]\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape4-W_shape4-1-0] _\u001b[0m\n",
      "\n",
      "Z_shape = (3, 16, 16, 2), W_shape = (3, 3, 2, 14), stride = 1, padding = 0\n",
      "backward = True, device = cuda()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[ -8.0968      -2.5552022    8.703147    -1.4674252    4.5861077\n",
      "     -0.28521433   4.383634    -9.13...727333   0.22582927   9.296732    -8.13161     -0.67411226\n",
      "     -2.9204676    1.675528   -12.187821     5.5746226 ]]]])\n",
      "W_shape    = (3, 3, 2, 14)\n",
      "Wtch       = tensor([[[[ -8.0968,  -2.5552,   8.7031,  -1.4674,   4.5861,  -0.2852,   4.3836,\n",
      "            -9.1346,  -2.0159,   4.74...0.2258,\n",
      "             9.2967,  -8.1316,  -0.6741,  -2.9205,   1.6755, -12.1878,   5.5746]]]],\n",
      "       requires_grad=True)\n",
      "Z          = needle.Tensor([[[[  8.820262     2.000786  ]\n",
      "   [  4.89369     11.204466  ]\n",
      "   [  9.33779     -4.8863893 ]\n",
      "   ...\n",
      "   [...   -5.112822  ]\n",
      "   ...\n",
      "   [ -7.922368     4.2222714 ]\n",
      "   [ -6.064339     1.4188478 ]\n",
      "   [ -1.4109794   -5.791016  ]]]])\n",
      "Z_shape    = (3, 16, 16, 2)\n",
      "Ztch       = tensor([[[[  8.8203,   2.0008],\n",
      "          [  4.8937,  11.2045],\n",
      "          [  9.3378,  -4.8864],\n",
      "          ...,\n",
      "       ...\n",
      "          [ -7.9224,   4.2223],\n",
      "          [ -6.0643,   1.4188],\n",
      "          [ -1.4110,  -5.7910]]]], requires_grad=True)\n",
      "_W         = array([[[[ -8.0968    ,  -2.5552022 ,   8.703147  ,  -1.4674252 ,\n",
      "            4.5861077 ,  -0.28521433,   4.383634  , ...        -8.13161   ,  -0.67411226,  -2.9204676 ,   1.675528  ,\n",
      "          -12.187821  ,   5.5746226 ]]]], dtype=float32)\n",
      "_Z         = array([[[[  8.820262  ,   2.000786  ],\n",
      "         [  4.89369   ,  11.204466  ],\n",
      "         [  9.33779   ,  -4.8863893 ],\n",
      " ...     [ -6.064339  ,   1.4188478 ],\n",
      "         [ -1.4109794 ,  -5.791016  ]]]],\n",
      "      shape=(3, 16, 16, 2), dtype=float32)\n",
      "backward   = True\n",
      "device     = cuda()\n",
      "err1       = np.float32(0.0002241043)\n",
      "err2       = np.float32(0.00065855857)\n",
      "out        = tensor([[[[-346.0716,  -28.1759,   63.5063,  ..., -158.1952,  -57.8746,\n",
      "             63.6776],\n",
      "          [  73.3426,  ...[  58.9731,    3.5575, -155.4996,  ...,  123.7366,   54.5836,\n",
      "             92.4735]]]], grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(-6321.1787, grad_fn=<SumBackward0>)\n",
      "padding    = 0\n",
      "stride     = 1\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c5655c50d0>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655c7560>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655c7560>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655c7560>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655c7560>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[ -68.282936   -68.282936   -68.282936   -68.282936   -68.282936\n",
      "     -68.282936   -68.282936   -68.282936   -68.282936   -68.282936\n",
      "     -68.282936   -68.282936   -68.282936   -68.282936 ]\n",
      "   [-118.24972   -118.24972   -118.24972   -118.24972   -118.24972\n",
      "    -118.24972   -118.24972   -118.24972   -118.24972   -118.24972\n",
      "    -118.24972   -118.24972   -118.24972   -118.24972  ]]\n",
      "\n",
      "  [[ -67.852554   -67.852554   -67.852554   -67.852554   -67.852554\n",
      "     -67.852554   -67.852554   -67.852554   -67.852554   -67.852554\n",
      "     -67.852554   -67.852554   -67.852554   -67.852554 ]\n",
      "   [ -95.73945    -95.73945    -95.73945    -95.73945    -95.73945\n",
      "     -95.73945    -95.73945    -95.73945    -95.73945    -95.73945\n",
      "     -95.73945    -95.73945    -95.73945    -95.73945  ]]\n",
      "\n",
      "  [[ -45.030754   -45.030754   -45.030754   -45.030754   -45.030754\n",
      "     -45.030754   -45.030754   -45.030754   -45.030754   -45.030754\n",
      "     -45.030754   -45.030754   -45.030754   -45.030754 ]\n",
      "   [ -95.70444    -95.70444    -95.70444    -95.70444    -95.70444\n",
      "     -95.70444    -95.70444    -95.70444    -95.70444    -95.70444\n",
      "     -95.70444    -95.70444    -95.70444    -95.70444  ]]]\n",
      "\n",
      "\n",
      " [[[-148.68748   -148.68748   -148.68748   -148.68748   -148.68748\n",
      "    -148.68748   -148.68748   -148.68748   -148.68748   -148.68748\n",
      "    -148.68748   -148.68748   -148.68748   -148.68748  ]\n",
      "   [ -60.701717   -60.701717   -60.701717   -60.701717   -60.701717\n",
      "     -60.701717   -60.701717   -60.701717   -60.701717   -60.701717\n",
      "     -60.701717   -60.701717   -60.701717   -60.701717 ]]\n",
      "\n",
      "  [[-127.58233   -127.58233   -127.58233   -127.58233   -127.58233\n",
      "    -127.58233   -127.58233   -127.58233   -127.58233   -127.58233\n",
      "    -127.58233   -127.58233   -127.58233   -127.58233  ]\n",
      "   [ -65.67272    -65.67272    -65.67272    -65.67272    -65.67272\n",
      "     -65.67272    -65.67272    -65.67272    -65.67272    -65.67272\n",
      "     -65.67272    -65.67272    -65.67272    -65.67272  ]]\n",
      "\n",
      "  [[-110.33866   -110.33866   -110.33866   -110.33866   -110.33866\n",
      "    -110.33866   -110.33866   -110.33866   -110.33866   -110.33866\n",
      "    -110.33866   -110.33866   -110.33866   -110.33866  ]\n",
      "   [ -75.60977    -75.60977    -75.60977    -75.60977    -75.60977\n",
      "     -75.60977    -75.60977    -75.60977    -75.60977    -75.60977\n",
      "     -75.60977    -75.60977    -75.60977    -75.60977  ]]]\n",
      "\n",
      "\n",
      " [[[-114.61824   -114.61824   -114.61824   -114.61824   -114.61824\n",
      "    -114.61824   -114.61824   -114.61824   -114.61824   -114.61824\n",
      "    -114.61824   -114.61824   -114.61824   -114.61824  ]\n",
      "   [   5.206314     5.206314     5.206314     5.206314     5.206314\n",
      "       5.206314     5.206314     5.206314     5.206314     5.206314\n",
      "       5.206314     5.206314     5.206314     5.206314 ]]\n",
      "\n",
      "  [[-103.69658   -103.69658   -103.69658   -103.69658   -103.69658\n",
      "    -103.69658   -103.69658   -103.69658   -103.69658   -103.69658\n",
      "    -103.69658   -103.69658   -103.69658   -103.69658  ]\n",
      "   [  -1.2657585   -1.2657585   -1.2657585   -1.2657585   -1.2657585\n",
      "      -1.2657585   -1.2657585   -1.2657585   -1.2657585   -1.2657585\n",
      "      -1.2657585   -1.2657585   -1.2657585   -1.2657585]]\n",
      "\n",
      "  [[ -74.390564   -74.390564   -74.390564   -74.390564   -74.390564\n",
      "     -74.390564   -74.390564   -74.390564   -74.390564   -74.390564\n",
      "     -74.390564   -74.390564   -74.390564   -74.390564 ]\n",
      "   [ -17.11633    -17.11633    -17.11633    -17.11633    -17.11633\n",
      "     -17.11633    -17.11633    -17.11633    -17.11633    -17.11633\n",
      "     -17.11633    -17.11633    -17.11633    -17.11633  ]]]], W.grad.numpy(): [[[[ -68.28293    -68.28293    -68.28293    -68.28293    -68.28293\n",
      "     -68.28293    -68.28293    -68.28293    -68.28293    -68.28293\n",
      "     -68.28293    -68.28293    -68.28293    -68.28293  ]\n",
      "   [-118.24967   -118.24967   -118.24967   -118.24967   -118.24967\n",
      "    -118.24967   -118.24967   -118.24967   -118.24967   -118.24967\n",
      "    -118.24967   -118.24967   -118.24967   -118.24967  ]]\n",
      "\n",
      "  [[ -67.85252    -67.85252    -67.85252    -67.85252    -67.85252\n",
      "     -67.85252    -67.85252    -67.85252    -67.85252    -67.85252\n",
      "     -67.85252    -67.85252    -67.85252    -67.85252  ]\n",
      "   [ -95.73942    -95.73942    -95.73942    -95.73942    -95.73942\n",
      "     -95.73942    -95.73942    -95.73942    -95.73942    -95.73942\n",
      "     -95.73942    -95.73942    -95.73942    -95.73942  ]]\n",
      "\n",
      "  [[ -45.030693   -45.030693   -45.030693   -45.030693   -45.030693\n",
      "     -45.030693   -45.030693   -45.030693   -45.030693   -45.030693\n",
      "     -45.030693   -45.030693   -45.030693   -45.030693 ]\n",
      "   [ -95.70441    -95.70441    -95.70441    -95.70441    -95.70441\n",
      "     -95.70441    -95.70441    -95.70441    -95.70441    -95.70441\n",
      "     -95.70441    -95.70441    -95.70441    -95.70441  ]]]\n",
      "\n",
      "\n",
      " [[[-148.6875    -148.6875    -148.6875    -148.6875    -148.6875\n",
      "    -148.6875    -148.6875    -148.6875    -148.6875    -148.6875\n",
      "    -148.6875    -148.6875    -148.6875    -148.6875   ]\n",
      "   [ -60.701725   -60.701725   -60.701725   -60.701725   -60.701725\n",
      "     -60.701725   -60.701725   -60.701725   -60.701725   -60.701725\n",
      "     -60.701725   -60.701725   -60.701725   -60.701725 ]]\n",
      "\n",
      "  [[-127.58232   -127.58232   -127.58232   -127.58232   -127.58232\n",
      "    -127.58232   -127.58232   -127.58232   -127.58232   -127.58232\n",
      "    -127.58232   -127.58232   -127.58232   -127.58232  ]\n",
      "   [ -65.672676   -65.672676   -65.672676   -65.672676   -65.672676\n",
      "     -65.672676   -65.672676   -65.672676   -65.672676   -65.672676\n",
      "     -65.672676   -65.672676   -65.672676   -65.672676 ]]\n",
      "\n",
      "  [[-110.33859   -110.33859   -110.33859   -110.33859   -110.33859\n",
      "    -110.33859   -110.33859   -110.33859   -110.33859   -110.33859\n",
      "    -110.33859   -110.33859   -110.33859   -110.33859  ]\n",
      "   [ -75.60969    -75.60969    -75.60969    -75.60969    -75.60969\n",
      "     -75.60969    -75.60969    -75.60969    -75.60969    -75.60969\n",
      "     -75.60969    -75.60969    -75.60969    -75.60969  ]]]\n",
      "\n",
      "\n",
      " [[[-114.61822   -114.61822   -114.61822   -114.61822   -114.61822\n",
      "    -114.61822   -114.61822   -114.61822   -114.61822   -114.61822\n",
      "    -114.61822   -114.61822   -114.61822   -114.61822  ]\n",
      "   [   5.206311     5.206311     5.206311     5.206311     5.206311\n",
      "       5.206311     5.206311     5.206311     5.206311     5.206311\n",
      "       5.206311     5.206311     5.206311     5.206311 ]]\n",
      "\n",
      "  [[-103.69654   -103.69654   -103.69654   -103.69654   -103.69654\n",
      "    -103.69654   -103.69654   -103.69654   -103.69654   -103.69654\n",
      "    -103.69654   -103.69654   -103.69654   -103.69654  ]\n",
      "   [  -1.2658191   -1.2658191   -1.2658191   -1.2658191   -1.2658191\n",
      "      -1.2658191   -1.2658191   -1.2658191   -1.2658191   -1.2658191\n",
      "      -1.2658191   -1.2658191   -1.2658191   -1.2658191]]\n",
      "\n",
      "  [[ -74.39059    -74.39059    -74.39059    -74.39059    -74.39059\n",
      "     -74.39059    -74.39059    -74.39059    -74.39059    -74.39059\n",
      "     -74.39059    -74.39059    -74.39059    -74.39059  ]\n",
      "   [ -17.116373   -17.116373   -17.116373   -17.116373   -17.116373\n",
      "     -17.116373   -17.116373   -17.116373   -17.116373   -17.116373\n",
      "     -17.116373   -17.116373   -17.116373   -17.116373 ]]]]\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape5-W_shape5-2-0] _\u001b[0m\n",
      "\n",
      "Z_shape = (3, 14, 14, 8), W_shape = (3, 3, 8, 16), stride = 2, padding = 0\n",
      "backward = True, device = cuda()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
      "      2.1704152   -0.38803983]\n",
      "   [  2.245844...2.618842     0.71487164]\n",
      "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
      "      0.03223436   2.0512383 ]]]])\n",
      "W_shape    = (3, 3, 8, 16)\n",
      "Wtch       = tensor([[[[  4.2827,   8.1336,  -4.6223,  ...,   2.0798,   2.1704,  -0.3880],\n",
      "          [  2.2458,  -0.6565,  -3.7547,...   0.7149],\n",
      "          [ -4.0937,   3.7292, -10.5518,  ...,   0.3174,   0.0322,   2.0512]]]],\n",
      "       requires_grad=True)\n",
      "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
      "     4.75044203e+00 -7.56786048e...3e+00]\n",
      "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
      "    -8.48226726e-01 -2.29984760e+00]]]])\n",
      "Z_shape    = (3, 14, 14, 8)\n",
      "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
      "            4.7504e+00, -7.5679e-01],\n",
      "          [...[ 1.0991e+01,  2.2317e+00,  4.6206e+00,  ..., -6.2309e-01,\n",
      "           -8.4823e-01, -2.2998e+00]]]], requires_grad=True)\n",
      "_W         = array([[[[  4.282669  ,   8.133604  ,  -4.6223483 , ...,   2.0798197 ,\n",
      "            2.1704152 ,  -0.38803983],\n",
      "        ... , -10.551835  , ...,   0.31741843,\n",
      "            0.03223436,   2.0512383 ]]]],\n",
      "      shape=(3, 3, 8, 16), dtype=float32)\n",
      "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
      "          -4.88638926e+00,  4.75044203e+00, -7.56786...9e+00, ...,\n",
      "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
      "      shape=(3, 14, 14, 8), dtype=float32)\n",
      "backward   = True\n",
      "device     = cuda()\n",
      "err1       = np.float32(0.00024521773)\n",
      "err2       = np.float32(0.0004235205)\n",
      "out        = tensor([[[[ -21.8508, -294.9621, -318.0497,   -4.7934,   59.4825, -104.8043],\n",
      "          [  14.3621,  303.2643, -221.53...          [ 183.8510, -115.7199,  115.7395, -105.5507,   75.9456, -171.5427]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(-4902.2178, grad_fn=<SumBackward0>)\n",
      "padding    = 0\n",
      "stride     = 2\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c5655c6c30>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655c7c20>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655c7c20>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655c7c20>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655c7c20>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[ -11.502274    -11.502274    -11.502274   ...  -11.502274\n",
      "     -11.502274    -11.502274  ]\n",
      "   [  62.8993       62.8993       62.8993     ...   62.8993\n",
      "      62.8993       62.8993    ]\n",
      "   [-100.44479    -100.44479    -100.44479    ... -100.44479\n",
      "    -100.44479    -100.44479   ]\n",
      "   ...\n",
      "   [ -13.736942    -13.736942    -13.736942   ...  -13.736942\n",
      "     -13.736942    -13.736942  ]\n",
      "   [  78.40697      78.40697      78.40697    ...   78.40697\n",
      "      78.40697      78.40697   ]\n",
      "   [  24.560968     24.560968     24.560968   ...   24.560968\n",
      "      24.560968     24.560968  ]]\n",
      "\n",
      "  [[ -27.166206    -27.166206    -27.166206   ...  -27.166206\n",
      "     -27.166206    -27.166206  ]\n",
      "   [  25.632101     25.632101     25.632101   ...   25.632101\n",
      "      25.632101     25.632101  ]\n",
      "   [   0.74779034    0.74779034    0.74779034 ...    0.74779034\n",
      "       0.74779034    0.74779034]\n",
      "   ...\n",
      "   [-103.41879    -103.41879    -103.41879    ... -103.41879\n",
      "    -103.41879    -103.41879   ]\n",
      "   [  58.430935     58.430935     58.430935   ...   58.430935\n",
      "      58.430935     58.430935  ]\n",
      "   [ -85.70644     -85.70644     -85.70644    ...  -85.70644\n",
      "     -85.70644     -85.70644   ]]\n",
      "\n",
      "  [[  -5.995693     -5.995693     -5.995693   ...   -5.995693\n",
      "      -5.995693     -5.995693  ]\n",
      "   [  85.216736     85.216736     85.216736   ...   85.216736\n",
      "      85.216736     85.216736  ]\n",
      "   [-124.07959    -124.07959    -124.07959    ... -124.07959\n",
      "    -124.07959    -124.07959   ]\n",
      "   ...\n",
      "   [  -4.409664     -4.409664     -4.409664   ...   -4.409664\n",
      "      -4.409664     -4.409664  ]\n",
      "   [  39.95012      39.95012      39.95012    ...   39.95012\n",
      "      39.95012      39.95012   ]\n",
      "   [  16.65237      16.65237      16.65237    ...   16.65237\n",
      "      16.65237      16.65237   ]]]\n",
      "\n",
      "\n",
      " [[[ -20.037218    -20.037218    -20.037218   ...  -20.037218\n",
      "     -20.037218    -20.037218  ]\n",
      "   [ -51.90564     -51.90564     -51.90564    ...  -51.90564\n",
      "     -51.90564     -51.90564   ]\n",
      "   [ -69.36232     -69.36232     -69.36232    ...  -69.36232\n",
      "     -69.36232     -69.36232   ]\n",
      "   ...\n",
      "   [  48.133972     48.133972     48.133972   ...   48.133972\n",
      "      48.133972     48.133972  ]\n",
      "   [ -49.624535    -49.624535    -49.624535   ...  -49.624535\n",
      "     -49.624535    -49.624535  ]\n",
      "   [ -29.244823    -29.244823    -29.244823   ...  -29.244823\n",
      "     -29.244823    -29.244823  ]]\n",
      "\n",
      "  [[ -59.15782     -59.15782     -59.15782    ...  -59.15782\n",
      "     -59.15782     -59.15782   ]\n",
      "   [ -54.930824    -54.930824    -54.930824   ...  -54.930824\n",
      "     -54.930824    -54.930824  ]\n",
      "   [  85.35348      85.35348      85.35348    ...   85.35348\n",
      "      85.35348      85.35348   ]\n",
      "   ...\n",
      "   [ -25.570671    -25.570671    -25.570671   ...  -25.570671\n",
      "     -25.570671    -25.570671  ]\n",
      "   [  26.286785     26.286785     26.286785   ...   26.286785\n",
      "      26.286785     26.286785  ]\n",
      "   [ -73.07514     -73.07514     -73.07514    ...  -73.07514\n",
      "     -73.07514     -73.07514   ]]\n",
      "\n",
      "  [[  19.932663     19.932663     19.932663   ...   19.932663\n",
      "      19.932663     19.932663  ]\n",
      "   [ -68.87308     -68.87308     -68.87308    ...  -68.87308\n",
      "     -68.87308     -68.87308   ]\n",
      "   [ -22.123959    -22.123959    -22.123959   ...  -22.123959\n",
      "     -22.123959    -22.123959  ]\n",
      "   ...\n",
      "   [  -1.5130348    -1.5130348    -1.5130348  ...   -1.5130348\n",
      "      -1.5130348    -1.5130348 ]\n",
      "   [ -66.619514    -66.619514    -66.619514   ...  -66.619514\n",
      "     -66.619514    -66.619514  ]\n",
      "   [  -7.8152523    -7.8152523    -7.8152523  ...   -7.8152523\n",
      "      -7.8152523    -7.8152523 ]]]\n",
      "\n",
      "\n",
      " [[[ -21.069193    -21.069193    -21.069193   ...  -21.069193\n",
      "     -21.069193    -21.069193  ]\n",
      "   [ 102.67703     102.67703     102.67703    ...  102.67703\n",
      "     102.67703     102.67703   ]\n",
      "   [ -80.154976    -80.154976    -80.154976   ...  -80.154976\n",
      "     -80.154976    -80.154976  ]\n",
      "   ...\n",
      "   [ -48.183594    -48.183594    -48.183594   ...  -48.183594\n",
      "     -48.183594    -48.183594  ]\n",
      "   [  35.556923     35.556923     35.556923   ...   35.556923\n",
      "      35.556923     35.556923  ]\n",
      "   [  32.271282     32.271282     32.271282   ...   32.271282\n",
      "      32.271282     32.271282  ]]\n",
      "\n",
      "  [[ -20.159918    -20.159918    -20.159918   ...  -20.159918\n",
      "     -20.159918    -20.159918  ]\n",
      "   [  32.194687     32.194687     32.194687   ...   32.194687\n",
      "      32.194687     32.194687  ]\n",
      "   [   2.9036512     2.9036512     2.9036512  ...    2.9036512\n",
      "       2.9036512     2.9036512 ]\n",
      "   ...\n",
      "   [-158.83664    -158.83664    -158.83664    ... -158.83664\n",
      "    -158.83664    -158.83664   ]\n",
      "   [  76.52881      76.52881      76.52881    ...   76.52881\n",
      "      76.52881      76.52881   ]\n",
      "   [ -23.696804    -23.696804    -23.696804   ...  -23.696804\n",
      "     -23.696804    -23.696804  ]]\n",
      "\n",
      "  [[  -4.9794235    -4.9794235    -4.9794235  ...   -4.9794235\n",
      "      -4.9794235    -4.9794235 ]\n",
      "   [  83.83303      83.83303      83.83303    ...   83.83303\n",
      "      83.83303      83.83303   ]\n",
      "   [-100.39087    -100.39087    -100.39087    ... -100.39087\n",
      "    -100.39087    -100.39087   ]\n",
      "   ...\n",
      "   [ -27.357765    -27.357765    -27.357765   ...  -27.357765\n",
      "     -27.357765    -27.357765  ]\n",
      "   [   2.9134874     2.9134874     2.9134874  ...    2.9134874\n",
      "       2.9134874     2.9134874 ]\n",
      "   [  10.759153     10.759153     10.759153   ...   10.759153\n",
      "      10.759153     10.759153  ]]]], W.grad.numpy(): [[[[ -11.502268   -11.502268   -11.502268  ...  -11.502268\n",
      "     -11.502268   -11.502268 ]\n",
      "   [  62.899284    62.899284    62.899284  ...   62.899284\n",
      "      62.899284    62.899284 ]\n",
      "   [-100.44482   -100.44482   -100.44482   ... -100.44482\n",
      "    -100.44482   -100.44482  ]\n",
      "   ...\n",
      "   [ -13.736955   -13.736955   -13.736955  ...  -13.736955\n",
      "     -13.736955   -13.736955 ]\n",
      "   [  78.406975    78.406975    78.406975  ...   78.406975\n",
      "      78.406975    78.406975 ]\n",
      "   [  24.560974    24.560974    24.560974  ...   24.560974\n",
      "      24.560974    24.560974 ]]\n",
      "\n",
      "  [[ -27.166191   -27.166191   -27.166191  ...  -27.166191\n",
      "     -27.166191   -27.166191 ]\n",
      "   [  25.632097    25.632097    25.632097  ...   25.632097\n",
      "      25.632097    25.632097 ]\n",
      "   [   0.7477932    0.7477932    0.7477932 ...    0.7477932\n",
      "       0.7477932    0.7477932]\n",
      "   ...\n",
      "   [-103.418755  -103.418755  -103.418755  ... -103.418755\n",
      "    -103.418755  -103.418755 ]\n",
      "   [  58.43092     58.43092     58.43092   ...   58.43092\n",
      "      58.43092     58.43092  ]\n",
      "   [ -85.70646    -85.70646    -85.70646   ...  -85.70646\n",
      "     -85.70646    -85.70646  ]]\n",
      "\n",
      "  [[  -5.995689    -5.995689    -5.995689  ...   -5.995689\n",
      "      -5.995689    -5.995689 ]\n",
      "   [  85.21674     85.21674     85.21674   ...   85.21674\n",
      "      85.21674     85.21674  ]\n",
      "   [-124.07961   -124.07961   -124.07961   ... -124.07961\n",
      "    -124.07961   -124.07961  ]\n",
      "   ...\n",
      "   [  -4.409664    -4.409664    -4.409664  ...   -4.409664\n",
      "      -4.409664    -4.409664 ]\n",
      "   [  39.95011     39.95011     39.95011   ...   39.95011\n",
      "      39.95011     39.95011  ]\n",
      "   [  16.652382    16.652382    16.652382  ...   16.652382\n",
      "      16.652382    16.652382 ]]]\n",
      "\n",
      "\n",
      " [[[ -20.03723    -20.03723    -20.03723   ...  -20.03723\n",
      "     -20.03723    -20.03723  ]\n",
      "   [ -51.905624   -51.905624   -51.905624  ...  -51.905624\n",
      "     -51.905624   -51.905624 ]\n",
      "   [ -69.36233    -69.36233    -69.36233   ...  -69.36233\n",
      "     -69.36233    -69.36233  ]\n",
      "   ...\n",
      "   [  48.13397     48.13397     48.13397   ...   48.13397\n",
      "      48.13397     48.13397  ]\n",
      "   [ -49.62454    -49.62454    -49.62454   ...  -49.62454\n",
      "     -49.62454    -49.62454  ]\n",
      "   [ -29.244816   -29.244816   -29.244816  ...  -29.244816\n",
      "     -29.244816   -29.244816 ]]\n",
      "\n",
      "  [[ -59.157806   -59.157806   -59.157806  ...  -59.157806\n",
      "     -59.157806   -59.157806 ]\n",
      "   [ -54.930824   -54.930824   -54.930824  ...  -54.930824\n",
      "     -54.930824   -54.930824 ]\n",
      "   [  85.35345     85.35345     85.35345   ...   85.35345\n",
      "      85.35345     85.35345  ]\n",
      "   ...\n",
      "   [ -25.57068    -25.57068    -25.57068   ...  -25.57068\n",
      "     -25.57068    -25.57068  ]\n",
      "   [  26.286789    26.286789    26.286789  ...   26.286789\n",
      "      26.286789    26.286789 ]\n",
      "   [ -73.075134   -73.075134   -73.075134  ...  -73.075134\n",
      "     -73.075134   -73.075134 ]]\n",
      "\n",
      "  [[  19.932655    19.932655    19.932655  ...   19.932655\n",
      "      19.932655    19.932655 ]\n",
      "   [ -68.87306    -68.87306    -68.87306   ...  -68.87306\n",
      "     -68.87306    -68.87306  ]\n",
      "   [ -22.123955   -22.123955   -22.123955  ...  -22.123955\n",
      "     -22.123955   -22.123955 ]\n",
      "   ...\n",
      "   [  -1.5130291   -1.5130291   -1.5130291 ...   -1.5130291\n",
      "      -1.5130291   -1.5130291]\n",
      "   [ -66.61953    -66.61953    -66.61953   ...  -66.61953\n",
      "     -66.61953    -66.61953  ]\n",
      "   [  -7.8152647   -7.8152647   -7.8152647 ...   -7.8152647\n",
      "      -7.8152647   -7.8152647]]]\n",
      "\n",
      "\n",
      " [[[ -21.069185   -21.069185   -21.069185  ...  -21.069185\n",
      "     -21.069185   -21.069185 ]\n",
      "   [ 102.677      102.677      102.677     ...  102.677\n",
      "     102.677      102.677    ]\n",
      "   [ -80.15498    -80.15498    -80.15498   ...  -80.15498\n",
      "     -80.15498    -80.15498  ]\n",
      "   ...\n",
      "   [ -48.183586   -48.183586   -48.183586  ...  -48.183586\n",
      "     -48.183586   -48.183586 ]\n",
      "   [  35.556923    35.556923    35.556923  ...   35.556923\n",
      "      35.556923    35.556923 ]\n",
      "   [  32.271282    32.271282    32.271282  ...   32.271282\n",
      "      32.271282    32.271282 ]]\n",
      "\n",
      "  [[ -20.159916   -20.159916   -20.159916  ...  -20.159916\n",
      "     -20.159916   -20.159916 ]\n",
      "   [  32.194683    32.194683    32.194683  ...   32.194683\n",
      "      32.194683    32.194683 ]\n",
      "   [   2.9036572    2.9036572    2.9036572 ...    2.9036572\n",
      "       2.9036572    2.9036572]\n",
      "   ...\n",
      "   [-158.83665   -158.83665   -158.83665   ... -158.83665\n",
      "    -158.83665   -158.83665  ]\n",
      "   [  76.5288      76.5288      76.5288    ...   76.5288\n",
      "      76.5288      76.5288   ]\n",
      "   [ -23.696812   -23.696812   -23.696812  ...  -23.696812\n",
      "     -23.696812   -23.696812 ]]\n",
      "\n",
      "  [[  -4.979428    -4.979428    -4.979428  ...   -4.979428\n",
      "      -4.979428    -4.979428 ]\n",
      "   [  83.833015    83.833015    83.833015  ...   83.833015\n",
      "      83.833015    83.833015 ]\n",
      "   [-100.390884  -100.390884  -100.390884  ... -100.390884\n",
      "    -100.390884  -100.390884 ]\n",
      "   ...\n",
      "   [ -27.35774    -27.35774    -27.35774   ...  -27.35774\n",
      "     -27.35774    -27.35774  ]\n",
      "   [   2.9134922    2.9134922    2.9134922 ...    2.9134922\n",
      "       2.9134922    2.9134922]\n",
      "   [  10.759179    10.759179    10.759179  ...   10.759179\n",
      "      10.759179    10.759179 ]]]]\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape6-W_shape6-2-1] _\u001b[0m\n",
      "\n",
      "Z_shape = (3, 14, 14, 8), W_shape = (3, 3, 8, 16), stride = 2, padding = 1\n",
      "backward = True, device = cuda()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
      "      2.1704152   -0.38803983]\n",
      "   [  2.245844...2.618842     0.71487164]\n",
      "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
      "      0.03223436   2.0512383 ]]]])\n",
      "W_shape    = (3, 3, 8, 16)\n",
      "Wtch       = tensor([[[[  4.2827,   8.1336,  -4.6223,  ...,   2.0798,   2.1704,  -0.3880],\n",
      "          [  2.2458,  -0.6565,  -3.7547,...   0.7149],\n",
      "          [ -4.0937,   3.7292, -10.5518,  ...,   0.3174,   0.0322,   2.0512]]]],\n",
      "       requires_grad=True)\n",
      "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
      "     4.75044203e+00 -7.56786048e...3e+00]\n",
      "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
      "    -8.48226726e-01 -2.29984760e+00]]]])\n",
      "Z_shape    = (3, 14, 14, 8)\n",
      "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
      "            4.7504e+00, -7.5679e-01],\n",
      "          [...[ 1.0991e+01,  2.2317e+00,  4.6206e+00,  ..., -6.2309e-01,\n",
      "           -8.4823e-01, -2.2998e+00]]]], requires_grad=True)\n",
      "_W         = array([[[[  4.282669  ,   8.133604  ,  -4.6223483 , ...,   2.0798197 ,\n",
      "            2.1704152 ,  -0.38803983],\n",
      "        ... , -10.551835  , ...,   0.31741843,\n",
      "            0.03223436,   2.0512383 ]]]],\n",
      "      shape=(3, 3, 8, 16), dtype=float32)\n",
      "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
      "          -4.88638926e+00,  4.75044203e+00, -7.56786...9e+00, ...,\n",
      "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
      "      shape=(3, 14, 14, 8), dtype=float32)\n",
      "backward   = True\n",
      "device     = cuda()\n",
      "err1       = np.float32(0.00028906864)\n",
      "err2       = np.float32(0.0004183153)\n",
      "out        = tensor([[[[ 1.0725e+02, -9.3744e+00,  2.7834e+02,  ..., -9.7155e+01,\n",
      "            1.3371e+02,  1.2725e+02],\n",
      "          [...,  5.7277e+02,  2.3476e+01,  ..., -2.1788e+02,\n",
      "           -1.8747e+02,  2.0660e+02]]]], grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(4313.9385, grad_fn=<SumBackward0>)\n",
      "padding    = 1\n",
      "stride     = 2\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c5656076b0>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5656075f0>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5656075f0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5656075f0>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5656075f0>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[ -59.15782    -59.15782    -59.15782   ...  -59.15782\n",
      "     -59.15782    -59.15782  ]\n",
      "   [ -54.930824   -54.930824   -54.930824  ...  -54.930824\n",
      "     -54.930824   -54.930824 ]\n",
      "   [  85.35348     85.35348     85.35348   ...   85.35348\n",
      "      85.35348     85.35348  ]\n",
      "   ...\n",
      "   [ -25.570671   -25.570671   -25.570671  ...  -25.570671\n",
      "     -25.570671   -25.570671 ]\n",
      "   [  26.286785    26.286785    26.286785  ...   26.286785\n",
      "      26.286785    26.286785 ]\n",
      "   [ -73.07514    -73.07514    -73.07514   ...  -73.07514\n",
      "     -73.07514    -73.07514  ]]\n",
      "\n",
      "  [[   4.4485264    4.4485264    4.4485264 ...    4.4485264\n",
      "       4.4485264    4.4485264]\n",
      "   [ -47.475483   -47.475483   -47.475483  ...  -47.475483\n",
      "     -47.475483   -47.475483 ]\n",
      "   [ -55.44758    -55.44758    -55.44758   ...  -55.44758\n",
      "     -55.44758    -55.44758  ]\n",
      "   ...\n",
      "   [  16.823595    16.823595    16.823595  ...   16.823595\n",
      "      16.823595    16.823595 ]\n",
      "   [ -76.023636   -76.023636   -76.023636  ...  -76.023636\n",
      "     -76.023636   -76.023636 ]\n",
      "   [ -42.504787   -42.504787   -42.504787  ...  -42.504787\n",
      "     -42.504787   -42.504787 ]]\n",
      "\n",
      "  [[ -54.476036   -54.476036   -54.476036  ...  -54.476036\n",
      "     -54.476036   -54.476036 ]\n",
      "   [ -39.680813   -39.680813   -39.680813  ...  -39.680813\n",
      "     -39.680813   -39.680813 ]\n",
      "   [  62.144325    62.144325    62.144325  ...   62.144325\n",
      "      62.144325    62.144325 ]\n",
      "   ...\n",
      "   [ -26.804808   -26.804808   -26.804808  ...  -26.804808\n",
      "     -26.804808   -26.804808 ]\n",
      "   [   7.073829     7.073829     7.073829  ...    7.073829\n",
      "       7.073829     7.073829 ]\n",
      "   [ -91.69252    -91.69252    -91.69252   ...  -91.69252\n",
      "     -91.69252    -91.69252  ]]]\n",
      "\n",
      "\n",
      " [[[  -2.852354    -2.852354    -2.852354  ...   -2.852354\n",
      "      -2.852354    -2.852354 ]\n",
      "   [  32.647278    32.647278    32.647278  ...   32.647278\n",
      "      32.647278    32.647278 ]\n",
      "   [ -12.749463   -12.749463   -12.749463  ...  -12.749463\n",
      "     -12.749463   -12.749463 ]\n",
      "   ...\n",
      "   [-127.388695  -127.388695  -127.388695  ... -127.388695\n",
      "    -127.388695  -127.388695 ]\n",
      "   [  64.75354     64.75354     64.75354   ...   64.75354\n",
      "      64.75354     64.75354  ]\n",
      "   [ -68.51874    -68.51874    -68.51874   ...  -68.51874\n",
      "     -68.51874    -68.51874  ]]\n",
      "\n",
      "  [[ -21.69799    -21.69799    -21.69799   ...  -21.69799\n",
      "     -21.69799    -21.69799  ]\n",
      "   [ 116.6776     116.6776     116.6776    ...  116.6776\n",
      "     116.6776     116.6776   ]\n",
      "   [-122.28533   -122.28533   -122.28533   ... -122.28533\n",
      "    -122.28533   -122.28533  ]\n",
      "   ...\n",
      "   [ -23.221539   -23.221539   -23.221539  ...  -23.221539\n",
      "     -23.221539   -23.221539 ]\n",
      "   [  -5.507147    -5.507147    -5.507147  ...   -5.507147\n",
      "      -5.507147    -5.507147 ]\n",
      "   [  32.978374    32.978374    32.978374  ...   32.978374\n",
      "      32.978374    32.978374 ]]\n",
      "\n",
      "  [[ -10.996902   -10.996902   -10.996902  ...  -10.996902\n",
      "     -10.996902   -10.996902 ]\n",
      "   [  45.05992     45.05992     45.05992   ...   45.05992\n",
      "      45.05992     45.05992  ]\n",
      "   [  12.558756    12.558756    12.558756  ...   12.558756\n",
      "      12.558756    12.558756 ]\n",
      "   ...\n",
      "   [-103.91963   -103.91963   -103.91963   ... -103.91963\n",
      "    -103.91963   -103.91963  ]\n",
      "   [  57.74255     57.74255     57.74255   ...   57.74255\n",
      "      57.74255     57.74255  ]\n",
      "   [ -70.708984   -70.708984   -70.708984  ...  -70.708984\n",
      "     -70.708984   -70.708984 ]]]\n",
      "\n",
      "\n",
      " [[[ -63.368553   -63.368553   -63.368553  ...  -63.368553\n",
      "     -63.368553   -63.368553 ]\n",
      "   [ -87.75679    -87.75679    -87.75679   ...  -87.75679\n",
      "     -87.75679    -87.75679  ]\n",
      "   [ 100.16784    100.16784    100.16784   ...  100.16784\n",
      "     100.16784    100.16784  ]\n",
      "   ...\n",
      "   [ -46.96363    -46.96363    -46.96363   ...  -46.96363\n",
      "     -46.96363    -46.96363  ]\n",
      "   [  38.047874    38.047874    38.047874  ...   38.047874\n",
      "      38.047874    38.047874 ]\n",
      "   [ -47.247185   -47.247185   -47.247185  ...  -47.247185\n",
      "     -47.247185   -47.247185 ]]\n",
      "\n",
      "  [[  12.512623    12.512623    12.512623  ...   12.512623\n",
      "      12.512623    12.512623 ]\n",
      "   [ -24.680618   -24.680618   -24.680618  ...  -24.680618\n",
      "     -24.680618   -24.680618 ]\n",
      "   [ -78.09189    -78.09189    -78.09189   ...  -78.09189\n",
      "     -78.09189    -78.09189  ]\n",
      "   ...\n",
      "   [  20.306242    20.306242    20.306242  ...   20.306242\n",
      "      20.306242    20.306242 ]\n",
      "   [-101.22749   -101.22749   -101.22749   ... -101.22749\n",
      "    -101.22749   -101.22749  ]\n",
      "   [ -37.777832   -37.777832   -37.777832  ...  -37.777832\n",
      "     -37.777832   -37.777832 ]]\n",
      "\n",
      "  [[ -39.68747    -39.68747    -39.68747   ...  -39.68747\n",
      "     -39.68747    -39.68747  ]\n",
      "   [ -76.38612    -76.38612    -76.38612   ...  -76.38612\n",
      "     -76.38612    -76.38612  ]\n",
      "   [  72.96721     72.96721     72.96721   ...   72.96721\n",
      "      72.96721     72.96721  ]\n",
      "   ...\n",
      "   [ -51.404034   -51.404034   -51.404034  ...  -51.404034\n",
      "     -51.404034   -51.404034 ]\n",
      "   [  15.85468     15.85468     15.85468   ...   15.85468\n",
      "      15.85468     15.85468  ]\n",
      "   [ -74.01355    -74.01355    -74.01355   ...  -74.01355\n",
      "     -74.01355    -74.01355  ]]]], W.grad.numpy(): [[[[ -59.157806   -59.157806   -59.157806  ...  -59.157806\n",
      "     -59.157806   -59.157806 ]\n",
      "   [ -54.930824   -54.930824   -54.930824  ...  -54.930824\n",
      "     -54.930824   -54.930824 ]\n",
      "   [  85.35345     85.35345     85.35345   ...   85.35345\n",
      "      85.35345     85.35345  ]\n",
      "   ...\n",
      "   [ -25.57068    -25.57068    -25.57068   ...  -25.57068\n",
      "     -25.57068    -25.57068  ]\n",
      "   [  26.286789    26.286789    26.286789  ...   26.286789\n",
      "      26.286789    26.286789 ]\n",
      "   [ -73.075134   -73.075134   -73.075134  ...  -73.075134\n",
      "     -73.075134   -73.075134 ]]\n",
      "\n",
      "  [[   4.448524     4.448524     4.448524  ...    4.448524\n",
      "       4.448524     4.448524 ]\n",
      "   [ -47.475468   -47.475468   -47.475468  ...  -47.475468\n",
      "     -47.475468   -47.475468 ]\n",
      "   [ -55.44758    -55.44758    -55.44758   ...  -55.44758\n",
      "     -55.44758    -55.44758  ]\n",
      "   ...\n",
      "   [  16.8236      16.8236      16.8236    ...   16.8236\n",
      "      16.8236      16.8236   ]\n",
      "   [ -76.023636   -76.023636   -76.023636  ...  -76.023636\n",
      "     -76.023636   -76.023636 ]\n",
      "   [ -42.504776   -42.504776   -42.504776  ...  -42.504776\n",
      "     -42.504776   -42.504776 ]]\n",
      "\n",
      "  [[ -54.476036   -54.476036   -54.476036  ...  -54.476036\n",
      "     -54.476036   -54.476036 ]\n",
      "   [ -39.680798   -39.680798   -39.680798  ...  -39.680798\n",
      "     -39.680798   -39.680798 ]\n",
      "   [  62.144302    62.144302    62.144302  ...   62.144302\n",
      "      62.144302    62.144302 ]\n",
      "   ...\n",
      "   [ -26.804815   -26.804815   -26.804815  ...  -26.804815\n",
      "     -26.804815   -26.804815 ]\n",
      "   [   7.073834     7.073834     7.073834  ...    7.073834\n",
      "       7.073834     7.073834 ]\n",
      "   [ -91.69253    -91.69253    -91.69253   ...  -91.69253\n",
      "     -91.69253    -91.69253  ]]]\n",
      "\n",
      "\n",
      " [[[  -2.8523357   -2.8523357   -2.8523357 ...   -2.8523357\n",
      "      -2.8523357   -2.8523357]\n",
      "   [  32.647274    32.647274    32.647274  ...   32.647274\n",
      "      32.647274    32.647274 ]\n",
      "   [ -12.749461   -12.749461   -12.749461  ...  -12.749461\n",
      "     -12.749461   -12.749461 ]\n",
      "   ...\n",
      "   [-127.388664  -127.388664  -127.388664  ... -127.388664\n",
      "    -127.388664  -127.388664 ]\n",
      "   [  64.75352     64.75352     64.75352   ...   64.75352\n",
      "      64.75352     64.75352  ]\n",
      "   [ -68.518745   -68.518745   -68.518745  ...  -68.518745\n",
      "     -68.518745   -68.518745 ]]\n",
      "\n",
      "  [[ -21.697983   -21.697983   -21.697983  ...  -21.697983\n",
      "     -21.697983   -21.697983 ]\n",
      "   [ 116.67762    116.67762    116.67762   ...  116.67762\n",
      "     116.67762    116.67762  ]\n",
      "   [-122.285324  -122.285324  -122.285324  ... -122.285324\n",
      "    -122.285324  -122.285324 ]\n",
      "   ...\n",
      "   [ -23.221544   -23.221544   -23.221544  ...  -23.221544\n",
      "     -23.221544   -23.221544 ]\n",
      "   [  -5.5071487   -5.5071487   -5.5071487 ...   -5.5071487\n",
      "      -5.5071487   -5.5071487]\n",
      "   [  32.97837     32.97837     32.97837   ...   32.97837\n",
      "      32.97837     32.97837  ]]\n",
      "\n",
      "  [[ -10.996884   -10.996884   -10.996884  ...  -10.996884\n",
      "     -10.996884   -10.996884 ]\n",
      "   [  45.059917    45.059917    45.059917  ...   45.059917\n",
      "      45.059917    45.059917 ]\n",
      "   [  12.558748    12.558748    12.558748  ...   12.558748\n",
      "      12.558748    12.558748 ]\n",
      "   ...\n",
      "   [-103.91965   -103.91965   -103.91965   ... -103.91965\n",
      "    -103.91965   -103.91965  ]\n",
      "   [  57.742542    57.742542    57.742542  ...   57.742542\n",
      "      57.742542    57.742542 ]\n",
      "   [ -70.708984   -70.708984   -70.708984  ...  -70.708984\n",
      "     -70.708984   -70.708984 ]]]\n",
      "\n",
      "\n",
      " [[[ -63.36854    -63.36854    -63.36854   ...  -63.36854\n",
      "     -63.36854    -63.36854  ]\n",
      "   [ -87.756805   -87.756805   -87.756805  ...  -87.756805\n",
      "     -87.756805   -87.756805 ]\n",
      "   [ 100.1678     100.1678     100.1678    ...  100.1678\n",
      "     100.1678     100.1678   ]\n",
      "   ...\n",
      "   [ -46.963646   -46.963646   -46.963646  ...  -46.963646\n",
      "     -46.963646   -46.963646 ]\n",
      "   [  38.047882    38.047882    38.047882  ...   38.047882\n",
      "      38.047882    38.047882 ]\n",
      "   [ -47.247173   -47.247173   -47.247173  ...  -47.247173\n",
      "     -47.247173   -47.247173 ]]\n",
      "\n",
      "  [[  12.512624    12.512624    12.512624  ...   12.512624\n",
      "      12.512624    12.512624 ]\n",
      "   [ -24.680601   -24.680601   -24.680601  ...  -24.680601\n",
      "     -24.680601   -24.680601 ]\n",
      "   [ -78.09188    -78.09188    -78.09188   ...  -78.09188\n",
      "     -78.09188    -78.09188  ]\n",
      "   ...\n",
      "   [  20.306244    20.306244    20.306244  ...   20.306244\n",
      "      20.306244    20.306244 ]\n",
      "   [-101.22749   -101.22749   -101.22749   ... -101.22749\n",
      "    -101.22749   -101.22749  ]\n",
      "   [ -37.777817   -37.777817   -37.777817  ...  -37.777817\n",
      "     -37.777817   -37.777817 ]]\n",
      "\n",
      "  [[ -39.687473   -39.687473   -39.687473  ...  -39.687473\n",
      "     -39.687473   -39.687473 ]\n",
      "   [ -76.38611    -76.38611    -76.38611   ...  -76.38611\n",
      "     -76.38611    -76.38611  ]\n",
      "   [  72.96718     72.96718     72.96718   ...   72.96718\n",
      "      72.96718     72.96718  ]\n",
      "   ...\n",
      "   [ -51.404037   -51.404037   -51.404037  ...  -51.404037\n",
      "     -51.404037   -51.404037 ]\n",
      "   [  15.854685    15.854685    15.854685  ...   15.854685\n",
      "      15.854685    15.854685 ]\n",
      "   [ -74.013565   -74.013565   -74.013565  ...  -74.013565\n",
      "     -74.013565   -74.013565 ]]]]\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape7-W_shape7-2-2] _\u001b[0m\n",
      "\n",
      "Z_shape = (3, 16, 16, 8), W_shape = (3, 3, 8, 16), stride = 2, padding = 2\n",
      "backward = True, device = cuda()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[  0.40910086  -0.64982927  11.320294   ...  -0.12077556\n",
      "      1.428692    -5.5845156 ]\n",
      "   [ -6.89178...-1.5437248  -10.136281  ]\n",
      "   [  1.1511405    0.7441038   16.463472   ...  -6.8931007\n",
      "     -0.5833115   -2.504636  ]]]])\n",
      "W_shape    = (3, 3, 8, 16)\n",
      "Wtch       = tensor([[[[  0.4091,  -0.6498,  11.3203,  ...,  -0.1208,   1.4287,  -5.5845],\n",
      "          [ -6.8918,  -9.3836,  10.6335,... -10.1363],\n",
      "          [  1.1511,   0.7441,  16.4635,  ...,  -6.8931,  -0.5833,  -2.5046]]]],\n",
      "       requires_grad=True)\n",
      "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
      "     4.75044203e+00 -7.56786048e...5e+00]\n",
      "   [ 6.10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
      "     3.33514667e+00 -1.35630560e+00]]]])\n",
      "Z_shape    = (3, 16, 16, 8)\n",
      "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
      "            4.7504e+00, -7.5679e-01],\n",
      "          [...[ 6.1037e+00, -2.0543e+00, -4.4138e+00,  ..., -6.1525e+00,\n",
      "            3.3351e+00, -1.3563e+00]]]], requires_grad=True)\n",
      "_W         = array([[[[  0.40910086,  -0.64982927,  11.320294  , ...,  -0.12077556,\n",
      "            1.428692  ,  -5.5845156 ],\n",
      "        ... ,  16.463472  , ...,  -6.8931007 ,\n",
      "           -0.5833115 ,  -2.504636  ]]]],\n",
      "      shape=(3, 3, 8, 16), dtype=float32)\n",
      "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
      "          -4.88638926e+00,  4.75044203e+00, -7.56786...6e+00, ...,\n",
      "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
      "      shape=(3, 16, 16, 8), dtype=float32)\n",
      "backward   = True\n",
      "device     = cuda()\n",
      "err1       = np.float32(0.00040186255)\n",
      "err2       = np.float32(0.0005360778)\n",
      "out        = tensor([[[[-6.3835e+01,  7.0442e+01, -1.5787e+02,  ..., -1.1571e+02,\n",
      "            2.7167e+02,  2.9473e+01],\n",
      "          [...,  1.5725e+02, -4.1424e+01,  ...,  1.6422e+02,\n",
      "            1.0298e+02,  8.0763e+01]]]], grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(-8988.4932, grad_fn=<SumBackward0>)\n",
      "padding    = 2\n",
      "stride     = 2\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c5655d76e0>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655d6b40>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655d6b40>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655d6b40>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655d6b40>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[  23.270412     23.270412     23.270412   ...   23.270412\n",
      "      23.270412     23.270412  ]\n",
      "   [  47.964565     47.964565     47.964565   ...   47.964565\n",
      "      47.964565     47.964565  ]\n",
      "   [-199.55396    -199.55396    -199.55396    ... -199.55396\n",
      "    -199.55396    -199.55396   ]\n",
      "   ...\n",
      "   [ -20.288277    -20.288277    -20.288277   ...  -20.288277\n",
      "     -20.288277    -20.288277  ]\n",
      "   [  55.916107     55.916107     55.916107   ...   55.916107\n",
      "      55.916107     55.916107  ]\n",
      "   [ -74.69081     -74.69081     -74.69081    ...  -74.69081\n",
      "     -74.69081     -74.69081   ]]\n",
      "\n",
      "  [[  19.853985     19.853985     19.853985   ...   19.853985\n",
      "      19.853985     19.853985  ]\n",
      "   [ -55.841957    -55.841957    -55.841957   ...  -55.841957\n",
      "     -55.841957    -55.841957  ]\n",
      "   [  91.77676      91.77676      91.77676    ...   91.77676\n",
      "      91.77676      91.77676   ]\n",
      "   ...\n",
      "   [ -23.842733    -23.842733    -23.842733   ...  -23.842733\n",
      "     -23.842733    -23.842733  ]\n",
      "   [ -17.848866    -17.848866    -17.848866   ...  -17.848866\n",
      "     -17.848866    -17.848866  ]\n",
      "   [-139.37263    -139.37263    -139.37263    ... -139.37263\n",
      "    -139.37263    -139.37263   ]]\n",
      "\n",
      "  [[  23.270412     23.270412     23.270412   ...   23.270412\n",
      "      23.270412     23.270412  ]\n",
      "   [  47.964565     47.964565     47.964565   ...   47.964565\n",
      "      47.964565     47.964565  ]\n",
      "   [-199.55396    -199.55396    -199.55396    ... -199.55396\n",
      "    -199.55396    -199.55396   ]\n",
      "   ...\n",
      "   [ -20.288277    -20.288277    -20.288277   ...  -20.288277\n",
      "     -20.288277    -20.288277  ]\n",
      "   [  55.916107     55.916107     55.916107   ...   55.916107\n",
      "      55.916107     55.916107  ]\n",
      "   [ -74.69081     -74.69081     -74.69081    ...  -74.69081\n",
      "     -74.69081     -74.69081   ]]]\n",
      "\n",
      "\n",
      " [[[ -50.711723    -50.711723    -50.711723   ...  -50.711723\n",
      "     -50.711723    -50.711723  ]\n",
      "   [  26.546358     26.546358     26.546358   ...   26.546358\n",
      "      26.546358     26.546358  ]\n",
      "   [ -41.690857    -41.690857    -41.690857   ...  -41.690857\n",
      "     -41.690857    -41.690857  ]\n",
      "   ...\n",
      "   [  58.001217     58.001217     58.001217   ...   58.001217\n",
      "      58.001217     58.001217  ]\n",
      "   [-131.91515    -131.91515    -131.91515    ... -131.91515\n",
      "    -131.91515    -131.91515   ]\n",
      "   [  -0.42793083   -0.42793083   -0.42793083 ...   -0.42793083\n",
      "      -0.42793083   -0.42793083]]\n",
      "\n",
      "  [[ -41.042408    -41.042408    -41.042408   ...  -41.042408\n",
      "     -41.042408    -41.042408  ]\n",
      "   [ -26.126831    -26.126831    -26.126831   ...  -26.126831\n",
      "     -26.126831    -26.126831  ]\n",
      "   [  46.335087     46.335087     46.335087   ...   46.335087\n",
      "      46.335087     46.335087  ]\n",
      "   ...\n",
      "   [ -86.61835     -86.61835     -86.61835    ...  -86.61835\n",
      "     -86.61835     -86.61835   ]\n",
      "   [  63.583405     63.583405     63.583405   ...   63.583405\n",
      "      63.583405     63.583405  ]\n",
      "   [  -9.2516365    -9.2516365    -9.2516365  ...   -9.2516365\n",
      "      -9.2516365    -9.2516365 ]]\n",
      "\n",
      "  [[ -50.711723    -50.711723    -50.711723   ...  -50.711723\n",
      "     -50.711723    -50.711723  ]\n",
      "   [  26.546358     26.546358     26.546358   ...   26.546358\n",
      "      26.546358     26.546358  ]\n",
      "   [ -41.690857    -41.690857    -41.690857   ...  -41.690857\n",
      "     -41.690857    -41.690857  ]\n",
      "   ...\n",
      "   [  58.001217     58.001217     58.001217   ...   58.001217\n",
      "      58.001217     58.001217  ]\n",
      "   [-131.91515    -131.91515    -131.91515    ... -131.91515\n",
      "    -131.91515    -131.91515   ]\n",
      "   [  -0.42793083   -0.42793083   -0.42793083 ...   -0.42793083\n",
      "      -0.42793083   -0.42793083]]]\n",
      "\n",
      "\n",
      " [[[  23.270412     23.270412     23.270412   ...   23.270412\n",
      "      23.270412     23.270412  ]\n",
      "   [  47.964565     47.964565     47.964565   ...   47.964565\n",
      "      47.964565     47.964565  ]\n",
      "   [-199.55396    -199.55396    -199.55396    ... -199.55396\n",
      "    -199.55396    -199.55396   ]\n",
      "   ...\n",
      "   [ -20.288277    -20.288277    -20.288277   ...  -20.288277\n",
      "     -20.288277    -20.288277  ]\n",
      "   [  55.916107     55.916107     55.916107   ...   55.916107\n",
      "      55.916107     55.916107  ]\n",
      "   [ -74.69081     -74.69081     -74.69081    ...  -74.69081\n",
      "     -74.69081     -74.69081   ]]\n",
      "\n",
      "  [[  19.853985     19.853985     19.853985   ...   19.853985\n",
      "      19.853985     19.853985  ]\n",
      "   [ -55.841957    -55.841957    -55.841957   ...  -55.841957\n",
      "     -55.841957    -55.841957  ]\n",
      "   [  91.77676      91.77676      91.77676    ...   91.77676\n",
      "      91.77676      91.77676   ]\n",
      "   ...\n",
      "   [ -23.842733    -23.842733    -23.842733   ...  -23.842733\n",
      "     -23.842733    -23.842733  ]\n",
      "   [ -17.848866    -17.848866    -17.848866   ...  -17.848866\n",
      "     -17.848866    -17.848866  ]\n",
      "   [-139.37263    -139.37263    -139.37263    ... -139.37263\n",
      "    -139.37263    -139.37263   ]]\n",
      "\n",
      "  [[  23.270412     23.270412     23.270412   ...   23.270412\n",
      "      23.270412     23.270412  ]\n",
      "   [  47.964565     47.964565     47.964565   ...   47.964565\n",
      "      47.964565     47.964565  ]\n",
      "   [-199.55396    -199.55396    -199.55396    ... -199.55396\n",
      "    -199.55396    -199.55396   ]\n",
      "   ...\n",
      "   [ -20.288277    -20.288277    -20.288277   ...  -20.288277\n",
      "     -20.288277    -20.288277  ]\n",
      "   [  55.916107     55.916107     55.916107   ...   55.916107\n",
      "      55.916107     55.916107  ]\n",
      "   [ -74.69081     -74.69081     -74.69081    ...  -74.69081\n",
      "     -74.69081     -74.69081   ]]]], W.grad.numpy(): [[[[  23.270412    23.270412    23.270412  ...   23.270412\n",
      "      23.270412    23.270412 ]\n",
      "   [  47.964546    47.964546    47.964546  ...   47.964546\n",
      "      47.964546    47.964546 ]\n",
      "   [-199.55397   -199.55397   -199.55397   ... -199.55397\n",
      "    -199.55397   -199.55397  ]\n",
      "   ...\n",
      "   [ -20.288273   -20.288273   -20.288273  ...  -20.288273\n",
      "     -20.288273   -20.288273 ]\n",
      "   [  55.9161      55.9161      55.9161    ...   55.9161\n",
      "      55.9161      55.9161   ]\n",
      "   [ -74.69081    -74.69081    -74.69081   ...  -74.69081\n",
      "     -74.69081    -74.69081  ]]\n",
      "\n",
      "  [[  19.85399     19.85399     19.85399   ...   19.85399\n",
      "      19.85399     19.85399  ]\n",
      "   [ -55.841965   -55.841965   -55.841965  ...  -55.841965\n",
      "     -55.841965   -55.841965 ]\n",
      "   [  91.776764    91.776764    91.776764  ...   91.776764\n",
      "      91.776764    91.776764 ]\n",
      "   ...\n",
      "   [ -23.842733   -23.842733   -23.842733  ...  -23.842733\n",
      "     -23.842733   -23.842733 ]\n",
      "   [ -17.848883   -17.848883   -17.848883  ...  -17.848883\n",
      "     -17.848883   -17.848883 ]\n",
      "   [-139.37262   -139.37262   -139.37262   ... -139.37262\n",
      "    -139.37262   -139.37262  ]]\n",
      "\n",
      "  [[  23.270412    23.270412    23.270412  ...   23.270412\n",
      "      23.270412    23.270412 ]\n",
      "   [  47.964546    47.964546    47.964546  ...   47.964546\n",
      "      47.964546    47.964546 ]\n",
      "   [-199.55397   -199.55397   -199.55397   ... -199.55397\n",
      "    -199.55397   -199.55397  ]\n",
      "   ...\n",
      "   [ -20.288273   -20.288273   -20.288273  ...  -20.288273\n",
      "     -20.288273   -20.288273 ]\n",
      "   [  55.9161      55.9161      55.9161    ...   55.9161\n",
      "      55.9161      55.9161   ]\n",
      "   [ -74.69081    -74.69081    -74.69081   ...  -74.69081\n",
      "     -74.69081    -74.69081  ]]]\n",
      "\n",
      "\n",
      " [[[ -50.71173    -50.71173    -50.71173   ...  -50.71173\n",
      "     -50.71173    -50.71173  ]\n",
      "   [  26.546333    26.546333    26.546333  ...   26.546333\n",
      "      26.546333    26.546333 ]\n",
      "   [ -41.690865   -41.690865   -41.690865  ...  -41.690865\n",
      "     -41.690865   -41.690865 ]\n",
      "   ...\n",
      "   [  58.001232    58.001232    58.001232  ...   58.001232\n",
      "      58.001232    58.001232 ]\n",
      "   [-131.91515   -131.91515   -131.91515   ... -131.91515\n",
      "    -131.91515   -131.91515  ]\n",
      "   [  -0.4279189   -0.4279189   -0.4279189 ...   -0.4279189\n",
      "      -0.4279189   -0.4279189]]\n",
      "\n",
      "  [[ -41.04242    -41.04242    -41.04242   ...  -41.04242\n",
      "     -41.04242    -41.04242  ]\n",
      "   [ -26.126842   -26.126842   -26.126842  ...  -26.126842\n",
      "     -26.126842   -26.126842 ]\n",
      "   [  46.3351      46.3351      46.3351    ...   46.3351\n",
      "      46.3351      46.3351   ]\n",
      "   ...\n",
      "   [ -86.61837    -86.61837    -86.61837   ...  -86.61837\n",
      "     -86.61837    -86.61837  ]\n",
      "   [  63.58337     63.58337     63.58337   ...   63.58337\n",
      "      63.58337     63.58337  ]\n",
      "   [  -9.251638    -9.251638    -9.251638  ...   -9.251638\n",
      "      -9.251638    -9.251638 ]]\n",
      "\n",
      "  [[ -50.71173    -50.71173    -50.71173   ...  -50.71173\n",
      "     -50.71173    -50.71173  ]\n",
      "   [  26.546333    26.546333    26.546333  ...   26.546333\n",
      "      26.546333    26.546333 ]\n",
      "   [ -41.690865   -41.690865   -41.690865  ...  -41.690865\n",
      "     -41.690865   -41.690865 ]\n",
      "   ...\n",
      "   [  58.001232    58.001232    58.001232  ...   58.001232\n",
      "      58.001232    58.001232 ]\n",
      "   [-131.91515   -131.91515   -131.91515   ... -131.91515\n",
      "    -131.91515   -131.91515  ]\n",
      "   [  -0.4279189   -0.4279189   -0.4279189 ...   -0.4279189\n",
      "      -0.4279189   -0.4279189]]]\n",
      "\n",
      "\n",
      " [[[  23.270412    23.270412    23.270412  ...   23.270412\n",
      "      23.270412    23.270412 ]\n",
      "   [  47.964546    47.964546    47.964546  ...   47.964546\n",
      "      47.964546    47.964546 ]\n",
      "   [-199.55397   -199.55397   -199.55397   ... -199.55397\n",
      "    -199.55397   -199.55397  ]\n",
      "   ...\n",
      "   [ -20.288273   -20.288273   -20.288273  ...  -20.288273\n",
      "     -20.288273   -20.288273 ]\n",
      "   [  55.9161      55.9161      55.9161    ...   55.9161\n",
      "      55.9161      55.9161   ]\n",
      "   [ -74.69081    -74.69081    -74.69081   ...  -74.69081\n",
      "     -74.69081    -74.69081  ]]\n",
      "\n",
      "  [[  19.85399     19.85399     19.85399   ...   19.85399\n",
      "      19.85399     19.85399  ]\n",
      "   [ -55.841965   -55.841965   -55.841965  ...  -55.841965\n",
      "     -55.841965   -55.841965 ]\n",
      "   [  91.776764    91.776764    91.776764  ...   91.776764\n",
      "      91.776764    91.776764 ]\n",
      "   ...\n",
      "   [ -23.842733   -23.842733   -23.842733  ...  -23.842733\n",
      "     -23.842733   -23.842733 ]\n",
      "   [ -17.848883   -17.848883   -17.848883  ...  -17.848883\n",
      "     -17.848883   -17.848883 ]\n",
      "   [-139.37262   -139.37262   -139.37262   ... -139.37262\n",
      "    -139.37262   -139.37262  ]]\n",
      "\n",
      "  [[  23.270412    23.270412    23.270412  ...   23.270412\n",
      "      23.270412    23.270412 ]\n",
      "   [  47.964546    47.964546    47.964546  ...   47.964546\n",
      "      47.964546    47.964546 ]\n",
      "   [-199.55397   -199.55397   -199.55397   ... -199.55397\n",
      "    -199.55397   -199.55397  ]\n",
      "   ...\n",
      "   [ -20.288273   -20.288273   -20.288273  ...  -20.288273\n",
      "     -20.288273   -20.288273 ]\n",
      "   [  55.9161      55.9161      55.9161    ...   55.9161\n",
      "      55.9161      55.9161   ]\n",
      "   [ -74.69081    -74.69081    -74.69081   ...  -74.69081\n",
      "     -74.69081    -74.69081  ]]]]\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape8-W_shape8-2-0] _\u001b[0m\n",
      "\n",
      "Z_shape = (3, 16, 16, 8), W_shape = (3, 3, 8, 14), stride = 2, padding = 0\n",
      "backward = True, device = cuda()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[ 4.09100860e-01 -6.49829268e-01  1.13202944e+01 ... -5.56089449e+00\n",
      "    -4.84385538e+00 -1.20775558e...5e+00]\n",
      "   [-1.10714078e+00  2.54448557e+00 -7.73867989e+00 ... -1.13336074e+00\n",
      "    -1.21658230e+00 -4.79330921e+00]]]])\n",
      "W_shape    = (3, 3, 8, 14)\n",
      "Wtch       = tensor([[[[ 4.0910e-01, -6.4983e-01,  1.1320e+01,  ..., -5.5609e+00,\n",
      "           -4.8439e+00, -1.2078e-01],\n",
      "          [...[-1.1071e+00,  2.5445e+00, -7.7387e+00,  ..., -1.1334e+00,\n",
      "           -1.2166e+00, -4.7933e+00]]]], requires_grad=True)\n",
      "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
      "     4.75044203e+00 -7.56786048e...5e+00]\n",
      "   [ 6.10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
      "     3.33514667e+00 -1.35630560e+00]]]])\n",
      "Z_shape    = (3, 16, 16, 8)\n",
      "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
      "            4.7504e+00, -7.5679e-01],\n",
      "          [...[ 6.1037e+00, -2.0543e+00, -4.4138e+00,  ..., -6.1525e+00,\n",
      "            3.3351e+00, -1.3563e+00]]]], requires_grad=True)\n",
      "_W         = array([[[[ 4.09100860e-01, -6.49829268e-01,  1.13202944e+01, ...,\n",
      "          -5.56089449e+00, -4.84385538e+00, -1.20775...89e+00, ...,\n",
      "          -1.13336074e+00, -1.21658230e+00, -4.79330921e+00]]]],\n",
      "      shape=(3, 3, 8, 14), dtype=float32)\n",
      "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
      "          -4.88638926e+00,  4.75044203e+00, -7.56786...6e+00, ...,\n",
      "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
      "      shape=(3, 16, 16, 8), dtype=float32)\n",
      "backward   = True\n",
      "device     = cuda()\n",
      "err1       = np.float32(0.00026534157)\n",
      "err2       = np.float32(0.0005267183)\n",
      "out        = tensor([[[[   5.7346,  -55.9106,  320.3619,  ..., -472.6719,  -63.6798,\n",
      "            226.2005],\n",
      "          [ -39.7949, -...[ -34.6254, -262.0989, -192.8079,  ..., -480.3307,  172.4242,\n",
      "            163.7107]]]], grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(10302.4697, grad_fn=<SumBackward0>)\n",
      "padding    = 0\n",
      "stride     = 2\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c5655e3170>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655e2d20>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655e2d20>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655e2d20>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655e2d20>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[  30.547173    30.547173    30.547173  ...   30.547173\n",
      "      30.547173    30.547173 ]\n",
      "   [  53.469177    53.469177    53.469177  ...   53.469177\n",
      "      53.469177    53.469177 ]\n",
      "   [-145.9325    -145.9325    -145.9325    ... -145.9325\n",
      "    -145.9325    -145.9325   ]\n",
      "   ...\n",
      "   [ -14.513361   -14.513361   -14.513361  ...  -14.513361\n",
      "     -14.513361   -14.513361 ]\n",
      "   [  15.266685    15.266685    15.266685  ...   15.266685\n",
      "      15.266685    15.266685 ]\n",
      "   [ -13.076628   -13.076628   -13.076628  ...  -13.076628\n",
      "     -13.076628   -13.076628 ]]\n",
      "\n",
      "  [[ -68.17785    -68.17785    -68.17785   ...  -68.17785\n",
      "     -68.17785    -68.17785  ]\n",
      "   [ -15.384946   -15.384946   -15.384946  ...  -15.384946\n",
      "     -15.384946   -15.384946 ]\n",
      "   [  83.73863     83.73863     83.73863   ...   83.73863\n",
      "      83.73863     83.73863  ]\n",
      "   ...\n",
      "   [  18.319536    18.319536    18.319536  ...   18.319536\n",
      "      18.319536    18.319536 ]\n",
      "   [  25.439444    25.439444    25.439444  ...   25.439444\n",
      "      25.439444    25.439444 ]\n",
      "   [ -96.62114    -96.62114    -96.62114   ...  -96.62114\n",
      "     -96.62114    -96.62114  ]]\n",
      "\n",
      "  [[   5.77079      5.77079      5.77079   ...    5.77079\n",
      "       5.77079      5.77079  ]\n",
      "   [  72.89382     72.89382     72.89382   ...   72.89382\n",
      "      72.89382     72.89382  ]\n",
      "   [-127.521706  -127.521706  -127.521706  ... -127.521706\n",
      "    -127.521706  -127.521706 ]\n",
      "   ...\n",
      "   [   4.302202     4.302202     4.302202  ...    4.302202\n",
      "       4.302202     4.302202 ]\n",
      "   [  -5.5214      -5.5214      -5.5214    ...   -5.5214\n",
      "      -5.5214      -5.5214   ]\n",
      "   [ -33.545734   -33.545734   -33.545734  ...  -33.545734\n",
      "     -33.545734   -33.545734 ]]]\n",
      "\n",
      "\n",
      " [[[ -73.30465    -73.30465    -73.30465   ...  -73.30465\n",
      "     -73.30465    -73.30465  ]\n",
      "   [  65.06516     65.06516     65.06516   ...   65.06516\n",
      "      65.06516     65.06516  ]\n",
      "   [  20.936012    20.936012    20.936012  ...   20.936012\n",
      "      20.936012    20.936012 ]\n",
      "   ...\n",
      "   [ -21.802673   -21.802673   -21.802673  ...  -21.802673\n",
      "     -21.802673   -21.802673 ]\n",
      "   [-117.2268    -117.2268    -117.2268    ... -117.2268\n",
      "    -117.2268    -117.2268   ]\n",
      "   [  17.847662    17.847662    17.847662  ...   17.847662\n",
      "      17.847662    17.847662 ]]\n",
      "\n",
      "  [[ -90.858345   -90.858345   -90.858345  ...  -90.858345\n",
      "     -90.858345   -90.858345 ]\n",
      "   [  -8.076708    -8.076708    -8.076708  ...   -8.076708\n",
      "      -8.076708    -8.076708 ]\n",
      "   [  75.35593     75.35593     75.35593   ...   75.35593\n",
      "      75.35593     75.35593  ]\n",
      "   ...\n",
      "   [ -29.262634   -29.262634   -29.262634  ...  -29.262634\n",
      "     -29.262634   -29.262634 ]\n",
      "   [  74.468475    74.468475    74.468475  ...   74.468475\n",
      "      74.468475    74.468475 ]\n",
      "   [ -15.215542   -15.215542   -15.215542  ...  -15.215542\n",
      "     -15.215542   -15.215542 ]]\n",
      "\n",
      "  [[ -79.51456    -79.51456    -79.51456   ...  -79.51456\n",
      "     -79.51456    -79.51456  ]\n",
      "   [  52.29492     52.29492     52.29492   ...   52.29492\n",
      "      52.29492     52.29492  ]\n",
      "   [  11.921398    11.921398    11.921398  ...   11.921398\n",
      "      11.921398    11.921398 ]\n",
      "   ...\n",
      "   [  26.79831     26.79831     26.79831   ...   26.79831\n",
      "      26.79831     26.79831  ]\n",
      "   [-137.8027    -137.8027    -137.8027    ... -137.8027\n",
      "    -137.8027    -137.8027   ]\n",
      "   [ -33.372818   -33.372818   -33.372818  ...  -33.372818\n",
      "     -33.372818   -33.372818 ]]]\n",
      "\n",
      "\n",
      " [[[  43.01931     43.01931     43.01931   ...   43.01931\n",
      "      43.01931     43.01931  ]\n",
      "   [  49.998737    49.998737    49.998737  ...   49.998737\n",
      "      49.998737    49.998737 ]\n",
      "   [-152.49677   -152.49677   -152.49677   ... -152.49677\n",
      "    -152.49677   -152.49677  ]\n",
      "   ...\n",
      "   [ -15.748844   -15.748844   -15.748844  ...  -15.748844\n",
      "     -15.748844   -15.748844 ]\n",
      "   [  31.96638     31.96638     31.96638   ...   31.96638\n",
      "      31.96638     31.96638  ]\n",
      "   [ -43.587334   -43.587334   -43.587334  ...  -43.587334\n",
      "     -43.587334   -43.587334 ]]\n",
      "\n",
      "  [[  -8.004757    -8.004757    -8.004757  ...   -8.004757\n",
      "      -8.004757    -8.004757 ]\n",
      "   [ -18.425175   -18.425175   -18.425175  ...  -18.425175\n",
      "     -18.425175   -18.425175 ]\n",
      "   [  86.11835     86.11835     86.11835   ...   86.11835\n",
      "      86.11835     86.11835  ]\n",
      "   ...\n",
      "   [ -19.514685   -19.514685   -19.514685  ...  -19.514685\n",
      "     -19.514685   -19.514685 ]\n",
      "   [ -21.324108   -21.324108   -21.324108  ...  -21.324108\n",
      "     -21.324108   -21.324108 ]\n",
      "   [-150.30342   -150.30342   -150.30342   ... -150.30342\n",
      "    -150.30342   -150.30342  ]]\n",
      "\n",
      "  [[  59.669495    59.669495    59.669495  ...   59.669495\n",
      "      59.669495    59.669495 ]\n",
      "   [  71.17648     71.17648     71.17648   ...   71.17648\n",
      "      71.17648     71.17648  ]\n",
      "   [-128.95201   -128.95201   -128.95201   ... -128.95201\n",
      "    -128.95201   -128.95201  ]\n",
      "   ...\n",
      "   [   8.888981     8.888981     8.888981  ...    8.888981\n",
      "       8.888981     8.888981 ]\n",
      "   [   7.3665056    7.3665056    7.3665056 ...    7.3665056\n",
      "       7.3665056    7.3665056]\n",
      "   [ -79.82819    -79.82819    -79.82819   ...  -79.82819\n",
      "     -79.82819    -79.82819  ]]]], W.grad.numpy(): [[[[  30.547167    30.547167    30.547167  ...   30.547167\n",
      "      30.547167    30.547167 ]\n",
      "   [  53.469166    53.469166    53.469166  ...   53.469166\n",
      "      53.469166    53.469166 ]\n",
      "   [-145.9325    -145.9325    -145.9325    ... -145.9325\n",
      "    -145.9325    -145.9325   ]\n",
      "   ...\n",
      "   [ -14.513368   -14.513368   -14.513368  ...  -14.513368\n",
      "     -14.513368   -14.513368 ]\n",
      "   [  15.266677    15.266677    15.266677  ...   15.266677\n",
      "      15.266677    15.266677 ]\n",
      "   [ -13.076618   -13.076618   -13.076618  ...  -13.076618\n",
      "     -13.076618   -13.076618 ]]\n",
      "\n",
      "  [[ -68.17786    -68.17786    -68.17786   ...  -68.17786\n",
      "     -68.17786    -68.17786  ]\n",
      "   [ -15.38494    -15.38494    -15.38494   ...  -15.38494\n",
      "     -15.38494    -15.38494  ]\n",
      "   [  83.738625    83.738625    83.738625  ...   83.738625\n",
      "      83.738625    83.738625 ]\n",
      "   ...\n",
      "   [  18.319536    18.319536    18.319536  ...   18.319536\n",
      "      18.319536    18.319536 ]\n",
      "   [  25.43943     25.43943     25.43943   ...   25.43943\n",
      "      25.43943     25.43943  ]\n",
      "   [ -96.62115    -96.62115    -96.62115   ...  -96.62115\n",
      "     -96.62115    -96.62115  ]]\n",
      "\n",
      "  [[   5.770788     5.770788     5.770788  ...    5.770788\n",
      "       5.770788     5.770788 ]\n",
      "   [  72.893814    72.893814    72.893814  ...   72.893814\n",
      "      72.893814    72.893814 ]\n",
      "   [-127.52174   -127.52174   -127.52174   ... -127.52174\n",
      "    -127.52174   -127.52174  ]\n",
      "   ...\n",
      "   [   4.302189     4.302189     4.302189  ...    4.302189\n",
      "       4.302189     4.302189 ]\n",
      "   [  -5.5214043   -5.5214043   -5.5214043 ...   -5.5214043\n",
      "      -5.5214043   -5.5214043]\n",
      "   [ -33.545734   -33.545734   -33.545734  ...  -33.545734\n",
      "     -33.545734   -33.545734 ]]]\n",
      "\n",
      "\n",
      " [[[ -73.30466    -73.30466    -73.30466   ...  -73.30466\n",
      "     -73.30466    -73.30466  ]\n",
      "   [  65.06517     65.06517     65.06517   ...   65.06517\n",
      "      65.06517     65.06517  ]\n",
      "   [  20.935993    20.935993    20.935993  ...   20.935993\n",
      "      20.935993    20.935993 ]\n",
      "   ...\n",
      "   [ -21.802668   -21.802668   -21.802668  ...  -21.802668\n",
      "     -21.802668   -21.802668 ]\n",
      "   [-117.22675   -117.22675   -117.22675   ... -117.22675\n",
      "    -117.22675   -117.22675  ]\n",
      "   [  17.847658    17.847658    17.847658  ...   17.847658\n",
      "      17.847658    17.847658 ]]\n",
      "\n",
      "  [[ -90.85834    -90.85834    -90.85834   ...  -90.85834\n",
      "     -90.85834    -90.85834  ]\n",
      "   [  -8.076723    -8.076723    -8.076723  ...   -8.076723\n",
      "      -8.076723    -8.076723 ]\n",
      "   [  75.3559      75.3559      75.3559    ...   75.3559\n",
      "      75.3559      75.3559   ]\n",
      "   ...\n",
      "   [ -29.262629   -29.262629   -29.262629  ...  -29.262629\n",
      "     -29.262629   -29.262629 ]\n",
      "   [  74.46847     74.46847     74.46847   ...   74.46847\n",
      "      74.46847     74.46847  ]\n",
      "   [ -15.215537   -15.215537   -15.215537  ...  -15.215537\n",
      "     -15.215537   -15.215537 ]]\n",
      "\n",
      "  [[ -79.51458    -79.51458    -79.51458   ...  -79.51458\n",
      "     -79.51458    -79.51458  ]\n",
      "   [  52.29493     52.29493     52.29493   ...   52.29493\n",
      "      52.29493     52.29493  ]\n",
      "   [  11.92141     11.92141     11.92141   ...   11.92141\n",
      "      11.92141     11.92141  ]\n",
      "   ...\n",
      "   [  26.798307    26.798307    26.798307  ...   26.798307\n",
      "      26.798307    26.798307 ]\n",
      "   [-137.80272   -137.80272   -137.80272   ... -137.80272\n",
      "    -137.80272   -137.80272  ]\n",
      "   [ -33.37282    -33.37282    -33.37282   ...  -33.37282\n",
      "     -33.37282    -33.37282  ]]]\n",
      "\n",
      "\n",
      " [[[  43.019302    43.019302    43.019302  ...   43.019302\n",
      "      43.019302    43.019302 ]\n",
      "   [  49.998714    49.998714    49.998714  ...   49.998714\n",
      "      49.998714    49.998714 ]\n",
      "   [-152.49683   -152.49683   -152.49683   ... -152.49683\n",
      "    -152.49683   -152.49683  ]\n",
      "   ...\n",
      "   [ -15.7488365  -15.7488365  -15.7488365 ...  -15.7488365\n",
      "     -15.7488365  -15.7488365]\n",
      "   [  31.966372    31.966372    31.966372  ...   31.966372\n",
      "      31.966372    31.966372 ]\n",
      "   [ -43.587345   -43.587345   -43.587345  ...  -43.587345\n",
      "     -43.587345   -43.587345 ]]\n",
      "\n",
      "  [[  -8.0047455   -8.0047455   -8.0047455 ...   -8.0047455\n",
      "      -8.0047455   -8.0047455]\n",
      "   [ -18.425167   -18.425167   -18.425167  ...  -18.425167\n",
      "     -18.425167   -18.425167 ]\n",
      "   [  86.11836     86.11836     86.11836   ...   86.11836\n",
      "      86.11836     86.11836  ]\n",
      "   ...\n",
      "   [ -19.51469    -19.51469    -19.51469   ...  -19.51469\n",
      "     -19.51469    -19.51469  ]\n",
      "   [ -21.32413    -21.32413    -21.32413   ...  -21.32413\n",
      "     -21.32413    -21.32413  ]\n",
      "   [-150.30345   -150.30345   -150.30345   ... -150.30345\n",
      "    -150.30345   -150.30345  ]]\n",
      "\n",
      "  [[  59.669487    59.669487    59.669487  ...   59.669487\n",
      "      59.669487    59.669487 ]\n",
      "   [  71.1765      71.1765      71.1765    ...   71.1765\n",
      "      71.1765      71.1765   ]\n",
      "   [-128.95201   -128.95201   -128.95201   ... -128.95201\n",
      "    -128.95201   -128.95201  ]\n",
      "   ...\n",
      "   [   8.888977     8.888977     8.888977  ...    8.888977\n",
      "       8.888977     8.888977 ]\n",
      "   [   7.3665347    7.3665347    7.3665347 ...    7.3665347\n",
      "       7.3665347    7.3665347]\n",
      "   [ -79.828186   -79.828186   -79.828186  ...  -79.828186\n",
      "     -79.828186   -79.828186 ]]]]\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape9-W_shape9-2-0] _\u001b[0m\n",
      "\n",
      "Z_shape = (3, 16, 16, 2), W_shape = (3, 3, 2, 14), stride = 2, padding = 0\n",
      "backward = True, device = cuda()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[ -8.0968      -2.5552022    8.703147    -1.4674252    4.5861077\n",
      "     -0.28521433   4.383634    -9.13...727333   0.22582927   9.296732    -8.13161     -0.67411226\n",
      "     -2.9204676    1.675528   -12.187821     5.5746226 ]]]])\n",
      "W_shape    = (3, 3, 2, 14)\n",
      "Wtch       = tensor([[[[ -8.0968,  -2.5552,   8.7031,  -1.4674,   4.5861,  -0.2852,   4.3836,\n",
      "            -9.1346,  -2.0159,   4.74...0.2258,\n",
      "             9.2967,  -8.1316,  -0.6741,  -2.9205,   1.6755, -12.1878,   5.5746]]]],\n",
      "       requires_grad=True)\n",
      "Z          = needle.Tensor([[[[  8.820262     2.000786  ]\n",
      "   [  4.89369     11.204466  ]\n",
      "   [  9.33779     -4.8863893 ]\n",
      "   ...\n",
      "   [...   -5.112822  ]\n",
      "   ...\n",
      "   [ -7.922368     4.2222714 ]\n",
      "   [ -6.064339     1.4188478 ]\n",
      "   [ -1.4109794   -5.791016  ]]]])\n",
      "Z_shape    = (3, 16, 16, 2)\n",
      "Ztch       = tensor([[[[  8.8203,   2.0008],\n",
      "          [  4.8937,  11.2045],\n",
      "          [  9.3378,  -4.8864],\n",
      "          ...,\n",
      "       ...\n",
      "          [ -7.9224,   4.2223],\n",
      "          [ -6.0643,   1.4188],\n",
      "          [ -1.4110,  -5.7910]]]], requires_grad=True)\n",
      "_W         = array([[[[ -8.0968    ,  -2.5552022 ,   8.703147  ,  -1.4674252 ,\n",
      "            4.5861077 ,  -0.28521433,   4.383634  , ...        -8.13161   ,  -0.67411226,  -2.9204676 ,   1.675528  ,\n",
      "          -12.187821  ,   5.5746226 ]]]], dtype=float32)\n",
      "_Z         = array([[[[  8.820262  ,   2.000786  ],\n",
      "         [  4.89369   ,  11.204466  ],\n",
      "         [  9.33779   ,  -4.8863893 ],\n",
      " ...     [ -6.064339  ,   1.4188478 ],\n",
      "         [ -1.4109794 ,  -5.791016  ]]]],\n",
      "      shape=(3, 16, 16, 2), dtype=float32)\n",
      "backward   = True\n",
      "device     = cuda()\n",
      "err1       = np.float32(0.00010036767)\n",
      "err2       = np.float32(0.0002815359)\n",
      "out        = tensor([[[[-3.4607e+02,  6.3506e+01, -3.3188e+01,  ...,  1.9525e+02,\n",
      "            1.2715e+02, -5.7875e+01],\n",
      "          [..., -1.1399e+02, -6.9067e+01,  ..., -1.4515e+02,\n",
      "            5.3236e+01,  3.2069e+00]]]], grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(-2297.1741, grad_fn=<SumBackward0>)\n",
      "padding    = 0\n",
      "stride     = 2\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c56558b140>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c56558a300>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c56558a300>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c56558a300>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c56558a300>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[ -31.111084  -31.111084  -31.111084  -31.111084  -31.111084\n",
      "     -31.111084  -31.111084  -31.111084  -31.111084  -31.111084\n",
      "     -31.111084  -31.111084  -31.111084  -31.111084]\n",
      "   [ -72.39707   -72.39707   -72.39707   -72.39707   -72.39707\n",
      "     -72.39707   -72.39707   -72.39707   -72.39707   -72.39707\n",
      "     -72.39707   -72.39707   -72.39707   -72.39707 ]]\n",
      "\n",
      "  [[  37.540268   37.540268   37.540268   37.540268   37.540268\n",
      "      37.540268   37.540268   37.540268   37.540268   37.540268\n",
      "      37.540268   37.540268   37.540268   37.540268]\n",
      "   [ -10.707729  -10.707729  -10.707729  -10.707729  -10.707729\n",
      "     -10.707729  -10.707729  -10.707729  -10.707729  -10.707729\n",
      "     -10.707729  -10.707729  -10.707729  -10.707729]]\n",
      "\n",
      "  [[ -44.690792  -44.690792  -44.690792  -44.690792  -44.690792\n",
      "     -44.690792  -44.690792  -44.690792  -44.690792  -44.690792\n",
      "     -44.690792  -44.690792  -44.690792  -44.690792]\n",
      "   [ -24.869858  -24.869858  -24.869858  -24.869858  -24.869858\n",
      "     -24.869858  -24.869858  -24.869858  -24.869858  -24.869858\n",
      "     -24.869858  -24.869858  -24.869858  -24.869858]]]\n",
      "\n",
      "\n",
      " [[[ -22.76244   -22.76244   -22.76244   -22.76244   -22.76244\n",
      "     -22.76244   -22.76244   -22.76244   -22.76244   -22.76244\n",
      "     -22.76244   -22.76244   -22.76244   -22.76244 ]\n",
      "   [ -81.52185   -81.52185   -81.52185   -81.52185   -81.52185\n",
      "     -81.52185   -81.52185   -81.52185   -81.52185   -81.52185\n",
      "     -81.52185   -81.52185   -81.52185   -81.52185 ]]\n",
      "\n",
      "  [[ -51.949696  -51.949696  -51.949696  -51.949696  -51.949696\n",
      "     -51.949696  -51.949696  -51.949696  -51.949696  -51.949696\n",
      "     -51.949696  -51.949696  -51.949696  -51.949696]\n",
      "   [  46.37689    46.37689    46.37689    46.37689    46.37689\n",
      "      46.37689    46.37689    46.37689    46.37689    46.37689\n",
      "      46.37689    46.37689    46.37689    46.37689 ]]\n",
      "\n",
      "  [[  -8.752304   -8.752304   -8.752304   -8.752304   -8.752304\n",
      "      -8.752304   -8.752304   -8.752304   -8.752304   -8.752304\n",
      "      -8.752304   -8.752304   -8.752304   -8.752304]\n",
      "   [-106.538734 -106.538734 -106.538734 -106.538734 -106.538734\n",
      "    -106.538734 -106.538734 -106.538734 -106.538734 -106.538734\n",
      "    -106.538734 -106.538734 -106.538734 -106.538734]]]\n",
      "\n",
      "\n",
      " [[[ -93.654     -93.654     -93.654     -93.654     -93.654\n",
      "     -93.654     -93.654     -93.654     -93.654     -93.654\n",
      "     -93.654     -93.654     -93.654     -93.654   ]\n",
      "   [ -47.379856  -47.379856  -47.379856  -47.379856  -47.379856\n",
      "     -47.379856  -47.379856  -47.379856  -47.379856  -47.379856\n",
      "     -47.379856  -47.379856  -47.379856  -47.379856]]\n",
      "\n",
      "  [[  19.678679   19.678679   19.678679   19.678679   19.678679\n",
      "      19.678679   19.678679   19.678679   19.678679   19.678679\n",
      "      19.678679   19.678679   19.678679   19.678679]\n",
      "   [  21.823034   21.823034   21.823034   21.823034   21.823034\n",
      "      21.823034   21.823034   21.823034   21.823034   21.823034\n",
      "      21.823034   21.823034   21.823034   21.823034]]\n",
      "\n",
      "  [[ -86.55904   -86.55904   -86.55904   -86.55904   -86.55904\n",
      "     -86.55904   -86.55904   -86.55904   -86.55904   -86.55904\n",
      "     -86.55904   -86.55904   -86.55904   -86.55904 ]\n",
      "   [ -27.33389   -27.33389   -27.33389   -27.33389   -27.33389\n",
      "     -27.33389   -27.33389   -27.33389   -27.33389   -27.33389\n",
      "     -27.33389   -27.33389   -27.33389   -27.33389 ]]]], W.grad.numpy(): [[[[ -31.11108   -31.11108   -31.11108   -31.11108   -31.11108\n",
      "     -31.11108   -31.11108   -31.11108   -31.11108   -31.11108\n",
      "     -31.11108   -31.11108   -31.11108   -31.11108 ]\n",
      "   [ -72.39707   -72.39707   -72.39707   -72.39707   -72.39707\n",
      "     -72.39707   -72.39707   -72.39707   -72.39707   -72.39707\n",
      "     -72.39707   -72.39707   -72.39707   -72.39707 ]]\n",
      "\n",
      "  [[  37.54029    37.54029    37.54029    37.54029    37.54029\n",
      "      37.54029    37.54029    37.54029    37.54029    37.54029\n",
      "      37.54029    37.54029    37.54029    37.54029 ]\n",
      "   [ -10.707729  -10.707729  -10.707729  -10.707729  -10.707729\n",
      "     -10.707729  -10.707729  -10.707729  -10.707729  -10.707729\n",
      "     -10.707729  -10.707729  -10.707729  -10.707729]]\n",
      "\n",
      "  [[ -44.6908    -44.6908    -44.6908    -44.6908    -44.6908\n",
      "     -44.6908    -44.6908    -44.6908    -44.6908    -44.6908\n",
      "     -44.6908    -44.6908    -44.6908    -44.6908  ]\n",
      "   [ -24.869854  -24.869854  -24.869854  -24.869854  -24.869854\n",
      "     -24.869854  -24.869854  -24.869854  -24.869854  -24.869854\n",
      "     -24.869854  -24.869854  -24.869854  -24.869854]]]\n",
      "\n",
      "\n",
      " [[[ -22.762438  -22.762438  -22.762438  -22.762438  -22.762438\n",
      "     -22.762438  -22.762438  -22.762438  -22.762438  -22.762438\n",
      "     -22.762438  -22.762438  -22.762438  -22.762438]\n",
      "   [ -81.52182   -81.52182   -81.52182   -81.52182   -81.52182\n",
      "     -81.52182   -81.52182   -81.52182   -81.52182   -81.52182\n",
      "     -81.52182   -81.52182   -81.52182   -81.52182 ]]\n",
      "\n",
      "  [[ -51.949703  -51.949703  -51.949703  -51.949703  -51.949703\n",
      "     -51.949703  -51.949703  -51.949703  -51.949703  -51.949703\n",
      "     -51.949703  -51.949703  -51.949703  -51.949703]\n",
      "   [  46.376892   46.376892   46.376892   46.376892   46.376892\n",
      "      46.376892   46.376892   46.376892   46.376892   46.376892\n",
      "      46.376892   46.376892   46.376892   46.376892]]\n",
      "\n",
      "  [[  -8.752316   -8.752316   -8.752316   -8.752316   -8.752316\n",
      "      -8.752316   -8.752316   -8.752316   -8.752316   -8.752316\n",
      "      -8.752316   -8.752316   -8.752316   -8.752316]\n",
      "   [-106.53872  -106.53872  -106.53872  -106.53872  -106.53872\n",
      "    -106.53872  -106.53872  -106.53872  -106.53872  -106.53872\n",
      "    -106.53872  -106.53872  -106.53872  -106.53872 ]]]\n",
      "\n",
      "\n",
      " [[[ -93.65402   -93.65402   -93.65402   -93.65402   -93.65402\n",
      "     -93.65402   -93.65402   -93.65402   -93.65402   -93.65402\n",
      "     -93.65402   -93.65402   -93.65402   -93.65402 ]\n",
      "   [ -47.37984   -47.37984   -47.37984   -47.37984   -47.37984\n",
      "     -47.37984   -47.37984   -47.37984   -47.37984   -47.37984\n",
      "     -47.37984   -47.37984   -47.37984   -47.37984 ]]\n",
      "\n",
      "  [[  19.678682   19.678682   19.678682   19.678682   19.678682\n",
      "      19.678682   19.678682   19.678682   19.678682   19.678682\n",
      "      19.678682   19.678682   19.678682   19.678682]\n",
      "   [  21.823029   21.823029   21.823029   21.823029   21.823029\n",
      "      21.823029   21.823029   21.823029   21.823029   21.823029\n",
      "      21.823029   21.823029   21.823029   21.823029]]\n",
      "\n",
      "  [[ -86.55898   -86.55898   -86.55898   -86.55898   -86.55898\n",
      "     -86.55898   -86.55898   -86.55898   -86.55898   -86.55898\n",
      "     -86.55898   -86.55898   -86.55898   -86.55898 ]\n",
      "   [ -27.33389   -27.33389   -27.33389   -27.33389   -27.33389\n",
      "     -27.33389   -27.33389   -27.33389   -27.33389   -27.33389\n",
      "     -27.33389   -27.33389   -27.33389   -27.33389 ]]]]\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape10-W_shape10-1-0] _\u001b[0m\n",
      "\n",
      "Z_shape = (3, 16, 16, 24), W_shape = (3, 3, 24, 14), stride = 1, padding = 0\n",
      "backward = True, device = cuda()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[ -1.3245817    1.0111231   -1.9236585  ...  -2.5907016\n",
      "     -0.36175704   4.6234684 ]\n",
      "   [  5.279258... -4.82095      4.98517   ]\n",
      "   [  3.2300415   -2.4161792   -3.420825   ...  -9.444658\n",
      "      8.537833     2.3818388 ]]]])\n",
      "W_shape    = (3, 3, 24, 14)\n",
      "Wtch       = tensor([[[[ -1.3246,   1.0111,  -1.9237,  ...,  -2.5907,  -0.3618,   4.6235],\n",
      "          [  5.2793,  -1.3090,   0.0500,...   4.9852],\n",
      "          [  3.2300,  -2.4162,  -3.4208,  ...,  -9.4447,   8.5378,   2.3818]]]],\n",
      "       requires_grad=True)\n",
      "Z          = needle.Tensor([[[[  8.820262     2.000786     4.89369    ...   3.2680929\n",
      "      4.322181    -3.7108252 ]\n",
      "   [ 11.348773...4.207389     8.935435  ]\n",
      "   [  2.5084004    3.1399443   -0.12958507 ...   0.13740699\n",
      "     -1.400853     0.07475674]]]])\n",
      "Z_shape    = (3, 16, 16, 24)\n",
      "Ztch       = tensor([[[[  8.8203,   2.0008,   4.8937,  ...,   3.2681,   4.3222,  -3.7108],\n",
      "          [ 11.3488,  -7.2718,   0.2288,...   8.9354],\n",
      "          [  2.5084,   3.1399,  -0.1296,  ...,   0.1374,  -1.4009,   0.0748]]]],\n",
      "       requires_grad=True)\n",
      "_W         = array([[[[ -1.3245817 ,   1.0111231 ,  -1.9236585 , ...,  -2.5907016 ,\n",
      "           -0.36175704,   4.6234684 ],\n",
      "        ...,  -3.420825  , ...,  -9.444658  ,\n",
      "            8.537833  ,   2.3818388 ]]]],\n",
      "      shape=(3, 3, 24, 14), dtype=float32)\n",
      "_Z         = array([[[[  8.820262  ,   2.000786  ,   4.89369   , ...,   3.2680929 ,\n",
      "            4.322181  ,  -3.7108252 ],\n",
      "        ...  -0.12958507, ...,   0.13740699,\n",
      "           -1.400853  ,   0.07475674]]]],\n",
      "      shape=(3, 16, 16, 24), dtype=float32)\n",
      "backward   = True\n",
      "device     = cuda()\n",
      "err1       = np.float32(0.001412236)\n",
      "err2       = np.float32(0.0039917207)\n",
      "out        = tensor([[[[ 5.9644e+02,  1.7622e+01, -3.8665e+02,  ..., -5.6437e+02,\n",
      "           -1.4383e+02, -1.2310e+02],\n",
      "          [..., -6.6977e+02,  7.6359e+00,  ...,  3.7344e+02,\n",
      "           -8.9822e+01,  1.5355e+02]]]], grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(-5941.3750, grad_fn=<SumBackward0>)\n",
      "padding    = 0\n",
      "stride     = 1\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c5655fdbb0>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655fe090>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655fe090>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655fe090>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655fe090>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[  99.66556     99.66556     99.66556   ...   99.66556\n",
      "      99.66556     99.66556  ]\n",
      "   [-104.73128   -104.73128   -104.73128   ... -104.73128\n",
      "    -104.73128   -104.73128  ]\n",
      "   [   6.4298763    6.4298763    6.4298763 ...    6.4298763\n",
      "       6.4298763    6.4298763]\n",
      "   ...\n",
      "   [ -61.407722   -61.407722   -61.407722  ...  -61.407722\n",
      "     -61.407722   -61.407722 ]\n",
      "   [ 164.9695     164.9695     164.9695    ...  164.9695\n",
      "     164.9695     164.9695   ]\n",
      "   [ -45.176285   -45.176285   -45.176285  ...  -45.176285\n",
      "     -45.176285   -45.176285 ]]\n",
      "\n",
      "  [[  36.721527    36.721527    36.721527  ...   36.721527\n",
      "      36.721527    36.721527 ]\n",
      "   [ -99.567825   -99.567825   -99.567825  ...  -99.567825\n",
      "     -99.567825   -99.567825 ]\n",
      "   [  45.52301     45.52301     45.52301   ...   45.52301\n",
      "      45.52301     45.52301  ]\n",
      "   ...\n",
      "   [ -15.012239   -15.012239   -15.012239  ...  -15.012239\n",
      "     -15.012239   -15.012239 ]\n",
      "   [ 151.13068    151.13068    151.13068   ...  151.13068\n",
      "     151.13068    151.13068  ]\n",
      "   [  11.02179     11.02179     11.02179   ...   11.02179\n",
      "      11.02179     11.02179  ]]\n",
      "\n",
      "  [[ -16.979103   -16.979103   -16.979103  ...  -16.979103\n",
      "     -16.979103   -16.979103 ]\n",
      "   [ -66.17146    -66.17146    -66.17146   ...  -66.17146\n",
      "     -66.17146    -66.17146  ]\n",
      "   [ -11.255241   -11.255241   -11.255241  ...  -11.255241\n",
      "     -11.255241   -11.255241 ]\n",
      "   ...\n",
      "   [ -29.803204   -29.803204   -29.803204  ...  -29.803204\n",
      "     -29.803204   -29.803204 ]\n",
      "   [ 104.24271    104.24271    104.24271   ...  104.24271\n",
      "     104.24271    104.24271  ]\n",
      "   [ -43.672226   -43.672226   -43.672226  ...  -43.672226\n",
      "     -43.672226   -43.672226 ]]]\n",
      "\n",
      "\n",
      " [[[  84.22443     84.22443     84.22443   ...   84.22443\n",
      "      84.22443     84.22443  ]\n",
      "   [-135.15842   -135.15842   -135.15842   ... -135.15842\n",
      "    -135.15842   -135.15842  ]\n",
      "   [-100.58326   -100.58326   -100.58326   ... -100.58326\n",
      "    -100.58326   -100.58326  ]\n",
      "   ...\n",
      "   [ -24.883554   -24.883554   -24.883554  ...  -24.883554\n",
      "     -24.883554   -24.883554 ]\n",
      "   [ 100.45781    100.45781    100.45781   ...  100.45781\n",
      "     100.45781    100.45781  ]\n",
      "   [ -85.92231    -85.92231    -85.92231   ...  -85.92231\n",
      "     -85.92231    -85.92231  ]]\n",
      "\n",
      "  [[  38.148136    38.148136    38.148136  ...   38.148136\n",
      "      38.148136    38.148136 ]\n",
      "   [ -94.912506   -94.912506   -94.912506  ...  -94.912506\n",
      "     -94.912506   -94.912506 ]\n",
      "   [ -47.50196    -47.50196    -47.50196   ...  -47.50196\n",
      "     -47.50196    -47.50196  ]\n",
      "   ...\n",
      "   [  31.187073    31.187073    31.187073  ...   31.187073\n",
      "      31.187073    31.187073 ]\n",
      "   [  82.53323     82.53323     82.53323   ...   82.53323\n",
      "      82.53323     82.53323  ]\n",
      "   [ -36.53698    -36.53698    -36.53698   ...  -36.53698\n",
      "     -36.53698    -36.53698  ]]\n",
      "\n",
      "  [[ -25.285572   -25.285572   -25.285572  ...  -25.285572\n",
      "     -25.285572   -25.285572 ]\n",
      "   [ -71.94115    -71.94115    -71.94115   ...  -71.94115\n",
      "     -71.94115    -71.94115  ]\n",
      "   [ -90.84924    -90.84924    -90.84924   ...  -90.84924\n",
      "     -90.84924    -90.84924  ]\n",
      "   ...\n",
      "   [  -9.12859     -9.12859     -9.12859   ...   -9.12859\n",
      "      -9.12859     -9.12859  ]\n",
      "   [  45.63051     45.63051     45.63051   ...   45.63051\n",
      "      45.63051     45.63051  ]\n",
      "   [ -75.96571    -75.96571    -75.96571   ...  -75.96571\n",
      "     -75.96571    -75.96571  ]]]\n",
      "\n",
      "\n",
      " [[[ 144.21216    144.21216    144.21216   ...  144.21216\n",
      "     144.21216    144.21216  ]\n",
      "   [ -84.14905    -84.14905    -84.14905   ...  -84.14905\n",
      "     -84.14905    -84.14905  ]\n",
      "   [ -88.05066    -88.05066    -88.05066   ...  -88.05066\n",
      "     -88.05066    -88.05066  ]\n",
      "   ...\n",
      "   [  19.75122     19.75122     19.75122   ...   19.75122\n",
      "      19.75122     19.75122  ]\n",
      "   [  23.33199     23.33199     23.33199   ...   23.33199\n",
      "      23.33199     23.33199  ]\n",
      "   [ -28.93097    -28.93097    -28.93097   ...  -28.93097\n",
      "     -28.93097    -28.93097  ]]\n",
      "\n",
      "  [[ 110.54175    110.54175    110.54175   ...  110.54175\n",
      "     110.54175    110.54175  ]\n",
      "   [ -76.64881    -76.64881    -76.64881   ...  -76.64881\n",
      "     -76.64881    -76.64881  ]\n",
      "   [ -39.343735   -39.343735   -39.343735  ...  -39.343735\n",
      "     -39.343735   -39.343735 ]\n",
      "   ...\n",
      "   [ 104.99714    104.99714    104.99714   ...  104.99714\n",
      "     104.99714    104.99714  ]\n",
      "   [  16.442848    16.442848    16.442848  ...   16.442848\n",
      "      16.442848    16.442848 ]\n",
      "   [  25.08516     25.08516     25.08516   ...   25.08516\n",
      "      25.08516     25.08516  ]]\n",
      "\n",
      "  [[  58.685844    58.685844    58.685844  ...   58.685844\n",
      "      58.685844    58.685844 ]\n",
      "   [ -54.270386   -54.270386   -54.270386  ...  -54.270386\n",
      "     -54.270386   -54.270386 ]\n",
      "   [ -98.79855    -98.79855    -98.79855   ...  -98.79855\n",
      "     -98.79855    -98.79855  ]\n",
      "   ...\n",
      "   [  55.918465    55.918465    55.918465  ...   55.918465\n",
      "      55.918465    55.918465 ]\n",
      "   [ -24.19175    -24.19175    -24.19175   ...  -24.19175\n",
      "     -24.19175    -24.19175  ]\n",
      "   [ -53.170853   -53.170853   -53.170853  ...  -53.170853\n",
      "     -53.170853   -53.170853 ]]]], W.grad.numpy(): [[[[  99.665535    99.665535    99.665535  ...   99.665535\n",
      "      99.665535    99.665535 ]\n",
      "   [-104.73127   -104.73127   -104.73127   ... -104.73127\n",
      "    -104.73127   -104.73127  ]\n",
      "   [   6.4298763    6.4298763    6.4298763 ...    6.4298763\n",
      "       6.4298763    6.4298763]\n",
      "   ...\n",
      "   [ -61.407658   -61.407658   -61.407658  ...  -61.407658\n",
      "     -61.407658   -61.407658 ]\n",
      "   [ 164.96954    164.96954    164.96954   ...  164.96954\n",
      "     164.96954    164.96954  ]\n",
      "   [ -45.176117   -45.176117   -45.176117  ...  -45.176117\n",
      "     -45.176117   -45.176117 ]]\n",
      "\n",
      "  [[  36.72144     36.72144     36.72144   ...   36.72144\n",
      "      36.72144     36.72144  ]\n",
      "   [ -99.567856   -99.567856   -99.567856  ...  -99.567856\n",
      "     -99.567856   -99.567856 ]\n",
      "   [  45.52297     45.52297     45.52297   ...   45.52297\n",
      "      45.52297     45.52297  ]\n",
      "   ...\n",
      "   [ -15.012265   -15.012265   -15.012265  ...  -15.012265\n",
      "     -15.012265   -15.012265 ]\n",
      "   [ 151.13083    151.13083    151.13083   ...  151.13083\n",
      "     151.13083    151.13083  ]\n",
      "   [  11.02182     11.02182     11.02182   ...   11.02182\n",
      "      11.02182     11.02182  ]]\n",
      "\n",
      "  [[ -16.979084   -16.979084   -16.979084  ...  -16.979084\n",
      "     -16.979084   -16.979084 ]\n",
      "   [ -66.17162    -66.17162    -66.17162   ...  -66.17162\n",
      "     -66.17162    -66.17162  ]\n",
      "   [ -11.255192   -11.255192   -11.255192  ...  -11.255192\n",
      "     -11.255192   -11.255192 ]\n",
      "   ...\n",
      "   [ -29.803177   -29.803177   -29.803177  ...  -29.803177\n",
      "     -29.803177   -29.803177 ]\n",
      "   [ 104.24278    104.24278    104.24278   ...  104.24278\n",
      "     104.24278    104.24278  ]\n",
      "   [ -43.6722     -43.6722     -43.6722    ...  -43.6722\n",
      "     -43.6722     -43.6722   ]]]\n",
      "\n",
      "\n",
      " [[[  84.224556    84.224556    84.224556  ...   84.224556\n",
      "      84.224556    84.224556 ]\n",
      "   [-135.15839   -135.15839   -135.15839   ... -135.15839\n",
      "    -135.15839   -135.15839  ]\n",
      "   [-100.583275  -100.583275  -100.583275  ... -100.583275\n",
      "    -100.583275  -100.583275 ]\n",
      "   ...\n",
      "   [ -24.883583   -24.883583   -24.883583  ...  -24.883583\n",
      "     -24.883583   -24.883583 ]\n",
      "   [ 100.45786    100.45786    100.45786   ...  100.45786\n",
      "     100.45786    100.45786  ]\n",
      "   [ -85.92214    -85.92214    -85.92214   ...  -85.92214\n",
      "     -85.92214    -85.92214  ]]\n",
      "\n",
      "  [[  38.148212    38.148212    38.148212  ...   38.148212\n",
      "      38.148212    38.148212 ]\n",
      "   [ -94.912384   -94.912384   -94.912384  ...  -94.912384\n",
      "     -94.912384   -94.912384 ]\n",
      "   [ -47.501945   -47.501945   -47.501945  ...  -47.501945\n",
      "     -47.501945   -47.501945 ]\n",
      "   ...\n",
      "   [  31.187088    31.187088    31.187088  ...   31.187088\n",
      "      31.187088    31.187088 ]\n",
      "   [  82.533356    82.533356    82.533356  ...   82.533356\n",
      "      82.533356    82.533356 ]\n",
      "   [ -36.536976   -36.536976   -36.536976  ...  -36.536976\n",
      "     -36.536976   -36.536976 ]]\n",
      "\n",
      "  [[ -25.28561    -25.28561    -25.28561   ...  -25.28561\n",
      "     -25.28561    -25.28561  ]\n",
      "   [ -71.9412     -71.9412     -71.9412    ...  -71.9412\n",
      "     -71.9412     -71.9412   ]\n",
      "   [ -90.849174   -90.849174   -90.849174  ...  -90.849174\n",
      "     -90.849174   -90.849174 ]\n",
      "   ...\n",
      "   [  -9.128554    -9.128554    -9.128554  ...   -9.128554\n",
      "      -9.128554    -9.128554 ]\n",
      "   [  45.630615    45.630615    45.630615  ...   45.630615\n",
      "      45.630615    45.630615 ]\n",
      "   [ -75.96561    -75.96561    -75.96561   ...  -75.96561\n",
      "     -75.96561    -75.96561  ]]]\n",
      "\n",
      "\n",
      " [[[ 144.2123     144.2123     144.2123    ...  144.2123\n",
      "     144.2123     144.2123   ]\n",
      "   [ -84.149055   -84.149055   -84.149055  ...  -84.149055\n",
      "     -84.149055   -84.149055 ]\n",
      "   [ -88.05058    -88.05058    -88.05058   ...  -88.05058\n",
      "     -88.05058    -88.05058  ]\n",
      "   ...\n",
      "   [  19.751228    19.751228    19.751228  ...   19.751228\n",
      "      19.751228    19.751228 ]\n",
      "   [  23.331924    23.331924    23.331924  ...   23.331924\n",
      "      23.331924    23.331924 ]\n",
      "   [ -28.930826   -28.930826   -28.930826  ...  -28.930826\n",
      "     -28.930826   -28.930826 ]]\n",
      "\n",
      "  [[ 110.54181    110.54181    110.54181   ...  110.54181\n",
      "     110.54181    110.54181  ]\n",
      "   [ -76.6487     -76.6487     -76.6487    ...  -76.6487\n",
      "     -76.6487     -76.6487   ]\n",
      "   [ -39.343678   -39.343678   -39.343678  ...  -39.343678\n",
      "     -39.343678   -39.343678 ]\n",
      "   ...\n",
      "   [ 104.99721    104.99721    104.99721   ...  104.99721\n",
      "     104.99721    104.99721  ]\n",
      "   [  16.44289     16.44289     16.44289   ...   16.44289\n",
      "      16.44289     16.44289  ]\n",
      "   [  25.085155    25.085155    25.085155  ...   25.085155\n",
      "      25.085155    25.085155 ]]\n",
      "\n",
      "  [[  58.68582     58.68582     58.68582   ...   58.68582\n",
      "      58.68582     58.68582  ]\n",
      "   [ -54.270306   -54.270306   -54.270306  ...  -54.270306\n",
      "     -54.270306   -54.270306 ]\n",
      "   [ -98.798485   -98.798485   -98.798485  ...  -98.798485\n",
      "     -98.798485   -98.798485 ]\n",
      "   ...\n",
      "   [  55.91839     55.91839     55.91839   ...   55.91839\n",
      "      55.91839     55.91839  ]\n",
      "   [ -24.19169    -24.19169    -24.19169   ...  -24.19169\n",
      "     -24.19169    -24.19169  ]\n",
      "   [ -53.170704   -53.170704   -53.170704  ...  -53.170704\n",
      "     -53.170704   -53.170704 ]]]]\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape11-W_shape11-1-0] _\u001b[0m\n",
      "\n",
      "Z_shape = (3, 14, 14, 8), W_shape = (5, 5, 8, 16), stride = 1, padding = 0\n",
      "backward = True, device = cuda()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[ 4.28266907e+00  8.13360405e+00 -4.62234831e+00 ...  2.07981968e+00\n",
      "     2.17041516e+00 -3.88039827e...7e+00]\n",
      "   [-7.86027253e-01  4.30947495e+00 -4.97804356e+00 ... -5.69430470e-01\n",
      "     4.27775383e-01 -3.84437203e+00]]]])\n",
      "W_shape    = (5, 5, 8, 16)\n",
      "Wtch       = tensor([[[[ 4.2827e+00,  8.1336e+00, -4.6223e+00,  ...,  2.0798e+00,\n",
      "            2.1704e+00, -3.8804e-01],\n",
      "          [...[-7.8603e-01,  4.3095e+00, -4.9780e+00,  ..., -5.6943e-01,\n",
      "            4.2778e-01, -3.8444e+00]]]], requires_grad=True)\n",
      "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
      "     4.75044203e+00 -7.56786048e...3e+00]\n",
      "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
      "    -8.48226726e-01 -2.29984760e+00]]]])\n",
      "Z_shape    = (3, 14, 14, 8)\n",
      "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
      "            4.7504e+00, -7.5679e-01],\n",
      "          [...[ 1.0991e+01,  2.2317e+00,  4.6206e+00,  ..., -6.2309e-01,\n",
      "           -8.4823e-01, -2.2998e+00]]]], requires_grad=True)\n",
      "_W         = array([[[[ 4.28266907e+00,  8.13360405e+00, -4.62234831e+00, ...,\n",
      "           2.07981968e+00,  2.17041516e+00, -3.88039...56e+00, ...,\n",
      "          -5.69430470e-01,  4.27775383e-01, -3.84437203e+00]]]],\n",
      "      shape=(5, 5, 8, 16), dtype=float32)\n",
      "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
      "          -4.88638926e+00,  4.75044203e+00, -7.56786...9e+00, ...,\n",
      "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
      "      shape=(3, 14, 14, 8), dtype=float32)\n",
      "backward   = True\n",
      "device     = cuda()\n",
      "err1       = np.float32(0.0018357928)\n",
      "err2       = np.float32(0.0014858997)\n",
      "out        = tensor([[[[ 1.7557e+02,  1.3950e+02,  4.5144e+02,  ...,  1.9506e+01,\n",
      "           -5.7378e+01, -2.2967e+02],\n",
      "          [...,  3.1106e+02,  4.1425e+02,  ...,  3.3462e+02,\n",
      "           -1.0345e+02,  2.4403e+02]]]], grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(-10705.7383, grad_fn=<SumBackward0>)\n",
      "padding    = 0\n",
      "stride     = 1\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c5655e0980>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655e0740>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655e0740>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655e0740>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655e0740>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[-1.16245209e+02 -1.16245209e+02 -1.16245209e+02 ... -1.16245209e+02\n",
      "    -1.16245209e+02 -1.16245209e+02]\n",
      "   [-3.44621315e+01 -3.44621315e+01 -3.44621315e+01 ... -3.44621315e+01\n",
      "    -3.44621315e+01 -3.44621315e+01]\n",
      "   [-1.64758881e+02 -1.64758881e+02 -1.64758881e+02 ... -1.64758881e+02\n",
      "    -1.64758881e+02 -1.64758881e+02]\n",
      "   ...\n",
      "   [-3.16865826e+01 -3.16865826e+01 -3.16865826e+01 ... -3.16865826e+01\n",
      "    -3.16865826e+01 -3.16865826e+01]\n",
      "   [ 8.40804977e+01  8.40804977e+01  8.40804977e+01 ...  8.40804977e+01\n",
      "     8.40804977e+01  8.40804977e+01]\n",
      "   [-9.92724152e+01 -9.92724152e+01 -9.92724152e+01 ... -9.92724152e+01\n",
      "    -9.92724152e+01 -9.92724152e+01]]\n",
      "\n",
      "  [[-1.12383026e+02 -1.12383026e+02 -1.12383026e+02 ... -1.12383026e+02\n",
      "    -1.12383026e+02 -1.12383026e+02]\n",
      "   [-2.81658592e+01 -2.81658592e+01 -2.81658592e+01 ... -2.81658592e+01\n",
      "    -2.81658592e+01 -2.81658592e+01]\n",
      "   [-1.70100220e+02 -1.70100220e+02 -1.70100220e+02 ... -1.70100220e+02\n",
      "    -1.70100220e+02 -1.70100220e+02]\n",
      "   ...\n",
      "   [-1.26563873e+01 -1.26563873e+01 -1.26563873e+01 ... -1.26563873e+01\n",
      "    -1.26563873e+01 -1.26563873e+01]\n",
      "   [ 1.16309891e+02  1.16309891e+02  1.16309891e+02 ...  1.16309891e+02\n",
      "     1.16309891e+02  1.16309891e+02]\n",
      "   [-9.04269104e+01 -9.04269104e+01 -9.04269104e+01 ... -9.04269104e+01\n",
      "    -9.04269104e+01 -9.04269104e+01]]\n",
      "\n",
      "  [[-5.86221962e+01 -5.86221962e+01 -5.86221962e+01 ... -5.86221962e+01\n",
      "    -5.86221962e+01 -5.86221962e+01]\n",
      "   [ 2.15058517e+00  2.15058517e+00  2.15058517e+00 ...  2.15058517e+00\n",
      "     2.15058517e+00  2.15058517e+00]\n",
      "   [-9.45261383e+01 -9.45261383e+01 -9.45261383e+01 ... -9.45261383e+01\n",
      "    -9.45261383e+01 -9.45261383e+01]\n",
      "   ...\n",
      "   [-1.06377201e+01 -1.06377201e+01 -1.06377201e+01 ... -1.06377201e+01\n",
      "    -1.06377201e+01 -1.06377201e+01]\n",
      "   [ 8.25016632e+01  8.25016632e+01  8.25016632e+01 ...  8.25016632e+01\n",
      "     8.25016632e+01  8.25016632e+01]\n",
      "   [-8.38581314e+01 -8.38581314e+01 -8.38581314e+01 ... -8.38581314e+01\n",
      "    -8.38581314e+01 -8.38581314e+01]]\n",
      "\n",
      "  [[-6.70073090e+01 -6.70073090e+01 -6.70073090e+01 ... -6.70073090e+01\n",
      "    -6.70073090e+01 -6.70073090e+01]\n",
      "   [ 4.87934113e-01  4.87934113e-01  4.87934113e-01 ...  4.87934113e-01\n",
      "     4.87934113e-01  4.87934113e-01]\n",
      "   [-8.68875732e+01 -8.68875732e+01 -8.68875732e+01 ... -8.68875732e+01\n",
      "    -8.68875732e+01 -8.68875732e+01]\n",
      "   ...\n",
      "   [-1.43081284e+01 -1.43081284e+01 -1.43081284e+01 ... -1.43081284e+01\n",
      "    -1.43081284e+01 -1.43081284e+01]\n",
      "   [ 3.96485863e+01  3.96485863e+01  3.96485863e+01 ...  3.96485863e+01\n",
      "     3.96485863e+01  3.96485863e+01]\n",
      "   [-1.05648560e+02 -1.05648560e+02 -1.05648560e+02 ... -1.05648560e+02\n",
      "    -1.05648560e+02 -1.05648560e+02]]\n",
      "\n",
      "  [[-5.62348137e+01 -5.62348137e+01 -5.62348137e+01 ... -5.62348137e+01\n",
      "    -5.62348137e+01 -5.62348137e+01]\n",
      "   [ 2.50358200e+01  2.50358200e+01  2.50358200e+01 ...  2.50358200e+01\n",
      "     2.50358200e+01  2.50358200e+01]\n",
      "   [-9.68896866e+01 -9.68896866e+01 -9.68896866e+01 ... -9.68896866e+01\n",
      "    -9.68896866e+01 -9.68896866e+01]\n",
      "   ...\n",
      "   [-1.26439514e+01 -1.26439514e+01 -1.26439514e+01 ... -1.26439514e+01\n",
      "    -1.26439514e+01 -1.26439514e+01]\n",
      "   [ 1.62703705e+00  1.62703705e+00  1.62703705e+00 ...  1.62703705e+00\n",
      "     1.62703705e+00  1.62703705e+00]\n",
      "   [-1.81933929e+02 -1.81933929e+02 -1.81933929e+02 ... -1.81933929e+02\n",
      "    -1.81933929e+02 -1.81933929e+02]]]\n",
      "\n",
      "\n",
      " [[[-1.17615128e+02 -1.17615128e+02 -1.17615128e+02 ... -1.17615128e+02\n",
      "    -1.17615128e+02 -1.17615128e+02]\n",
      "   [ 5.95184898e+00  5.95184898e+00  5.95184898e+00 ...  5.95184898e+00\n",
      "     5.95184898e+00  5.95184898e+00]\n",
      "   [-8.92560120e+01 -8.92560120e+01 -8.92560120e+01 ... -8.92560120e+01\n",
      "    -8.92560120e+01 -8.92560120e+01]\n",
      "   ...\n",
      "   [-1.20959213e+02 -1.20959213e+02 -1.20959213e+02 ... -1.20959213e+02\n",
      "    -1.20959213e+02 -1.20959213e+02]\n",
      "   [ 1.06997871e+02  1.06997871e+02  1.06997871e+02 ...  1.06997871e+02\n",
      "     1.06997871e+02  1.06997871e+02]\n",
      "   [-5.44203796e+01 -5.44203796e+01 -5.44203796e+01 ... -5.44203796e+01\n",
      "    -5.44203796e+01 -5.44203796e+01]]\n",
      "\n",
      "  [[-1.07528992e+02 -1.07528992e+02 -1.07528992e+02 ... -1.07528992e+02\n",
      "    -1.07528992e+02 -1.07528992e+02]\n",
      "   [-2.63620777e+01 -2.63620777e+01 -2.63620777e+01 ... -2.63620777e+01\n",
      "    -2.63620777e+01 -2.63620777e+01]\n",
      "   [-8.02585983e+01 -8.02585983e+01 -8.02585983e+01 ... -8.02585983e+01\n",
      "    -8.02585983e+01 -8.02585983e+01]\n",
      "   ...\n",
      "   [-1.30162384e+02 -1.30162384e+02 -1.30162384e+02 ... -1.30162384e+02\n",
      "    -1.30162384e+02 -1.30162384e+02]\n",
      "   [ 1.58434586e+02  1.58434586e+02  1.58434586e+02 ...  1.58434586e+02\n",
      "     1.58434586e+02  1.58434586e+02]\n",
      "   [-5.02668991e+01 -5.02668991e+01 -5.02668991e+01 ... -5.02668991e+01\n",
      "    -5.02668991e+01 -5.02668991e+01]]\n",
      "\n",
      "  [[-3.91359787e+01 -3.91359787e+01 -3.91359787e+01 ... -3.91359787e+01\n",
      "    -3.91359787e+01 -3.91359787e+01]\n",
      "   [ 2.53128986e+01  2.53128986e+01  2.53128986e+01 ...  2.53128986e+01\n",
      "     2.53128986e+01  2.53128986e+01]\n",
      "   [-7.78603745e+00 -7.78603745e+00 -7.78603745e+00 ... -7.78603745e+00\n",
      "    -7.78603745e+00 -7.78603745e+00]\n",
      "   ...\n",
      "   [-1.23830475e+02 -1.23830475e+02 -1.23830475e+02 ... -1.23830475e+02\n",
      "    -1.23830475e+02 -1.23830475e+02]\n",
      "   [ 1.20911484e+02  1.20911484e+02  1.20911484e+02 ...  1.20911484e+02\n",
      "     1.20911484e+02  1.20911484e+02]\n",
      "   [-5.19391441e+01 -5.19391441e+01 -5.19391441e+01 ... -5.19391441e+01\n",
      "    -5.19391441e+01 -5.19391441e+01]]\n",
      "\n",
      "  [[-4.20618286e+01 -4.20618286e+01 -4.20618286e+01 ... -4.20618286e+01\n",
      "    -4.20618286e+01 -4.20618286e+01]\n",
      "   [ 1.26867943e+01  1.26867943e+01  1.26867943e+01 ...  1.26867943e+01\n",
      "     1.26867943e+01  1.26867943e+01]\n",
      "   [-2.25820427e+01 -2.25820427e+01 -2.25820427e+01 ... -2.25820427e+01\n",
      "    -2.25820427e+01 -2.25820427e+01]\n",
      "   ...\n",
      "   [-9.31390762e+01 -9.31390762e+01 -9.31390762e+01 ... -9.31390762e+01\n",
      "    -9.31390762e+01 -9.31390762e+01]\n",
      "   [ 1.04962341e+02  1.04962341e+02  1.04962341e+02 ...  1.04962341e+02\n",
      "     1.04962341e+02  1.04962341e+02]\n",
      "   [-7.80756454e+01 -7.80756454e+01 -7.80756454e+01 ... -7.80756454e+01\n",
      "    -7.80756454e+01 -7.80756454e+01]]\n",
      "\n",
      "  [[-1.09563560e+01 -1.09563560e+01 -1.09563560e+01 ... -1.09563560e+01\n",
      "    -1.09563560e+01 -1.09563560e+01]\n",
      "   [ 3.37870865e+01  3.37870865e+01  3.37870865e+01 ...  3.37870865e+01\n",
      "     3.37870865e+01  3.37870865e+01]\n",
      "   [-1.52067757e+01 -1.52067757e+01 -1.52067757e+01 ... -1.52067757e+01\n",
      "    -1.52067757e+01 -1.52067757e+01]\n",
      "   ...\n",
      "   [-6.06810417e+01 -6.06810417e+01 -6.06810417e+01 ... -6.06810417e+01\n",
      "    -6.06810417e+01 -6.06810417e+01]\n",
      "   [ 4.86012001e+01  4.86012001e+01  4.86012001e+01 ...  4.86012001e+01\n",
      "     4.86012001e+01  4.86012001e+01]\n",
      "   [-1.48817383e+02 -1.48817383e+02 -1.48817383e+02 ... -1.48817383e+02\n",
      "    -1.48817383e+02 -1.48817383e+02]]]\n",
      "\n",
      "\n",
      " [[[-1.26848694e+02 -1.26848694e+02 -1.26848694e+02 ... -1.26848694e+02\n",
      "    -1.26848694e+02 -1.26848694e+02]\n",
      "   [ 1.36254635e+01  1.36254635e+01  1.36254635e+01 ...  1.36254635e+01\n",
      "     1.36254635e+01  1.36254635e+01]\n",
      "   [-7.57005005e+01 -7.57005005e+01 -7.57005005e+01 ... -7.57005005e+01\n",
      "    -7.57005005e+01 -7.57005005e+01]\n",
      "   ...\n",
      "   [-1.24673889e+02 -1.24673889e+02 -1.24673889e+02 ... -1.24673889e+02\n",
      "    -1.24673889e+02 -1.24673889e+02]\n",
      "   [ 6.19116325e+01  6.19116325e+01  6.19116325e+01 ...  6.19116325e+01\n",
      "     6.19116325e+01  6.19116325e+01]\n",
      "   [-7.19311447e+01 -7.19311447e+01 -7.19311447e+01 ... -7.19311447e+01\n",
      "    -7.19311447e+01 -7.19311447e+01]]\n",
      "\n",
      "  [[-1.12900421e+02 -1.12900421e+02 -1.12900421e+02 ... -1.12900421e+02\n",
      "    -1.12900421e+02 -1.12900421e+02]\n",
      "   [-1.10641861e+01 -1.10641861e+01 -1.10641861e+01 ... -1.10641861e+01\n",
      "    -1.10641861e+01 -1.10641861e+01]\n",
      "   [-4.78104820e+01 -4.78104820e+01 -4.78104820e+01 ... -4.78104820e+01\n",
      "    -4.78104820e+01 -4.78104820e+01]\n",
      "   ...\n",
      "   [-1.48546387e+02 -1.48546387e+02 -1.48546387e+02 ... -1.48546387e+02\n",
      "    -1.48546387e+02 -1.48546387e+02]\n",
      "   [ 1.17091370e+02  1.17091370e+02  1.17091370e+02 ...  1.17091370e+02\n",
      "     1.17091370e+02  1.17091370e+02]\n",
      "   [-8.47998123e+01 -8.47998123e+01 -8.47998123e+01 ... -8.47998123e+01\n",
      "    -8.47998123e+01 -8.47998123e+01]]\n",
      "\n",
      "  [[-4.45975990e+01 -4.45975990e+01 -4.45975990e+01 ... -4.45975990e+01\n",
      "    -4.45975990e+01 -4.45975990e+01]\n",
      "   [ 7.07967567e+00  7.07967567e+00  7.07967567e+00 ...  7.07967567e+00\n",
      "     7.07967567e+00  7.07967567e+00]\n",
      "   [ 1.15620651e+01  1.15620651e+01  1.15620651e+01 ...  1.15620651e+01\n",
      "     1.15620651e+01  1.15620651e+01]\n",
      "   ...\n",
      "   [-1.26221176e+02 -1.26221176e+02 -1.26221176e+02 ... -1.26221176e+02\n",
      "    -1.26221176e+02 -1.26221176e+02]\n",
      "   [ 9.70882034e+01  9.70882034e+01  9.70882034e+01 ...  9.70882034e+01\n",
      "     9.70882034e+01  9.70882034e+01]\n",
      "   [-8.03393860e+01 -8.03393860e+01 -8.03393860e+01 ... -8.03393860e+01\n",
      "    -8.03393860e+01 -8.03393860e+01]]\n",
      "\n",
      "  [[-4.61898727e+01 -4.61898727e+01 -4.61898727e+01 ... -4.61898727e+01\n",
      "    -4.61898727e+01 -4.61898727e+01]\n",
      "   [ 3.04283905e+00  3.04283905e+00  3.04283905e+00 ...  3.04283905e+00\n",
      "     3.04283905e+00  3.04283905e+00]\n",
      "   [ 9.44609070e+00  9.44609070e+00  9.44609070e+00 ...  9.44609070e+00\n",
      "     9.44609070e+00  9.44609070e+00]\n",
      "   ...\n",
      "   [-1.36858246e+02 -1.36858246e+02 -1.36858246e+02 ... -1.36858246e+02\n",
      "    -1.36858246e+02 -1.36858246e+02]\n",
      "   [ 7.66677246e+01  7.66677246e+01  7.66677246e+01 ...  7.66677246e+01\n",
      "     7.66677246e+01  7.66677246e+01]\n",
      "   [-9.62865448e+01 -9.62865448e+01 -9.62865448e+01 ... -9.62865448e+01\n",
      "    -9.62865448e+01 -9.62865448e+01]]\n",
      "\n",
      "  [[-6.22673988e+00 -6.22673988e+00 -6.22673988e+00 ... -6.22673988e+00\n",
      "    -6.22673988e+00 -6.22673988e+00]\n",
      "   [ 1.91820450e+01  1.91820450e+01  1.91820450e+01 ...  1.91820450e+01\n",
      "     1.91820450e+01  1.91820450e+01]\n",
      "   [-9.85822296e+00 -9.85822296e+00 -9.85822296e+00 ... -9.85822296e+00\n",
      "    -9.85822296e+00 -9.85822296e+00]\n",
      "   ...\n",
      "   [-7.14098740e+01 -7.14098740e+01 -7.14098740e+01 ... -7.14098740e+01\n",
      "    -7.14098740e+01 -7.14098740e+01]\n",
      "   [ 4.94573364e+01  4.94573364e+01  4.94573364e+01 ...  4.94573364e+01\n",
      "     4.94573364e+01  4.94573364e+01]\n",
      "   [-1.89678497e+02 -1.89678497e+02 -1.89678497e+02 ... -1.89678497e+02\n",
      "    -1.89678497e+02 -1.89678497e+02]]]\n",
      "\n",
      "\n",
      " [[[-7.13851089e+01 -7.13851089e+01 -7.13851089e+01 ... -7.13851089e+01\n",
      "    -7.13851089e+01 -7.13851089e+01]\n",
      "   [ 4.19347305e+01  4.19347305e+01  4.19347305e+01 ...  4.19347305e+01\n",
      "     4.19347305e+01  4.19347305e+01]\n",
      "   [-4.58315659e+01 -4.58315659e+01 -4.58315659e+01 ... -4.58315659e+01\n",
      "    -4.58315659e+01 -4.58315659e+01]\n",
      "   ...\n",
      "   [-1.21203827e+02 -1.21203827e+02 -1.21203827e+02 ... -1.21203827e+02\n",
      "    -1.21203827e+02 -1.21203827e+02]\n",
      "   [ 7.28883133e+01  7.28883133e+01  7.28883133e+01 ...  7.28883133e+01\n",
      "     7.28883133e+01  7.28883133e+01]\n",
      "   [-2.14865799e+01 -2.14865799e+01 -2.14865799e+01 ... -2.14865799e+01\n",
      "    -2.14865799e+01 -2.14865799e+01]]\n",
      "\n",
      "  [[-7.61646957e+01 -7.61646957e+01 -7.61646957e+01 ... -7.61646957e+01\n",
      "    -7.61646957e+01 -7.61646957e+01]\n",
      "   [ 1.62770462e+01  1.62770462e+01  1.62770462e+01 ...  1.62770462e+01\n",
      "     1.62770462e+01  1.62770462e+01]\n",
      "   [-1.02499542e+01 -1.02499542e+01 -1.02499542e+01 ... -1.02499542e+01\n",
      "    -1.02499542e+01 -1.02499542e+01]\n",
      "   ...\n",
      "   [-1.29019180e+02 -1.29019180e+02 -1.29019180e+02 ... -1.29019180e+02\n",
      "    -1.29019180e+02 -1.29019180e+02]\n",
      "   [ 1.09344589e+02  1.09344589e+02  1.09344589e+02 ...  1.09344589e+02\n",
      "     1.09344589e+02  1.09344589e+02]\n",
      "   [-6.96123505e+01 -6.96123505e+01 -6.96123505e+01 ... -6.96123505e+01\n",
      "    -6.96123505e+01 -6.96123505e+01]]\n",
      "\n",
      "  [[-2.29666405e+01 -2.29666405e+01 -2.29666405e+01 ... -2.29666405e+01\n",
      "    -2.29666405e+01 -2.29666405e+01]\n",
      "   [ 2.46142731e+01  2.46142731e+01  2.46142731e+01 ...  2.46142731e+01\n",
      "     2.46142731e+01  2.46142731e+01]\n",
      "   [ 3.10823975e+01  3.10823975e+01  3.10823975e+01 ...  3.10823975e+01\n",
      "     3.10823975e+01  3.10823975e+01]\n",
      "   ...\n",
      "   [-1.14508492e+02 -1.14508492e+02 -1.14508492e+02 ... -1.14508492e+02\n",
      "    -1.14508492e+02 -1.14508492e+02]\n",
      "   [ 1.11675400e+02  1.11675400e+02  1.11675400e+02 ...  1.11675400e+02\n",
      "     1.11675400e+02  1.11675400e+02]\n",
      "   [-6.20354652e+01 -6.20354652e+01 -6.20354652e+01 ... -6.20354652e+01\n",
      "    -6.20354652e+01 -6.20354652e+01]]\n",
      "\n",
      "  [[-3.52518730e+01 -3.52518730e+01 -3.52518730e+01 ... -3.52518730e+01\n",
      "    -3.52518730e+01 -3.52518730e+01]\n",
      "   [ 1.19222536e+01  1.19222536e+01  1.19222536e+01 ...  1.19222536e+01\n",
      "     1.19222536e+01  1.19222536e+01]\n",
      "   [ 2.78897705e+01  2.78897705e+01  2.78897705e+01 ...  2.78897705e+01\n",
      "     2.78897705e+01  2.78897705e+01]\n",
      "   ...\n",
      "   [-1.23644325e+02 -1.23644325e+02 -1.23644325e+02 ... -1.23644325e+02\n",
      "    -1.23644325e+02 -1.23644325e+02]\n",
      "   [ 9.16775665e+01  9.16775665e+01  9.16775665e+01 ...  9.16775665e+01\n",
      "     9.16775665e+01  9.16775665e+01]\n",
      "   [-7.70715942e+01 -7.70715942e+01 -7.70715942e+01 ... -7.70715942e+01\n",
      "    -7.70715942e+01 -7.70715942e+01]]\n",
      "\n",
      "  [[-2.90821934e+00 -2.90821934e+00 -2.90821934e+00 ... -2.90821934e+00\n",
      "    -2.90821934e+00 -2.90821934e+00]\n",
      "   [ 1.50837154e+01  1.50837154e+01  1.50837154e+01 ...  1.50837154e+01\n",
      "     1.50837154e+01  1.50837154e+01]\n",
      "   [ 1.51008606e-01  1.51008606e-01  1.51008606e-01 ...  1.51008606e-01\n",
      "     1.51008606e-01  1.51008606e-01]\n",
      "   ...\n",
      "   [-7.35042648e+01 -7.35042648e+01 -7.35042648e+01 ... -7.35042648e+01\n",
      "    -7.35042648e+01 -7.35042648e+01]\n",
      "   [ 8.44047699e+01  8.44047699e+01  8.44047699e+01 ...  8.44047699e+01\n",
      "     8.44047699e+01  8.44047699e+01]\n",
      "   [-1.77175781e+02 -1.77175781e+02 -1.77175781e+02 ... -1.77175781e+02\n",
      "    -1.77175781e+02 -1.77175781e+02]]]\n",
      "\n",
      "\n",
      " [[[-5.48747063e+01 -5.48747063e+01 -5.48747063e+01 ... -5.48747063e+01\n",
      "    -5.48747063e+01 -5.48747063e+01]\n",
      "   [ 6.71577225e+01  6.71577225e+01  6.71577225e+01 ...  6.71577225e+01\n",
      "     6.71577225e+01  6.71577225e+01]\n",
      "   [-8.42740936e+01 -8.42740936e+01 -8.42740936e+01 ... -8.42740936e+01\n",
      "    -8.42740936e+01 -8.42740936e+01]\n",
      "   ...\n",
      "   [-1.33038605e+02 -1.33038605e+02 -1.33038605e+02 ... -1.33038605e+02\n",
      "    -1.33038605e+02 -1.33038605e+02]\n",
      "   [ 2.63858604e+01  2.63858604e+01  2.63858604e+01 ...  2.63858604e+01\n",
      "     2.63858604e+01  2.63858604e+01]\n",
      "   [-1.84680748e+00 -1.84680748e+00 -1.84680748e+00 ... -1.84680748e+00\n",
      "    -1.84680748e+00 -1.84680748e+00]]\n",
      "\n",
      "  [[-7.81479187e+01 -7.81479187e+01 -7.81479187e+01 ... -7.81479187e+01\n",
      "    -7.81479187e+01 -7.81479187e+01]\n",
      "   [ 5.98763428e+01  5.98763428e+01  5.98763428e+01 ...  5.98763428e+01\n",
      "     5.98763428e+01  5.98763428e+01]\n",
      "   [-5.36792297e+01 -5.36792297e+01 -5.36792297e+01 ... -5.36792297e+01\n",
      "    -5.36792297e+01 -5.36792297e+01]\n",
      "   ...\n",
      "   [-1.45820892e+02 -1.45820892e+02 -1.45820892e+02 ... -1.45820892e+02\n",
      "    -1.45820892e+02 -1.45820892e+02]\n",
      "   [ 7.88428574e+01  7.88428574e+01  7.88428574e+01 ...  7.88428574e+01\n",
      "     7.88428574e+01  7.88428574e+01]\n",
      "   [-7.27277527e+01 -7.27277527e+01 -7.27277527e+01 ... -7.27277527e+01\n",
      "    -7.27277527e+01 -7.27277527e+01]]\n",
      "\n",
      "  [[-3.96777382e+01 -3.96777382e+01 -3.96777382e+01 ... -3.96777382e+01\n",
      "    -3.96777382e+01 -3.96777382e+01]\n",
      "   [ 6.11086349e+01  6.11086349e+01  6.11086349e+01 ...  6.11086349e+01\n",
      "     6.11086349e+01  6.11086349e+01]\n",
      "   [-1.43451614e+01 -1.43451614e+01 -1.43451614e+01 ... -1.43451614e+01\n",
      "    -1.43451614e+01 -1.43451614e+01]\n",
      "   ...\n",
      "   [-1.30441879e+02 -1.30441879e+02 -1.30441879e+02 ... -1.30441879e+02\n",
      "    -1.30441879e+02 -1.30441879e+02]\n",
      "   [ 1.08515823e+02  1.08515823e+02  1.08515823e+02 ...  1.08515823e+02\n",
      "     1.08515823e+02  1.08515823e+02]\n",
      "   [-5.35747337e+01 -5.35747337e+01 -5.35747337e+01 ... -5.35747337e+01\n",
      "    -5.35747337e+01 -5.35747337e+01]]\n",
      "\n",
      "  [[-4.10589294e+01 -4.10589294e+01 -4.10589294e+01 ... -4.10589294e+01\n",
      "    -4.10589294e+01 -4.10589294e+01]\n",
      "   [ 4.04711456e+01  4.04711456e+01  4.04711456e+01 ...  4.04711456e+01\n",
      "     4.04711456e+01  4.04711456e+01]\n",
      "   [-1.92358284e+01 -1.92358284e+01 -1.92358284e+01 ... -1.92358284e+01\n",
      "    -1.92358284e+01 -1.92358284e+01]\n",
      "   ...\n",
      "   [-1.45154953e+02 -1.45154953e+02 -1.45154953e+02 ... -1.45154953e+02\n",
      "    -1.45154953e+02 -1.45154953e+02]\n",
      "   [ 7.30680237e+01  7.30680237e+01  7.30680237e+01 ...  7.30680237e+01\n",
      "     7.30680237e+01  7.30680237e+01]\n",
      "   [-5.29791145e+01 -5.29791145e+01 -5.29791145e+01 ... -5.29791145e+01\n",
      "    -5.29791145e+01 -5.29791145e+01]]\n",
      "\n",
      "  [[ 3.63612270e+00  3.63612270e+00  3.63612270e+00 ...  3.63612270e+00\n",
      "     3.63612270e+00  3.63612270e+00]\n",
      "   [ 5.11792603e+01  5.11792603e+01  5.11792603e+01 ...  5.11792603e+01\n",
      "     5.11792603e+01  5.11792603e+01]\n",
      "   [-3.99396896e+01 -3.99396896e+01 -3.99396896e+01 ... -3.99396896e+01\n",
      "    -3.99396896e+01 -3.99396896e+01]\n",
      "   ...\n",
      "   [-9.13451843e+01 -9.13451843e+01 -9.13451843e+01 ... -9.13451843e+01\n",
      "    -9.13451843e+01 -9.13451843e+01]\n",
      "   [ 6.85575409e+01  6.85575409e+01  6.85575409e+01 ...  6.85575409e+01\n",
      "     6.85575409e+01  6.85575409e+01]\n",
      "   [-1.46652435e+02 -1.46652435e+02 -1.46652435e+02 ... -1.46652435e+02\n",
      "    -1.46652435e+02 -1.46652435e+02]]]], W.grad.numpy(): [[[[-1.16245270e+02 -1.16245270e+02 -1.16245270e+02 ... -1.16245270e+02\n",
      "    -1.16245270e+02 -1.16245270e+02]\n",
      "   [-3.44621201e+01 -3.44621201e+01 -3.44621201e+01 ... -3.44621201e+01\n",
      "    -3.44621201e+01 -3.44621201e+01]\n",
      "   [-1.64758835e+02 -1.64758835e+02 -1.64758835e+02 ... -1.64758835e+02\n",
      "    -1.64758835e+02 -1.64758835e+02]\n",
      "   ...\n",
      "   [-3.16865616e+01 -3.16865616e+01 -3.16865616e+01 ... -3.16865616e+01\n",
      "    -3.16865616e+01 -3.16865616e+01]\n",
      "   [ 8.40804901e+01  8.40804901e+01  8.40804901e+01 ...  8.40804901e+01\n",
      "     8.40804901e+01  8.40804901e+01]\n",
      "   [-9.92724228e+01 -9.92724228e+01 -9.92724228e+01 ... -9.92724228e+01\n",
      "    -9.92724228e+01 -9.92724228e+01]]\n",
      "\n",
      "  [[-1.12383057e+02 -1.12383057e+02 -1.12383057e+02 ... -1.12383057e+02\n",
      "    -1.12383057e+02 -1.12383057e+02]\n",
      "   [-2.81658459e+01 -2.81658459e+01 -2.81658459e+01 ... -2.81658459e+01\n",
      "    -2.81658459e+01 -2.81658459e+01]\n",
      "   [-1.70100220e+02 -1.70100220e+02 -1.70100220e+02 ... -1.70100220e+02\n",
      "    -1.70100220e+02 -1.70100220e+02]\n",
      "   ...\n",
      "   [-1.26563616e+01 -1.26563616e+01 -1.26563616e+01 ... -1.26563616e+01\n",
      "    -1.26563616e+01 -1.26563616e+01]\n",
      "   [ 1.16309853e+02  1.16309853e+02  1.16309853e+02 ...  1.16309853e+02\n",
      "     1.16309853e+02  1.16309853e+02]\n",
      "   [-9.04269562e+01 -9.04269562e+01 -9.04269562e+01 ... -9.04269562e+01\n",
      "    -9.04269562e+01 -9.04269562e+01]]\n",
      "\n",
      "  [[-5.86222191e+01 -5.86222191e+01 -5.86222191e+01 ... -5.86222191e+01\n",
      "    -5.86222191e+01 -5.86222191e+01]\n",
      "   [ 2.15059662e+00  2.15059662e+00  2.15059662e+00 ...  2.15059662e+00\n",
      "     2.15059662e+00  2.15059662e+00]\n",
      "   [-9.45261765e+01 -9.45261765e+01 -9.45261765e+01 ... -9.45261765e+01\n",
      "    -9.45261765e+01 -9.45261765e+01]\n",
      "   ...\n",
      "   [-1.06377125e+01 -1.06377125e+01 -1.06377125e+01 ... -1.06377125e+01\n",
      "    -1.06377125e+01 -1.06377125e+01]\n",
      "   [ 8.25016479e+01  8.25016479e+01  8.25016479e+01 ...  8.25016479e+01\n",
      "     8.25016479e+01  8.25016479e+01]\n",
      "   [-8.38581696e+01 -8.38581696e+01 -8.38581696e+01 ... -8.38581696e+01\n",
      "    -8.38581696e+01 -8.38581696e+01]]\n",
      "\n",
      "  [[-6.70073318e+01 -6.70073318e+01 -6.70073318e+01 ... -6.70073318e+01\n",
      "    -6.70073318e+01 -6.70073318e+01]\n",
      "   [ 4.87926006e-01  4.87926006e-01  4.87926006e-01 ...  4.87926006e-01\n",
      "     4.87926006e-01  4.87926006e-01]\n",
      "   [-8.68875809e+01 -8.68875809e+01 -8.68875809e+01 ... -8.68875809e+01\n",
      "    -8.68875809e+01 -8.68875809e+01]\n",
      "   ...\n",
      "   [-1.43081293e+01 -1.43081293e+01 -1.43081293e+01 ... -1.43081293e+01\n",
      "    -1.43081293e+01 -1.43081293e+01]\n",
      "   [ 3.96485748e+01  3.96485748e+01  3.96485748e+01 ...  3.96485748e+01\n",
      "     3.96485748e+01  3.96485748e+01]\n",
      "   [-1.05648605e+02 -1.05648605e+02 -1.05648605e+02 ... -1.05648605e+02\n",
      "    -1.05648605e+02 -1.05648605e+02]]\n",
      "\n",
      "  [[-5.62348061e+01 -5.62348061e+01 -5.62348061e+01 ... -5.62348061e+01\n",
      "    -5.62348061e+01 -5.62348061e+01]\n",
      "   [ 2.50358467e+01  2.50358467e+01  2.50358467e+01 ...  2.50358467e+01\n",
      "     2.50358467e+01  2.50358467e+01]\n",
      "   [-9.68896790e+01 -9.68896790e+01 -9.68896790e+01 ... -9.68896790e+01\n",
      "    -9.68896790e+01 -9.68896790e+01]\n",
      "   ...\n",
      "   [-1.26439657e+01 -1.26439657e+01 -1.26439657e+01 ... -1.26439657e+01\n",
      "    -1.26439657e+01 -1.26439657e+01]\n",
      "   [ 1.62705123e+00  1.62705123e+00  1.62705123e+00 ...  1.62705123e+00\n",
      "     1.62705123e+00  1.62705123e+00]\n",
      "   [-1.81934006e+02 -1.81934006e+02 -1.81934006e+02 ... -1.81934006e+02\n",
      "    -1.81934006e+02 -1.81934006e+02]]]\n",
      "\n",
      "\n",
      " [[[-1.17615143e+02 -1.17615143e+02 -1.17615143e+02 ... -1.17615143e+02\n",
      "    -1.17615143e+02 -1.17615143e+02]\n",
      "   [ 5.95184326e+00  5.95184326e+00  5.95184326e+00 ...  5.95184326e+00\n",
      "     5.95184326e+00  5.95184326e+00]\n",
      "   [-8.92560120e+01 -8.92560120e+01 -8.92560120e+01 ... -8.92560120e+01\n",
      "    -8.92560120e+01 -8.92560120e+01]\n",
      "   ...\n",
      "   [-1.20959198e+02 -1.20959198e+02 -1.20959198e+02 ... -1.20959198e+02\n",
      "    -1.20959198e+02 -1.20959198e+02]\n",
      "   [ 1.06997864e+02  1.06997864e+02  1.06997864e+02 ...  1.06997864e+02\n",
      "     1.06997864e+02  1.06997864e+02]\n",
      "   [-5.44203606e+01 -5.44203606e+01 -5.44203606e+01 ... -5.44203606e+01\n",
      "    -5.44203606e+01 -5.44203606e+01]]\n",
      "\n",
      "  [[-1.07529015e+02 -1.07529015e+02 -1.07529015e+02 ... -1.07529015e+02\n",
      "    -1.07529015e+02 -1.07529015e+02]\n",
      "   [-2.63620720e+01 -2.63620720e+01 -2.63620720e+01 ... -2.63620720e+01\n",
      "    -2.63620720e+01 -2.63620720e+01]\n",
      "   [-8.02586517e+01 -8.02586517e+01 -8.02586517e+01 ... -8.02586517e+01\n",
      "    -8.02586517e+01 -8.02586517e+01]\n",
      "   ...\n",
      "   [-1.30162415e+02 -1.30162415e+02 -1.30162415e+02 ... -1.30162415e+02\n",
      "    -1.30162415e+02 -1.30162415e+02]\n",
      "   [ 1.58434586e+02  1.58434586e+02  1.58434586e+02 ...  1.58434586e+02\n",
      "     1.58434586e+02  1.58434586e+02]\n",
      "   [-5.02669182e+01 -5.02669182e+01 -5.02669182e+01 ... -5.02669182e+01\n",
      "    -5.02669182e+01 -5.02669182e+01]]\n",
      "\n",
      "  [[-3.91359596e+01 -3.91359596e+01 -3.91359596e+01 ... -3.91359596e+01\n",
      "    -3.91359596e+01 -3.91359596e+01]\n",
      "   [ 2.53129139e+01  2.53129139e+01  2.53129139e+01 ...  2.53129139e+01\n",
      "     2.53129139e+01  2.53129139e+01]\n",
      "   [-7.78604126e+00 -7.78604126e+00 -7.78604126e+00 ... -7.78604126e+00\n",
      "    -7.78604126e+00 -7.78604126e+00]\n",
      "   ...\n",
      "   [-1.23830452e+02 -1.23830452e+02 -1.23830452e+02 ... -1.23830452e+02\n",
      "    -1.23830452e+02 -1.23830452e+02]\n",
      "   [ 1.20911415e+02  1.20911415e+02  1.20911415e+02 ...  1.20911415e+02\n",
      "     1.20911415e+02  1.20911415e+02]\n",
      "   [-5.19391327e+01 -5.19391327e+01 -5.19391327e+01 ... -5.19391327e+01\n",
      "    -5.19391327e+01 -5.19391327e+01]]\n",
      "\n",
      "  [[-4.20618248e+01 -4.20618248e+01 -4.20618248e+01 ... -4.20618248e+01\n",
      "    -4.20618248e+01 -4.20618248e+01]\n",
      "   [ 1.26868229e+01  1.26868229e+01  1.26868229e+01 ...  1.26868229e+01\n",
      "     1.26868229e+01  1.26868229e+01]\n",
      "   [-2.25820465e+01 -2.25820465e+01 -2.25820465e+01 ... -2.25820465e+01\n",
      "    -2.25820465e+01 -2.25820465e+01]\n",
      "   ...\n",
      "   [-9.31390533e+01 -9.31390533e+01 -9.31390533e+01 ... -9.31390533e+01\n",
      "    -9.31390533e+01 -9.31390533e+01]\n",
      "   [ 1.04962318e+02  1.04962318e+02  1.04962318e+02 ...  1.04962318e+02\n",
      "     1.04962318e+02  1.04962318e+02]\n",
      "   [-7.80756378e+01 -7.80756378e+01 -7.80756378e+01 ... -7.80756378e+01\n",
      "    -7.80756378e+01 -7.80756378e+01]]\n",
      "\n",
      "  [[-1.09563522e+01 -1.09563522e+01 -1.09563522e+01 ... -1.09563522e+01\n",
      "    -1.09563522e+01 -1.09563522e+01]\n",
      "   [ 3.37870750e+01  3.37870750e+01  3.37870750e+01 ...  3.37870750e+01\n",
      "     3.37870750e+01  3.37870750e+01]\n",
      "   [-1.52067833e+01 -1.52067833e+01 -1.52067833e+01 ... -1.52067833e+01\n",
      "    -1.52067833e+01 -1.52067833e+01]\n",
      "   ...\n",
      "   [-6.06810684e+01 -6.06810684e+01 -6.06810684e+01 ... -6.06810684e+01\n",
      "    -6.06810684e+01 -6.06810684e+01]\n",
      "   [ 4.86012497e+01  4.86012497e+01  4.86012497e+01 ...  4.86012497e+01\n",
      "     4.86012497e+01  4.86012497e+01]\n",
      "   [-1.48817474e+02 -1.48817474e+02 -1.48817474e+02 ... -1.48817474e+02\n",
      "    -1.48817474e+02 -1.48817474e+02]]]\n",
      "\n",
      "\n",
      " [[[-1.26848717e+02 -1.26848717e+02 -1.26848717e+02 ... -1.26848717e+02\n",
      "    -1.26848717e+02 -1.26848717e+02]\n",
      "   [ 1.36254711e+01  1.36254711e+01  1.36254711e+01 ...  1.36254711e+01\n",
      "     1.36254711e+01  1.36254711e+01]\n",
      "   [-7.57005386e+01 -7.57005386e+01 -7.57005386e+01 ... -7.57005386e+01\n",
      "    -7.57005386e+01 -7.57005386e+01]\n",
      "   ...\n",
      "   [-1.24673882e+02 -1.24673882e+02 -1.24673882e+02 ... -1.24673882e+02\n",
      "    -1.24673882e+02 -1.24673882e+02]\n",
      "   [ 6.19115868e+01  6.19115868e+01  6.19115868e+01 ...  6.19115868e+01\n",
      "     6.19115868e+01  6.19115868e+01]\n",
      "   [-7.19311523e+01 -7.19311523e+01 -7.19311523e+01 ... -7.19311523e+01\n",
      "    -7.19311523e+01 -7.19311523e+01]]\n",
      "\n",
      "  [[-1.12900391e+02 -1.12900391e+02 -1.12900391e+02 ... -1.12900391e+02\n",
      "    -1.12900391e+02 -1.12900391e+02]\n",
      "   [-1.10641861e+01 -1.10641861e+01 -1.10641861e+01 ... -1.10641861e+01\n",
      "    -1.10641861e+01 -1.10641861e+01]\n",
      "   [-4.78105011e+01 -4.78105011e+01 -4.78105011e+01 ... -4.78105011e+01\n",
      "    -4.78105011e+01 -4.78105011e+01]\n",
      "   ...\n",
      "   [-1.48546432e+02 -1.48546432e+02 -1.48546432e+02 ... -1.48546432e+02\n",
      "    -1.48546432e+02 -1.48546432e+02]\n",
      "   [ 1.17091347e+02  1.17091347e+02  1.17091347e+02 ...  1.17091347e+02\n",
      "     1.17091347e+02  1.17091347e+02]\n",
      "   [-8.47998199e+01 -8.47998199e+01 -8.47998199e+01 ... -8.47998199e+01\n",
      "    -8.47998199e+01 -8.47998199e+01]]\n",
      "\n",
      "  [[-4.45975952e+01 -4.45975952e+01 -4.45975952e+01 ... -4.45975952e+01\n",
      "    -4.45975952e+01 -4.45975952e+01]\n",
      "   [ 7.07967281e+00  7.07967281e+00  7.07967281e+00 ...  7.07967281e+00\n",
      "     7.07967281e+00  7.07967281e+00]\n",
      "   [ 1.15620632e+01  1.15620632e+01  1.15620632e+01 ...  1.15620632e+01\n",
      "     1.15620632e+01  1.15620632e+01]\n",
      "   ...\n",
      "   [-1.26221176e+02 -1.26221176e+02 -1.26221176e+02 ... -1.26221176e+02\n",
      "    -1.26221176e+02 -1.26221176e+02]\n",
      "   [ 9.70881882e+01  9.70881882e+01  9.70881882e+01 ...  9.70881882e+01\n",
      "     9.70881882e+01  9.70881882e+01]\n",
      "   [-8.03393402e+01 -8.03393402e+01 -8.03393402e+01 ... -8.03393402e+01\n",
      "    -8.03393402e+01 -8.03393402e+01]]\n",
      "\n",
      "  [[-4.61899071e+01 -4.61899071e+01 -4.61899071e+01 ... -4.61899071e+01\n",
      "    -4.61899071e+01 -4.61899071e+01]\n",
      "   [ 3.04286289e+00  3.04286289e+00  3.04286289e+00 ...  3.04286289e+00\n",
      "     3.04286289e+00  3.04286289e+00]\n",
      "   [ 9.44606209e+00  9.44606209e+00  9.44606209e+00 ...  9.44606209e+00\n",
      "     9.44606209e+00  9.44606209e+00]\n",
      "   ...\n",
      "   [-1.36858292e+02 -1.36858292e+02 -1.36858292e+02 ... -1.36858292e+02\n",
      "    -1.36858292e+02 -1.36858292e+02]\n",
      "   [ 7.66677399e+01  7.66677399e+01  7.66677399e+01 ...  7.66677399e+01\n",
      "     7.66677399e+01  7.66677399e+01]\n",
      "   [-9.62865601e+01 -9.62865601e+01 -9.62865601e+01 ... -9.62865601e+01\n",
      "    -9.62865601e+01 -9.62865601e+01]]\n",
      "\n",
      "  [[-6.22671700e+00 -6.22671700e+00 -6.22671700e+00 ... -6.22671700e+00\n",
      "    -6.22671700e+00 -6.22671700e+00]\n",
      "   [ 1.91820202e+01  1.91820202e+01  1.91820202e+01 ...  1.91820202e+01\n",
      "     1.91820202e+01  1.91820202e+01]\n",
      "   [-9.85820389e+00 -9.85820389e+00 -9.85820389e+00 ... -9.85820389e+00\n",
      "    -9.85820389e+00 -9.85820389e+00]\n",
      "   ...\n",
      "   [-7.14098663e+01 -7.14098663e+01 -7.14098663e+01 ... -7.14098663e+01\n",
      "    -7.14098663e+01 -7.14098663e+01]\n",
      "   [ 4.94573631e+01  4.94573631e+01  4.94573631e+01 ...  4.94573631e+01\n",
      "     4.94573631e+01  4.94573631e+01]\n",
      "   [-1.89678574e+02 -1.89678574e+02 -1.89678574e+02 ... -1.89678574e+02\n",
      "    -1.89678574e+02 -1.89678574e+02]]]\n",
      "\n",
      "\n",
      " [[[-7.13851395e+01 -7.13851395e+01 -7.13851395e+01 ... -7.13851395e+01\n",
      "    -7.13851395e+01 -7.13851395e+01]\n",
      "   [ 4.19347229e+01  4.19347229e+01  4.19347229e+01 ...  4.19347229e+01\n",
      "     4.19347229e+01  4.19347229e+01]\n",
      "   [-4.58315964e+01 -4.58315964e+01 -4.58315964e+01 ... -4.58315964e+01\n",
      "    -4.58315964e+01 -4.58315964e+01]\n",
      "   ...\n",
      "   [-1.21203835e+02 -1.21203835e+02 -1.21203835e+02 ... -1.21203835e+02\n",
      "    -1.21203835e+02 -1.21203835e+02]\n",
      "   [ 7.28882828e+01  7.28882828e+01  7.28882828e+01 ...  7.28882828e+01\n",
      "     7.28882828e+01  7.28882828e+01]\n",
      "   [-2.14865780e+01 -2.14865780e+01 -2.14865780e+01 ... -2.14865780e+01\n",
      "    -2.14865780e+01 -2.14865780e+01]]\n",
      "\n",
      "  [[-7.61646957e+01 -7.61646957e+01 -7.61646957e+01 ... -7.61646957e+01\n",
      "    -7.61646957e+01 -7.61646957e+01]\n",
      "   [ 1.62770348e+01  1.62770348e+01  1.62770348e+01 ...  1.62770348e+01\n",
      "     1.62770348e+01  1.62770348e+01]\n",
      "   [-1.02499657e+01 -1.02499657e+01 -1.02499657e+01 ... -1.02499657e+01\n",
      "    -1.02499657e+01 -1.02499657e+01]\n",
      "   ...\n",
      "   [-1.29019150e+02 -1.29019150e+02 -1.29019150e+02 ... -1.29019150e+02\n",
      "    -1.29019150e+02 -1.29019150e+02]\n",
      "   [ 1.09344612e+02  1.09344612e+02  1.09344612e+02 ...  1.09344612e+02\n",
      "     1.09344612e+02  1.09344612e+02]\n",
      "   [-6.96123047e+01 -6.96123047e+01 -6.96123047e+01 ... -6.96123047e+01\n",
      "    -6.96123047e+01 -6.96123047e+01]]\n",
      "\n",
      "  [[-2.29666557e+01 -2.29666557e+01 -2.29666557e+01 ... -2.29666557e+01\n",
      "    -2.29666557e+01 -2.29666557e+01]\n",
      "   [ 2.46142788e+01  2.46142788e+01  2.46142788e+01 ...  2.46142788e+01\n",
      "     2.46142788e+01  2.46142788e+01]\n",
      "   [ 3.10823860e+01  3.10823860e+01  3.10823860e+01 ...  3.10823860e+01\n",
      "     3.10823860e+01  3.10823860e+01]\n",
      "   ...\n",
      "   [-1.14508507e+02 -1.14508507e+02 -1.14508507e+02 ... -1.14508507e+02\n",
      "    -1.14508507e+02 -1.14508507e+02]\n",
      "   [ 1.11675385e+02  1.11675385e+02  1.11675385e+02 ...  1.11675385e+02\n",
      "     1.11675385e+02  1.11675385e+02]\n",
      "   [-6.20354843e+01 -6.20354843e+01 -6.20354843e+01 ... -6.20354843e+01\n",
      "    -6.20354843e+01 -6.20354843e+01]]\n",
      "\n",
      "  [[-3.52519035e+01 -3.52519035e+01 -3.52519035e+01 ... -3.52519035e+01\n",
      "    -3.52519035e+01 -3.52519035e+01]\n",
      "   [ 1.19222498e+01  1.19222498e+01  1.19222498e+01 ...  1.19222498e+01\n",
      "     1.19222498e+01  1.19222498e+01]\n",
      "   [ 2.78897743e+01  2.78897743e+01  2.78897743e+01 ...  2.78897743e+01\n",
      "     2.78897743e+01  2.78897743e+01]\n",
      "   ...\n",
      "   [-1.23644302e+02 -1.23644302e+02 -1.23644302e+02 ... -1.23644302e+02\n",
      "    -1.23644302e+02 -1.23644302e+02]\n",
      "   [ 9.16775131e+01  9.16775131e+01  9.16775131e+01 ...  9.16775131e+01\n",
      "     9.16775131e+01  9.16775131e+01]\n",
      "   [-7.70716171e+01 -7.70716171e+01 -7.70716171e+01 ... -7.70716171e+01\n",
      "    -7.70716171e+01 -7.70716171e+01]]\n",
      "\n",
      "  [[-2.90820122e+00 -2.90820122e+00 -2.90820122e+00 ... -2.90820122e+00\n",
      "    -2.90820122e+00 -2.90820122e+00]\n",
      "   [ 1.50837240e+01  1.50837240e+01  1.50837240e+01 ...  1.50837240e+01\n",
      "     1.50837240e+01  1.50837240e+01]\n",
      "   [ 1.50992870e-01  1.50992870e-01  1.50992870e-01 ...  1.50992870e-01\n",
      "     1.50992870e-01  1.50992870e-01]\n",
      "   ...\n",
      "   [-7.35042877e+01 -7.35042877e+01 -7.35042877e+01 ... -7.35042877e+01\n",
      "    -7.35042877e+01 -7.35042877e+01]\n",
      "   [ 8.44047775e+01  8.44047775e+01  8.44047775e+01 ...  8.44047775e+01\n",
      "     8.44047775e+01  8.44047775e+01]\n",
      "   [-1.77175797e+02 -1.77175797e+02 -1.77175797e+02 ... -1.77175797e+02\n",
      "    -1.77175797e+02 -1.77175797e+02]]]\n",
      "\n",
      "\n",
      " [[[-5.48747063e+01 -5.48747063e+01 -5.48747063e+01 ... -5.48747063e+01\n",
      "    -5.48747063e+01 -5.48747063e+01]\n",
      "   [ 6.71577148e+01  6.71577148e+01  6.71577148e+01 ...  6.71577148e+01\n",
      "     6.71577148e+01  6.71577148e+01]\n",
      "   [-8.42740784e+01 -8.42740784e+01 -8.42740784e+01 ... -8.42740784e+01\n",
      "    -8.42740784e+01 -8.42740784e+01]\n",
      "   ...\n",
      "   [-1.33038651e+02 -1.33038651e+02 -1.33038651e+02 ... -1.33038651e+02\n",
      "    -1.33038651e+02 -1.33038651e+02]\n",
      "   [ 2.63858166e+01  2.63858166e+01  2.63858166e+01 ...  2.63858166e+01\n",
      "     2.63858166e+01  2.63858166e+01]\n",
      "   [-1.84679961e+00 -1.84679961e+00 -1.84679961e+00 ... -1.84679961e+00\n",
      "    -1.84679961e+00 -1.84679961e+00]]\n",
      "\n",
      "  [[-7.81479187e+01 -7.81479187e+01 -7.81479187e+01 ... -7.81479187e+01\n",
      "    -7.81479187e+01 -7.81479187e+01]\n",
      "   [ 5.98763008e+01  5.98763008e+01  5.98763008e+01 ...  5.98763008e+01\n",
      "     5.98763008e+01  5.98763008e+01]\n",
      "   [-5.36792336e+01 -5.36792336e+01 -5.36792336e+01 ... -5.36792336e+01\n",
      "    -5.36792336e+01 -5.36792336e+01]\n",
      "   ...\n",
      "   [-1.45820877e+02 -1.45820877e+02 -1.45820877e+02 ... -1.45820877e+02\n",
      "    -1.45820877e+02 -1.45820877e+02]\n",
      "   [ 7.88428955e+01  7.88428955e+01  7.88428955e+01 ...  7.88428955e+01\n",
      "     7.88428955e+01  7.88428955e+01]\n",
      "   [-7.27277527e+01 -7.27277527e+01 -7.27277527e+01 ... -7.27277527e+01\n",
      "    -7.27277527e+01 -7.27277527e+01]]\n",
      "\n",
      "  [[-3.96777382e+01 -3.96777382e+01 -3.96777382e+01 ... -3.96777382e+01\n",
      "    -3.96777382e+01 -3.96777382e+01]\n",
      "   [ 6.11086273e+01  6.11086273e+01  6.11086273e+01 ...  6.11086273e+01\n",
      "     6.11086273e+01  6.11086273e+01]\n",
      "   [-1.43451614e+01 -1.43451614e+01 -1.43451614e+01 ... -1.43451614e+01\n",
      "    -1.43451614e+01 -1.43451614e+01]\n",
      "   ...\n",
      "   [-1.30441895e+02 -1.30441895e+02 -1.30441895e+02 ... -1.30441895e+02\n",
      "    -1.30441895e+02 -1.30441895e+02]\n",
      "   [ 1.08515816e+02  1.08515816e+02  1.08515816e+02 ...  1.08515816e+02\n",
      "     1.08515816e+02  1.08515816e+02]\n",
      "   [-5.35747871e+01 -5.35747871e+01 -5.35747871e+01 ... -5.35747871e+01\n",
      "    -5.35747871e+01 -5.35747871e+01]]\n",
      "\n",
      "  [[-4.10589485e+01 -4.10589485e+01 -4.10589485e+01 ... -4.10589485e+01\n",
      "    -4.10589485e+01 -4.10589485e+01]\n",
      "   [ 4.04711304e+01  4.04711304e+01  4.04711304e+01 ...  4.04711304e+01\n",
      "     4.04711304e+01  4.04711304e+01]\n",
      "   [-1.92358437e+01 -1.92358437e+01 -1.92358437e+01 ... -1.92358437e+01\n",
      "    -1.92358437e+01 -1.92358437e+01]\n",
      "   ...\n",
      "   [-1.45154907e+02 -1.45154907e+02 -1.45154907e+02 ... -1.45154907e+02\n",
      "    -1.45154907e+02 -1.45154907e+02]\n",
      "   [ 7.30679855e+01  7.30679855e+01  7.30679855e+01 ...  7.30679855e+01\n",
      "     7.30679855e+01  7.30679855e+01]\n",
      "   [-5.29791298e+01 -5.29791298e+01 -5.29791298e+01 ... -5.29791298e+01\n",
      "    -5.29791298e+01 -5.29791298e+01]]\n",
      "\n",
      "  [[ 3.63614941e+00  3.63614941e+00  3.63614941e+00 ...  3.63614941e+00\n",
      "     3.63614941e+00  3.63614941e+00]\n",
      "   [ 5.11792679e+01  5.11792679e+01  5.11792679e+01 ...  5.11792679e+01\n",
      "     5.11792679e+01  5.11792679e+01]\n",
      "   [-3.99397011e+01 -3.99397011e+01 -3.99397011e+01 ... -3.99397011e+01\n",
      "    -3.99397011e+01 -3.99397011e+01]\n",
      "   ...\n",
      "   [-9.13452225e+01 -9.13452225e+01 -9.13452225e+01 ... -9.13452225e+01\n",
      "    -9.13452225e+01 -9.13452225e+01]\n",
      "   [ 6.85575027e+01  6.85575027e+01  6.85575027e+01 ...  6.85575027e+01\n",
      "     6.85575027e+01  6.85575027e+01]\n",
      "   [-1.46652481e+02 -1.46652481e+02 -1.46652481e+02 ... -1.46652481e+02\n",
      "    -1.46652481e+02 -1.46652481e+02]]]]\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape12-W_shape12-1-0] _\u001b[0m\n",
      "\n",
      "Z_shape = (3, 17, 17, 8), W_shape = (5, 5, 8, 16), stride = 1, padding = 0\n",
      "backward = True, device = cuda()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[ 5.93117094e+00 -4.61600447e+00 -7.43411541e+00 ...  9.49053860e+00\n",
      "     6.47611380e+00 -3.38525438e...7e+00]\n",
      "   [-3.93575430e+00 -6.98609781e+00  1.63659811e+00 ...  8.22474575e+00\n",
      "     2.56555057e+00  1.63004756e+00]]]])\n",
      "W_shape    = (5, 5, 8, 16)\n",
      "Wtch       = tensor([[[[ 5.9312e+00, -4.6160e+00, -7.4341e+00,  ...,  9.4905e+00,\n",
      "            6.4761e+00, -3.3853e+00],\n",
      "          [...[-3.9358e+00, -6.9861e+00,  1.6366e+00,  ...,  8.2247e+00,\n",
      "            2.5656e+00,  1.6300e+00]]]], requires_grad=True)\n",
      "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
      "     4.75044203e+00 -7.56786048e...8e+00]\n",
      "   [ 2.80155873e+00  3.11298299e+00 -3.24756050e+00 ... -7.96233535e-01\n",
      "     4.72636795e+00 -5.75466204e+00]]]])\n",
      "Z_shape    = (3, 17, 17, 8)\n",
      "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ..., -4.8864e+00,\n",
      "            4.7504e+00, -7.5679e-01],\n",
      "          [...[ 2.8016e+00,  3.1130e+00, -3.2476e+00,  ..., -7.9623e-01,\n",
      "            4.7264e+00, -5.7547e+00]]]], requires_grad=True)\n",
      "_W         = array([[[[ 5.93117094e+00, -4.61600447e+00, -7.43411541e+00, ...,\n",
      "           9.49053860e+00,  6.47611380e+00, -3.38525...11e+00, ...,\n",
      "           8.22474575e+00,  2.56555057e+00,  1.63004756e+00]]]],\n",
      "      shape=(5, 5, 8, 16), dtype=float32)\n",
      "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
      "          -4.88638926e+00,  4.75044203e+00, -7.56786...0e+00, ...,\n",
      "          -7.96233535e-01,  4.72636795e+00, -5.75466204e+00]]]],\n",
      "      shape=(3, 17, 17, 8), dtype=float32)\n",
      "backward   = True\n",
      "device     = cuda()\n",
      "err1       = np.float32(0.0016586707)\n",
      "err2       = np.float32(0.0030867655)\n",
      "out        = tensor([[[[ 5.8605e+02,  6.5851e+02,  3.1471e+01,  ..., -2.0572e+02,\n",
      "           -5.6982e+02, -7.7784e+02],\n",
      "          [...,  1.3106e+02, -3.2224e+02,  ...,  7.1755e+01,\n",
      "           -5.2006e+02, -6.5310e+01]]]], grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(50567.7344, grad_fn=<SumBackward0>)\n",
      "padding    = 0\n",
      "stride     = 1\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c5655c7530>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655c5e20>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655c5e20>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655c5e20>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655c5e20>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[  37.84839     37.84839     37.84839   ...   37.84839\n",
      "      37.84839     37.84839  ]\n",
      "   [ -33.60088    -33.60088    -33.60088   ...  -33.60088\n",
      "     -33.60088    -33.60088  ]\n",
      "   [ -36.00153    -36.00153    -36.00153   ...  -36.00153\n",
      "     -36.00153    -36.00153  ]\n",
      "   ...\n",
      "   [  36.27931     36.27931     36.27931   ...   36.27931\n",
      "      36.27931     36.27931  ]\n",
      "   [  -8.610425    -8.610425    -8.610425  ...   -8.610425\n",
      "      -8.610425    -8.610425 ]\n",
      "   [-214.67365   -214.67365   -214.67365   ... -214.67365\n",
      "    -214.67365   -214.67365  ]]\n",
      "\n",
      "  [[  45.22556     45.22556     45.22556   ...   45.22556\n",
      "      45.22556     45.22556  ]\n",
      "   [ -13.485558   -13.485558   -13.485558  ...  -13.485558\n",
      "     -13.485558   -13.485558 ]\n",
      "   [ -29.072964   -29.072964   -29.072964  ...  -29.072964\n",
      "     -29.072964   -29.072964 ]\n",
      "   ...\n",
      "   [  73.40308     73.40308     73.40308   ...   73.40308\n",
      "      73.40308     73.40308  ]\n",
      "   [ -15.808004   -15.808004   -15.808004  ...  -15.808004\n",
      "     -15.808004   -15.808004 ]\n",
      "   [-163.33002   -163.33002   -163.33002   ... -163.33002\n",
      "    -163.33002   -163.33002  ]]\n",
      "\n",
      "  [[  13.053932    13.053932    13.053932  ...   13.053932\n",
      "      13.053932    13.053932 ]\n",
      "   [ -78.65258    -78.65258    -78.65258   ...  -78.65258\n",
      "     -78.65258    -78.65258  ]\n",
      "   [  10.061691    10.061691    10.061691  ...   10.061691\n",
      "      10.061691    10.061691 ]\n",
      "   ...\n",
      "   [  -2.7422943   -2.7422943   -2.7422943 ...   -2.7422943\n",
      "      -2.7422943   -2.7422943]\n",
      "   [ -17.210348   -17.210348   -17.210348  ...  -17.210348\n",
      "     -17.210348   -17.210348 ]\n",
      "   [-192.476     -192.476     -192.476     ... -192.476\n",
      "    -192.476     -192.476    ]]\n",
      "\n",
      "  [[ -38.955643   -38.955643   -38.955643  ...  -38.955643\n",
      "     -38.955643   -38.955643 ]\n",
      "   [ -22.549774   -22.549774   -22.549774  ...  -22.549774\n",
      "     -22.549774   -22.549774 ]\n",
      "   [  -7.3511505   -7.3511505   -7.3511505 ...   -7.3511505\n",
      "      -7.3511505   -7.3511505]\n",
      "   ...\n",
      "   [ -11.800983   -11.800983   -11.800983  ...  -11.800983\n",
      "     -11.800983   -11.800983 ]\n",
      "   [   9.1125       9.1125       9.1125    ...    9.1125\n",
      "       9.1125       9.1125   ]\n",
      "   [-109.37804   -109.37804   -109.37804   ... -109.37804\n",
      "    -109.37804   -109.37804  ]]\n",
      "\n",
      "  [[ -47.215958   -47.215958   -47.215958  ...  -47.215958\n",
      "     -47.215958   -47.215958 ]\n",
      "   [  23.65165     23.65165     23.65165   ...   23.65165\n",
      "      23.65165     23.65165  ]\n",
      "   [ -58.59626    -58.59626    -58.59626   ...  -58.59626\n",
      "     -58.59626    -58.59626  ]\n",
      "   ...\n",
      "   [-122.06634   -122.06634   -122.06634   ... -122.06634\n",
      "    -122.06634   -122.06634  ]\n",
      "   [  -2.0951347   -2.0951347   -2.0951347 ...   -2.0951347\n",
      "      -2.0951347   -2.0951347]\n",
      "   [-111.00746   -111.00746   -111.00746   ... -111.00746\n",
      "    -111.00746   -111.00746  ]]]\n",
      "\n",
      "\n",
      " [[[  -1.2779949   -1.2779949   -1.2779949 ...   -1.2779949\n",
      "      -1.2779949   -1.2779949]\n",
      "   [  -7.0218735   -7.0218735   -7.0218735 ...   -7.0218735\n",
      "      -7.0218735   -7.0218735]\n",
      "   [ -64.33977    -64.33977    -64.33977   ...  -64.33977\n",
      "     -64.33977    -64.33977  ]\n",
      "   ...\n",
      "   [   7.7821045    7.7821045    7.7821045 ...    7.7821045\n",
      "       7.7821045    7.7821045]\n",
      "   [  36.20109     36.20109     36.20109   ...   36.20109\n",
      "      36.20109     36.20109  ]\n",
      "   [-186.4855    -186.4855    -186.4855    ... -186.4855\n",
      "    -186.4855    -186.4855   ]]\n",
      "\n",
      "  [[   7.297121     7.297121     7.297121  ...    7.297121\n",
      "       7.297121     7.297121 ]\n",
      "   [ -11.920391   -11.920391   -11.920391  ...  -11.920391\n",
      "     -11.920391   -11.920391 ]\n",
      "   [ -43.225067   -43.225067   -43.225067  ...  -43.225067\n",
      "     -43.225067   -43.225067 ]\n",
      "   ...\n",
      "   [  12.711544    12.711544    12.711544  ...   12.711544\n",
      "      12.711544    12.711544 ]\n",
      "   [  51.456886    51.456886    51.456886  ...   51.456886\n",
      "      51.456886    51.456886 ]\n",
      "   [-135.76584   -135.76584   -135.76584   ... -135.76584\n",
      "    -135.76584   -135.76584  ]]\n",
      "\n",
      "  [[ -23.308205   -23.308205   -23.308205  ...  -23.308205\n",
      "     -23.308205   -23.308205 ]\n",
      "   [ -53.463135   -53.463135   -53.463135  ...  -53.463135\n",
      "     -53.463135   -53.463135 ]\n",
      "   [ -13.30697    -13.30697    -13.30697   ...  -13.30697\n",
      "     -13.30697    -13.30697  ]\n",
      "   ...\n",
      "   [ -68.48101    -68.48101    -68.48101   ...  -68.48101\n",
      "     -68.48101    -68.48101  ]\n",
      "   [  37.520813    37.520813    37.520813  ...   37.520813\n",
      "      37.520813    37.520813 ]\n",
      "   [-172.19931   -172.19931   -172.19931   ... -172.19931\n",
      "    -172.19931   -172.19931  ]]\n",
      "\n",
      "  [[ -53.48913    -53.48913    -53.48913   ...  -53.48913\n",
      "     -53.48913    -53.48913  ]\n",
      "   [  20.761837    20.761837    20.761837  ...   20.761837\n",
      "      20.761837    20.761837 ]\n",
      "   [ -59.05236    -59.05236    -59.05236   ...  -59.05236\n",
      "     -59.05236    -59.05236  ]\n",
      "   ...\n",
      "   [ -64.18131    -64.18131    -64.18131   ...  -64.18131\n",
      "     -64.18131    -64.18131  ]\n",
      "   [  75.395935    75.395935    75.395935  ...   75.395935\n",
      "      75.395935    75.395935 ]\n",
      "   [-118.91438   -118.91438   -118.91438   ... -118.91438\n",
      "    -118.91438   -118.91438  ]]\n",
      "\n",
      "  [[ -44.630768   -44.630768   -44.630768  ...  -44.630768\n",
      "     -44.630768   -44.630768 ]\n",
      "   [  24.693897    24.693897    24.693897  ...   24.693897\n",
      "      24.693897    24.693897 ]\n",
      "   [ -92.68728    -92.68728    -92.68728   ...  -92.68728\n",
      "     -92.68728    -92.68728  ]\n",
      "   ...\n",
      "   [-154.33562   -154.33562   -154.33562   ... -154.33562\n",
      "    -154.33562   -154.33562  ]\n",
      "   [  35.56113     35.56113     35.56113   ...   35.56113\n",
      "      35.56113     35.56113  ]\n",
      "   [-142.5783    -142.5783    -142.5783    ... -142.5783\n",
      "    -142.5783    -142.5783   ]]]\n",
      "\n",
      "\n",
      " [[[  20.505566    20.505566    20.505566  ...   20.505566\n",
      "      20.505566    20.505566 ]\n",
      "   [  22.888199    22.888199    22.888199  ...   22.888199\n",
      "      22.888199    22.888199 ]\n",
      "   [-102.739334  -102.739334  -102.739334  ... -102.739334\n",
      "    -102.739334  -102.739334 ]\n",
      "   ...\n",
      "   [ -40.526775   -40.526775   -40.526775  ...  -40.526775\n",
      "     -40.526775   -40.526775 ]\n",
      "   [  55.49948     55.49948     55.49948   ...   55.49948\n",
      "      55.49948     55.49948  ]\n",
      "   [-166.16568   -166.16568   -166.16568   ... -166.16568\n",
      "    -166.16568   -166.16568  ]]\n",
      "\n",
      "  [[  32.04589     32.04589     32.04589   ...   32.04589\n",
      "      32.04589     32.04589  ]\n",
      "   [  39.361004    39.361004    39.361004  ...   39.361004\n",
      "      39.361004    39.361004 ]\n",
      "   [ -63.935757   -63.935757   -63.935757  ...  -63.935757\n",
      "     -63.935757   -63.935757 ]\n",
      "   ...\n",
      "   [  -9.228447    -9.228447    -9.228447  ...   -9.228447\n",
      "      -9.228447    -9.228447 ]\n",
      "   [  65.521286    65.521286    65.521286  ...   65.521286\n",
      "      65.521286    65.521286 ]\n",
      "   [-117.32037   -117.32037   -117.32037   ... -117.32037\n",
      "    -117.32037   -117.32037  ]]\n",
      "\n",
      "  [[  28.711174    28.711174    28.711174  ...   28.711174\n",
      "      28.711174    28.711174 ]\n",
      "   [   6.415102     6.415102     6.415102  ...    6.415102\n",
      "       6.415102     6.415102 ]\n",
      "   [ -72.76602    -72.76602    -72.76602   ...  -72.76602\n",
      "     -72.76602    -72.76602  ]\n",
      "   ...\n",
      "   [ -64.881874   -64.881874   -64.881874  ...  -64.881874\n",
      "     -64.881874   -64.881874 ]\n",
      "   [  25.8516      25.8516      25.8516    ...   25.8516\n",
      "      25.8516      25.8516   ]\n",
      "   [-133.74744   -133.74744   -133.74744   ... -133.74744\n",
      "    -133.74744   -133.74744  ]]\n",
      "\n",
      "  [[  26.208084    26.208084    26.208084  ...   26.208084\n",
      "      26.208084    26.208084 ]\n",
      "   [  67.0835      67.0835      67.0835    ...   67.0835\n",
      "      67.0835      67.0835   ]\n",
      "   [-117.0288    -117.0288    -117.0288    ... -117.0288\n",
      "    -117.0288    -117.0288   ]\n",
      "   ...\n",
      "   [ -53.710926   -53.710926   -53.710926  ...  -53.710926\n",
      "     -53.710926   -53.710926 ]\n",
      "   [  89.51799     89.51799     89.51799   ...   89.51799\n",
      "      89.51799     89.51799  ]\n",
      "   [-112.57427   -112.57427   -112.57427   ... -112.57427\n",
      "    -112.57427   -112.57427  ]]\n",
      "\n",
      "  [[  25.827133    25.827133    25.827133  ...   25.827133\n",
      "      25.827133    25.827133 ]\n",
      "   [  70.78707     70.78707     70.78707   ...   70.78707\n",
      "      70.78707     70.78707  ]\n",
      "   [-136.19943   -136.19943   -136.19943   ... -136.19943\n",
      "    -136.19943   -136.19943  ]\n",
      "   ...\n",
      "   [-138.49365   -138.49365   -138.49365   ... -138.49365\n",
      "    -138.49365   -138.49365  ]\n",
      "   [  64.13403     64.13403     64.13403   ...   64.13403\n",
      "      64.13403     64.13403  ]\n",
      "   [-131.67484   -131.67484   -131.67484   ... -131.67484\n",
      "    -131.67484   -131.67484  ]]]\n",
      "\n",
      "\n",
      " [[[ -38.771248   -38.771248   -38.771248  ...  -38.771248\n",
      "     -38.771248   -38.771248 ]\n",
      "   [  55.660534    55.660534    55.660534  ...   55.660534\n",
      "      55.660534    55.660534 ]\n",
      "   [ -58.84326    -58.84326    -58.84326   ...  -58.84326\n",
      "     -58.84326    -58.84326  ]\n",
      "   ...\n",
      "   [ -68.098465   -68.098465   -68.098465  ...  -68.098465\n",
      "     -68.098465   -68.098465 ]\n",
      "   [ 105.072464   105.072464   105.072464  ...  105.072464\n",
      "     105.072464   105.072464 ]\n",
      "   [-172.75125   -172.75125   -172.75125   ... -172.75125\n",
      "    -172.75125   -172.75125  ]]\n",
      "\n",
      "  [[ -19.080677   -19.080677   -19.080677  ...  -19.080677\n",
      "     -19.080677   -19.080677 ]\n",
      "   [  75.96222     75.96222     75.96222   ...   75.96222\n",
      "      75.96222     75.96222  ]\n",
      "   [  -6.3991375   -6.3991375   -6.3991375 ...   -6.3991375\n",
      "      -6.3991375   -6.3991375]\n",
      "   ...\n",
      "   [ -38.36323    -38.36323    -38.36323   ...  -38.36323\n",
      "     -38.36323    -38.36323  ]\n",
      "   [  94.805756    94.805756    94.805756  ...   94.805756\n",
      "      94.805756    94.805756 ]\n",
      "   [-151.25008   -151.25008   -151.25008   ... -151.25008\n",
      "    -151.25008   -151.25008  ]]\n",
      "\n",
      "  [[ -28.224709   -28.224709   -28.224709  ...  -28.224709\n",
      "     -28.224709   -28.224709 ]\n",
      "   [  61.893845    61.893845    61.893845  ...   61.893845\n",
      "      61.893845    61.893845 ]\n",
      "   [ -23.010807   -23.010807   -23.010807  ...  -23.010807\n",
      "     -23.010807   -23.010807 ]\n",
      "   ...\n",
      "   [ -85.93101    -85.93101    -85.93101   ...  -85.93101\n",
      "     -85.93101    -85.93101  ]\n",
      "   [  12.877844    12.877844    12.877844  ...   12.877844\n",
      "      12.877844    12.877844 ]\n",
      "   [-182.13937   -182.13937   -182.13937   ... -182.13937\n",
      "    -182.13937   -182.13937  ]]\n",
      "\n",
      "  [[  -7.8191986   -7.8191986   -7.8191986 ...   -7.8191986\n",
      "      -7.8191986   -7.8191986]\n",
      "   [ 130.69197    130.69197    130.69197   ...  130.69197\n",
      "     130.69197    130.69197  ]\n",
      "   [ -90.35755    -90.35755    -90.35755   ...  -90.35755\n",
      "     -90.35755    -90.35755  ]\n",
      "   ...\n",
      "   [-101.219124  -101.219124  -101.219124  ... -101.219124\n",
      "    -101.219124  -101.219124 ]\n",
      "   [  83.750465    83.750465    83.750465  ...   83.750465\n",
      "      83.750465    83.750465 ]\n",
      "   [-145.51433   -145.51433   -145.51433   ... -145.51433\n",
      "    -145.51433   -145.51433  ]]\n",
      "\n",
      "  [[  -4.4875793   -4.4875793   -4.4875793 ...   -4.4875793\n",
      "      -4.4875793   -4.4875793]\n",
      "   [ 135.53217    135.53217    135.53217   ...  135.53217\n",
      "     135.53217    135.53217  ]\n",
      "   [-105.655136  -105.655136  -105.655136  ... -105.655136\n",
      "    -105.655136  -105.655136 ]\n",
      "   ...\n",
      "   [-196.41483   -196.41483   -196.41483   ... -196.41483\n",
      "    -196.41483   -196.41483  ]\n",
      "   [  44.195637    44.195637    44.195637  ...   44.195637\n",
      "      44.195637    44.195637 ]\n",
      "   [-182.15768   -182.15768   -182.15768   ... -182.15768\n",
      "    -182.15768   -182.15768  ]]]\n",
      "\n",
      "\n",
      " [[[ -42.303696   -42.303696   -42.303696  ...  -42.303696\n",
      "     -42.303696   -42.303696 ]\n",
      "   [  65.14844     65.14844     65.14844   ...   65.14844\n",
      "      65.14844     65.14844  ]\n",
      "   [ -37.44847    -37.44847    -37.44847   ...  -37.44847\n",
      "     -37.44847    -37.44847  ]\n",
      "   ...\n",
      "   [  -8.610771    -8.610771    -8.610771  ...   -8.610771\n",
      "      -8.610771    -8.610771 ]\n",
      "   [  60.187237    60.187237    60.187237  ...   60.187237\n",
      "      60.187237    60.187237 ]\n",
      "   [-136.29202   -136.29202   -136.29202   ... -136.29202\n",
      "    -136.29202   -136.29202  ]]\n",
      "\n",
      "  [[ -28.928822   -28.928822   -28.928822  ...  -28.928822\n",
      "     -28.928822   -28.928822 ]\n",
      "   [ 109.613174   109.613174   109.613174  ...  109.613174\n",
      "     109.613174   109.613174 ]\n",
      "   [   3.8004622    3.8004622    3.8004622 ...    3.8004622\n",
      "       3.8004622    3.8004622]\n",
      "   ...\n",
      "   [  -6.9245186   -6.9245186   -6.9245186 ...   -6.9245186\n",
      "      -6.9245186   -6.9245186]\n",
      "   [  76.35927     76.35927     76.35927   ...   76.35927\n",
      "      76.35927     76.35927  ]\n",
      "   [-122.47401   -122.47401   -122.47401   ... -122.47401\n",
      "    -122.47401   -122.47401  ]]\n",
      "\n",
      "  [[ -24.669014   -24.669014   -24.669014  ...  -24.669014\n",
      "     -24.669014   -24.669014 ]\n",
      "   [ 105.10323    105.10323    105.10323   ...  105.10323\n",
      "     105.10323    105.10323  ]\n",
      "   [ -13.3821945  -13.3821945  -13.3821945 ...  -13.3821945\n",
      "     -13.3821945  -13.3821945]\n",
      "   ...\n",
      "   [ -42.399345   -42.399345   -42.399345  ...  -42.399345\n",
      "     -42.399345   -42.399345 ]\n",
      "   [  -6.947056    -6.947056    -6.947056  ...   -6.947056\n",
      "      -6.947056    -6.947056 ]\n",
      "   [-146.68968   -146.68968   -146.68968   ... -146.68968\n",
      "    -146.68968   -146.68968  ]]\n",
      "\n",
      "  [[  11.993847    11.993847    11.993847  ...   11.993847\n",
      "      11.993847    11.993847 ]\n",
      "   [ 167.03633    167.03633    167.03633   ...  167.03633\n",
      "     167.03633    167.03633  ]\n",
      "   [ -48.706627   -48.706627   -48.706627  ...  -48.706627\n",
      "     -48.706627   -48.706627 ]\n",
      "   ...\n",
      "   [ -66.51558    -66.51558    -66.51558   ...  -66.51558\n",
      "     -66.51558    -66.51558  ]\n",
      "   [  74.40559     74.40559     74.40559   ...   74.40559\n",
      "      74.40559     74.40559  ]\n",
      "   [-126.74048   -126.74048   -126.74048   ... -126.74048\n",
      "    -126.74048   -126.74048  ]]\n",
      "\n",
      "  [[  45.36252     45.36252     45.36252   ...   45.36252\n",
      "      45.36252     45.36252  ]\n",
      "   [ 162.20001    162.20001    162.20001   ...  162.20001\n",
      "     162.20001    162.20001  ]\n",
      "   [ -79.81204    -79.81204    -79.81204   ...  -79.81204\n",
      "     -79.81204    -79.81204  ]\n",
      "   ...\n",
      "   [-187.95674   -187.95674   -187.95674   ... -187.95674\n",
      "    -187.95674   -187.95674  ]\n",
      "   [  17.109993    17.109993    17.109993  ...   17.109993\n",
      "      17.109993    17.109993 ]\n",
      "   [-145.3532    -145.3532    -145.3532    ... -145.3532\n",
      "    -145.3532    -145.3532   ]]]], W.grad.numpy(): [[[[  37.848366    37.848366    37.848366  ...   37.848366\n",
      "      37.848366    37.848366 ]\n",
      "   [ -33.600903   -33.600903   -33.600903  ...  -33.600903\n",
      "     -33.600903   -33.600903 ]\n",
      "   [ -36.001495   -36.001495   -36.001495  ...  -36.001495\n",
      "     -36.001495   -36.001495 ]\n",
      "   ...\n",
      "   [  36.279297    36.279297    36.279297  ...   36.279297\n",
      "      36.279297    36.279297 ]\n",
      "   [  -8.610411    -8.610411    -8.610411  ...   -8.610411\n",
      "      -8.610411    -8.610411 ]\n",
      "   [-214.67365   -214.67365   -214.67365   ... -214.67365\n",
      "    -214.67365   -214.67365  ]]\n",
      "\n",
      "  [[  45.22555     45.22555     45.22555   ...   45.22555\n",
      "      45.22555     45.22555  ]\n",
      "   [ -13.485528   -13.485528   -13.485528  ...  -13.485528\n",
      "     -13.485528   -13.485528 ]\n",
      "   [ -29.072966   -29.072966   -29.072966  ...  -29.072966\n",
      "     -29.072966   -29.072966 ]\n",
      "   ...\n",
      "   [  73.4031      73.4031      73.4031    ...   73.4031\n",
      "      73.4031      73.4031   ]\n",
      "   [ -15.807903   -15.807903   -15.807903  ...  -15.807903\n",
      "     -15.807903   -15.807903 ]\n",
      "   [-163.33008   -163.33008   -163.33008   ... -163.33008\n",
      "    -163.33008   -163.33008  ]]\n",
      "\n",
      "  [[  13.053965    13.053965    13.053965  ...   13.053965\n",
      "      13.053965    13.053965 ]\n",
      "   [ -78.65251    -78.65251    -78.65251   ...  -78.65251\n",
      "     -78.65251    -78.65251  ]\n",
      "   [  10.06167     10.06167     10.06167   ...   10.06167\n",
      "      10.06167     10.06167  ]\n",
      "   ...\n",
      "   [  -2.7423272   -2.7423272   -2.7423272 ...   -2.7423272\n",
      "      -2.7423272   -2.7423272]\n",
      "   [ -17.210379   -17.210379   -17.210379  ...  -17.210379\n",
      "     -17.210379   -17.210379 ]\n",
      "   [-192.47601   -192.47601   -192.47601   ... -192.47601\n",
      "    -192.47601   -192.47601  ]]\n",
      "\n",
      "  [[ -38.955738   -38.955738   -38.955738  ...  -38.955738\n",
      "     -38.955738   -38.955738 ]\n",
      "   [ -22.5498     -22.5498     -22.5498    ...  -22.5498\n",
      "     -22.5498     -22.5498   ]\n",
      "   [  -7.3511524   -7.3511524   -7.3511524 ...   -7.3511524\n",
      "      -7.3511524   -7.3511524]\n",
      "   ...\n",
      "   [ -11.800994   -11.800994   -11.800994  ...  -11.800994\n",
      "     -11.800994   -11.800994 ]\n",
      "   [   9.112514     9.112514     9.112514  ...    9.112514\n",
      "       9.112514     9.112514 ]\n",
      "   [-109.3781    -109.3781    -109.3781    ... -109.3781\n",
      "    -109.3781    -109.3781   ]]\n",
      "\n",
      "  [[ -47.215862   -47.215862   -47.215862  ...  -47.215862\n",
      "     -47.215862   -47.215862 ]\n",
      "   [  23.651663    23.651663    23.651663  ...   23.651663\n",
      "      23.651663    23.651663 ]\n",
      "   [ -58.596237   -58.596237   -58.596237  ...  -58.596237\n",
      "     -58.596237   -58.596237 ]\n",
      "   ...\n",
      "   [-122.06638   -122.06638   -122.06638   ... -122.06638\n",
      "    -122.06638   -122.06638  ]\n",
      "   [  -2.0951338   -2.0951338   -2.0951338 ...   -2.0951338\n",
      "      -2.0951338   -2.0951338]\n",
      "   [-111.007484  -111.007484  -111.007484  ... -111.007484\n",
      "    -111.007484  -111.007484 ]]]\n",
      "\n",
      "\n",
      " [[[  -1.2779698   -1.2779698   -1.2779698 ...   -1.2779698\n",
      "      -1.2779698   -1.2779698]\n",
      "   [  -7.021856    -7.021856    -7.021856  ...   -7.021856\n",
      "      -7.021856    -7.021856 ]\n",
      "   [ -64.339775   -64.339775   -64.339775  ...  -64.339775\n",
      "     -64.339775   -64.339775 ]\n",
      "   ...\n",
      "   [   7.782082     7.782082     7.782082  ...    7.782082\n",
      "       7.782082     7.782082 ]\n",
      "   [  36.201096    36.201096    36.201096  ...   36.201096\n",
      "      36.201096    36.201096 ]\n",
      "   [-186.4855    -186.4855    -186.4855    ... -186.4855\n",
      "    -186.4855    -186.4855   ]]\n",
      "\n",
      "  [[   7.297106     7.297106     7.297106  ...    7.297106\n",
      "       7.297106     7.297106 ]\n",
      "   [ -11.920423   -11.920423   -11.920423  ...  -11.920423\n",
      "     -11.920423   -11.920423 ]\n",
      "   [ -43.22507    -43.22507    -43.22507   ...  -43.22507\n",
      "     -43.22507    -43.22507  ]\n",
      "   ...\n",
      "   [  12.711528    12.711528    12.711528  ...   12.711528\n",
      "      12.711528    12.711528 ]\n",
      "   [  51.456947    51.456947    51.456947  ...   51.456947\n",
      "      51.456947    51.456947 ]\n",
      "   [-135.76595   -135.76595   -135.76595   ... -135.76595\n",
      "    -135.76595   -135.76595  ]]\n",
      "\n",
      "  [[ -23.308178   -23.308178   -23.308178  ...  -23.308178\n",
      "     -23.308178   -23.308178 ]\n",
      "   [ -53.46307    -53.46307    -53.46307   ...  -53.46307\n",
      "     -53.46307    -53.46307  ]\n",
      "   [ -13.306931   -13.306931   -13.306931  ...  -13.306931\n",
      "     -13.306931   -13.306931 ]\n",
      "   ...\n",
      "   [ -68.48108    -68.48108    -68.48108   ...  -68.48108\n",
      "     -68.48108    -68.48108  ]\n",
      "   [  37.520813    37.520813    37.520813  ...   37.520813\n",
      "      37.520813    37.520813 ]\n",
      "   [-172.19933   -172.19933   -172.19933   ... -172.19933\n",
      "    -172.19933   -172.19933  ]]\n",
      "\n",
      "  [[ -53.489227   -53.489227   -53.489227  ...  -53.489227\n",
      "     -53.489227   -53.489227 ]\n",
      "   [  20.761784    20.761784    20.761784  ...   20.761784\n",
      "      20.761784    20.761784 ]\n",
      "   [ -59.052353   -59.052353   -59.052353  ...  -59.052353\n",
      "     -59.052353   -59.052353 ]\n",
      "   ...\n",
      "   [ -64.18136    -64.18136    -64.18136   ...  -64.18136\n",
      "     -64.18136    -64.18136  ]\n",
      "   [  75.39585     75.39585     75.39585   ...   75.39585\n",
      "      75.39585     75.39585  ]\n",
      "   [-118.91447   -118.91447   -118.91447   ... -118.91447\n",
      "    -118.91447   -118.91447  ]]\n",
      "\n",
      "  [[ -44.630737   -44.630737   -44.630737  ...  -44.630737\n",
      "     -44.630737   -44.630737 ]\n",
      "   [  24.693851    24.693851    24.693851  ...   24.693851\n",
      "      24.693851    24.693851 ]\n",
      "   [ -92.687256   -92.687256   -92.687256  ...  -92.687256\n",
      "     -92.687256   -92.687256 ]\n",
      "   ...\n",
      "   [-154.33566   -154.33566   -154.33566   ... -154.33566\n",
      "    -154.33566   -154.33566  ]\n",
      "   [  35.56114     35.56114     35.56114   ...   35.56114\n",
      "      35.56114     35.56114  ]\n",
      "   [-142.57841   -142.57841   -142.57841   ... -142.57841\n",
      "    -142.57841   -142.57841  ]]]\n",
      "\n",
      "\n",
      " [[[  20.505552    20.505552    20.505552  ...   20.505552\n",
      "      20.505552    20.505552 ]\n",
      "   [  22.88821     22.88821     22.88821   ...   22.88821\n",
      "      22.88821     22.88821  ]\n",
      "   [-102.73929   -102.73929   -102.73929   ... -102.73929\n",
      "    -102.73929   -102.73929  ]\n",
      "   ...\n",
      "   [ -40.526764   -40.526764   -40.526764  ...  -40.526764\n",
      "     -40.526764   -40.526764 ]\n",
      "   [  55.499443    55.499443    55.499443  ...   55.499443\n",
      "      55.499443    55.499443 ]\n",
      "   [-166.16582   -166.16582   -166.16582   ... -166.16582\n",
      "    -166.16582   -166.16582  ]]\n",
      "\n",
      "  [[  32.045937    32.045937    32.045937  ...   32.045937\n",
      "      32.045937    32.045937 ]\n",
      "   [  39.360985    39.360985    39.360985  ...   39.360985\n",
      "      39.360985    39.360985 ]\n",
      "   [ -63.935753   -63.935753   -63.935753  ...  -63.935753\n",
      "     -63.935753   -63.935753 ]\n",
      "   ...\n",
      "   [  -9.228405    -9.228405    -9.228405  ...   -9.228405\n",
      "      -9.228405    -9.228405 ]\n",
      "   [  65.5213      65.5213      65.5213    ...   65.5213\n",
      "      65.5213      65.5213   ]\n",
      "   [-117.32046   -117.32046   -117.32046   ... -117.32046\n",
      "    -117.32046   -117.32046  ]]\n",
      "\n",
      "  [[  28.711185    28.711185    28.711185  ...   28.711185\n",
      "      28.711185    28.711185 ]\n",
      "   [   6.415094     6.415094     6.415094  ...    6.415094\n",
      "       6.415094     6.415094 ]\n",
      "   [ -72.766014   -72.766014   -72.766014  ...  -72.766014\n",
      "     -72.766014   -72.766014 ]\n",
      "   ...\n",
      "   [ -64.88187    -64.88187    -64.88187   ...  -64.88187\n",
      "     -64.88187    -64.88187  ]\n",
      "   [  25.851608    25.851608    25.851608  ...   25.851608\n",
      "      25.851608    25.851608 ]\n",
      "   [-133.74748   -133.74748   -133.74748   ... -133.74748\n",
      "    -133.74748   -133.74748  ]]\n",
      "\n",
      "  [[  26.208073    26.208073    26.208073  ...   26.208073\n",
      "      26.208073    26.208073 ]\n",
      "   [  67.08351     67.08351     67.08351   ...   67.08351\n",
      "      67.08351     67.08351  ]\n",
      "   [-117.02879   -117.02879   -117.02879   ... -117.02879\n",
      "    -117.02879   -117.02879  ]\n",
      "   ...\n",
      "   [ -53.710922   -53.710922   -53.710922  ...  -53.710922\n",
      "     -53.710922   -53.710922 ]\n",
      "   [  89.51796     89.51796     89.51796   ...   89.51796\n",
      "      89.51796     89.51796  ]\n",
      "   [-112.57429   -112.57429   -112.57429   ... -112.57429\n",
      "    -112.57429   -112.57429  ]]\n",
      "\n",
      "  [[  25.827087    25.827087    25.827087  ...   25.827087\n",
      "      25.827087    25.827087 ]\n",
      "   [  70.786995    70.786995    70.786995  ...   70.786995\n",
      "      70.786995    70.786995 ]\n",
      "   [-136.1994    -136.1994    -136.1994    ... -136.1994\n",
      "    -136.1994    -136.1994   ]\n",
      "   ...\n",
      "   [-138.49368   -138.49368   -138.49368   ... -138.49368\n",
      "    -138.49368   -138.49368  ]\n",
      "   [  64.13405     64.13405     64.13405   ...   64.13405\n",
      "      64.13405     64.13405  ]\n",
      "   [-131.67485   -131.67485   -131.67485   ... -131.67485\n",
      "    -131.67485   -131.67485  ]]]\n",
      "\n",
      "\n",
      " [[[ -38.771248   -38.771248   -38.771248  ...  -38.771248\n",
      "     -38.771248   -38.771248 ]\n",
      "   [  55.660515    55.660515    55.660515  ...   55.660515\n",
      "      55.660515    55.660515 ]\n",
      "   [ -58.843227   -58.843227   -58.843227  ...  -58.843227\n",
      "     -58.843227   -58.843227 ]\n",
      "   ...\n",
      "   [ -68.098495   -68.098495   -68.098495  ...  -68.098495\n",
      "     -68.098495   -68.098495 ]\n",
      "   [ 105.07254    105.07254    105.07254   ...  105.07254\n",
      "     105.07254    105.07254  ]\n",
      "   [-172.75133   -172.75133   -172.75133   ... -172.75133\n",
      "    -172.75133   -172.75133  ]]\n",
      "\n",
      "  [[ -19.080675   -19.080675   -19.080675  ...  -19.080675\n",
      "     -19.080675   -19.080675 ]\n",
      "   [  75.96222     75.96222     75.96222   ...   75.96222\n",
      "      75.96222     75.96222  ]\n",
      "   [  -6.3991485   -6.3991485   -6.3991485 ...   -6.3991485\n",
      "      -6.3991485   -6.3991485]\n",
      "   ...\n",
      "   [ -38.36324    -38.36324    -38.36324   ...  -38.36324\n",
      "     -38.36324    -38.36324  ]\n",
      "   [  94.80576     94.80576     94.80576   ...   94.80576\n",
      "      94.80576     94.80576  ]\n",
      "   [-151.25017   -151.25017   -151.25017   ... -151.25017\n",
      "    -151.25017   -151.25017  ]]\n",
      "\n",
      "  [[ -28.224741   -28.224741   -28.224741  ...  -28.224741\n",
      "     -28.224741   -28.224741 ]\n",
      "   [  61.89383     61.89383     61.89383   ...   61.89383\n",
      "      61.89383     61.89383  ]\n",
      "   [ -23.010817   -23.010817   -23.010817  ...  -23.010817\n",
      "     -23.010817   -23.010817 ]\n",
      "   ...\n",
      "   [ -85.93102    -85.93102    -85.93102   ...  -85.93102\n",
      "     -85.93102    -85.93102  ]\n",
      "   [  12.877874    12.877874    12.877874  ...   12.877874\n",
      "      12.877874    12.877874 ]\n",
      "   [-182.13948   -182.13948   -182.13948   ... -182.13948\n",
      "    -182.13948   -182.13948  ]]\n",
      "\n",
      "  [[  -7.819177    -7.819177    -7.819177  ...   -7.819177\n",
      "      -7.819177    -7.819177 ]\n",
      "   [ 130.69185    130.69185    130.69185   ...  130.69185\n",
      "     130.69185    130.69185  ]\n",
      "   [ -90.35754    -90.35754    -90.35754   ...  -90.35754\n",
      "     -90.35754    -90.35754  ]\n",
      "   ...\n",
      "   [-101.21911   -101.21911   -101.21911   ... -101.21911\n",
      "    -101.21911   -101.21911  ]\n",
      "   [  83.75045     83.75045     83.75045   ...   83.75045\n",
      "      83.75045     83.75045  ]\n",
      "   [-145.51437   -145.51437   -145.51437   ... -145.51437\n",
      "    -145.51437   -145.51437  ]]\n",
      "\n",
      "  [[  -4.4876738   -4.4876738   -4.4876738 ...   -4.4876738\n",
      "      -4.4876738   -4.4876738]\n",
      "   [ 135.53204    135.53204    135.53204   ...  135.53204\n",
      "     135.53204    135.53204  ]\n",
      "   [-105.65515   -105.65515   -105.65515   ... -105.65515\n",
      "    -105.65515   -105.65515  ]\n",
      "   ...\n",
      "   [-196.41483   -196.41483   -196.41483   ... -196.41483\n",
      "    -196.41483   -196.41483  ]\n",
      "   [  44.195614    44.195614    44.195614  ...   44.195614\n",
      "      44.195614    44.195614 ]\n",
      "   [-182.15776   -182.15776   -182.15776   ... -182.15776\n",
      "    -182.15776   -182.15776  ]]]\n",
      "\n",
      "\n",
      " [[[ -42.3037     -42.3037     -42.3037    ...  -42.3037\n",
      "     -42.3037     -42.3037   ]\n",
      "   [  65.14845     65.14845     65.14845   ...   65.14845\n",
      "      65.14845     65.14845  ]\n",
      "   [ -37.448483   -37.448483   -37.448483  ...  -37.448483\n",
      "     -37.448483   -37.448483 ]\n",
      "   ...\n",
      "   [  -8.6107855   -8.6107855   -8.6107855 ...   -8.6107855\n",
      "      -8.6107855   -8.6107855]\n",
      "   [  60.187218    60.187218    60.187218  ...   60.187218\n",
      "      60.187218    60.187218 ]\n",
      "   [-136.2921    -136.2921    -136.2921    ... -136.2921\n",
      "    -136.2921    -136.2921   ]]\n",
      "\n",
      "  [[ -28.928797   -28.928797   -28.928797  ...  -28.928797\n",
      "     -28.928797   -28.928797 ]\n",
      "   [ 109.61315    109.61315    109.61315   ...  109.61315\n",
      "     109.61315    109.61315  ]\n",
      "   [   3.8004546    3.8004546    3.8004546 ...    3.8004546\n",
      "       3.8004546    3.8004546]\n",
      "   ...\n",
      "   [  -6.924535    -6.924535    -6.924535  ...   -6.924535\n",
      "      -6.924535    -6.924535 ]\n",
      "   [  76.35929     76.35929     76.35929   ...   76.35929\n",
      "      76.35929     76.35929  ]\n",
      "   [-122.47409   -122.47409   -122.47409   ... -122.47409\n",
      "    -122.47409   -122.47409  ]]\n",
      "\n",
      "  [[ -24.668985   -24.668985   -24.668985  ...  -24.668985\n",
      "     -24.668985   -24.668985 ]\n",
      "   [ 105.10323    105.10323    105.10323   ...  105.10323\n",
      "     105.10323    105.10323  ]\n",
      "   [ -13.382187   -13.382187   -13.382187  ...  -13.382187\n",
      "     -13.382187   -13.382187 ]\n",
      "   ...\n",
      "   [ -42.399326   -42.399326   -42.399326  ...  -42.399326\n",
      "     -42.399326   -42.399326 ]\n",
      "   [  -6.9470625   -6.9470625   -6.9470625 ...   -6.9470625\n",
      "      -6.9470625   -6.9470625]\n",
      "   [-146.68968   -146.68968   -146.68968   ... -146.68968\n",
      "    -146.68968   -146.68968  ]]\n",
      "\n",
      "  [[  11.993857    11.993857    11.993857  ...   11.993857\n",
      "      11.993857    11.993857 ]\n",
      "   [ 167.03622    167.03622    167.03622   ...  167.03622\n",
      "     167.03622    167.03622  ]\n",
      "   [ -48.706654   -48.706654   -48.706654  ...  -48.706654\n",
      "     -48.706654   -48.706654 ]\n",
      "   ...\n",
      "   [ -66.515594   -66.515594   -66.515594  ...  -66.515594\n",
      "     -66.515594   -66.515594 ]\n",
      "   [  74.40558     74.40558     74.40558   ...   74.40558\n",
      "      74.40558     74.40558  ]\n",
      "   [-126.74044   -126.74044   -126.74044   ... -126.74044\n",
      "    -126.74044   -126.74044  ]]\n",
      "\n",
      "  [[  45.362568    45.362568    45.362568  ...   45.362568\n",
      "      45.362568    45.362568 ]\n",
      "   [ 162.19994    162.19994    162.19994   ...  162.19994\n",
      "     162.19994    162.19994  ]\n",
      "   [ -79.812065   -79.812065   -79.812065  ...  -79.812065\n",
      "     -79.812065   -79.812065 ]\n",
      "   ...\n",
      "   [-187.9567    -187.9567    -187.9567    ... -187.9567\n",
      "    -187.9567    -187.9567   ]\n",
      "   [  17.109974    17.109974    17.109974  ...   17.109974\n",
      "      17.109974    17.109974 ]\n",
      "   [-145.35323   -145.35323   -145.35323   ... -145.35323\n",
      "    -145.35323   -145.35323  ]]]]\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape13-W_shape13-1-0] _\u001b[0m\n",
      "\n",
      "Z_shape = (3, 17, 17, 1), W_shape = (5, 5, 1, 16), stride = 1, padding = 0\n",
      "backward = True, device = cuda()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[  1.5437562   -6.8538       4.3282647    5.4068804   -3.15688\n",
      "     -1.206689    -4.3909516    3.4969...448   -2.242325     0.6578698\n",
      "     -7.0278      -1.7489109   10.11736      2.5269346    1.7962458\n",
      "     -7.9124722 ]]]])\n",
      "W_shape    = (5, 5, 1, 16)\n",
      "Wtch       = tensor([[[[  1.5438,  -6.8538,   4.3283,   5.4069,  -3.1569,  -1.2067,  -4.3910,\n",
      "             3.4969,  -5.3061,  -1.11...461,  -2.2423,   0.6579,  -7.0278,  -1.7489,  10.1174,   2.5269,\n",
      "             1.7962,  -7.9125]]]], requires_grad=True)\n",
      "Z          = needle.Tensor([[[[ 8.82026196e+00]\n",
      "   [ 2.00078607e+00]\n",
      "   [ 4.89369011e+00]\n",
      "   [ 1.12044659e+01]\n",
      "   [ 9.33778954e+00]...22066e-01]\n",
      "   [ 1.05310105e-01]\n",
      "   [ 4.97272283e-01]\n",
      "   [ 1.13696384e+00]\n",
      "   [-5.08369303e+00]\n",
      "   [-5.73876619e-01]]]])\n",
      "Z_shape    = (3, 17, 17, 1)\n",
      "Ztch       = tensor([[[[ 8.8203e+00],\n",
      "          [ 2.0008e+00],\n",
      "          [ 4.8937e+00],\n",
      "          [ 1.1204e+01],\n",
      "          [ 9.3378...       [ 4.9727e-01],\n",
      "          [ 1.1370e+00],\n",
      "          [-5.0837e+00],\n",
      "          [-5.7388e-01]]]], requires_grad=True)\n",
      "_W         = array([[[[  1.5437562 ,  -6.8538    ,   4.3282647 ,   5.4068804 ,\n",
      "           -3.15688   ,  -1.206689  ,  -4.3909516 , ...  -7.0278    ,  -1.7489109 ,\n",
      "           10.11736   ,   2.5269346 ,   1.7962458 ,  -7.9124722 ]]]],\n",
      "      dtype=float32)\n",
      "_Z         = array([[[[ 8.82026196e+00],\n",
      "         [ 2.00078607e+00],\n",
      "         [ 4.89369011e+00],\n",
      "         [ 1.12044659e+01],\n",
      "      ... 4.97272283e-01],\n",
      "         [ 1.13696384e+00],\n",
      "         [-5.08369303e+00],\n",
      "         [-5.73876619e-01]]]], dtype=float32)\n",
      "backward   = True\n",
      "device     = cuda()\n",
      "err1       = np.float32(0.00040977314)\n",
      "err2       = np.float32(0.0014183288)\n",
      "out        = tensor([[[[ 4.1444e+01,  7.2539e+01, -1.2076e+02,  ...,  5.7938e+01,\n",
      "           -1.5660e+01, -6.3388e+00],\n",
      "          [...,  1.4962e+02,  3.9613e+01,  ...,  6.5264e+01,\n",
      "            1.5128e+01, -1.2588e+02]]]], grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(-27459.7266, grad_fn=<SumBackward0>)\n",
      "padding    = 0\n",
      "stride     = 1\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c55d748aa0>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c55d748e60>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c55d748e60>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c55d748e60>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c55d748e60>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[-103.754875 -103.754875 -103.754875 -103.754875 -103.754875\n",
      "    -103.754875 -103.754875 -103.754875 -103.754875 -103.754875\n",
      "    -103.754875 -103.754875 -103.754875 -103.754875 -103.754875\n",
      "    -103.754875]]\n",
      "\n",
      "  [[-180.10439  -180.10439  -180.10439  -180.10439  -180.10439\n",
      "    -180.10439  -180.10439  -180.10439  -180.10439  -180.10439\n",
      "    -180.10439  -180.10439  -180.10439  -180.10439  -180.10439\n",
      "    -180.10439 ]]\n",
      "\n",
      "  [[-190.08365  -190.08365  -190.08365  -190.08365  -190.08365\n",
      "    -190.08365  -190.08365  -190.08365  -190.08365  -190.08365\n",
      "    -190.08365  -190.08365  -190.08365  -190.08365  -190.08365\n",
      "    -190.08365 ]]\n",
      "\n",
      "  [[-174.23862  -174.23862  -174.23862  -174.23862  -174.23862\n",
      "    -174.23862  -174.23862  -174.23862  -174.23862  -174.23862\n",
      "    -174.23862  -174.23862  -174.23862  -174.23862  -174.23862\n",
      "    -174.23862 ]]\n",
      "\n",
      "  [[-175.81735  -175.81735  -175.81735  -175.81735  -175.81735\n",
      "    -175.81735  -175.81735  -175.81735  -175.81735  -175.81735\n",
      "    -175.81735  -175.81735  -175.81735  -175.81735  -175.81735\n",
      "    -175.81735 ]]]\n",
      "\n",
      "\n",
      " [[[-161.4056   -161.4056   -161.4056   -161.4056   -161.4056\n",
      "    -161.4056   -161.4056   -161.4056   -161.4056   -161.4056\n",
      "    -161.4056   -161.4056   -161.4056   -161.4056   -161.4056\n",
      "    -161.4056  ]]\n",
      "\n",
      "  [[-229.05672  -229.05672  -229.05672  -229.05672  -229.05672\n",
      "    -229.05672  -229.05672  -229.05672  -229.05672  -229.05672\n",
      "    -229.05672  -229.05672  -229.05672  -229.05672  -229.05672\n",
      "    -229.05672 ]]\n",
      "\n",
      "  [[-242.01685  -242.01685  -242.01685  -242.01685  -242.01685\n",
      "    -242.01685  -242.01685  -242.01685  -242.01685  -242.01685\n",
      "    -242.01685  -242.01685  -242.01685  -242.01685  -242.01685\n",
      "    -242.01685 ]]\n",
      "\n",
      "  [[-227.32703  -227.32703  -227.32703  -227.32703  -227.32703\n",
      "    -227.32703  -227.32703  -227.32703  -227.32703  -227.32703\n",
      "    -227.32703  -227.32703  -227.32703  -227.32703  -227.32703\n",
      "    -227.32703 ]]\n",
      "\n",
      "  [[-195.55923  -195.55923  -195.55923  -195.55923  -195.55923\n",
      "    -195.55923  -195.55923  -195.55923  -195.55923  -195.55923\n",
      "    -195.55923  -195.55923  -195.55923  -195.55923  -195.55923\n",
      "    -195.55923 ]]]\n",
      "\n",
      "\n",
      " [[[-127.323654 -127.323654 -127.323654 -127.323654 -127.323654\n",
      "    -127.323654 -127.323654 -127.323654 -127.323654 -127.323654\n",
      "    -127.323654 -127.323654 -127.323654 -127.323654 -127.323654\n",
      "    -127.323654]]\n",
      "\n",
      "  [[-211.80472  -211.80472  -211.80472  -211.80472  -211.80472\n",
      "    -211.80472  -211.80472  -211.80472  -211.80472  -211.80472\n",
      "    -211.80472  -211.80472  -211.80472  -211.80472  -211.80472\n",
      "    -211.80472 ]]\n",
      "\n",
      "  [[-232.33528  -232.33528  -232.33528  -232.33528  -232.33528\n",
      "    -232.33528  -232.33528  -232.33528  -232.33528  -232.33528\n",
      "    -232.33528  -232.33528  -232.33528  -232.33528  -232.33528\n",
      "    -232.33528 ]]\n",
      "\n",
      "  [[-197.0064   -197.0064   -197.0064   -197.0064   -197.0064\n",
      "    -197.0064   -197.0064   -197.0064   -197.0064   -197.0064\n",
      "    -197.0064   -197.0064   -197.0064   -197.0064   -197.0064\n",
      "    -197.0064  ]]\n",
      "\n",
      "  [[-144.13293  -144.13293  -144.13293  -144.13293  -144.13293\n",
      "    -144.13293  -144.13293  -144.13293  -144.13293  -144.13293\n",
      "    -144.13293  -144.13293  -144.13293  -144.13293  -144.13293\n",
      "    -144.13293 ]]]\n",
      "\n",
      "\n",
      " [[[-129.75711  -129.75711  -129.75711  -129.75711  -129.75711\n",
      "    -129.75711  -129.75711  -129.75711  -129.75711  -129.75711\n",
      "    -129.75711  -129.75711  -129.75711  -129.75711  -129.75711\n",
      "    -129.75711 ]]\n",
      "\n",
      "  [[-205.2602   -205.2602   -205.2602   -205.2602   -205.2602\n",
      "    -205.2602   -205.2602   -205.2602   -205.2602   -205.2602\n",
      "    -205.2602   -205.2602   -205.2602   -205.2602   -205.2602\n",
      "    -205.2602  ]]\n",
      "\n",
      "  [[-224.77884  -224.77884  -224.77884  -224.77884  -224.77884\n",
      "    -224.77884  -224.77884  -224.77884  -224.77884  -224.77884\n",
      "    -224.77884  -224.77884  -224.77884  -224.77884  -224.77884\n",
      "    -224.77884 ]]\n",
      "\n",
      "  [[-197.76212  -197.76212  -197.76212  -197.76212  -197.76212\n",
      "    -197.76212  -197.76212  -197.76212  -197.76212  -197.76212\n",
      "    -197.76212  -197.76212  -197.76212  -197.76212  -197.76212\n",
      "    -197.76212 ]]\n",
      "\n",
      "  [[-119.871445 -119.871445 -119.871445 -119.871445 -119.871445\n",
      "    -119.871445 -119.871445 -119.871445 -119.871445 -119.871445\n",
      "    -119.871445 -119.871445 -119.871445 -119.871445 -119.871445\n",
      "    -119.871445]]]\n",
      "\n",
      "\n",
      " [[[-131.72517  -131.72517  -131.72517  -131.72517  -131.72517\n",
      "    -131.72517  -131.72517  -131.72517  -131.72517  -131.72517\n",
      "    -131.72517  -131.72517  -131.72517  -131.72517  -131.72517\n",
      "    -131.72517 ]]\n",
      "\n",
      "  [[-192.7218   -192.7218   -192.7218   -192.7218   -192.7218\n",
      "    -192.7218   -192.7218   -192.7218   -192.7218   -192.7218\n",
      "    -192.7218   -192.7218   -192.7218   -192.7218   -192.7218\n",
      "    -192.7218  ]]\n",
      "\n",
      "  [[-213.31113  -213.31113  -213.31113  -213.31113  -213.31113\n",
      "    -213.31113  -213.31113  -213.31113  -213.31113  -213.31113\n",
      "    -213.31113  -213.31113  -213.31113  -213.31113  -213.31113\n",
      "    -213.31113 ]]\n",
      "\n",
      "  [[-168.52386  -168.52386  -168.52386  -168.52386  -168.52386\n",
      "    -168.52386  -168.52386  -168.52386  -168.52386  -168.52386\n",
      "    -168.52386  -168.52386  -168.52386  -168.52386  -168.52386\n",
      "    -168.52386 ]]\n",
      "\n",
      "  [[ -76.436874  -76.436874  -76.436874  -76.436874  -76.436874\n",
      "     -76.436874  -76.436874  -76.436874  -76.436874  -76.436874\n",
      "     -76.436874  -76.436874  -76.436874  -76.436874  -76.436874\n",
      "     -76.436874]]]], W.grad.numpy(): [[[[-103.75482  -103.75482  -103.75482  -103.75482  -103.75482\n",
      "    -103.75482  -103.75482  -103.75482  -103.75482  -103.75482\n",
      "    -103.75482  -103.75482  -103.75482  -103.75482  -103.75482\n",
      "    -103.75482 ]]\n",
      "\n",
      "  [[-180.10437  -180.10437  -180.10437  -180.10437  -180.10437\n",
      "    -180.10437  -180.10437  -180.10437  -180.10437  -180.10437\n",
      "    -180.10437  -180.10437  -180.10437  -180.10437  -180.10437\n",
      "    -180.10437 ]]\n",
      "\n",
      "  [[-190.08366  -190.08366  -190.08366  -190.08366  -190.08366\n",
      "    -190.08366  -190.08366  -190.08366  -190.08366  -190.08366\n",
      "    -190.08366  -190.08366  -190.08366  -190.08366  -190.08366\n",
      "    -190.08366 ]]\n",
      "\n",
      "  [[-174.23856  -174.23856  -174.23856  -174.23856  -174.23856\n",
      "    -174.23856  -174.23856  -174.23856  -174.23856  -174.23856\n",
      "    -174.23856  -174.23856  -174.23856  -174.23856  -174.23856\n",
      "    -174.23856 ]]\n",
      "\n",
      "  [[-175.81732  -175.81732  -175.81732  -175.81732  -175.81732\n",
      "    -175.81732  -175.81732  -175.81732  -175.81732  -175.81732\n",
      "    -175.81732  -175.81732  -175.81732  -175.81732  -175.81732\n",
      "    -175.81732 ]]]\n",
      "\n",
      "\n",
      " [[[-161.40565  -161.40565  -161.40565  -161.40565  -161.40565\n",
      "    -161.40565  -161.40565  -161.40565  -161.40565  -161.40565\n",
      "    -161.40565  -161.40565  -161.40565  -161.40565  -161.40565\n",
      "    -161.40565 ]]\n",
      "\n",
      "  [[-229.0568   -229.0568   -229.0568   -229.0568   -229.0568\n",
      "    -229.0568   -229.0568   -229.0568   -229.0568   -229.0568\n",
      "    -229.0568   -229.0568   -229.0568   -229.0568   -229.0568\n",
      "    -229.0568  ]]\n",
      "\n",
      "  [[-242.01685  -242.01685  -242.01685  -242.01685  -242.01685\n",
      "    -242.01685  -242.01685  -242.01685  -242.01685  -242.01685\n",
      "    -242.01685  -242.01685  -242.01685  -242.01685  -242.01685\n",
      "    -242.01685 ]]\n",
      "\n",
      "  [[-227.32701  -227.32701  -227.32701  -227.32701  -227.32701\n",
      "    -227.32701  -227.32701  -227.32701  -227.32701  -227.32701\n",
      "    -227.32701  -227.32701  -227.32701  -227.32701  -227.32701\n",
      "    -227.32701 ]]\n",
      "\n",
      "  [[-195.55927  -195.55927  -195.55927  -195.55927  -195.55927\n",
      "    -195.55927  -195.55927  -195.55927  -195.55927  -195.55927\n",
      "    -195.55927  -195.55927  -195.55927  -195.55927  -195.55927\n",
      "    -195.55927 ]]]\n",
      "\n",
      "\n",
      " [[[-127.323616 -127.323616 -127.323616 -127.323616 -127.323616\n",
      "    -127.323616 -127.323616 -127.323616 -127.323616 -127.323616\n",
      "    -127.323616 -127.323616 -127.323616 -127.323616 -127.323616\n",
      "    -127.323616]]\n",
      "\n",
      "  [[-211.80469  -211.80469  -211.80469  -211.80469  -211.80469\n",
      "    -211.80469  -211.80469  -211.80469  -211.80469  -211.80469\n",
      "    -211.80469  -211.80469  -211.80469  -211.80469  -211.80469\n",
      "    -211.80469 ]]\n",
      "\n",
      "  [[-232.3352   -232.3352   -232.3352   -232.3352   -232.3352\n",
      "    -232.3352   -232.3352   -232.3352   -232.3352   -232.3352\n",
      "    -232.3352   -232.3352   -232.3352   -232.3352   -232.3352\n",
      "    -232.3352  ]]\n",
      "\n",
      "  [[-197.0063   -197.0063   -197.0063   -197.0063   -197.0063\n",
      "    -197.0063   -197.0063   -197.0063   -197.0063   -197.0063\n",
      "    -197.0063   -197.0063   -197.0063   -197.0063   -197.0063\n",
      "    -197.0063  ]]\n",
      "\n",
      "  [[-144.13295  -144.13295  -144.13295  -144.13295  -144.13295\n",
      "    -144.13295  -144.13295  -144.13295  -144.13295  -144.13295\n",
      "    -144.13295  -144.13295  -144.13295  -144.13295  -144.13295\n",
      "    -144.13295 ]]]\n",
      "\n",
      "\n",
      " [[[-129.75711  -129.75711  -129.75711  -129.75711  -129.75711\n",
      "    -129.75711  -129.75711  -129.75711  -129.75711  -129.75711\n",
      "    -129.75711  -129.75711  -129.75711  -129.75711  -129.75711\n",
      "    -129.75711 ]]\n",
      "\n",
      "  [[-205.26006  -205.26006  -205.26006  -205.26006  -205.26006\n",
      "    -205.26006  -205.26006  -205.26006  -205.26006  -205.26006\n",
      "    -205.26006  -205.26006  -205.26006  -205.26006  -205.26006\n",
      "    -205.26006 ]]\n",
      "\n",
      "  [[-224.77878  -224.77878  -224.77878  -224.77878  -224.77878\n",
      "    -224.77878  -224.77878  -224.77878  -224.77878  -224.77878\n",
      "    -224.77878  -224.77878  -224.77878  -224.77878  -224.77878\n",
      "    -224.77878 ]]\n",
      "\n",
      "  [[-197.76195  -197.76195  -197.76195  -197.76195  -197.76195\n",
      "    -197.76195  -197.76195  -197.76195  -197.76195  -197.76195\n",
      "    -197.76195  -197.76195  -197.76195  -197.76195  -197.76195\n",
      "    -197.76195 ]]\n",
      "\n",
      "  [[-119.87145  -119.87145  -119.87145  -119.87145  -119.87145\n",
      "    -119.87145  -119.87145  -119.87145  -119.87145  -119.87145\n",
      "    -119.87145  -119.87145  -119.87145  -119.87145  -119.87145\n",
      "    -119.87145 ]]]\n",
      "\n",
      "\n",
      " [[[-131.7252   -131.7252   -131.7252   -131.7252   -131.7252\n",
      "    -131.7252   -131.7252   -131.7252   -131.7252   -131.7252\n",
      "    -131.7252   -131.7252   -131.7252   -131.7252   -131.7252\n",
      "    -131.7252  ]]\n",
      "\n",
      "  [[-192.72165  -192.72165  -192.72165  -192.72165  -192.72165\n",
      "    -192.72165  -192.72165  -192.72165  -192.72165  -192.72165\n",
      "    -192.72165  -192.72165  -192.72165  -192.72165  -192.72165\n",
      "    -192.72165 ]]\n",
      "\n",
      "  [[-213.311    -213.311    -213.311    -213.311    -213.311\n",
      "    -213.311    -213.311    -213.311    -213.311    -213.311\n",
      "    -213.311    -213.311    -213.311    -213.311    -213.311\n",
      "    -213.311   ]]\n",
      "\n",
      "  [[-168.52388  -168.52388  -168.52388  -168.52388  -168.52388\n",
      "    -168.52388  -168.52388  -168.52388  -168.52388  -168.52388\n",
      "    -168.52388  -168.52388  -168.52388  -168.52388  -168.52388\n",
      "    -168.52388 ]]\n",
      "\n",
      "  [[ -76.43688   -76.43688   -76.43688   -76.43688   -76.43688\n",
      "     -76.43688   -76.43688   -76.43688   -76.43688   -76.43688\n",
      "     -76.43688   -76.43688   -76.43688   -76.43688   -76.43688\n",
      "     -76.43688 ]]]]\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape14-W_shape14-1-0] _\u001b[0m\n",
      "\n",
      "Z_shape = (3, 17, 17, 16), W_shape = (5, 5, 16, 1), stride = 1, padding = 0\n",
      "backward = True, device = cuda()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[ 1.55579513e-02]\n",
      "   [-3.04658723e+00]\n",
      "   [ 4.09725952e+00]\n",
      "   [ 1.29906273e+00]\n",
      "   [-7.50546598e+00]...75421e+00]\n",
      "   [ 3.02805209e+00]\n",
      "   [-4.20992136e+00]\n",
      "   [ 4.11707735e+00]\n",
      "   [ 4.99041653e+00]\n",
      "   [ 5.11040497e+00]]]])\n",
      "W_shape    = (5, 5, 16, 1)\n",
      "Wtch       = tensor([[[[ 1.5558e-02],\n",
      "          [-3.0466e+00],\n",
      "          [ 4.0973e+00],\n",
      "          [ 1.2991e+00],\n",
      "          [-7.5055...       [-4.2099e+00],\n",
      "          [ 4.1171e+00],\n",
      "          [ 4.9904e+00],\n",
      "          [ 5.1104e+00]]]], requires_grad=True)\n",
      "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ...  6.08375072e-01\n",
      "     2.21931624e+00  1.66837168e...3e+00]\n",
      "   [-1.25365603e+00 -1.71452928e+00  1.35930243e+01 ...  3.13170171e+00\n",
      "    -1.35708165e+00  1.29997072e+01]]]])\n",
      "Z_shape    = (3, 17, 17, 16)\n",
      "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ...,  6.0838e-01,\n",
      "            2.2193e+00,  1.6684e+00],\n",
      "          [...[-1.2537e+00, -1.7145e+00,  1.3593e+01,  ...,  3.1317e+00,\n",
      "           -1.3571e+00,  1.3000e+01]]]], requires_grad=True)\n",
      "_W         = array([[[[ 1.55579513e-02],\n",
      "         [-3.04658723e+00],\n",
      "         [ 4.09725952e+00],\n",
      "         [ 1.29906273e+00],\n",
      "      ...-4.20992136e+00],\n",
      "         [ 4.11707735e+00],\n",
      "         [ 4.99041653e+00],\n",
      "         [ 5.11040497e+00]]]], dtype=float32)\n",
      "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
      "           6.08375072e-01,  2.21931624e+00,  1.66837...e+01, ...,\n",
      "           3.13170171e+00, -1.35708165e+00,  1.29997072e+01]]]],\n",
      "      shape=(3, 17, 17, 16), dtype=float32)\n",
      "backward   = True\n",
      "device     = cuda()\n",
      "err1       = np.float32(0.00026052116)\n",
      "err2       = np.float32(0.0009914576)\n",
      "out        = tensor([[[[  173.2376,  -598.2368, -1057.3813,   300.5164,   -78.8975,\n",
      "             272.9615,  -484.4884,   -84.3478, ...4923,  -241.7713,   538.5468,\n",
      "             257.2256,   163.9202,  1022.2947]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(-8337.0508, grad_fn=<SumBackward0>)\n",
      "padding    = 0\n",
      "stride     = 1\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c5655e2810>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655e1a00>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655e1a00>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655e1a00>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655e1a00>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[-1.05645676e+02]\n",
      "   [-2.01233444e+01]\n",
      "   [-1.49882324e+02]\n",
      "   [ 2.06188095e+02]\n",
      "   [-1.35001236e+02]\n",
      "   [-2.34928131e-01]\n",
      "   [-3.76055069e+01]\n",
      "   [ 3.27950478e+00]\n",
      "   [ 1.12367420e+01]\n",
      "   [ 4.94731102e+01]\n",
      "   [ 9.88436050e+01]\n",
      "   [ 1.26689705e+02]\n",
      "   [-6.32781334e+01]\n",
      "   [-1.41452454e+02]\n",
      "   [ 8.20149460e+01]\n",
      "   [-2.11831238e+02]]\n",
      "\n",
      "  [[-8.49279556e+01]\n",
      "   [-2.75491333e+01]\n",
      "   [-2.05616409e+02]\n",
      "   [ 1.50188782e+02]\n",
      "   [-1.33572311e+02]\n",
      "   [ 2.57772121e+01]\n",
      "   [-1.11375771e+01]\n",
      "   [-6.65546417e+00]\n",
      "   [ 1.65217648e+01]\n",
      "   [-2.94588890e+01]\n",
      "   [ 1.34262085e+02]\n",
      "   [ 4.88686790e+01]\n",
      "   [-1.13592529e+00]\n",
      "   [-1.99641006e+02]\n",
      "   [ 6.50487747e+01]\n",
      "   [-2.95012939e+02]]\n",
      "\n",
      "  [[-6.90266418e+01]\n",
      "   [-4.15997925e+01]\n",
      "   [-2.57041748e+02]\n",
      "   [ 2.30137726e+02]\n",
      "   [-1.08954964e+02]\n",
      "   [ 5.65249634e+00]\n",
      "   [ 3.30040359e+01]\n",
      "   [-3.96655464e+01]\n",
      "   [ 5.29014397e+00]\n",
      "   [-4.12875137e+01]\n",
      "   [ 1.68186310e+02]\n",
      "   [ 4.47323647e+01]\n",
      "   [ 5.60536957e+01]\n",
      "   [-1.86990753e+02]\n",
      "   [ 7.51118565e+00]\n",
      "   [-2.69889038e+02]]\n",
      "\n",
      "  [[-4.90958595e+01]\n",
      "   [-3.52368851e+01]\n",
      "   [-2.34394928e+02]\n",
      "   [ 2.24959808e+02]\n",
      "   [-1.33998230e+02]\n",
      "   [-3.78519287e+01]\n",
      "   [ 6.25473976e+01]\n",
      "   [-9.65747986e+01]\n",
      "   [-1.04519157e+01]\n",
      "   [-5.41348000e+01]\n",
      "   [ 1.50591003e+02]\n",
      "   [ 1.25959396e+00]\n",
      "   [ 5.39370918e+01]\n",
      "   [-1.30859909e+02]\n",
      "   [-5.90740128e+01]\n",
      "   [-2.57829193e+02]]\n",
      "\n",
      "  [[-9.34716873e+01]\n",
      "   [ 3.94592476e+00]\n",
      "   [-2.59044647e+02]\n",
      "   [ 2.11363220e+02]\n",
      "   [-1.24154709e+02]\n",
      "   [-9.59835052e+00]\n",
      "   [ 2.54309120e+01]\n",
      "   [-1.28694855e+02]\n",
      "   [ 3.11064320e+01]\n",
      "   [-3.63582268e+01]\n",
      "   [ 1.91347946e+02]\n",
      "   [ 1.28790474e+01]\n",
      "   [ 6.02757797e+01]\n",
      "   [-1.43611069e+02]\n",
      "   [-2.12342987e+01]\n",
      "   [-3.02779114e+02]]]\n",
      "\n",
      "\n",
      " [[[-1.30759583e+02]\n",
      "   [-5.30780487e+01]\n",
      "   [-3.65081177e+01]\n",
      "   [ 1.16226929e+02]\n",
      "   [-1.43968109e+02]\n",
      "   [ 2.62289505e+01]\n",
      "   [-4.83289680e+01]\n",
      "   [-4.52546740e+00]\n",
      "   [-1.54871845e+01]\n",
      "   [ 1.65274841e+02]\n",
      "   [ 6.37024536e+01]\n",
      "   [ 1.20104134e+02]\n",
      "   [-6.70979233e+01]\n",
      "   [-1.77250320e+02]\n",
      "   [ 9.24350739e+01]\n",
      "   [-1.95128540e+02]]\n",
      "\n",
      "  [[-1.16220718e+02]\n",
      "   [-3.30083237e+01]\n",
      "   [-1.03258156e+02]\n",
      "   [ 5.67695160e+01]\n",
      "   [-1.42624527e+02]\n",
      "   [ 4.47735291e+01]\n",
      "   [-1.14148540e+01]\n",
      "   [-2.06628742e+01]\n",
      "   [-4.33662987e+01]\n",
      "   [ 9.86896973e+01]\n",
      "   [ 8.88732147e+01]\n",
      "   [ 5.40591049e+01]\n",
      "   [ 2.64871216e+00]\n",
      "   [-2.29597626e+02]\n",
      "   [ 1.02947128e+02]\n",
      "   [-2.64780121e+02]]\n",
      "\n",
      "  [[-9.37098465e+01]\n",
      "   [-8.36794472e+00]\n",
      "   [-1.61437607e+02]\n",
      "   [ 1.25073807e+02]\n",
      "   [-1.41490036e+02]\n",
      "   [ 1.70049286e+01]\n",
      "   [ 4.18273125e+01]\n",
      "   [-5.35076942e+01]\n",
      "   [-2.52867661e+01]\n",
      "   [ 6.81087189e+01]\n",
      "   [ 9.66426697e+01]\n",
      "   [ 3.23420486e+01]\n",
      "   [ 9.01497040e+01]\n",
      "   [-1.88990189e+02]\n",
      "   [ 2.60766754e+01]\n",
      "   [-2.34107742e+02]]\n",
      "\n",
      "  [[-5.85137558e+01]\n",
      "   [-2.33966064e+00]\n",
      "   [-1.52788696e+02]\n",
      "   [ 1.25451736e+02]\n",
      "   [-1.37870880e+02]\n",
      "   [-5.23325348e+00]\n",
      "   [ 5.57009888e+01]\n",
      "   [-1.10888382e+02]\n",
      "   [-5.09408836e+01]\n",
      "   [ 9.69206238e+00]\n",
      "   [ 7.61016083e+01]\n",
      "   [ 4.83363342e+00]\n",
      "   [ 7.97956619e+01]\n",
      "   [-1.32182144e+02]\n",
      "   [-3.02678833e+01]\n",
      "   [-2.18942780e+02]]\n",
      "\n",
      "  [[-1.21423080e+02]\n",
      "   [ 4.10961990e+01]\n",
      "   [-1.86889618e+02]\n",
      "   [ 1.26133331e+02]\n",
      "   [-1.17518356e+02]\n",
      "   [ 4.11687164e+01]\n",
      "   [-2.13943481e-01]\n",
      "   [-1.13331619e+02]\n",
      "   [ 9.72501564e+00]\n",
      "   [ 3.09898376e+00]\n",
      "   [ 1.06382553e+02]\n",
      "   [ 1.49877357e+00]\n",
      "   [ 7.09051056e+01]\n",
      "   [-1.29133743e+02]\n",
      "   [-1.71551762e+01]\n",
      "   [-2.63589874e+02]]]\n",
      "\n",
      "\n",
      " [[[-7.35902710e+01]\n",
      "   [-3.58177185e+01]\n",
      "   [-3.91609955e+01]\n",
      "   [ 9.34227524e+01]\n",
      "   [-2.34856689e+02]\n",
      "   [-1.34908752e+01]\n",
      "   [-2.10024605e+01]\n",
      "   [-7.26594849e+01]\n",
      "   [-3.30976562e+01]\n",
      "   [ 1.88550934e+02]\n",
      "   [ 8.42464066e+01]\n",
      "   [ 8.25404816e+01]\n",
      "   [-3.08872375e+01]\n",
      "   [-2.25946472e+02]\n",
      "   [ 1.05908890e+02]\n",
      "   [-1.99482315e+02]]\n",
      "\n",
      "  [[-4.86232986e+01]\n",
      "   [-2.93912888e+01]\n",
      "   [-1.08916702e+02]\n",
      "   [ 5.14841843e+01]\n",
      "   [-2.17893280e+02]\n",
      "   [ 2.58462753e+01]\n",
      "   [ 1.49251270e+01]\n",
      "   [-6.35332642e+01]\n",
      "   [-4.49299622e+01]\n",
      "   [ 1.38390854e+02]\n",
      "   [ 1.41977051e+02]\n",
      "   [ 2.77889214e+01]\n",
      "   [ 5.09371300e+01]\n",
      "   [-2.80378052e+02]\n",
      "   [ 8.05643463e+01]\n",
      "   [-2.19628311e+02]]\n",
      "\n",
      "  [[-2.75799179e+01]\n",
      "   [ 7.72900772e+00]\n",
      "   [-1.96252747e+02]\n",
      "   [ 1.15850616e+02]\n",
      "   [-2.17371368e+02]\n",
      "   [ 2.22289505e+01]\n",
      "   [ 6.18700638e+01]\n",
      "   [-9.50438995e+01]\n",
      "   [-4.10829773e+01]\n",
      "   [ 1.38915436e+02]\n",
      "   [ 1.76892029e+02]\n",
      "   [ 2.75100040e+01]\n",
      "   [ 1.36497986e+02]\n",
      "   [-2.32300034e+02]\n",
      "   [-2.27395172e+01]\n",
      "   [-1.75595825e+02]]\n",
      "\n",
      "  [[-1.20369625e+00]\n",
      "   [ 3.28416443e+01]\n",
      "   [-1.74532135e+02]\n",
      "   [ 9.16016083e+01]\n",
      "   [-1.88469650e+02]\n",
      "   [-7.50865936e+00]\n",
      "   [ 9.53312759e+01]\n",
      "   [-1.50747742e+02]\n",
      "   [-5.55727577e+01]\n",
      "   [ 9.05028687e+01]\n",
      "   [ 1.57531250e+02]\n",
      "   [-1.13201141e-02]\n",
      "   [ 1.29644974e+02]\n",
      "   [-1.74706711e+02]\n",
      "   [-7.50932617e+01]\n",
      "   [-1.73175659e+02]]\n",
      "\n",
      "  [[-8.27279510e+01]\n",
      "   [ 9.17663116e+01]\n",
      "   [-2.11898956e+02]\n",
      "   [ 8.55281982e+01]\n",
      "   [-1.51297256e+02]\n",
      "   [ 3.81872406e+01]\n",
      "   [ 3.21424026e+01]\n",
      "   [-1.30792511e+02]\n",
      "   [-5.38527822e+00]\n",
      "   [ 8.17421722e+01]\n",
      "   [ 1.57631378e+02]\n",
      "   [ 9.59311485e+00]\n",
      "   [ 1.16108604e+02]\n",
      "   [-1.72706970e+02]\n",
      "   [-9.88096313e+01]\n",
      "   [-2.33995575e+02]]]\n",
      "\n",
      "\n",
      " [[[-6.85261688e+01]\n",
      "   [ 8.99101257e+00]\n",
      "   [-2.81572075e+01]\n",
      "   [ 1.15900055e+02]\n",
      "   [-2.29621170e+02]\n",
      "   [-5.39785233e+01]\n",
      "   [-9.98587799e+01]\n",
      "   [-2.90465508e+01]\n",
      "   [-2.23617859e+01]\n",
      "   [ 9.50817871e+01]\n",
      "   [-1.11478958e+01]\n",
      "   [ 5.28827400e+01]\n",
      "   [ 5.54485626e+01]\n",
      "   [-2.22198471e+02]\n",
      "   [ 5.97513809e+01]\n",
      "   [-1.49237839e+02]]\n",
      "\n",
      "  [[-4.44186172e+01]\n",
      "   [ 2.82013512e+01]\n",
      "   [-9.02769165e+01]\n",
      "   [ 5.59393349e+01]\n",
      "   [-2.21031433e+02]\n",
      "   [-7.60000610e+00]\n",
      "   [-6.08905563e+01]\n",
      "   [-2.28381844e+01]\n",
      "   [-3.46667328e+01]\n",
      "   [ 6.92671814e+01]\n",
      "   [ 2.38992043e+01]\n",
      "   [-3.00072479e+00]\n",
      "   [ 9.71094818e+01]\n",
      "   [-2.89730530e+02]\n",
      "   [ 2.70176888e+01]\n",
      "   [-1.93462585e+02]]\n",
      "\n",
      "  [[-3.01555920e+01]\n",
      "   [ 8.00485611e+01]\n",
      "   [-1.68488037e+02]\n",
      "   [ 1.12476364e+02]\n",
      "   [-2.13198593e+02]\n",
      "   [ 6.55252838e+00]\n",
      "   [-1.75311756e+01]\n",
      "   [-6.33629837e+01]\n",
      "   [-1.79664097e+01]\n",
      "   [ 7.39581451e+01]\n",
      "   [ 9.30036621e+01]\n",
      "   [-3.75135002e+01]\n",
      "   [ 1.58500153e+02]\n",
      "   [-2.49379181e+02]\n",
      "   [-8.68544464e+01]\n",
      "   [-1.36189758e+02]]\n",
      "\n",
      "  [[-2.60655174e+01]\n",
      "   [ 9.56661072e+01]\n",
      "   [-1.25311806e+02]\n",
      "   [ 6.70733643e+01]\n",
      "   [-1.81189484e+02]\n",
      "   [ 5.58429718e+00]\n",
      "   [-3.89003754e-02]\n",
      "   [-1.07580338e+02]\n",
      "   [-1.93449421e+01]\n",
      "   [ 2.14163094e+01]\n",
      "   [ 8.63074799e+01]\n",
      "   [-7.84052734e+01]\n",
      "   [ 1.52514069e+02]\n",
      "   [-2.33951828e+02]\n",
      "   [-1.25663284e+02]\n",
      "   [-9.89776077e+01]]\n",
      "\n",
      "  [[-1.14351440e+02]\n",
      "   [ 1.39550461e+02]\n",
      "   [-1.41039001e+02]\n",
      "   [ 6.27747612e+01]\n",
      "   [-1.49565582e+02]\n",
      "   [ 2.90751648e+01]\n",
      "   [-9.58589478e+01]\n",
      "   [-8.81796417e+01]\n",
      "   [ 6.13546677e+01]\n",
      "   [ 1.70148468e+00]\n",
      "   [ 1.09770325e+02]\n",
      "   [-7.64088898e+01]\n",
      "   [ 1.27648277e+02]\n",
      "   [-2.48892548e+02]\n",
      "   [-1.67490875e+02]\n",
      "   [-1.71769913e+02]]]\n",
      "\n",
      "\n",
      " [[[-3.71691055e+01]\n",
      "   [ 6.06578712e+01]\n",
      "   [ 2.86122398e+01]\n",
      "   [ 7.48125992e+01]\n",
      "   [-2.52475082e+02]\n",
      "   [-5.52984543e+01]\n",
      "   [-1.09553833e+02]\n",
      "   [ 1.29867363e+00]\n",
      "   [ 5.50941849e+00]\n",
      "   [ 8.60286713e+01]\n",
      "   [-2.11065903e+01]\n",
      "   [ 2.94571571e+01]\n",
      "   [ 6.11403198e+01]\n",
      "   [-2.93847198e+02]\n",
      "   [ 5.16431427e+01]\n",
      "   [-1.63697815e+02]]\n",
      "\n",
      "  [[-5.56609650e+01]\n",
      "   [ 8.81326294e+01]\n",
      "   [-4.71937599e+01]\n",
      "   [ 2.38224106e+01]\n",
      "   [-2.36439178e+02]\n",
      "   [-2.61135483e+01]\n",
      "   [-1.09901421e+02]\n",
      "   [-2.84123573e+01]\n",
      "   [-2.24042225e+01]\n",
      "   [ 8.58246155e+01]\n",
      "   [ 6.00190544e+00]\n",
      "   [-5.53628159e+00]\n",
      "   [ 9.65991516e+01]\n",
      "   [-3.83463318e+02]\n",
      "   [ 1.29948807e+01]\n",
      "   [-2.15638977e+02]]\n",
      "\n",
      "  [[-3.15154362e+01]\n",
      "   [ 1.02364609e+02]\n",
      "   [-1.43450378e+02]\n",
      "   [ 8.59698944e+01]\n",
      "   [-2.52504684e+02]\n",
      "   [ 3.67879486e+00]\n",
      "   [-5.47437515e+01]\n",
      "   [-8.35332947e+01]\n",
      "   [ 4.11245108e+00]\n",
      "   [ 9.98336105e+01]\n",
      "   [ 7.23171844e+01]\n",
      "   [-2.81989632e+01]\n",
      "   [ 1.53107117e+02]\n",
      "   [-3.52592896e+02]\n",
      "   [-1.03662476e+02]\n",
      "   [-1.72460007e+02]]\n",
      "\n",
      "  [[-3.39471397e+01]\n",
      "   [ 1.18370895e+02]\n",
      "   [-1.01947884e+02]\n",
      "   [ 3.66761017e+01]\n",
      "   [-2.13524948e+02]\n",
      "   [ 1.20986099e+01]\n",
      "   [-6.58131332e+01]\n",
      "   [-1.23648956e+02]\n",
      "   [-1.59972591e+01]\n",
      "   [ 3.64599190e+01]\n",
      "   [ 6.14349861e+01]\n",
      "   [-6.69352722e+01]\n",
      "   [ 1.50962967e+02]\n",
      "   [-3.50062439e+02]\n",
      "   [-1.37491165e+02]\n",
      "   [-1.09821625e+02]]\n",
      "\n",
      "  [[-1.25043159e+02]\n",
      "   [ 1.49498444e+02]\n",
      "   [-9.47135086e+01]\n",
      "   [ 4.55731354e+01]\n",
      "   [-1.88620514e+02]\n",
      "   [ 6.57851257e+01]\n",
      "   [-1.30634857e+02]\n",
      "   [-1.11287056e+02]\n",
      "   [ 5.90753975e+01]\n",
      "   [-1.45174065e+01]\n",
      "   [ 9.58364029e+01]\n",
      "   [-6.84039536e+01]\n",
      "   [ 1.24927536e+02]\n",
      "   [-3.46854065e+02]\n",
      "   [-1.64414337e+02]\n",
      "   [-1.52620514e+02]]]], W.grad.numpy(): [[[[-1.05645691e+02]\n",
      "   [-2.01233635e+01]\n",
      "   [-1.49882278e+02]\n",
      "   [ 2.06188095e+02]\n",
      "   [-1.35001266e+02]\n",
      "   [-2.34929562e-01]\n",
      "   [-3.76054802e+01]\n",
      "   [ 3.27953625e+00]\n",
      "   [ 1.12367458e+01]\n",
      "   [ 4.94730835e+01]\n",
      "   [ 9.88435898e+01]\n",
      "   [ 1.26689674e+02]\n",
      "   [-6.32781029e+01]\n",
      "   [-1.41452454e+02]\n",
      "   [ 8.20149231e+01]\n",
      "   [-2.11831131e+02]]\n",
      "\n",
      "  [[-8.49279404e+01]\n",
      "   [-2.75491028e+01]\n",
      "   [-2.05616425e+02]\n",
      "   [ 1.50188751e+02]\n",
      "   [-1.33572327e+02]\n",
      "   [ 2.57772083e+01]\n",
      "   [-1.11375246e+01]\n",
      "   [-6.65546417e+00]\n",
      "   [ 1.65217152e+01]\n",
      "   [-2.94589367e+01]\n",
      "   [ 1.34262085e+02]\n",
      "   [ 4.88686790e+01]\n",
      "   [-1.13591099e+00]\n",
      "   [-1.99641098e+02]\n",
      "   [ 6.50487442e+01]\n",
      "   [-2.95012909e+02]]\n",
      "\n",
      "  [[-6.90266495e+01]\n",
      "   [-4.15998268e+01]\n",
      "   [-2.57041779e+02]\n",
      "   [ 2.30137833e+02]\n",
      "   [-1.08955025e+02]\n",
      "   [ 5.65249825e+00]\n",
      "   [ 3.30039291e+01]\n",
      "   [-3.96655273e+01]\n",
      "   [ 5.29015827e+00]\n",
      "   [-4.12875557e+01]\n",
      "   [ 1.68186295e+02]\n",
      "   [ 4.47323456e+01]\n",
      "   [ 5.60536690e+01]\n",
      "   [-1.86990860e+02]\n",
      "   [ 7.51116705e+00]\n",
      "   [-2.69889038e+02]]\n",
      "\n",
      "  [[-4.90958710e+01]\n",
      "   [-3.52368660e+01]\n",
      "   [-2.34394928e+02]\n",
      "   [ 2.24959946e+02]\n",
      "   [-1.33998215e+02]\n",
      "   [-3.78519363e+01]\n",
      "   [ 6.25472870e+01]\n",
      "   [-9.65747910e+01]\n",
      "   [-1.04518909e+01]\n",
      "   [-5.41348114e+01]\n",
      "   [ 1.50591019e+02]\n",
      "   [ 1.25958347e+00]\n",
      "   [ 5.39370422e+01]\n",
      "   [-1.30859909e+02]\n",
      "   [-5.90739632e+01]\n",
      "   [-2.57829102e+02]]\n",
      "\n",
      "  [[-9.34716721e+01]\n",
      "   [ 3.94591999e+00]\n",
      "   [-2.59044708e+02]\n",
      "   [ 2.11363235e+02]\n",
      "   [-1.24154663e+02]\n",
      "   [-9.59835625e+00]\n",
      "   [ 2.54309349e+01]\n",
      "   [-1.28695007e+02]\n",
      "   [ 3.11065025e+01]\n",
      "   [-3.63582687e+01]\n",
      "   [ 1.91348022e+02]\n",
      "   [ 1.28790646e+01]\n",
      "   [ 6.02757530e+01]\n",
      "   [-1.43611084e+02]\n",
      "   [-2.12342758e+01]\n",
      "   [-3.02779022e+02]]]\n",
      "\n",
      "\n",
      " [[[-1.30759598e+02]\n",
      "   [-5.30780144e+01]\n",
      "   [-3.65081406e+01]\n",
      "   [ 1.16226929e+02]\n",
      "   [-1.43968079e+02]\n",
      "   [ 2.62289371e+01]\n",
      "   [-4.83289413e+01]\n",
      "   [-4.52541113e+00]\n",
      "   [-1.54871950e+01]\n",
      "   [ 1.65274841e+02]\n",
      "   [ 6.37024689e+01]\n",
      "   [ 1.20104179e+02]\n",
      "   [-6.70979309e+01]\n",
      "   [-1.77250290e+02]\n",
      "   [ 9.24349976e+01]\n",
      "   [-1.95128494e+02]]\n",
      "\n",
      "  [[-1.16220749e+02]\n",
      "   [-3.30083466e+01]\n",
      "   [-1.03258072e+02]\n",
      "   [ 5.67695122e+01]\n",
      "   [-1.42624481e+02]\n",
      "   [ 4.47735443e+01]\n",
      "   [-1.14147892e+01]\n",
      "   [-2.06628780e+01]\n",
      "   [-4.33663559e+01]\n",
      "   [ 9.86896820e+01]\n",
      "   [ 8.88731918e+01]\n",
      "   [ 5.40590668e+01]\n",
      "   [ 2.64875650e+00]\n",
      "   [-2.29597656e+02]\n",
      "   [ 1.02947083e+02]\n",
      "   [-2.64780060e+02]]\n",
      "\n",
      "  [[-9.37098083e+01]\n",
      "   [-8.36794472e+00]\n",
      "   [-1.61437592e+02]\n",
      "   [ 1.25073792e+02]\n",
      "   [-1.41489975e+02]\n",
      "   [ 1.70049362e+01]\n",
      "   [ 4.18273544e+01]\n",
      "   [-5.35077095e+01]\n",
      "   [-2.52867470e+01]\n",
      "   [ 6.81087036e+01]\n",
      "   [ 9.66426849e+01]\n",
      "   [ 3.23420296e+01]\n",
      "   [ 9.01497269e+01]\n",
      "   [-1.88990158e+02]\n",
      "   [ 2.60766048e+01]\n",
      "   [-2.34107651e+02]]\n",
      "\n",
      "  [[-5.85138016e+01]\n",
      "   [-2.33964562e+00]\n",
      "   [-1.52788635e+02]\n",
      "   [ 1.25451736e+02]\n",
      "   [-1.37870758e+02]\n",
      "   [-5.23326015e+00]\n",
      "   [ 5.57009163e+01]\n",
      "   [-1.10888412e+02]\n",
      "   [-5.09408722e+01]\n",
      "   [ 9.69201374e+00]\n",
      "   [ 7.61016159e+01]\n",
      "   [ 4.83366203e+00]\n",
      "   [ 7.97956543e+01]\n",
      "   [-1.32182144e+02]\n",
      "   [-3.02678795e+01]\n",
      "   [-2.18942764e+02]]\n",
      "\n",
      "  [[-1.21423073e+02]\n",
      "   [ 4.10962067e+01]\n",
      "   [-1.86889618e+02]\n",
      "   [ 1.26133377e+02]\n",
      "   [-1.17518234e+02]\n",
      "   [ 4.11687317e+01]\n",
      "   [-2.13897467e-01]\n",
      "   [-1.13331795e+02]\n",
      "   [ 9.72499943e+00]\n",
      "   [ 3.09898901e+00]\n",
      "   [ 1.06382538e+02]\n",
      "   [ 1.49879825e+00]\n",
      "   [ 7.09051208e+01]\n",
      "   [-1.29133682e+02]\n",
      "   [-1.71551418e+01]\n",
      "   [-2.63589844e+02]]]\n",
      "\n",
      "\n",
      " [[[-7.35902939e+01]\n",
      "   [-3.58176994e+01]\n",
      "   [-3.91610184e+01]\n",
      "   [ 9.34227600e+01]\n",
      "   [-2.34856644e+02]\n",
      "   [-1.34909077e+01]\n",
      "   [-2.10024471e+01]\n",
      "   [-7.26594772e+01]\n",
      "   [-3.30976982e+01]\n",
      "   [ 1.88550903e+02]\n",
      "   [ 8.42464371e+01]\n",
      "   [ 8.25404968e+01]\n",
      "   [-3.08872318e+01]\n",
      "   [-2.25946426e+02]\n",
      "   [ 1.05908760e+02]\n",
      "   [-1.99482285e+02]]\n",
      "\n",
      "  [[-4.86233177e+01]\n",
      "   [-2.93912754e+01]\n",
      "   [-1.08916718e+02]\n",
      "   [ 5.14841805e+01]\n",
      "   [-2.17893204e+02]\n",
      "   [ 2.58462696e+01]\n",
      "   [ 1.49251928e+01]\n",
      "   [-6.35331993e+01]\n",
      "   [-4.49299583e+01]\n",
      "   [ 1.38390915e+02]\n",
      "   [ 1.41977020e+02]\n",
      "   [ 2.77888927e+01]\n",
      "   [ 5.09371300e+01]\n",
      "   [-2.80378174e+02]\n",
      "   [ 8.05642776e+01]\n",
      "   [-2.19628326e+02]]\n",
      "\n",
      "  [[-2.75799141e+01]\n",
      "   [ 7.72902632e+00]\n",
      "   [-1.96252594e+02]\n",
      "   [ 1.15850624e+02]\n",
      "   [-2.17371338e+02]\n",
      "   [ 2.22289600e+01]\n",
      "   [ 6.18699608e+01]\n",
      "   [-9.50439224e+01]\n",
      "   [-4.10830002e+01]\n",
      "   [ 1.38915527e+02]\n",
      "   [ 1.76892029e+02]\n",
      "   [ 2.75099983e+01]\n",
      "   [ 1.36497986e+02]\n",
      "   [-2.32300049e+02]\n",
      "   [-2.27395325e+01]\n",
      "   [-1.75595795e+02]]\n",
      "\n",
      "  [[-1.20376694e+00]\n",
      "   [ 3.28416061e+01]\n",
      "   [-1.74532043e+02]\n",
      "   [ 9.16015930e+01]\n",
      "   [-1.88469589e+02]\n",
      "   [-7.50869465e+00]\n",
      "   [ 9.53311615e+01]\n",
      "   [-1.50747940e+02]\n",
      "   [-5.55728226e+01]\n",
      "   [ 9.05029755e+01]\n",
      "   [ 1.57531174e+02]\n",
      "   [-1.13067478e-02]\n",
      "   [ 1.29644882e+02]\n",
      "   [-1.74706665e+02]\n",
      "   [-7.50932388e+01]\n",
      "   [-1.73175674e+02]]\n",
      "\n",
      "  [[-8.27279892e+01]\n",
      "   [ 9.17663345e+01]\n",
      "   [-2.11898926e+02]\n",
      "   [ 8.55282059e+01]\n",
      "   [-1.51297302e+02]\n",
      "   [ 3.81872597e+01]\n",
      "   [ 3.21423988e+01]\n",
      "   [-1.30792694e+02]\n",
      "   [-5.38524199e+00]\n",
      "   [ 8.17423019e+01]\n",
      "   [ 1.57631317e+02]\n",
      "   [ 9.59306526e+00]\n",
      "   [ 1.16108559e+02]\n",
      "   [-1.72706940e+02]\n",
      "   [-9.88096619e+01]\n",
      "   [-2.33995529e+02]]]\n",
      "\n",
      "\n",
      " [[[-6.85262146e+01]\n",
      "   [ 8.99102688e+00]\n",
      "   [-2.81572704e+01]\n",
      "   [ 1.15900093e+02]\n",
      "   [-2.29621170e+02]\n",
      "   [-5.39785194e+01]\n",
      "   [-9.98587036e+01]\n",
      "   [-2.90465279e+01]\n",
      "   [-2.23618031e+01]\n",
      "   [ 9.50817947e+01]\n",
      "   [-1.11478710e+01]\n",
      "   [ 5.28827477e+01]\n",
      "   [ 5.54485245e+01]\n",
      "   [-2.22198456e+02]\n",
      "   [ 5.97512474e+01]\n",
      "   [-1.49237808e+02]]\n",
      "\n",
      "  [[-4.44186554e+01]\n",
      "   [ 2.82013912e+01]\n",
      "   [-9.02769470e+01]\n",
      "   [ 5.59393463e+01]\n",
      "   [-2.21031433e+02]\n",
      "   [-7.59994698e+00]\n",
      "   [-6.08904991e+01]\n",
      "   [-2.28381920e+01]\n",
      "   [-3.46667175e+01]\n",
      "   [ 6.92672653e+01]\n",
      "   [ 2.38991852e+01]\n",
      "   [-3.00068474e+00]\n",
      "   [ 9.71094894e+01]\n",
      "   [-2.89730560e+02]\n",
      "   [ 2.70176468e+01]\n",
      "   [-1.93462601e+02]]\n",
      "\n",
      "  [[-3.01555843e+01]\n",
      "   [ 8.00485687e+01]\n",
      "   [-1.68487930e+02]\n",
      "   [ 1.12476326e+02]\n",
      "   [-2.13198685e+02]\n",
      "   [ 6.55252790e+00]\n",
      "   [-1.75311279e+01]\n",
      "   [-6.33630104e+01]\n",
      "   [-1.79664211e+01]\n",
      "   [ 7.39582291e+01]\n",
      "   [ 9.30036774e+01]\n",
      "   [-3.75135269e+01]\n",
      "   [ 1.58500168e+02]\n",
      "   [-2.49379196e+02]\n",
      "   [-8.68544693e+01]\n",
      "   [-1.36189743e+02]]\n",
      "\n",
      "  [[-2.60655365e+01]\n",
      "   [ 9.56660767e+01]\n",
      "   [-1.25311752e+02]\n",
      "   [ 6.70733109e+01]\n",
      "   [-1.81189468e+02]\n",
      "   [ 5.58428907e+00]\n",
      "   [-3.88610959e-02]\n",
      "   [-1.07580330e+02]\n",
      "   [-1.93448830e+01]\n",
      "   [ 2.14163246e+01]\n",
      "   [ 8.63074722e+01]\n",
      "   [-7.84052734e+01]\n",
      "   [ 1.52513947e+02]\n",
      "   [-2.33951843e+02]\n",
      "   [-1.25663277e+02]\n",
      "   [-9.89775620e+01]]\n",
      "\n",
      "  [[-1.14351463e+02]\n",
      "   [ 1.39550476e+02]\n",
      "   [-1.41038986e+02]\n",
      "   [ 6.27747345e+01]\n",
      "   [-1.49565643e+02]\n",
      "   [ 2.90752068e+01]\n",
      "   [-9.58589859e+01]\n",
      "   [-8.81796570e+01]\n",
      "   [ 6.13546944e+01]\n",
      "   [ 1.70150375e+00]\n",
      "   [ 1.09770340e+02]\n",
      "   [-7.64088745e+01]\n",
      "   [ 1.27648170e+02]\n",
      "   [-2.48892548e+02]\n",
      "   [-1.67490860e+02]\n",
      "   [-1.71769913e+02]]]\n",
      "\n",
      "\n",
      " [[[-3.71691208e+01]\n",
      "   [ 6.06578369e+01]\n",
      "   [ 2.86121750e+01]\n",
      "   [ 7.48125916e+01]\n",
      "   [-2.52475189e+02]\n",
      "   [-5.52984734e+01]\n",
      "   [-1.09553802e+02]\n",
      "   [ 1.29864430e+00]\n",
      "   [ 5.50939941e+00]\n",
      "   [ 8.60286255e+01]\n",
      "   [-2.11065712e+01]\n",
      "   [ 2.94571457e+01]\n",
      "   [ 6.11403580e+01]\n",
      "   [-2.93847137e+02]\n",
      "   [ 5.16430550e+01]\n",
      "   [-1.63697739e+02]]\n",
      "\n",
      "  [[-5.56609879e+01]\n",
      "   [ 8.81326065e+01]\n",
      "   [-4.71938210e+01]\n",
      "   [ 2.38223972e+01]\n",
      "   [-2.36439331e+02]\n",
      "   [-2.61135597e+01]\n",
      "   [-1.09901405e+02]\n",
      "   [-2.84123058e+01]\n",
      "   [-2.24042530e+01]\n",
      "   [ 8.58246155e+01]\n",
      "   [ 6.00187540e+00]\n",
      "   [-5.53630495e+00]\n",
      "   [ 9.65991669e+01]\n",
      "   [-3.83463318e+02]\n",
      "   [ 1.29948740e+01]\n",
      "   [-2.15639008e+02]]\n",
      "\n",
      "  [[-3.15154762e+01]\n",
      "   [ 1.02364578e+02]\n",
      "   [-1.43450241e+02]\n",
      "   [ 8.59699097e+01]\n",
      "   [-2.52504745e+02]\n",
      "   [ 3.67876625e+00]\n",
      "   [-5.47436943e+01]\n",
      "   [-8.35332642e+01]\n",
      "   [ 4.11248875e+00]\n",
      "   [ 9.98335953e+01]\n",
      "   [ 7.23172607e+01]\n",
      "   [-2.81989555e+01]\n",
      "   [ 1.53107147e+02]\n",
      "   [-3.52592834e+02]\n",
      "   [-1.03662437e+02]\n",
      "   [-1.72459976e+02]]\n",
      "\n",
      "  [[-3.39471626e+01]\n",
      "   [ 1.18370903e+02]\n",
      "   [-1.01947792e+02]\n",
      "   [ 3.66761398e+01]\n",
      "   [-2.13524933e+02]\n",
      "   [ 1.20985832e+01]\n",
      "   [-6.58130722e+01]\n",
      "   [-1.23648987e+02]\n",
      "   [-1.59971714e+01]\n",
      "   [ 3.64600220e+01]\n",
      "   [ 6.14349976e+01]\n",
      "   [-6.69352951e+01]\n",
      "   [ 1.50962952e+02]\n",
      "   [-3.50062347e+02]\n",
      "   [-1.37491211e+02]\n",
      "   [-1.09821609e+02]]\n",
      "\n",
      "  [[-1.25043182e+02]\n",
      "   [ 1.49498459e+02]\n",
      "   [-9.47134552e+01]\n",
      "   [ 4.55731850e+01]\n",
      "   [-1.88620590e+02]\n",
      "   [ 6.57851181e+01]\n",
      "   [-1.30634872e+02]\n",
      "   [-1.11287102e+02]\n",
      "   [ 5.90754128e+01]\n",
      "   [-1.45173502e+01]\n",
      "   [ 9.58364258e+01]\n",
      "   [-6.84039917e+01]\n",
      "   [ 1.24927521e+02]\n",
      "   [-3.46853943e+02]\n",
      "   [-1.64414398e+02]\n",
      "   [-1.52620514e+02]]]]\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape15-W_shape15-1-0] _\u001b[0m\n",
      "\n",
      "Z_shape = (3, 17, 17, 16), W_shape = (1, 1, 16, 1), stride = 1, padding = 0\n",
      "backward = True, device = cuda()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[ 0.01555795]\n",
      "   [-3.0465872 ]\n",
      "   [ 4.0972595 ]\n",
      "   [ 1.2990627 ]\n",
      "   [-7.505466  ]\n",
      "   [-1.7335238 ]\n",
      "  ...[ 5.6893935 ]\n",
      "   [ 2.267663  ]\n",
      "   [-1.0709513 ]\n",
      "   [-5.0566583 ]\n",
      "   [-0.23777105]\n",
      "   [-9.931785  ]\n",
      "   [-0.44905776]]]])\n",
      "W_shape    = (1, 1, 16, 1)\n",
      "Wtch       = tensor([[[[ 0.0156],\n",
      "          [-3.0466],\n",
      "          [ 4.0973],\n",
      "          [ 1.2991],\n",
      "          [-7.5055],\n",
      "          [-1...  [-1.0710],\n",
      "          [-5.0567],\n",
      "          [-0.2378],\n",
      "          [-9.9318],\n",
      "          [-0.4491]]]], requires_grad=True)\n",
      "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ...  6.08375072e-01\n",
      "     2.21931624e+00  1.66837168e...3e+00]\n",
      "   [-1.25365603e+00 -1.71452928e+00  1.35930243e+01 ...  3.13170171e+00\n",
      "    -1.35708165e+00  1.29997072e+01]]]])\n",
      "Z_shape    = (3, 17, 17, 16)\n",
      "Ztch       = tensor([[[[ 8.8203e+00,  2.0008e+00,  4.8937e+00,  ...,  6.0838e-01,\n",
      "            2.2193e+00,  1.6684e+00],\n",
      "          [...[-1.2537e+00, -1.7145e+00,  1.3593e+01,  ...,  3.1317e+00,\n",
      "           -1.3571e+00,  1.3000e+01]]]], requires_grad=True)\n",
      "_W         = array([[[[ 0.01555795],\n",
      "         [-3.0465872 ],\n",
      "         [ 4.0972595 ],\n",
      "         [ 1.2990627 ],\n",
      "         [-7.505466  ]...13 ],\n",
      "         [-5.0566583 ],\n",
      "         [-0.23777105],\n",
      "         [-9.931785  ],\n",
      "         [-0.44905776]]]], dtype=float32)\n",
      "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
      "           6.08375072e-01,  2.21931624e+00,  1.66837...e+01, ...,\n",
      "           3.13170171e+00, -1.35708165e+00,  1.29997072e+01]]]],\n",
      "      shape=(3, 17, 17, 16), dtype=float32)\n",
      "backward   = True\n",
      "device     = cuda()\n",
      "err1       = np.float32(0.0)\n",
      "err2       = np.float32(0.00029865085)\n",
      "out        = tensor([[[[ -89.1888,   65.9584,  -71.3126,   94.1300,   58.1957, -154.0715,\n",
      "           -179.3213,  -36.3653,   84.003... -53.1932,\n",
      "             18.7652,    0.4121, -161.6255,   16.9990,  227.2095]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(2183.7771, grad_fn=<SumBackward0>)\n",
      "padding    = 0\n",
      "stride     = 1\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c5655fd2b0>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655fe3f0>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655fe3f0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655fe3f0>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c5655fe3f0>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[ -98.53308 ]\n",
      "   [ 116.89258 ]\n",
      "   [-204.87402 ]\n",
      "   [ 196.45303 ]\n",
      "   [-292.5897  ]\n",
      "   [ -45.538574]\n",
      "   [ -92.34815 ]\n",
      "   [ -49.117893]\n",
      "   [  18.121897]\n",
      "   [ -97.632866]\n",
      "   [ 158.6374  ]\n",
      "   [ -19.121422]\n",
      "   [  87.739204]\n",
      "   [-367.89557 ]\n",
      "   [-107.21064 ]\n",
      "   [-347.36365 ]]]], W.grad.numpy(): [[[[ -98.53316 ]\n",
      "   [ 116.89256 ]\n",
      "   [-204.87398 ]\n",
      "   [ 196.45316 ]\n",
      "   [-292.5897  ]\n",
      "   [ -45.5386  ]\n",
      "   [ -92.34817 ]\n",
      "   [ -49.118015]\n",
      "   [  18.121944]\n",
      "   [ -97.63288 ]\n",
      "   [ 158.63751 ]\n",
      "   [ -19.121498]\n",
      "   [  87.73919 ]\n",
      "   [-367.89545 ]\n",
      "   [-107.210556]\n",
      "   [-347.36356 ]]]]\n",
      "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape16-W_shape16-1-0] _\u001b[0m\n",
      "\n",
      "Z_shape = (1, 14, 14, 2), W_shape = (3, 3, 2, 2), stride = 1, padding = 0\n",
      "backward = True, device = cuda()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
      "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
      "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        y2 = y.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            y2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch = torch.Tensor(_Z).float()\u001b[90m\u001b[39;49;00m\n",
      "        Ztch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        Wtch = torch.Tensor(_W).float()\u001b[90m\u001b[39;49;00m\n",
      "        Wtch.requires_grad=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        out = torch.nn.functional.conv2d(Ztch.permute(\u001b[94m0\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), Wtch.permute(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
      "        out2 = out.sum()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            out2.backward()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
      "            err1 = np.linalg.norm(Ztch.grad.numpy() - Z.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            err2 = np.linalg.norm(Wtch.grad.numpy() - W.grad.numpy())\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mWtch.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mWtch.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m, W.grad.numpy(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mW.grad.numpy()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       err3 = np.linalg.norm(out2.detach().numpy() - y2.numpy())\u001b[90m\u001b[39;49;00m\n",
      "                                                      ^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "W          = needle.Tensor([[[[ -1.7671587   -8.082371  ]\n",
      "   [ -1.4591868   -3.807461  ]]\n",
      "\n",
      "  [[  4.2896194    5.705509  ]\n",
      "   [  7.3...7526     2.911123  ]\n",
      "   [-10.473016     0.61860955]]\n",
      "\n",
      "  [[ -0.65053475   0.46976614]\n",
      "   [  4.7152305  -13.698386  ]]]])\n",
      "W_shape    = (3, 3, 2, 2)\n",
      "Wtch       = tensor([[[[ -1.7672,  -8.0824],\n",
      "          [ -1.4592,  -3.8075]],\n",
      "\n",
      "         [[  4.2896,   5.7055],\n",
      "          [  7.3329,...         [-10.4730,   0.6186]],\n",
      "\n",
      "         [[ -0.6505,   0.4698],\n",
      "          [  4.7152, -13.6984]]]], requires_grad=True)\n",
      "Z          = needle.Tensor([[[[  8.820262     2.000786  ]\n",
      "   [  4.89369     11.204466  ]\n",
      "   [  9.33779     -4.8863893 ]\n",
      "   [  4.750...19315276  -8.283575  ]\n",
      "   [ -4.9275537   -7.359175  ]\n",
      "   [  8.240675     0.8211388 ]\n",
      "   [  2.8364513   -1.1133755 ]]]])\n",
      "Z_shape    = (1, 14, 14, 2)\n",
      "Ztch       = tensor([[[[  8.8203,   2.0008],\n",
      "          [  4.8937,  11.2045],\n",
      "          [  9.3378,  -4.8864],\n",
      "          [  4.7504,  ...\n",
      "          [ -4.9276,  -7.3592],\n",
      "          [  8.2407,   0.8211],\n",
      "          [  2.8365,  -1.1134]]]], requires_grad=True)\n",
      "_W         = array([[[[ -1.7671587 ,  -8.082371  ],\n",
      "         [ -1.4591868 ,  -3.807461  ]],\n",
      "\n",
      "        [[  4.2896194 ,   5.705509  ],...016  ,   0.61860955]],\n",
      "\n",
      "        [[ -0.65053475,   0.46976614],\n",
      "         [  4.7152305 , -13.698386  ]]]], dtype=float32)\n",
      "_Z         = array([[[[  8.820262  ,   2.000786  ],\n",
      "         [  4.89369   ,  11.204466  ],\n",
      "         [  9.33779   ,  -4.8863893 ],\n",
      " ...275537 ,  -7.359175  ],\n",
      "         [  8.240675  ,   0.8211388 ],\n",
      "         [  2.8364513 ,  -1.1133755 ]]]], dtype=float32)\n",
      "backward   = True\n",
      "device     = cuda()\n",
      "err1       = np.float32(1.2557781e-05)\n",
      "err2       = np.float32(8.0786966e-05)\n",
      "out        = tensor([[[[ -83.1438,   -6.3602,   93.8760,  -41.2035,  -96.8909,  152.8543,\n",
      "           -101.4654,  259.1811,    7.015...            -60.5771,   13.6480,  228.9975,    8.4413, -121.9792,   26.1601]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "out2       = tensor(2243.9304, grad_fn=<SumBackward0>)\n",
      "padding    = 0\n",
      "stride     = 1\n",
      "torch      = <module 'torch' from '/home/tyler/Documents/CMU/DL-Systems-Project/.venv/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "y          = <[TypeError(\"Conv.compute() missing 2 required positional arguments: 'A' and 'B'\") raised in repr()] Tensor object at 0x76c6759c0590>\n",
      "y2         = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c6759c0560>\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:445: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:306: in numpy\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "        self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c6759c0560>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c6759c0560>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mrealize_cached_data\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Run compute to realize the cached data\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# avoid recomputation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.cached_data\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# note: data implicitly calls realized cached data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
      "            *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: Summation.compute() missing 1 required positional argument: 'a'\u001b[0m\n",
      "\n",
      "self       = <[TypeError(\"Summation.compute() missing 1 required positional argument: 'a'\") raised in repr()] Tensor object at 0x76c6759c0560>\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: TypeError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Wtch.grad.numpy(): [[[[ -48.98436   -48.98436 ]\n",
      "   [  89.055916   89.055916]]\n",
      "\n",
      "  [[ -57.23758   -57.23758 ]\n",
      "   [  26.450378   26.450378]]\n",
      "\n",
      "  [[ -99.13748   -99.13748 ]\n",
      "   [ -26.94374   -26.94374 ]]]\n",
      "\n",
      "\n",
      " [[[-106.9129   -106.9129  ]\n",
      "   [  66.44665    66.44665 ]]\n",
      "\n",
      "  [[-105.4229   -105.4229  ]\n",
      "   [  10.877884   10.877884]]\n",
      "\n",
      "  [[-134.57861  -134.57861 ]\n",
      "   [ -36.973785  -36.973785]]]\n",
      "\n",
      "\n",
      " [[[ -97.087906  -97.087906]\n",
      "   [  23.784714   23.784714]]\n",
      "\n",
      "  [[ -77.06088   -77.06088 ]\n",
      "   [ -18.51759   -18.51759 ]]\n",
      "\n",
      "  [[-101.51124  -101.51124 ]\n",
      "   [ -65.75924   -65.75924 ]]]], W.grad.numpy(): [[[[ -48.984367  -48.984367]\n",
      "   [  89.05592    89.05592 ]]\n",
      "\n",
      "  [[ -57.23759   -57.23759 ]\n",
      "   [  26.450375   26.450375]]\n",
      "\n",
      "  [[ -99.137474  -99.137474]\n",
      "   [ -26.94374   -26.94374 ]]]\n",
      "\n",
      "\n",
      " [[[-106.91289  -106.91289 ]\n",
      "   [  66.44665    66.44665 ]]\n",
      "\n",
      "  [[-105.42286  -105.42286 ]\n",
      "   [  10.877888   10.877888]]\n",
      "\n",
      "  [[-134.57863  -134.57863 ]\n",
      "   [ -36.973785  -36.973785]]]\n",
      "\n",
      "\n",
      " [[[ -97.08791   -97.08791 ]\n",
      "   [  23.784695   23.784695]]\n",
      "\n",
      "  [[ -77.060905  -77.060905]\n",
      "   [ -18.517588  -18.517588]]\n",
      "\n",
      "  [[-101.51124  -101.51124 ]\n",
      "   [ -65.75923   -65.75923 ]]]]\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape0-W_shape0-1-0]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape1-W_shape1-1-1]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape2-W_shape2-1-2]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape3-W_shape3-1-0]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape4-W_shape4-1-0]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape5-W_shape5-2-0]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape6-W_shape6-2-1]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape7-W_shape7-2-2]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape8-W_shape8-2-0]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape9-W_shape9-2-0]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape10-W_shape10-1-0]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape11-W_shape11-1-0]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape12-W_shape12-1-0]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape13-W_shape13-1-0]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape14-W_shape14-1-0]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape15-W_shape15-1-0]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape16-W_shape16-1-0]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape0-W_shape0-1-0]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape1-W_shape1-1-1]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape2-W_shape2-1-2]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape3-W_shape3-1-0]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape4-W_shape4-1-0]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape5-W_shape5-2-0]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape6-W_shape6-2-1]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape7-W_shape7-2-2]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape8-W_shape8-2-0]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape9-W_shape9-2-0]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape10-W_shape10-1-0]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape11-W_shape11-1-0]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape12-W_shape12-1-0]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape13-W_shape13-1-0]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape14-W_shape14-1-0]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape15-W_shape15-1-0]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape16-W_shape16-1-0]\u001b[0m - TypeError: Summation.compute() missing 1 required positional argument: 'a'\n",
      "\u001b[31m===================== \u001b[31m\u001b[1m34 failed\u001b[0m, \u001b[33m1769 deselected\u001b[0m\u001b[31m in 2.48s\u001b[0m\u001b[31m ======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"op_conv and backward\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Fixing init._calculate_fans for convolution\n",
    "Previously, we have implemented Kaiming uniform/normal initializations, where we essentially assigned `fan_in = input_size` and `fan_out = output_size`.\n",
    "For convolution, this becomes somewhat more detailed, in that you should multiply both of these by the \"receptive field size\", which is in this case just the product of the kernel sizes -- which in our case are always going to be the same, i.e., $k\\times k$ kernels.\n",
    "\n",
    "**You will need to edit your `kaiming_uniform` in `python/needle/init/init_initializers.py`, etc. init functions to support multidimensional arrays.** In particular, it should support a new `shape` argument which is then passed to, e.g., the underlying `rand` function. Specifically, if the argument `shape` is not `None`, then ignore `fan_in` and `fan_out`, and use the value of `shape` for initializations instead.\n",
    "\n",
    "You can test this below; though it is not _directly_ graded, it must match ours to pass the nn.Conv mugrade tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]9;4;3;\u001b\\\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.11, pytest-9.0.1, pluggy-1.6.0 -- /home/tyler/Documents/CMU/DL-Systems-Project/.venv/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/tyler/Documents/CMU/DL-Systems-Project\n",
      "plugins: anyio-4.11.0\n",
      "collected 1803 items / 1801 deselected / 2 selected                            \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_conv.py::test_init_kaiming_uniform[needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;0\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_init_kaiming_uniform[needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;50\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\u001b]9;4;0;\u001b\\\n",
      "\n",
      "\u001b[32m====================== \u001b[32m\u001b[1m2 passed\u001b[0m, \u001b[33m1801 deselected\u001b[0m\u001b[32m in 0.92s\u001b[0m\u001b[32m ======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"kaiming_uniform\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing nn.Conv\n",
    "\n",
    "Essentially, nn.Conv is just a wrapper of the convolution operator we previously implemented\n",
    "which adds a bias term, initializes the weight and bias, and ensures that the padding is set so that the input and output dimensions are the same (in the `stride=1` case, anyways). \n",
    "\n",
    "Importantly, nn.Conv should support NCHW format instead of NHWC format. In particular, we think this makes more sense given our current BatchNorm implementation. You can implement this by applying `transpose` twice to both the input and output.  \n",
    "\n",
    "- Ensure nn.Conv works for `(N, C, H, W)` tensors even though we implemented the conv op for `(N, H, W, C)` tensors\n",
    "- Initialize the `(k, k, i, o)` weight tensor using Kaiming uniform initialization with default settings\n",
    "- Initialize the `(o,)` bias tensor using uniform initialization on the interval $\\displaystyle\\pm\\frac{1}{\\sqrt{\\verb|in_channels| \\times \\verb|kernel_size|^2}}$\n",
    "- Calculate the appropriate padding to ensure input and output dimensions are the same\n",
    "- Calculate the convolution, then add the properly-broadcasted bias term if present\n",
    "\n",
    "You can now test your nn.Conv against PyTorch's nn.Conv2d with the two PyTest calls below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]9;4;3;\u001b\\\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.11, pytest-9.0.1, pluggy-1.6.0 -- /home/tyler/Documents/CMU/DL-Systems-Project/.venv/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/tyler/Documents/CMU/DL-Systems-Project\n",
      "plugins: anyio-4.11.0\n",
      "collected 1803 items / 1793 deselected / 10 selected                           \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-4-8-16-3-1] \u001b]9;4;1;0\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-32-8-16-3-2] \u001b]9;4;1;10\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-32-8-8-3-2] \u001b]9;4;1;20\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-32-16-8-3-1] \u001b]9;4;1;30\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-32-16-8-3-2] \u001b]9;4;1;40\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-4-8-16-3-1] \u001b]9;4;1;50\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-32-8-16-3-2] \u001b]9;4;1;60\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-32-8-8-3-2] \u001b]9;4;1;70\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-32-16-8-3-1] \u001b]9;4;1;80\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-32-16-8-3-2] \u001b]9;4;1;90\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\u001b]9;4;0;\u001b\\\n",
      "\n",
      "\u001b[32m===================== \u001b[32m\u001b[1m10 passed\u001b[0m, \u001b[33m1793 deselected\u001b[0m\u001b[32m in 1.14s\u001b[0m\u001b[32m ======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"nn_conv_forward\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]9;4;3;\u001b\\\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.11, pytest-9.0.1, pluggy-1.6.0 -- /home/tyler/Documents/CMU/DL-Systems-Project/.venv/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/tyler/Documents/CMU/DL-Systems-Project\n",
      "plugins: anyio-4.11.0\n",
      "collected 1803 items / 1789 deselected / 14 selected                           \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-4-1-1-3-1] \u001b]9;4;1;0\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-8-16-3-1] \u001b]9;4;1;7\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-8-16-3-2] \u001b]9;4;1;14\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-8-8-3-1] \u001b]9;4;1;21\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-8-8-3-2] \u001b]9;4;1;28\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-16-8-3-1] \u001b]9;4;1;35\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-16-8-3-2] \u001b]9;4;1;42\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-4-1-1-3-1] \u001b]9;4;1;50\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-8-16-3-1] \u001b]9;4;1;57\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-8-16-3-2] \u001b]9;4;1;64\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-8-8-3-1] \u001b]9;4;1;71\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-8-8-3-2] \u001b]9;4;1;78\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-16-8-3-1] \u001b]9;4;1;85\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-16-8-3-2] \u001b]9;4;1;92\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\u001b]9;4;0;\u001b\\\n",
      "\n",
      "\u001b[32m===================== \u001b[32m\u001b[1m14 passed\u001b[0m, \u001b[33m1789 deselected\u001b[0m\u001b[32m in 1.03s\u001b[0m\u001b[32m ======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"nn_conv_backward\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit nn.Conv to mugrade [20 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b]9;4;3;\u001b\\\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.11, pytest-9.0.1, pluggy-1.6.0\n",
      "rootdir: /home/tyler/Documents/CMU/DL-Systems-Project\n",
      "plugins: anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mUsing needle backend\n",
      "collected 10 items / 9 deselected / 1 selected                                 \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_conv.py \u001b]9;4;2;0\u001b\\\u001b[31mF\u001b[0m\u001b]9;4;0;\u001b\\\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_____________________________ submit_conv_forward ______________________________\u001b[0m\n",
      "\n",
      "pyfuncitem = <Function submit_conv_forward>\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.hookimpl(hookwrapper=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mpytest_pyfunc_call\u001b[39;49;00m(pyfuncitem):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m## prior to test, initialize submission\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mglobal\u001b[39;49;00m _values, _submission_id, _errors\u001b[90m\u001b[39;49;00m\n",
      "        _values = []\u001b[90m\u001b[39;49;00m\n",
      "        _errors = \u001b[94m0\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        func_name = pyfuncitem.name[\u001b[94m7\u001b[39;49;00m:]\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mMUGRADE_OP\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] == \u001b[33m\"\u001b[39;49;00m\u001b[33msubmit\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      ">           _submission_id = start_submission(func_name)\u001b[90m\u001b[39;49;00m\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31m.venv/lib/python3.12/site-packages/mugrade/mugrade.py\u001b[0m:105: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "func_name = 'conv_forward'\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mstart_submission\u001b[39;49;00m(func_name):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\" Begin a submisssion to the mugrade server \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        response = requests.post(_server_url + \u001b[33m\"\u001b[39;49;00m\u001b[33msubmit\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                                 params = {\u001b[33m\"\u001b[39;49;00m\u001b[33muser_key\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mMUGRADE_KEY\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
      "                                           \u001b[33m\"\u001b[39;49;00m\u001b[33massignment\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mMUGRADE_HW\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
      "                                           \u001b[33m\"\u001b[39;49;00m\u001b[33mproblem\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: func_name},\u001b[90m\u001b[39;49;00m\n",
      "                                 verify=\u001b[94mFalse\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m response.status_code != \u001b[94m200\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      ">           \u001b[94mraise\u001b[39;49;00m \u001b[96mException\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mError : \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mresponse.text\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           Exception: Error : {\"detail\":\"Invalid API key\"}\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m.venv/lib/python3.12/site-packages/mugrade/mugrade.py\u001b[0m:56: Exception\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1msubmit_conv_forward\u001b[0m - Exception: Error : {\"detail\":\"Invalid API key\"}\n",
      "\u001b[31m======================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m9 deselected\u001b[0m\u001b[31m in 0.81s\u001b[0m\u001b[31m ========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"$MY_API_KEY\" \"$HW4_NAME\" -k \"conv_forward\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b]9;4;3;\u001b\\\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.11, pytest-9.0.1, pluggy-1.6.0\n",
      "rootdir: /home/tyler/Documents/CMU/DL-Systems-Project\n",
      "plugins: anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mUsing needle backend\n",
      "collected 10 items / 9 deselected / 1 selected                                 \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_conv.py \u001b]9;4;2;0\u001b\\\u001b[31mF\u001b[0m\u001b]9;4;0;\u001b\\\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_____________________________ submit_conv_backward _____________________________\u001b[0m\n",
      "\n",
      "pyfuncitem = <Function submit_conv_backward>\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.hookimpl(hookwrapper=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mpytest_pyfunc_call\u001b[39;49;00m(pyfuncitem):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m## prior to test, initialize submission\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mglobal\u001b[39;49;00m _values, _submission_id, _errors\u001b[90m\u001b[39;49;00m\n",
      "        _values = []\u001b[90m\u001b[39;49;00m\n",
      "        _errors = \u001b[94m0\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        func_name = pyfuncitem.name[\u001b[94m7\u001b[39;49;00m:]\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mMUGRADE_OP\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] == \u001b[33m\"\u001b[39;49;00m\u001b[33msubmit\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      ">           _submission_id = start_submission(func_name)\u001b[90m\u001b[39;49;00m\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31m.venv/lib/python3.12/site-packages/mugrade/mugrade.py\u001b[0m:105: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "func_name = 'conv_backward'\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mstart_submission\u001b[39;49;00m(func_name):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\" Begin a submisssion to the mugrade server \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        response = requests.post(_server_url + \u001b[33m\"\u001b[39;49;00m\u001b[33msubmit\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                                 params = {\u001b[33m\"\u001b[39;49;00m\u001b[33muser_key\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mMUGRADE_KEY\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
      "                                           \u001b[33m\"\u001b[39;49;00m\u001b[33massignment\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mMUGRADE_HW\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
      "                                           \u001b[33m\"\u001b[39;49;00m\u001b[33mproblem\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: func_name},\u001b[90m\u001b[39;49;00m\n",
      "                                 verify=\u001b[94mFalse\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m response.status_code != \u001b[94m200\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      ">           \u001b[94mraise\u001b[39;49;00m \u001b[96mException\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mError : \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mresponse.text\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           Exception: Error : {\"detail\":\"Invalid API key\"}\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m.venv/lib/python3.12/site-packages/mugrade/mugrade.py\u001b[0m:56: Exception\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1msubmit_conv_backward\u001b[0m - Exception: Error : {\"detail\":\"Invalid API key\"}\n",
      "\u001b[31m======================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m9 deselected\u001b[0m\u001b[31m in 0.86s\u001b[0m\u001b[31m ========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"$MY_API_KEY\" \"$HW4_NAME\" -k \"conv_backward\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Implementing \"ResNet9\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now use your convolutional layer to implement a model similar to _ResNet9_, which is known to be a reasonable model for getting good accuracy on CIFAR-10 quickly (see [here](https://github.com/davidcpage/cifar10-fast)). Our main change is that we used striding instead of pooling and divided all of the channels by 4 for the sake of performance (as our framework is not as well-optimized as industry-grade frameworks).\n",
    "\n",
    "In the figure below, before the first linear layer, you should \"flatten\" the tensor. You can use the module `Flatten` in `nn_basic.py`, or you can simply use `.reshape` in the `forward()` method of your ResNet9.\n",
    "\n",
    "Make sure that you pass the device to all modules in your model; otherwise, you will get errors about mismatched devices when trying to run with CUDA.\n",
    "\n",
    "<center><img src=\"https://github.com/dlsyscourse/hw4/blob/main/ResNet9.png?raw=true\" alt=\"ResNet9\" style=\"width: 400px;\" /></center>\n",
    "\n",
    "We have tried to make it easier to pass the tests here than for previous assignments where you have implemented models. In particular, we are just going to make sure it has the right number of parameters and similar accuracy and loss after 1 or 2 batches of CIFAR-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]9;4;3;\u001b\\\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.11, pytest-9.0.1, pluggy-1.6.0 -- /home/tyler/Documents/CMU/DL-Systems-Project/.venv/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/tyler/Documents/CMU/DL-Systems-Project\n",
      "plugins: anyio-4.11.0\n",
      "collected 1803 items / 1801 deselected / 2 selected                            \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_conv.py::test_resnet9[needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;0\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_resnet9[needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;50\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\u001b]9;4;0;\u001b\\\n",
      "\n",
      "\u001b[32m====================== \u001b[32m\u001b[1m2 passed\u001b[0m, \u001b[33m1801 deselected\u001b[0m\u001b[32m in 0.99s\u001b[0m\u001b[32m ======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"resnet9\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train a ResNet on CIFAR10: (remember to copy the solutions in `python/needle/optim.py` from previous homeworks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]9;4;3;\u001b\\\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.11, pytest-9.0.1, pluggy-1.6.0 -- /home/tyler/Documents/CMU/DL-Systems-Project/.venv/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/tyler/Documents/CMU/DL-Systems-Project\n",
      "plugins: anyio-4.11.0\n",
      "collected 1803 items / 1801 deselected / 2 selected                            \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_conv.py::test_train_cifar10[needle.backend_ndarray.ndarray_backend_cpu] \u001b]9;4;1;0\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_conv.py::test_train_cifar10[needle.backend_ndarray.ndarray_backend_cuda] \u001b]9;4;1;50\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\u001b]9;4;0;\u001b\\\n",
      "\n",
      "\u001b[32m====================== \u001b[32m\u001b[1m2 passed\u001b[0m, \u001b[33m1801 deselected\u001b[0m\u001b[32m in 8.73s\u001b[0m\u001b[32m ======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"train_cifar10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit ResNet9 to mugrade [10 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b]9;4;3;\u001b\\\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.11, pytest-9.0.1, pluggy-1.6.0\n",
      "rootdir: /home/tyler/Documents/CMU/DL-Systems-Project\n",
      "plugins: anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mUsing needle backend\n",
      "collected 10 items / 9 deselected / 1 selected                                 \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_conv.py \u001b]9;4;2;0\u001b\\\u001b[31mF\u001b[0m\u001b]9;4;0;\u001b\\\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m________________________________ submit_resnet9 ________________________________\u001b[0m\n",
      "\n",
      "pyfuncitem = <Function submit_resnet9>\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.hookimpl(hookwrapper=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mpytest_pyfunc_call\u001b[39;49;00m(pyfuncitem):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m## prior to test, initialize submission\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mglobal\u001b[39;49;00m _values, _submission_id, _errors\u001b[90m\u001b[39;49;00m\n",
      "        _values = []\u001b[90m\u001b[39;49;00m\n",
      "        _errors = \u001b[94m0\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        func_name = pyfuncitem.name[\u001b[94m7\u001b[39;49;00m:]\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mMUGRADE_OP\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] == \u001b[33m\"\u001b[39;49;00m\u001b[33msubmit\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      ">           _submission_id = start_submission(func_name)\u001b[90m\u001b[39;49;00m\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31m.venv/lib/python3.12/site-packages/mugrade/mugrade.py\u001b[0m:105: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "func_name = 'resnet9'\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mstart_submission\u001b[39;49;00m(func_name):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\" Begin a submisssion to the mugrade server \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        response = requests.post(_server_url + \u001b[33m\"\u001b[39;49;00m\u001b[33msubmit\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                                 params = {\u001b[33m\"\u001b[39;49;00m\u001b[33muser_key\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mMUGRADE_KEY\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
      "                                           \u001b[33m\"\u001b[39;49;00m\u001b[33massignment\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mMUGRADE_HW\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
      "                                           \u001b[33m\"\u001b[39;49;00m\u001b[33mproblem\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: func_name},\u001b[90m\u001b[39;49;00m\n",
      "                                 verify=\u001b[94mFalse\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m response.status_code != \u001b[94m200\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      ">           \u001b[94mraise\u001b[39;49;00m \u001b[96mException\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mError : \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mresponse.text\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           Exception: Error : {\"detail\":\"Invalid API key\"}\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m.venv/lib/python3.12/site-packages/mugrade/mugrade.py\u001b[0m:56: Exception\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1msubmit_resnet9\u001b[0m - Exception: Error : {\"detail\":\"Invalid API key\"}\n",
      "\u001b[31m======================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m9 deselected\u001b[0m\u001b[31m in 0.82s\u001b[0m\u001b[31m ========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"$MY_API_KEY\" \"$HW4_NAME\" -k \"resnet9\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can train your model on CIFAR-10 using the following code. Note that this is likely going to be quite slow, and also  not all that accurate due to the lack of data augmentation. You should expect it to take around 500s per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using needle backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|| 391/391 [00:54<00:00,  7.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Accuracy: 0.39073689258312017, Loss: 1.698575735092163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|| 391/391 [00:52<00:00,  7.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Accuracy: 0.49613171355498725, Loss: 1.3987921476364136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  84%| | 329/391 [00:46<00:08,  7.09it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     10\u001b[39m dataloader = ndl.data.DataLoader(\n\u001b[32m     11\u001b[39m          dataset=dataset,\n\u001b[32m     12\u001b[39m          batch_size=\u001b[32m128\u001b[39m,\n\u001b[32m     13\u001b[39m          shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m,)\n\u001b[32m     14\u001b[39m model = ResNet9(device=device, dtype=\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43mtrain_cifar10\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mndl\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAdam\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m      \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m evaluate_cifar10(model, dataloader)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CMU/DL-Systems-Project/apps/simple_ml.py:189\u001b[39m, in \u001b[36mtrain_cifar10\u001b[39m\u001b[34m(model, dataloader, n_epochs, optimizer, lr, weight_decay, loss_fn)\u001b[39m\n\u001b[32m    187\u001b[39m avg_acc, avg_loss = \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     avg_acc, avg_loss = \u001b[43mepoch_general_cifar10\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    190\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m avg_acc, avg_loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CMU/DL-Systems-Project/apps/simple_ml.py:157\u001b[39m, in \u001b[36mepoch_general_cifar10\u001b[39m\u001b[34m(dataloader, model, loss_fn, opt)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m opt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    156\u001b[39m     opt.reset_grad()\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m     opt.step()\n\u001b[32m    159\u001b[39m accs.append(acc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CMU/DL-Systems-Project/python/needle/autograd.py:297\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, out_grad)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m, out_grad=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    292\u001b[39m     out_grad = (\n\u001b[32m    293\u001b[39m         out_grad\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m out_grad\n\u001b[32m    295\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m init.ones(*\u001b[38;5;28mself\u001b[39m.shape, dtype=\u001b[38;5;28mself\u001b[39m.dtype, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m    296\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m     \u001b[43mcompute_gradient_of_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_grad\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CMU/DL-Systems-Project/python/needle/autograd.py:390\u001b[39m, in \u001b[36mcompute_gradient_of_variables\u001b[39m\u001b[34m(output_tensor, out_grad)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m node.requires_grad \u001b[38;5;129;01mor\u001b[39;00m node.is_leaf():\n\u001b[32m    389\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m out_grads = \u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgradient_as_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28minput\u001b[39m, out_grad \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node.inputs, out_grads):\n\u001b[32m    392\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m node_to_output_grads_list:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CMU/DL-Systems-Project/python/needle/autograd.py:67\u001b[39m, in \u001b[36mOp.gradient_as_tuple\u001b[39m\u001b[34m(self, out_grad, node)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgradient_as_tuple\u001b[39m(\u001b[38;5;28mself\u001b[39m, out_grad: \u001b[33m\"\u001b[39m\u001b[33mValue\u001b[39m\u001b[33m\"\u001b[39m, node: \u001b[33m\"\u001b[39m\u001b[33mValue\u001b[39m\u001b[33m\"\u001b[39m) -> Tuple[\u001b[33m\"\u001b[39m\u001b[33mValue\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m     66\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Convenience method to always return a tuple from gradient call\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m     69\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CMU/DL-Systems-Project/python/needle/ops/ops_mathematic.py:571\u001b[39m, in \u001b[36mConv.gradient\u001b[39m\u001b[34m(self, out_grad, node)\u001b[39m\n\u001b[32m    569\u001b[39m out_grad_HWNC = out_grad.transpose((\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m)).transpose((\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m))\n\u001b[32m    570\u001b[39m out_grad_HWNC = dilate(out_grad_HWNC, axes=(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m), dilation=\u001b[38;5;28mself\u001b[39m.stride - \u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m B_grad = \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA_CHWN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_grad_HWNC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    572\u001b[39m B_grad = B_grad.transpose((\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m)).transpose((\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m))\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m A_grad, B_grad\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CMU/DL-Systems-Project/python/needle/ops/ops_mathematic.py:579\u001b[39m, in \u001b[36mconv\u001b[39m\u001b[34m(a, b, stride, padding)\u001b[39m\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconv\u001b[39m(a, b, stride=\u001b[32m1\u001b[39m, padding=\u001b[32m1\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mConv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CMU/DL-Systems-Project/python/needle/autograd.py:80\u001b[39m, in \u001b[36mTensorOp.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args):\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmake_from_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CMU/DL-Systems-Project/python/needle/autograd.py:242\u001b[39m, in \u001b[36mTensor.make_from_op\u001b[39m\u001b[34m(op, inputs)\u001b[39m\n\u001b[32m    240\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tensor.requires_grad:\n\u001b[32m    241\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m tensor.detach()\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m     \u001b[43mtensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrealize_cached_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CMU/DL-Systems-Project/python/needle/autograd.py:107\u001b[39m, in \u001b[36mValue.realize_cached_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cached_data\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# note: data implicitly calls realized cached data\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m \u001b[38;5;28mself\u001b[39m.cached_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrealize_cached_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cached_data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CMU/DL-Systems-Project/python/needle/ops/ops_mathematic.py:547\u001b[39m, in \u001b[36mConv.compute\u001b[39m\u001b[34m(self, A, B)\u001b[39m\n\u001b[32m    545\u001b[39m         row_slice = \u001b[38;5;28mslice\u001b[39m(i, i + \u001b[38;5;28mself\u001b[39m.stride * out_h, \u001b[38;5;28mself\u001b[39m.stride)\n\u001b[32m    546\u001b[39m         col_slice = \u001b[38;5;28mslice\u001b[39m(j, j + \u001b[38;5;28mself\u001b[39m.stride * out_w, \u001b[38;5;28mself\u001b[39m.stride)\n\u001b[32m--> \u001b[39m\u001b[32m547\u001b[39m         \u001b[43mim2col_result\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m = A[:, row_slice, col_slice, :]\n\u001b[32m    549\u001b[39m im2col_reshaped = im2col_result.reshape((N * out_h * out_w, K_h * K_w * C_in))\n\u001b[32m    550\u001b[39m B = B.compact()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CMU/DL-Systems-Project/python/needle/backend_ndarray/ndarray.py:418\u001b[39m, in \u001b[36mNDArray.__setitem__\u001b[39m\u001b[34m(self, idxs, other)\u001b[39m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__setitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idxs, other):\n\u001b[32m    416\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Set the values of a view into an array, using the same semantics\u001b[39;00m\n\u001b[32m    417\u001b[39m \u001b[33;03m    as __getitem__().\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m     view = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43midxs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    419\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, NDArray):\n\u001b[32m    420\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m prod(view.shape) == prod(other.shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CMU/DL-Systems-Project/python/needle/backend_ndarray/ndarray.py:405\u001b[39m, in \u001b[36mNDArray.__getitem__\u001b[39m\u001b[34m(self, idxs)\u001b[39m\n\u001b[32m    403\u001b[39m     new_shape.append((stop - start + step - \u001b[32m1\u001b[39m) // step)\n\u001b[32m    404\u001b[39m     new_strides.append(\u001b[38;5;28mself\u001b[39m._strides[i] * step)\n\u001b[32m--> \u001b[39m\u001b[32m405\u001b[39m     new_offset += \u001b[38;5;28mself\u001b[39m._strides[i] * start\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m NDArray.make(\n\u001b[32m    407\u001b[39m     \u001b[38;5;28mtuple\u001b[39m(new_shape),\n\u001b[32m    408\u001b[39m     strides=\u001b[38;5;28mtuple\u001b[39m(new_strides),\n\u001b[32m   (...)\u001b[39m\u001b[32m    411\u001b[39m     offset=new_offset,\n\u001b[32m    412\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./python')\n",
    "sys.path.append('./apps')\n",
    "import needle as ndl\n",
    "from models import ResNet9\n",
    "from simple_ml import train_cifar10, evaluate_cifar10\n",
    "\n",
    "device = ndl.cuda()\n",
    "dataset = ndl.data.CIFAR10Dataset(\"data/cifar-10-batches-py\", train=True)\n",
    "dataloader = ndl.data.DataLoader(\n",
    "         dataset=dataset,\n",
    "         batch_size=128,\n",
    "         shuffle=True,)\n",
    "model = ResNet9(device=device, dtype=\"float32\")\n",
    "train_cifar10(model, dataloader, n_epochs=10, optimizer=ndl.optim.Adam,\n",
    "      lr=0.001, weight_decay=0.001)\n",
    "evaluate_cifar10(model, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Recurrent neural network [10 points]\n",
    "\n",
    "**Note:** In the following sections, you may find yourself wanting to index into tensors, i.e., to use getitem or setitem. However, we have not implemented these for tensors in our library; instead, you should use `stack` and `split` operations.\n",
    "\n",
    "In `python/needle/nn/nn_sequence.py`, implement `RNNCell`.\n",
    "\n",
    "$h^\\prime = \\text{tanh}(xW_{ih} + b_{ih} + hW_{hh} + b_{hh})$. If nonlinearity is 'relu', then ReLU is used in place of tanh.\n",
    "\n",
    "All weights and biases should be uniformly initialized on the interval $\\displaystyle\\pm\\frac{1}{\\sqrt{\\verb|hidden_size|}}$.\n",
    "\n",
    "In `python/needle/nn/nn_sequence.py`, implement `RNN`.\n",
    "\n",
    "For each element in the input sequence, each layer computes the following function:\n",
    "\n",
    "$h_t = \\text{tanh}(x_tW_{ih} + b_{ih} + h_{(t-1)}W_{hh} + b_{hh})$\n",
    "\n",
    "where $h_t$ is the hidden state at time $t$, $x_t$ is the input at time $t$, and $h_{(t-1)}$ is the hidden state of the previous layer at time $t-1$ or the initial hidden state at time $0$. If nonlinearity is 'relu', then ReLU is used in place of tanh.\n",
    "\n",
    "In a multi-layer RNN, the input $x_t^{(l)}$ of the $l$-th layer ($l \\ge 2$) is the hidden state $h_t^{(l-1)}$ of the previous layer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.11, pytest-8.4.1, pluggy-1.6.0 -- /home/tyler/Documents/CMU/Deep-Learning-Systems/.venv/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/tyler/Documents/CMU/Deep-Learning-Systems/hw4\n",
      "plugins: anyio-4.10.0\n",
      "collected 1803 items / 1163 deselected / 640 selected                          \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-tanh-True-True-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  0%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-tanh-True-True-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  0%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-tanh-True-True-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  0%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-tanh-True-True-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  0%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-tanh-True-True-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  0%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-tanh-True-True-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  0%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-tanh-True-True-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-tanh-True-True-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-tanh-True-False-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-tanh-True-False-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-tanh-True-False-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-tanh-True-False-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-tanh-True-False-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-tanh-True-False-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-tanh-True-False-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-tanh-True-False-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-tanh-False-True-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-tanh-False-True-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-tanh-False-True-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-tanh-False-True-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-tanh-False-True-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-tanh-False-True-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-tanh-False-True-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-tanh-False-True-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-tanh-False-False-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-tanh-False-False-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-tanh-False-False-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-tanh-False-False-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-tanh-False-False-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-tanh-False-False-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-tanh-False-False-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-tanh-False-False-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-relu-True-True-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-relu-True-True-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-relu-True-True-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-relu-True-True-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-relu-True-True-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-relu-True-True-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-relu-True-True-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-relu-True-True-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-relu-True-False-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-relu-True-False-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-relu-True-False-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-relu-True-False-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-relu-True-False-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-relu-True-False-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-relu-True-False-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-relu-True-False-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-relu-False-True-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-relu-False-True-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-relu-False-True-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-relu-False-True-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-relu-False-True-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-relu-False-True-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-relu-False-True-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-relu-False-True-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-relu-False-False-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-relu-False-False-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-relu-False-False-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-relu-False-False-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-relu-False-False-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-relu-False-False-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-relu-False-False-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cpu-relu-False-False-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-tanh-True-True-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-tanh-True-True-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-tanh-True-True-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-tanh-True-True-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-tanh-True-True-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-tanh-True-True-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-tanh-True-True-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-tanh-True-True-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-tanh-True-False-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-tanh-True-False-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-tanh-True-False-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-tanh-True-False-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-tanh-True-False-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-tanh-True-False-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-tanh-True-False-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-tanh-True-False-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-tanh-False-True-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-tanh-False-True-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-tanh-False-True-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-tanh-False-True-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-tanh-False-True-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-tanh-False-True-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-tanh-False-True-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-tanh-False-True-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-tanh-False-False-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-tanh-False-False-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-tanh-False-False-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-tanh-False-False-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-tanh-False-False-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-tanh-False-False-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-tanh-False-False-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-tanh-False-False-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-relu-True-True-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-relu-True-True-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-relu-True-True-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-relu-True-True-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-relu-True-True-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-relu-True-True-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-relu-True-True-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-relu-True-True-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-relu-True-False-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-relu-True-False-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-relu-True-False-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-relu-True-False-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-relu-True-False-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-relu-True-False-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-relu-True-False-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-relu-True-False-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-relu-False-True-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-relu-False-True-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-relu-False-True-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-relu-False-True-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-relu-False-True-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-relu-False-True-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-relu-False-True-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-relu-False-True-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-relu-False-False-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-relu-False-False-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-relu-False-False-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-relu-False-False-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-relu-False-False-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-relu-False-False-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-relu-False-False-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn_cell[cuda-relu-False-False-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-True-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-True-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-True-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-True-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-True-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-True-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-True-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-True-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-True-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-True-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 24%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-True-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 24%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-True-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 24%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-True-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 24%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-True-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 24%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-True-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 24%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-True-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-False-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-False-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-False-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-False-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-False-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-False-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-False-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-False-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-False-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-False-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-False-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-False-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-False-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-False-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-False-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-True-False-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-True-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-True-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-True-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-True-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-True-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-True-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-True-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-True-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-True-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-True-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-True-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-True-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-True-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-True-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-True-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-True-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-False-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-False-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-False-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-False-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-False-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-False-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-False-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-False-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-False-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-False-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 39%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-False-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 39%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-False-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 39%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-False-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 39%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-False-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 39%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-False-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 39%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-tanh-False-False-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-True-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-True-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-True-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-True-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-True-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-True-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-True-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-True-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-True-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-True-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-True-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-True-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-True-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-True-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-True-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-True-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-False-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-False-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-False-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-False-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-False-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-False-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-False-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-False-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 48%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 48%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 48%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 48%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 48%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-False-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 48%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-False-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 49%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-False-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 49%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-False-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 49%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-False-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 49%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-False-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 49%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-False-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 49%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-True-False-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 51%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 51%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-True-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 51%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-True-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 51%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-True-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 51%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-True-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 51%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-True-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-True-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-True-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-True-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-True-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-True-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 54%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-True-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 54%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-True-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 54%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-True-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 54%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-True-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 54%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-True-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 54%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-True-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-False-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-False-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-False-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-False-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-False-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-False-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-False-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-False-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-False-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-False-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-False-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-False-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-False-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-False-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-False-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cpu-relu-False-False-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-True-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-True-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-True-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-True-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-True-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-True-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-True-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-True-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 63%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 63%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 63%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 63%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 63%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-True-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 63%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-True-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-True-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-True-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-True-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-True-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-True-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-True-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-False-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-False-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-False-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-False-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-False-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-False-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-False-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-False-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-False-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-False-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-False-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-False-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-False-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-False-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-False-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-True-False-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-True-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-True-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-True-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-True-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-True-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-True-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-True-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-True-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-True-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-True-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-True-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-True-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-True-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-True-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-True-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-True-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-False-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-False-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-False-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-False-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-False-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-False-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-False-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-False-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-False-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-False-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-False-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-False-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-False-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-False-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-False-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-tanh-False-False-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-True-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-True-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-True-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-True-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-True-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-True-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-True-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-True-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-True-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-True-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-True-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-True-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-True-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-True-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-True-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-True-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-False-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-False-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-False-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-False-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-False-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-False-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-False-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-False-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-False-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-False-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-False-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-False-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-False-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-False-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-False-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-True-False-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-True-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-True-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-True-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-True-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-True-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-True-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-True-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-True-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-True-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-True-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-True-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-True-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-True-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-True-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-True-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-True-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-False-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-False-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-False-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-False-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-False-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-False-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-False-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-False-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-False-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-False-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-False-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-False-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-False-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-False-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-False-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_rnn[cuda-relu-False-False-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m===================== \u001b[32m\u001b[1m640 passed\u001b[0m, \u001b[33m1163 deselected\u001b[0m\u001b[32m in 5.19s\u001b[0m\u001b[32m =====================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"test_rnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.11, pytest-8.4.1, pluggy-1.6.0\n",
      "rootdir: /home/tyler/Documents/CMU/Deep-Learning-Systems/hw4\n",
      "plugins: anyio-4.10.0\n",
      "\u001b[1mcollecting ... \u001b[0mUsing needle backend\n",
      "collected 10 items / 9 deselected / 1 selected                                 \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_sequence_models.py \n",
      "Submitting rnn...\n",
      "Grader test 1 passed\n",
      "Grader test 2 passed\n",
      "Grader test 3 passed\n",
      "Grader test 4 passed\n",
      "Grader test 5 passed\n",
      "Grader test 6 passed\n",
      "Grader test 7 passed\n",
      "Grader test 8 passed\n",
      "Grader test 9 passed\n",
      "Grader test 10 passed\n",
      "Grader test 11 passed\n",
      "Grader test 12 passed\n",
      "\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m9 deselected\u001b[0m\u001b[32m in 3.19s\u001b[0m\u001b[32m ========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"$MY_API_KEY\" \"$HW4_NAME\" -k \"rnn\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Long short-term memory network [10 points]\n",
    "In `python/needle/nn/nn_sequence.py`, implement `Sigmoid`.\n",
    "\n",
    "$$\\sigma(x) = \\frac{1}{1 + \\text{exp}(-x)}$$\n",
    "\n",
    "In `python/needle/nn/nn_sequence.py`, implement `LSTMCell`.\n",
    "\n",
    "\\begin{align*}\n",
    "i &= \\sigma(xW_{ii} + b_{ii} + hW_{hi} + b_{hi}) \\\\\n",
    "f &= \\sigma(xW_{if} + b_{if} + hW_{hf} + b_{hf}) \\\\\n",
    "g &= \\text{tanh}(xW_{ig} + b_{ig} + hW_{hg} + b_{hg}) \\\\\n",
    "o &= \\sigma(xW_{io} + b_{io} + hW_{ho} + b_{ho}) \\\\\n",
    "c^\\prime &= f * c + i * g \\\\\n",
    "h^\\prime &= o * \\text{tanh}(c^\\prime)\n",
    "\\end{align*}\n",
    "\n",
    "where $\\sigma$ is the sigmoid function, and $i$, $f$, $g$, $o$ are the input, forget, cell, and output gates, respectively. \n",
    "\n",
    "All weights and biases should be uniformly initialized on the interval $\\displaystyle\\pm\\frac{1}{\\sqrt{\\verb|hidden_size|}}$.\n",
    "\n",
    "Now implement `LSTM` in `python/needle/nn/nn_sequence.py`, which applies a multi-layer LSTM RNN to an input sequence. For each element in the input sequence, each layer computes the following function:\n",
    "\n",
    "\\begin{align*}\n",
    "i_t &= \\sigma(x_tW_{ii} + b_{ii} + h_{(t-1)}W_{hi} + b_{hi}) \\\\\n",
    "f_t &= \\sigma(x_tW_{if} + b_{if} + h_{(t-1)}W_{hf} + b_{hf}) \\\\\n",
    "g_t &= \\text{tanh}(x_tW_{ig} + b_{ig} + h_{(t-1)}W_{hg} + b_{hg}) \\\\\n",
    "o_t &= \\sigma(x_tW_{io} + b_{io} + h_{(t-1)}W_{ho} + b_{ho}) \\\\\n",
    "c_t &= f * c_{(t-1)} + i * g \\\\\n",
    "h_t &= o * \\text{tanh}(c_t)\n",
    "\\end{align*}\n",
    "\n",
    "where $h_t$ is the hidden state at time $t$, $c_t$ is the cell state at time $t$, $x_t$ is the input at time $t$, $h_{(t-1)}$ is the hidden state of the layer at time $t-1$ or the initial hidden state at time $0$, and $i_t$, $f_t$, $g_t$, $o_t$ are the input, forget, cell, and output gates at time $t$ respectively. \n",
    "\n",
    "In a multi-layer LSTM, the input $x_t^{(l)}$ of the $l$-th layer ($l \\ge 2$) is the hidden state $h_t^{(l-1)}$ of the previous layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.11, pytest-8.4.1, pluggy-1.6.0 -- /home/tyler/Documents/CMU/Deep-Learning-Systems/.venv/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/tyler/Documents/CMU/Deep-Learning-Systems/hw4\n",
      "plugins: anyio-4.10.0\n",
      "collected 1803 items / 1483 deselected / 320 selected                          \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cpu-True-True-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  0%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cpu-True-True-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  0%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cpu-True-True-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  0%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cpu-True-True-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cpu-True-True-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cpu-True-True-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cpu-True-True-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cpu-True-True-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cpu-True-False-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cpu-True-False-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cpu-True-False-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cpu-True-False-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cpu-True-False-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cpu-True-False-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cpu-True-False-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cpu-True-False-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cpu-False-True-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cpu-False-True-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cpu-False-True-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cpu-False-True-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cpu-False-True-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cpu-False-True-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cpu-False-True-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cpu-False-True-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cpu-False-False-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cpu-False-False-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cpu-False-False-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cpu-False-False-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cpu-False-False-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cpu-False-False-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cpu-False-False-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cpu-False-False-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cuda-True-True-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cuda-True-True-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cuda-True-True-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cuda-True-True-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cuda-True-True-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cuda-True-True-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cuda-True-True-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cuda-True-True-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cuda-True-False-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cuda-True-False-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cuda-True-False-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cuda-True-False-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cuda-True-False-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cuda-True-False-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cuda-True-False-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cuda-True-False-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cuda-False-True-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cuda-False-True-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cuda-False-True-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cuda-False-True-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cuda-False-True-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cuda-False-True-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cuda-False-True-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cuda-False-True-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cuda-False-False-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cuda-False-False-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cuda-False-False-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cuda-False-False-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cuda-False-False-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cuda-False-False-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cuda-False-False-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm_cell[cuda-False-False-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-True-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-True-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-True-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-True-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-True-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 24%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-True-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 24%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-True-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 24%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-True-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-True-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-True-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-True-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-True-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-True-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-True-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-True-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-True-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-False-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-False-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-False-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-False-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-False-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-False-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-False-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-False-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-False-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-False-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-False-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-False-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-False-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 39%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-False-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 39%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-False-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 39%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-True-False-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-True-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-True-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-True-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-True-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-True-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-True-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-True-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-True-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-True-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-True-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 48%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-True-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 48%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-True-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 48%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-True-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 49%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-True-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 49%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-True-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 49%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-True-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 51%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 51%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 51%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-False-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-False-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-False-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-False-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-False-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 54%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-False-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 54%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-False-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 54%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-False-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-False-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-False-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-False-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-False-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-False-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-False-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-False-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cpu-False-False-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-True-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-True-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 63%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-True-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 63%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-True-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 63%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-True-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-True-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-True-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-True-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-True-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-True-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-True-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-True-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-True-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-True-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-True-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-True-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-False-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-False-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-False-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-False-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-False-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-False-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-False-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-False-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-False-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-False-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-False-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-False-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-False-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-False-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-False-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-True-False-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-True-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-True-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-True-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-True-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-True-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-True-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-True-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-True-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-True-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-True-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-True-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-True-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-True-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-True-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-True-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-True-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-False-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-False-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-False-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-False-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-False-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-False-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-False-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-False-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-False-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-False-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-False-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-False-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-False-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-False-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-False-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_lstm[cuda-False-False-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m===================== \u001b[32m\u001b[1m320 passed\u001b[0m, \u001b[33m1483 deselected\u001b[0m\u001b[32m in 6.49s\u001b[0m\u001b[32m =====================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"test_lstm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.11, pytest-8.4.1, pluggy-1.6.0\n",
      "rootdir: /home/tyler/Documents/CMU/Deep-Learning-Systems/hw4\n",
      "plugins: anyio-4.10.0\n",
      "\u001b[1mcollecting ... \u001b[0mUsing needle backend\n",
      "collected 10 items / 9 deselected / 1 selected                                 \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_sequence_models.py \n",
      "Submitting lstm...\n",
      "Grader test 1 passed\n",
      "Grader test 2 passed\n",
      "Grader test 3 passed\n",
      "Grader test 4 passed\n",
      "Grader test 5 passed\n",
      "Grader test 6 passed\n",
      "Grader test 7 passed\n",
      "Grader test 8 passed\n",
      "Grader test 9 passed\n",
      "Grader test 10 passed\n",
      "Grader test 11 passed\n",
      "Grader test 12 passed\n",
      "Grader test 13 passed\n",
      "Grader test 14 passed\n",
      "Grader test 15 passed\n",
      "Grader test 16 passed\n",
      "\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m9 deselected\u001b[0m\u001b[32m in 4.40s\u001b[0m\u001b[32m ========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"$MY_API_KEY\" \"$HW4_NAME\" -k \"lstm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Penn Treebank dataset [10 points]\n",
    "\n",
    "In word-level language modeling tasks, the model predicts the probability of the next word in the sequence, based on the words already observed in the sequence. You will write support for the Penn Treebank dataset, which consists of stories from the Wall Street Journal, to train and evaluate a language model on word-level prediction.\n",
    "\n",
    "In `python/needle/data/datasets/ptb_dataset.py`, start by implementing the `Dictionary` class, which creates a dictionary from a list of words, mapping each word to a unique integer.\n",
    "\n",
    "Next, we will use this `Dictionary` class to create a corpus from the train and test txt files in the Penn Treebank dataset that you downloaded at the beginning of the notebook. Implement the `tokenize` function in the `Corpus` class to do this.\n",
    "\n",
    "In order to prepare the data for training and evaluation, you will next implement the `batchify` function. Starting from sequential data, batchify arranges the dataset into columns. For instance, with the alphabet as the sequence and batch size 4, we'd get\n",
    "\n",
    "```\n",
    " a g m s \n",
    " b h n t \n",
    " c i o u \n",
    " d j p v \n",
    " e k q w \n",
    " f l r x \n",
    "```\n",
    "\n",
    "These columns are treated as independent by the model, which means that the dependence of e. g. 'g' on 'f' cannot be learned, but allows more efficient batch processing.\n",
    "\n",
    "Next, implement the `get_batch` function. `get_batch` subdivides the source data into chunks of length `bptt`. If source is equal to the example output of the batchify function, with a bptt-limit of 2, we'd get the following two `Tensor`s for i = 0:\n",
    "```\n",
    " a g m s   b h n t \n",
    " b h n t   c i o u \n",
    "```\n",
    "Note that despite the name of the function, the subdivison of data is not done along the batch dimension (i.e. dimension 1), since that was handled by the batchify function. The chunks are along dimension 0, corresponding to the seq_len dimension in the LSTM or RNN. Also, as per the function docs, the second returned `Tensor` (the targets) should be reshaped to be 1-dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.11, pytest-8.4.1, pluggy-1.6.0 -- /home/tyler/Documents/CMU/Deep-Learning-Systems/.venv/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/tyler/Documents/CMU/Deep-Learning-Systems/hw4\n",
      "plugins: anyio-4.10.0\n",
      "collected 1803 items / 1777 deselected / 26 selected                           \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_cifar_ptb_data.py::test_cifar10_dataset[True] \u001b[32mPASSED\u001b[0m\u001b[32m      [  3%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_cifar10_dataset[False] \u001b[32mPASSED\u001b[0m\u001b[32m     [  7%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cpu-True-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cpu-True-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cpu-False-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cpu-False-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cuda-True-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cuda-True-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cuda-False-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cuda-False-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_ptb_dataset[cpu-True-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 42%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_ptb_dataset[cpu-True-3-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_ptb_dataset[cpu-True-32-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_ptb_dataset[cpu-True-32-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_ptb_dataset[cpu-False-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_ptb_dataset[cpu-False-3-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_ptb_dataset[cpu-False-32-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_ptb_dataset[cpu-False-32-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_ptb_dataset[cuda-True-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_ptb_dataset[cuda-True-3-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_ptb_dataset[cuda-True-32-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_ptb_dataset[cuda-True-32-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_ptb_dataset[cuda-False-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_ptb_dataset[cuda-False-3-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_ptb_dataset[cuda-False-32-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
      "tests/hw4/test_cifar_ptb_data.py::test_ptb_dataset[cuda-False-32-15] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m===================== \u001b[32m\u001b[1m26 passed\u001b[0m, \u001b[33m1777 deselected\u001b[0m\u001b[32m in 4.90s\u001b[0m\u001b[32m ======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"ptb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.11, pytest-8.4.1, pluggy-1.6.0\n",
      "rootdir: /home/tyler/Documents/CMU/Deep-Learning-Systems/hw4\n",
      "plugins: anyio-4.10.0\n",
      "\u001b[1mcollecting ... \u001b[0mUsing needle backend\n",
      "collected 10 items / 8 deselected / 2 selected                                 \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_cifar_ptb_data.py \n",
      "Submitting cifar10...\n",
      "Grader test 1 passed\n",
      "Grader test 2 passed\n",
      "Grader test 3 passed\n",
      "Grader test 4 passed\n",
      "Grader test 5 passed\n",
      "Grader test 6 passed\n",
      "Grader test 7 passed\n",
      "Grader test 8 passed\n",
      "Grader test 9 passed\n",
      "Grader test 10 passed\n",
      "Grader test 11 passed\n",
      "Grader test 12 passed\n",
      "Grader test 13 passed\n",
      "Grader test 14 passed\n",
      "Grader test 15 passed\n",
      "Grader test 16 passed\n",
      "Grader test 17 passed\n",
      "Grader test 18 passed\n",
      "\u001b[32m.\u001b[0m\n",
      "Submitting ptb...\n",
      "Grader test 1 passed\n",
      "Grader test 2 passed\n",
      "Grader test 3 passed\n",
      "Grader test 4 passed\n",
      "Grader test 5 passed\n",
      "Grader test 6 passed\n",
      "Grader test 7 passed\n",
      "Grader test 8 passed\n",
      "Grader test 9 passed\n",
      "Grader test 10 passed\n",
      "Grader test 11 passed\n",
      "Grader test 12 passed\n",
      "Grader test 13 passed\n",
      "Grader test 14 passed\n",
      "Grader test 15 passed\n",
      "Grader test 16 passed\n",
      "Grader test 17 passed\n",
      "Grader test 18 passed\n",
      "Grader test 19 passed\n",
      "Grader test 20 passed\n",
      "Grader test 21 passed\n",
      "Error : Internal Server Error\n",
      "Grader test 23 passed\n",
      "Grader test 24 passed\n",
      "Grader test 25 passed\n",
      "Grader test 26 passed\n",
      "Grader test 27 passed\n",
      "Grader test 28 passed\n",
      "Grader test 29 passed\n",
      "Grader test 30 passed\n",
      "Grader test 31 passed\n",
      "Grader test 32 passed\n",
      "Grader test 33 passed\n",
      "Grader test 34 passed\n",
      "Grader test 35 passed\n",
      "Grader test 36 passed\n",
      "Grader test 37 passed\n",
      "Grader test 38 passed\n",
      "Grader test 39 passed\n",
      "Grader test 40 passed\n",
      "Grader test 41 passed\n",
      "Grader test 42 passed\n",
      "Grader test 43 passed\n",
      "Grader test 44 passed\n",
      "Grader test 45 passed\n",
      "Grader test 46 passed\n",
      "Grader test 47 passed\n",
      "Grader test 48 passed\n",
      "Grader test 49 passed\n",
      "\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m2 passed\u001b[0m, \u001b[33m8 deselected\u001b[0m\u001b[32m in 44.62s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"$MY_API_KEY\" \"$HW4_NAME\" -k \"ptb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Training a word-level language model [10 points]\n",
    "\n",
    "Finally, you will use the `RNN` and `LSTM` components you have written to construct a language model that we will train on the Penn Treebank dataset.\n",
    "\n",
    "First, in `python/needle/nn/nn_sequence.py` implement `Embedding`. Consider we have a dictionary with 1000 words. Then for a word which indexes into this dictionary, we can represent this word as a one-hot vector of size 1000, and then use a linear layer to project this to a vector of some embedding size.\n",
    "\n",
    "In `apps/models.py`, you can now implement `LanguageModel`. Your language model should consist of \n",
    "\n",
    "- An embedding layer (which maps word IDs to embeddings) \n",
    "- A sequence model (either RNN or LSTM)\n",
    "- A linear layer (which outputs probabilities of the next word)\n",
    "\n",
    "In `apps/simple_ml.py` implement `epoch_general_ptb`, `train_ptb`, and `evaluate_ptb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.11, pytest-8.4.1, pluggy-1.6.0 -- /home/tyler/Documents/CMU/Deep-Learning-Systems/.venv/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/tyler/Documents/CMU/Deep-Learning-Systems/hw4\n",
      "plugins: anyio-4.10.0\n",
      "\u001b[1mcollecting ... \u001b[0mUsing needle backend\n",
      "collected 1 item                                                               \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.73s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m pytest -l -v -s \"tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-1-1-1]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4138.23s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.11, pytest-8.4.1, pluggy-1.6.0 -- /home/tyler/Documents/CMU/Deep-Learning-Systems/.venv/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/tyler/Documents/CMU/Deep-Learning-Systems/hw4\n",
      "plugins: anyio-4.10.0\n",
      "collected 1803 items / 1291 deselected / 512 selected                          \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  0%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  0%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  0%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  0%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  0%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-True-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1-False-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-True-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 24%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 24%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 24%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 24%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 24%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-rnn-1000-False-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-True-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1-False-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 39%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 39%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 39%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 39%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 39%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-True-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 48%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 48%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 48%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 48%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 48%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 49%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 49%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 49%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 49%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 49%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cpu-lstm-1000-False-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 51%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 51%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 51%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 51%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 51%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 54%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 54%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 54%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 54%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 54%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-True-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1-False-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 63%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 63%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 63%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 63%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 63%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-True-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-rnn-1000-False-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-True-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1-False-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-True-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-1-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_implementation[cuda-lstm-1000-False-12-34-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m===================== \u001b[32m\u001b[1m512 passed\u001b[0m, \u001b[33m1291 deselected\u001b[0m\u001b[32m in 9.42s\u001b[0m\u001b[32m =====================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"language_model_implementation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.11, pytest-8.4.1, pluggy-1.6.0 -- /home/tyler/Documents/CMU/Deep-Learning-Systems/.venv/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/tyler/Documents/CMU/Deep-Learning-Systems/hw4\n",
      "plugins: anyio-4.10.0\n",
      "collected 1803 items / 1801 deselected / 2 selected                            \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_sequence_models.py::test_language_model_training[cpu] \u001b[31mFAILED\u001b[0m\u001b[31m [ 50%]\u001b[0m\n",
      "tests/hw4/test_sequence_models.py::test_language_model_training[cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m______________________ test_language_model_training[cpu] _______________________\u001b[0m\n",
      "\n",
      "device = cpu()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_language_model_training\u001b[39;49;00m(device):\u001b[90m\u001b[39;49;00m\n",
      "        corpus = ndl.data.Corpus(\u001b[33m\"\u001b[39;49;00m\u001b[33mdata/ptb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, max_lines=\u001b[94m20\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        seq_len = \u001b[94m10\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        num_examples = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        batch_size = \u001b[94m16\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        seq_model = \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        num_layers = \u001b[94m2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        hidden_size = \u001b[94m10\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        n_epochs=\u001b[94m2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        train_data = ndl.data.batchify(corpus.train, batch_size=batch_size, device=device, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        model = LanguageModel(\u001b[94m30\u001b[39;49;00m, \u001b[96mlen\u001b[39;49;00m(corpus.dictionary), hidden_size=hidden_size, num_layers=num_layers, seq_model=seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        train_acc, train_loss = train_ptb(model, train_data, seq_len=seq_len, n_epochs=n_epochs, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        test_acc, test_loss = evaluate_ptb(model, train_data, seq_len=seq_len, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mstr\u001b[39;49;00m(device) == \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu()\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      ">           np.testing.assert_allclose(\u001b[94m5.65995\u001b[39;49;00m, train_loss, atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
      "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
      "\u001b[1m\u001b[31mE           \u001b[0m\n",
      "\u001b[1m\u001b[31mE           Mismatched elements: 1 / 1 (100%)\u001b[0m\n",
      "\u001b[1m\u001b[31mE           Max absolute difference among violations: 0.17366912\u001b[0m\n",
      "\u001b[1m\u001b[31mE           Max relative difference among violations: 0.02977039\u001b[0m\n",
      "\u001b[1m\u001b[31mE            ACTUAL: array(5.65995)\u001b[0m\n",
      "\u001b[1m\u001b[31mE            DESIRED: array(5.833619, dtype=float32)\u001b[0m\n",
      "\n",
      "batch_size = 16\n",
      "corpus     = <needle.data.datasets.ptb_dataset.Corpus object at 0x7bade98dd2b0>\n",
      "device     = cpu()\n",
      "hidden_size = 10\n",
      "model      = <models.LanguageModel object at 0x7bacaf88de50>\n",
      "n_epochs   = 2\n",
      "num_examples = 100\n",
      "num_layers = 2\n",
      "seq_len    = 10\n",
      "seq_model  = 'rnn'\n",
      "test_acc   = np.float64(0.078125)\n",
      "test_loss  = np.float32(5.412592)\n",
      "train_acc  = np.float64(0.03125)\n",
      "train_data = array([[  0.,  26.,  24.,  60.,  79.,  91., 108., 120., 131., 147., 158.,\n",
      "        165., 181.,  87., 197.,  26.],\n",
      "     ...25.,  46.,  35.,  78.,  78.,  26., 101., 130.,  26., 157.,  73.,\n",
      "        180., 105.,  32., 206., 148.]], dtype=float32)\n",
      "train_loss = np.float32(5.833619)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:239: AssertionError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Epoch 1/2, Accuracy: 0.00625, Loss: 6.077015399932861\n",
      "Epoch 2/2, Accuracy: 0.03125, Loss: 5.833619117736816\n",
      "----------------------------- Captured stderr call -----------------------------\n",
      "Processing Batches: 100%|| 2/2 [00:00<00:00, 37.16it/s]\n",
      "Processing Batches: 100%|| 2/2 [00:00<00:00, 39.90it/s]\n",
      "Processing Batches: 100%|| 2/2 [00:00<00:00, 165.15it/s]\n",
      "\u001b[31m\u001b[1m______________________ test_language_model_training[cuda] ______________________\u001b[0m\n",
      "\n",
      "device = cuda()\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_language_model_training\u001b[39;49;00m(device):\u001b[90m\u001b[39;49;00m\n",
      "        corpus = ndl.data.Corpus(\u001b[33m\"\u001b[39;49;00m\u001b[33mdata/ptb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, max_lines=\u001b[94m20\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        seq_len = \u001b[94m10\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        num_examples = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        batch_size = \u001b[94m16\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        seq_model = \u001b[33m'\u001b[39;49;00m\u001b[33mrnn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        num_layers = \u001b[94m2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        hidden_size = \u001b[94m10\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        n_epochs=\u001b[94m2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        train_data = ndl.data.batchify(corpus.train, batch_size=batch_size, device=device, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        model = LanguageModel(\u001b[94m30\u001b[39;49;00m, \u001b[96mlen\u001b[39;49;00m(corpus.dictionary), hidden_size=hidden_size, num_layers=num_layers, seq_model=seq_model, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        train_acc, train_loss = train_ptb(model, train_data, seq_len=seq_len, n_epochs=n_epochs, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        test_acc, test_loss = evaluate_ptb(model, train_data, seq_len=seq_len, device=device)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mstr\u001b[39;49;00m(device) == \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu()\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            np.testing.assert_allclose(\u001b[94m5.65995\u001b[39;49;00m, train_loss, atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            np.testing.assert_allclose(\u001b[94m5.328375\u001b[39;49;00m, test_loss, atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96mstr\u001b[39;49;00m(device) == \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda()\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      ">           np.testing.assert_allclose(\u001b[94m5.837475\u001b[39;49;00m, train_loss, atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
      "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
      "\u001b[1m\u001b[31mE           \u001b[0m\n",
      "\u001b[1m\u001b[31mE           Mismatched elements: 1 / 1 (100%)\u001b[0m\n",
      "\u001b[1m\u001b[31mE           Max absolute difference among violations: 0.03820116\u001b[0m\n",
      "\u001b[1m\u001b[31mE           Max relative difference among violations: 0.00650158\u001b[0m\n",
      "\u001b[1m\u001b[31mE            ACTUAL: array(5.837475)\u001b[0m\n",
      "\u001b[1m\u001b[31mE            DESIRED: array(5.875676, dtype=float32)\u001b[0m\n",
      "\n",
      "batch_size = 16\n",
      "corpus     = <needle.data.datasets.ptb_dataset.Corpus object at 0x7bacae4b9b80>\n",
      "device     = cuda()\n",
      "hidden_size = 10\n",
      "model      = <models.LanguageModel object at 0x7bacae4bad80>\n",
      "n_epochs   = 2\n",
      "num_examples = 100\n",
      "num_layers = 2\n",
      "seq_len    = 10\n",
      "seq_model  = 'rnn'\n",
      "test_acc   = np.float64(0.071875)\n",
      "test_loss  = np.float32(5.3347654)\n",
      "train_acc  = np.float64(0.028125)\n",
      "train_data = array([[  0.,  26.,  24.,  60.,  79.,  91., 108., 120., 131., 147., 158.,\n",
      "        165., 181.,  87., 197.,  26.],\n",
      "     ...25.,  46.,  35.,  78.,  78.,  26., 101., 130.,  26., 157.,  73.,\n",
      "        180., 105.,  32., 206., 148.]], dtype=float32)\n",
      "train_loss = np.float32(5.875676)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:242: AssertionError\n",
      "----------------------------- Captured stdout call -----------------------------\n",
      "Epoch 1/2, Accuracy: 0.009375000000000001, Loss: 6.098977088928223\n",
      "Epoch 2/2, Accuracy: 0.028125, Loss: 5.875676155090332\n",
      "----------------------------- Captured stderr call -----------------------------\n",
      "Processing Batches: 100%|| 2/2 [00:00<00:00, 14.32it/s]\n",
      "Processing Batches: 100%|| 2/2 [00:00<00:00, 41.31it/s]\n",
      "Processing Batches: 100%|| 2/2 [00:00<00:00, 187.12it/s]\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_training[cpu]\u001b[0m - AssertionError: \n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_language_model_training[cuda]\u001b[0m - AssertionError: \n",
      "\u001b[31m====================== \u001b[31m\u001b[1m2 failed\u001b[0m, \u001b[33m1801 deselected\u001b[0m\u001b[31m in 1.35s\u001b[0m\u001b[31m ======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"language_model_training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5545.17s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.11, pytest-8.4.1, pluggy-1.6.0\n",
      "rootdir: /home/tyler/Documents/CMU/Deep-Learning-Systems/hw4\n",
      "plugins: anyio-4.10.0\n",
      "\u001b[1mcollecting ... \u001b[0mUsing needle backend\n",
      "collected 10 items / 9 deselected / 1 selected                                 \u001b[0m\u001b[1m\n",
      "\n",
      "tests/hw4/test_sequence_models.py \n",
      "Submitting language_model...\n",
      "Grader test 1 passed\n",
      "Grader test 2 passed\n",
      "Grader test 3 passed\n",
      "Grader test 4 passed\n",
      "Grader test 5 passed\n",
      "Grader test 6 passed\n",
      "Grader test 7 passed\n",
      "Grader test 8 passed\n",
      "Grader test 9 passed\n",
      "Grader test 10 passed\n",
      "Processing Batches: 100%|| 4/4 [00:00<00:00, 30.66it/s]\n",
      "Epoch 1/2, Accuracy: 0.0234375, Loss: 5.849331378936768\n",
      "Processing Batches: 100%|| 4/4 [00:00<00:00, 38.83it/s]\n",
      "Epoch 2/2, Accuracy: 0.052083333333333336, Loss: 5.537635803222656\n",
      "Processing Batches: 100%|| 4/4 [00:00<00:00, 152.14it/s]\n",
      "Grader test 11 failed\n",
      "Grader test 12 passed\n",
      "\u001b[31mF\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m____________________________ submit_language_model _____________________________\u001b[0m\n",
      "\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1msubmit_language_model\u001b[0m - Failed\n",
      "\u001b[31m================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m9 deselected\u001b[0m, \u001b[33m1 warning\u001b[0m\u001b[31m in 3.52s\u001b[0m\u001b[31m ==================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"$MY_API_KEY\" \"$HW4_NAME\" -k \"language_model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can train your language model on the Penn Treebank dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|| 1452/1452 [07:05<00:00,  3.41it/s]\n",
      "Processing Batches: 100%|| 1452/1452 [07:05<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|| 1452/1452 [07:05<00:00,  3.41it/s]\n",
      "Processing Batches: 100%|| 1452/1452 [07:05<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Accuracy: 0.10468642389807162, Loss: 6.482345104217529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|| 1452/1452 [02:35<00:00,  9.35it/s]\n",
      "Processing Batches: 100%|| 1452/1452 [02:35<00:00,  9.35it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|| 1452/1452 [07:05<00:00,  3.41it/s]\n",
      "Processing Batches: 100%|| 1452/1452 [07:05<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Accuracy: 0.10468642389807162, Loss: 6.482345104217529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|| 1452/1452 [02:35<00:00,  9.35it/s]\n",
      "Processing Batches: 100%|| 1452/1452 [02:35<00:00,  9.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.11968943698347108), np.float32(6.2231727))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import needle as ndl\n",
    "sys.path.append('./apps')\n",
    "from models import LanguageModel\n",
    "from simple_ml import train_ptb, evaluate_ptb\n",
    "\n",
    "device = ndl.cuda()\n",
    "corpus = ndl.data.Corpus(\"data/ptb\")\n",
    "train_data = ndl.data.batchify(corpus.train, batch_size=16, device=device, dtype=\"float32\")\n",
    "model = LanguageModel(30, len(corpus.dictionary), hidden_size=10, num_layers=2, seq_model='rnn', device=device)\n",
    "train_ptb(model, train_data, seq_len=40, n_epochs=1, device=device)\n",
    "evaluate_ptb(model, train_data, seq_len=40, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
