{"cells":[{"cell_type":"markdown","id":"b38216e2","metadata":{"id":"b38216e2"},"source":["# Homework 3: Building an NDArray library\n","\n","In this homework, you will build a simple backing library for the processing that underlies most deep learning systems: the n-dimensional array (a.k.a. the NDArray).  Up until now, you have largely been using numpy for this purpose, but this homework will walk you through developing what amounts to your own (albeit much more limited) variant of numpy, which will support both CPU and GPU backends.  What's more, unlike numpy (and even variants like PyTorch), you won't simply call out to existing highly-optimized variants of matrix multiplication or other manipulation code, but actually write your own versions that are reasonably competitive will the highly optimized code backing these standard libraries (by some measure, i.e., \"only 2-3x slower\" ... which is a whole lot better than naive code that can easily be 100x slower).  This class will ultimately be integrated into `needle`, but for this assignment you can _only_ focus on the ndarray module, as this will be the only subject of the tests.\n","\n","**Note**: To avoid exhausting limited GPU resources in Colab, start by using CPU runtime for coding and testing non-GPU functions. Switch to GPU runtime when testing CUDA or GPU-accelerated code. This approach ensures efficient GPU usage and prevents running out of resources during critical tasks.\n"]},{"cell_type":"code","execution_count":53,"id":"db5a484c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8608,"status":"ok","timestamp":1763673758603,"user":{"displayName":"Andrew Zhang","userId":"07979726580656669632"},"user_tz":300},"id":"db5a484c","outputId":"0b407544-6eea-4a64-c61d-bc999b18c822"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive\n","/content/drive/MyDrive/10714\n","/content/drive/MyDrive/10714/DL-Systems-Project\n","Collecting git+https://github.com/dlsys10714/mugrade.git\n","  Cloning https://github.com/dlsys10714/mugrade.git to /tmp/pip-req-build-l8ij1h00\n","  Running command git clone --filter=blob:none --quiet https://github.com/dlsys10714/mugrade.git /tmp/pip-req-build-l8ij1h00\n","  Resolved https://github.com/dlsys10714/mugrade.git to commit ac73f725eb2ce0e2c6a38fa540035ee970b8b873\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pybind11 in /usr/local/lib/python3.12/dist-packages (3.0.1)\n"]}],"source":["# Code to set up the assignment\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/\n","!mkdir -p 10714\n","%cd /content/drive/MyDrive/10714\n","%cd /content/drive/MyDrive/10714/DL-Systems-Project\n","\n","!pip3 install --upgrade --no-deps git+https://github.com/dlsys10714/mugrade.git\n","!pip3 install pybind11"]},{"cell_type":"code","execution_count":54,"id":"1833_Ylh_yss","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":168,"status":"ok","timestamp":1763673758771,"user":{"displayName":"Andrew Zhang","userId":"07979726580656669632"},"user_tz":300},"id":"1833_Ylh_yss","outputId":"fe000288-3d1d-44ea-a8fa-ee1dbcdc4839"},"outputs":[{"output_type":"stream","name":"stdout","text":["bench_quantization_large.py  build\t     proj_andrew.ipynb\tsrc\n","bench_quantization.py\t     CMakeLists.txt  python\t\ttests\n","bench_quantization_xl.py     Makefile\t     README.md\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":48,"id":"09eedbc6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3560,"status":"ok","timestamp":1763673725167,"user":{"displayName":"Andrew Zhang","userId":"07979726580656669632"},"user_tz":300},"id":"09eedbc6","outputId":"405b8db9-15b1-4cbd-fc66-3ea243a2d583"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0mCMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n","  Compatibility with CMake < 3.10 will be removed from a future version of\n","  CMake.\n","\n","  Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n","  to tell CMake that the project requires at least <min> but has been updated\n","  to work with policies introduced by <max> or earlier.\n","\n","\u001b[0m\n","-- Found pybind11: /usr/local/lib/python3.12/dist-packages/pybind11/include (found version \"3.0.1\")\n","-- Found cuda, building cuda backend\n","Thu Nov 20 21:22:02 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n","-- Autodetected CUDA architecture(s):  7.5\n","-- Configuring done (1.0s)\n","-- Generating done (0.7s)\n","-- Build files have been written to: /content/drive/MyDrive/10714/DL-Systems-Project/build\n","make[1]: Entering directory '/content/drive/MyDrive/10714/DL-Systems-Project/build'\n","make[2]: Entering directory '/content/drive/MyDrive/10714/DL-Systems-Project/build'\n","make[3]: Entering directory '/content/drive/MyDrive/10714/DL-Systems-Project/build'\n","make[3]: Leaving directory '/content/drive/MyDrive/10714/DL-Systems-Project/build'\n","[  0%] Built target ndarray_backend_cpu\n","make[3]: Entering directory '/content/drive/MyDrive/10714/DL-Systems-Project/build'\n","make[3]: Leaving directory '/content/drive/MyDrive/10714/DL-Systems-Project/build'\n","[ 50%] Built target ndarray_backend_cuda\n","make[2]: Leaving directory '/content/drive/MyDrive/10714/DL-Systems-Project/build'\n","make[1]: Leaving directory '/content/drive/MyDrive/10714/DL-Systems-Project/build'\n"]}],"source":["!make"]},{"cell_type":"markdown","id":"a9ae72a5","metadata":{"id":"a9ae72a5"},"source":["The make command reads the Makefile in the current directory. The Makefile contains rules that define how to build targets (like executables or libraries). For each target specified in the Makefile, make checks the timestamps of the target file and its dependencies (like .c, .cpp, or .h files). If any dependency has been modified recently, it must rebuild the target."]},{"cell_type":"code","execution_count":null,"id":"glK6Q7Ik-2cJ","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39,"status":"ok","timestamp":1763673163599,"user":{"displayName":"Andrew Zhang","userId":"07979726580656669632"},"user_tz":300},"id":"glK6Q7Ik-2cJ","outputId":"528f288a-98eb-49a7-a49d-0d35b0738bb1"},"outputs":[{"output_type":"stream","name":"stdout","text":["env: PYTHONPATH=./python\n","env: NEEDLE_BACKEND=nd\n"]}],"source":["%set_env PYTHONPATH ./python\n","%set_env NEEDLE_BACKEND nd"]},{"cell_type":"code","execution_count":null,"id":"e7aadcf9","metadata":{"id":"e7aadcf9"},"outputs":[],"source":["import sys\n","sys.path.append('./python')"]},{"cell_type":"markdown","id":"4yBc5GW6_BTV","metadata":{"id":"4yBc5GW6_BTV"},"source":["## Int8 quantization checks\n","\n","These cells validate the new int8 quantization path (post-training).\n","They run quickly on CPU/GPU in Colab and ensure the quantized linear layer\n","tracks the float32 reference within a small tolerance.\n"]},{"cell_type":"code","execution_count":61,"id":"T7N0lXC1_BTV","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1712,"status":"ok","timestamp":1763674046837,"user":{"displayName":"Andrew Zhang","userId":"07979726580656669632"},"user_tz":300},"id":"T7N0lXC1_BTV","outputId":"c254e05d-efcd-498a-9ce0-d88a929a0302"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m============================= test session starts ==============================\u001b[0m\n","platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\n","cachedir: .pytest_cache\n","rootdir: /content/drive/MyDrive/10714/DL-Systems-Project\n","plugins: typeguard-4.4.4, langsmith-0.4.42, anyio-4.11.0\n","collected 11 items                                                             \u001b[0m\n","\n","tests/hw3/test_quantization.py::test_quantize_round_trip \u001b[32mPASSED\u001b[0m\u001b[32m          [  9%]\u001b[0m\n","tests/hw3/test_quantization.py::test_per_channel_quantization_shapes \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n","tests/hw3/test_quantization.py::test_linear_quantized_matches_float \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n","tests/hw3/test_quantization.py::test_quantize_zero_tensor \u001b[32mPASSED\u001b[0m\u001b[32m         [ 36%]\u001b[0m\n","tests/hw3/test_quantization.py::test_quantization_per_axis_negative_axis \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n","tests/hw3/test_quantization.py::test_quantized_tensor_cache_reuse \u001b[32mPASSED\u001b[0m\u001b[32m [ 54%]\u001b[0m\n","tests/hw3/test_quantization.py::test_quantized_matmul_shape \u001b[32mPASSED\u001b[0m\u001b[32m       [ 63%]\u001b[0m\n","tests/hw3/test_quantization.py::test_linear_disable_quantization \u001b[32mPASSED\u001b[0m\u001b[32m  [ 72%]\u001b[0m\n","tests/hw3/test_quantization.py::test_quantization_bias_effect \u001b[32mPASSED\u001b[0m\u001b[32m     [ 81%]\u001b[0m\n","tests/hw3/test_quantization.py::test_quantization_memory_bytes_smaller \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n","tests/hw3/test_quantization.py::test_linear_multiple_forward_reuses_quantized \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n","\n","\u001b[32m============================== \u001b[32m\u001b[1m11 passed\u001b[0m\u001b[32m in 0.58s\u001b[0m\u001b[32m ==============================\u001b[0m\n"]}],"source":["!python3 -m pytest -v tests/hw3/test_quantization.py"]},{"cell_type":"markdown","id":"659c113b","metadata":{"id":"659c113b"},"source":["## Quantization performance benchmark\n","\n","Runs a float32 vs int8 (weights) Linear forward benchmark. Adjust flags to explore other shapes.\n"]},{"cell_type":"code","execution_count":null,"id":"f578219a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f578219a","executionInfo":{"status":"ok","timestamp":1763673172376,"user_tz":300,"elapsed":2316,"user":{"displayName":"Andrew Zhang","userId":"07979726580656669632"}},"outputId":"9b5a8d39-cb05-43ae-f0be-b76229a1ff78"},"outputs":[{"output_type":"stream","name":"stdout","text":["Backend: nd\n","Using needle backend\n","float32 avg: 29.119 ms\n","int8 avg:   28.800 ms\n","speedup:    1.01x\n","\n","Full results: {'float32_total_s': 0.8735800450001534, 'int8_total_s': 0.863994803000196, 'float32_avg_ms': 29.119334833338446, 'int8_avg_ms': 28.799826766673203, 'speedup_x': 1.0110940968240467}\n"]}],"source":["!python3 bench_quantization.py --batch 256 --in-features 1024 --out-features 4096 --steps 30"]},{"cell_type":"markdown","metadata":{"id":"UP8uwL_5FXEi"},"source":["## Large-mode quantization benchmark\n","\n","Heavier feedforward-style run (two Linear layers). Adjust flags for size/steps.\n"],"id":"UP8uwL_5FXEi"},{"cell_type":"code","source":["!python3 bench_quantization_large.py --batch 512 --in-features 4096 --hidden 4096 --out-features 4096 --steps 20"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1ISMZzsHICnD","executionInfo":{"status":"ok","timestamp":1763673553697,"user_tz":300,"elapsed":21175,"user":{"displayName":"Andrew Zhang","userId":"07979726580656669632"}},"outputId":"6e236abb-0db3-41fd-c40a-a1417ad27535"},"id":"1ISMZzsHICnD","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Backend: nd\n","Using needle backend\n","float32 avg: 491.531 ms\n","int8 avg:   416.374 ms\n","speedup:    1.18x\n","\n","Full results: {'float32_total_s': 9.830616287000112, 'int8_total_s': 8.327470392000123, 'float32_avg_ms': 491.5308143500056, 'int8_avg_ms': 416.37351960000615, 'speedup_x': 1.1805045018765845}\n"]}]},{"cell_type":"markdown","metadata":{"id":"yCd8nJFRF0_b"},"source":["## Extra-large quantization benchmark\n","\n","Four-layer stack at large hidden size to stress performance. Adjust flags as needed.\n"],"id":"yCd8nJFRF0_b"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ToEzq6zBF0_b","executionInfo":{"status":"ok","timestamp":1763673377884,"user_tz":300,"elapsed":177121,"user":{"displayName":"Andrew Zhang","userId":"07979726580656669632"}},"outputId":"f13af7c7-6857-469c-9e8d-ae7fa7b8ec70"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Backend: nd\n","Using needle backend\n","float32 avg: 7517.686 ms\n","int8 avg:   7438.163 ms\n","speedup:    1.01x\n","\n","Full results: {'float32_total_s': 75.17685518000008, 'int8_total_s': 74.38163200900021, 'float32_avg_ms': 7517.6855180000075, 'int8_avg_ms': 7438.163200900021, 'speedup_x': 1.010691122922708}\n"]}],"source":["!python3 bench_quantization_xl.py --batch 1024 --dim 8192 --steps 10"],"id":"ToEzq6zBF0_b"},{"cell_type":"markdown","metadata":{"id":"gYxYNPurJMph"},"source":["## Quantization memory comparison\n","\n","Reports parameter counts and memory for float32 vs int8-quantized weights.\n"],"id":"gYxYNPurJMph"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Itf66DPxJMph","executionInfo":{"status":"ok","timestamp":1763673837016,"user_tz":300,"elapsed":512,"user":{"displayName":"Andrew Zhang","userId":"07979726580656669632"}},"outputId":"eb4e7d67-df06-4526-f903-0b9bb43b6b5e"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["Using needle backend\n","Backend: nd\n","Layer: Linear(1024, 4096)\n","Parameters: weights=4,194,304, bias=4,096, total=4,198,400\n","Float32 memory: 16.794 MB\n","Int8 memory:   4.231 MB (weights int8 + scale/zp + float32 bias)\n","Memory reduction: 74.80%\n"]}],"source":["!python3 bench_quantization_memory.py --in-features 1024 --out-features 4096"],"id":"Itf66DPxJMph"}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.11"}},"nbformat":4,"nbformat_minor":5}